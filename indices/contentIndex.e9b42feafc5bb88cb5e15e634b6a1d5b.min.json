{"/":{"title":"ikorihn Digitalgarden","content":"\n[Quartz](https://github.com/jackyzha0/quartz) で作成した [digital garden](https://jzhao.xyz/posts/networked-thought) です。\n\n[Obsidian で作成しているノートから一部を公開しています。](blog/Quartzを使ってObsidianを無料で公開してみた.md)\n\n- [About me](aboutme)\n- [All Tags](/tags) … タグ一覧\n- [Notes](/note) … Obsidianで取っているメモ\n- [Blog](/blog) … ブログに相当するコンテンツ\n","lastmodified":"2023-07-29T08:18:43.011495969Z","tags":[]},"/aboutme":{"title":"about me","content":"\nikorihn(イコ)\n\n都内のWeb系企業でソフトウェアエンジニアをしています。\n主にバックエンド、SREを担当しています。\nフロントエンドも書けますがメイン領域ではありません。\n\n## Social\n\n- [GitHub](https://github.com/ikorihn)\n- [X](https://twitter.com/r57ty7)\n- [Bluesky](https://bsky.app/profile/ikorihn.bsky.social)\n\n## スキルマップ\n\n| スキル          | 内容                                                                                                              |\n| ----            | ----                                                                                                              |\n| Go              | 2020年以降では一番書いていて好きな言語。CLI、Webアプリケーション、k8s関連など幅広い領域で使用                     |\n| TypeScript      | JavaScriptよりも経験が長い。フロントエンドを書くときは間違いなくこちらを選ぶ。型パズルは苦手。                    |\n| Java            | キャリアの最初に学んだ言語で、使用歴は一番長い。Java 9以降の知識は薄い。JAX-RS(Jersey)、Spring Bootなどの経験あり |\n| Kotlin          | Androidを半年くらい開発していたときと、サーバーサイド開発でKotlin + Spring Bootでの開発経験あり。                 |\n| Shell Script    | ちょっとしたことはシェル芸でなんとかしがち。                                                                      |\n| Python          | 本格的に開発したことはなく、小さいスクリプトを読み書きした程度。                                                  |\n| Vue.js(Nuxt.js) | 業務で1からWebアプリケーション構築経験あり。2、3両方触ったことがある。                                            |\n| Docker          | 開発環境での利用、ECS等の運用、コンテナサイズを意識したDockerfileの作成など一通り可能。                           |\n| Kubernetes      | 業務の一部で利用中。Argo CDを用いたGitOpsでの運用経験あり。                                                       |\n| AWS Lambda      | API Gatewayと組み合わせたRESTful API、SQSと組み合わせたバッチなど                                                 |\n\n## 経歴\n\nTODO\n\n## 趣味\n\n### マラソン\n\n- 2018年ごろから初めて、大会にはちょくちょく出ている。月100kmくらい走る。\n- フルマラソン 3:36:50\n- ハーフマラソン 1:38:00\n- 10km 44:55\n\n","lastmodified":"2023-07-29T08:18:43.011495969Z","tags":[]},"/blog/%E3%82%BF%E3%83%BC%E3%83%9F%E3%83%8A%E3%83%AB%E5%85%A5%E9%96%80":{"title":"ターミナル入門","content":"\n## 私のターミナル歴\n\n* 2015 新卒入社 Windows時代 まだコマンドプロンプトって黒い画面で怖いと思っていた\n  * コマンドプロンプトでantのbuildをする程度\n* 2016\n  * batファイルを触ることが増えてきた\n* 2017 gvimで初めてvimに触れる。これまでサクラエディタとか秀丸を使っていたし周りでもvimという単語を聞いたことがなかったので、マイナーなエディタを使っている俺かっけーと思っていた。どうやら2大エディタらしいと知るのはもう少しあとになってから\n  * 簡単な作業をbatファイル書いてやらせたりし始めた\n* 2018\n  * mac\n  * \n\n## 基本操作\n\n* tabでバシバシ補完する\n* \n\n## キーバインドを覚えよう\n\n* ターミナルではemacs風のキーバインドが使える\n  * ホームポジションから動かずにカーソル操作ができるようになる\n  * macの場合はだいたいのアプリでも同じなので覚えておくと便利\n* `ctrl-n/p`: next/previous\n* `ctrl-f/b`: front/back\n* `ctrl-h/d`: backspace/delete\n* `ctrl-a/e`: ahead/end\n\n## .zshrc\n\n````shell\n# ヒストリの設定\nexport HISTFILE=~/.zsh_history\nexport HISTSIZE=1000000\nexport SAVEHIST=1000000\n````\n\n## PATHってなに\n\n## aliasを設定しよう\n\n## 見た目をかっこよくしよう\n\n## fuzzy finder(fzf, peco)を使おう\n\n* \n\n## tabでファイル名をfzfで選択するウィンドウを表示させる\n\n````shell\n# 補完機能を有効にする\nautoload -Uz compinit\ncompinit\n````\n\nzinit\n\n````shell\n#######\n# https://github.com/Aloxaf/fzf-tab\n#######\nzinit light \"Aloxaf/fzf-tab\"\nenable-fzf-tab\n# zstyle ':fzf-tab:*' fzf-command ftb-tmux-popup\nzstyle ':fzf-tab:complete:cd:*' fzf-preview 'exa -1 --color=always $realpath'\nzstyle ':fzf-tab:*' fzf-bindings 'ctrl-j:accept' 'ctrl-a:toggle-all' 'ctrl-space:toggle+down'\n# disable sort when completing `git checkout`\nzstyle ':completion:*:git-checkout:*' sort false\n# set descriptions format to enable group support\nzstyle ':completion:*:descriptions' format '[%d]'\n# set list-colors to enable filename colorizing\nzstyle ':completion:*' list-colors ${(s.:.)LS_COLORS}\n# preview directory's content with exa when completing cd\nzstyle ':fzf-tab:complete:cd:*' fzf-preview 'exa -1 --color=always $realpath'\n# switch group using `,` and `.`\nzstyle ':fzf-tab:*' switch-group ',' '.'\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["terminal"]},"/blog/%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AB%E5%BF%9C%E3%81%98%E3%81%A6%E5%87%A6%E7%90%86%E3%82%92%E6%8C%AF%E3%82%8A%E5%88%86%E3%81%91%E3%82%8B%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88":{"title":"ネットワークに応じて処理を振り分けるスクリプト","content":"\n\\#shell\n\n## ネットワークに応じて処理を振り分けるスクリプト\n\n````shell:switch_location.sh\n#!/bin/zsh\n\n# ネットワーク環境を切り替える\nswitchNetwork() {\n  local location=$1\n  currentLocation=$(networksetup -getcurrentlocation)\n  if test $currentLocation = $location; then\n    return\n  fi\n\n  scselect $(scselect | grep $location | awk '{ print $1 }')\n  osascript -e 'display notification \"'\"Switch network location to ${1}\"'\" with title \"'\"${0##*/}\"'\" '\n}\n\n# Git リポジトリ設定を切り替える\nswitchGitConfig() {\n  local location=$1\n\n  case \"$location\" in\n    Home)\n      git config --global --replace-all http.$GIT_REPO_URL_HTTPS.proxy $PROXY_URL\n      git config --global --replace-all url.$GIT_REPO_URL_HTTPS.insteadOf $GIT_REPO_URL_SSH\n      git config --global --replace-all url.$GIT_REPO_URL_HTTPS.insteadOf ssh://$GIT_REPO_URL_SSH --add\n      ;;\n    Office)\n      git config --global --unset-all http.$GIT_REPO_URL_HTTPS.proxy\n      git config --global --unset-all url.$GIT_REPO_URL_HTTPS.insteadOf\n      ;;\n  esac\n}\n\nmain() {\n  set -x\n  ADAPTER=en0\n\n  # Wi-FiがONになっているか\n  airportpower=$(networksetup -getairportpower $ADAPTER | awk -F': ' '{ print $2 }')\n  if test ${airportpower} = 'Off'; then\n    echo 'Wifi is Off.'\n    exit\n  fi\n\n  # SSIDを取得\n  ssid=$(networksetup -getairportnetwork $ADAPTER | awk -F': ' '{ print $2 }')\n\n  location=Automatic\n  case \"$ssid\" in\n    $SSID_HOME)\n      location=Home\n      ;;\n    $SSID_OFFICE)\n      location=Office\n      ;;\n  esac\n\n  switchNetwork $location\n  switchGitConfig $location\n  set +x\n}\n\nmain\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["shell"]},"/blog/%E3%83%9E%E3%82%A4%E3%82%AF%E3%81%AE%E3%83%9F%E3%83%A5%E3%83%BC%E3%83%88%E3%82%A2%E3%83%B3%E3%83%9F%E3%83%A5%E3%83%BC%E3%83%88%E3%82%92%E5%88%87%E3%82%8A%E6%9B%BF%E3%81%88%E3%82%8B":{"title":"マイクのミュート・アンミュートを切り替える","content":"\n\\#Mac\n\n````oascript\nset micVolume to toggleMic()\ndisplay notification micVolume with title \"Mic\"\nreturn micVolume\n\non toggleMic()\n\tset inputVolume to input volume of (get volume settings)\n\tif inputVolume ≤ 5 then\n\t\tset inputVolume to 100\n\t\tset micVal to \"🔈 unmuted\"\n\telse\n\t\tset inputVolume to 0\n\t\tset micVal to \"🔇 muted\"\n\tend if\n\tset volume input volume inputVolume\n\treturn micVal\nend toggleMic\n````\n\nAutomator \u003e Quick Action から作成して、システム設定 \u003e キーボード \u003e ショートカット \u003e サービス でキーボードショートカットを設定すれば一発で切り替えられるようになる\n\n[macのマイクをボリュームで擬似的にON/OFF - Qiita](https://qiita.com/okoshi/items/35b17c0865c83e20ea0c)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Mac"]},"/blog/%E6%84%9B%E7%94%A8%E3%81%97%E3%81%A6%E3%81%84%E3%82%8Bvim%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3":{"title":"愛用しているvimプラグイン","content":"\n### gina\n\nhttps://github.com/lambdalisue/gina.vim\n[gina.vimとGitHubの連携を向上させる | Input中心のブログ](https://kitagry.github.io/blog/programmings/2020/09/gina-browse/)\n\nfugitiveのほうが `:Git log` などが見やすい気がする\n`:Gina! log` で同じようなことはできる模様。\n`:Gina!!` と double bang にすると生のgitコマンドが実行される。\nfzf-previewと連携しやすいのでGinaにしてみた。\n\n### fzf-preview\n\n[TypeScriptでVimのファジーファインダーを実装して開発体験が最高になっている話](https://zenn.dev/yano/articles/vim_with_fzf_preview_is_best_experience)\n[Vimにたくさんあるファジーファインダー系プラグインを比較してみる](https://zenn.dev/yutakatay/articles/vim-fuzzy-finder)\n[無人島に持っていく(Neo)vimプラグイン10選 (TS開発環境編)](https://zenn.dev/yano/articles/vim_plugin_top_10)\n\nCOC版を入れた。\nfzf.vimで良かった気もする\n\n### vim-ripgrep\n\n[vim-ripgrepを作った話](https://zenn.dev/kyoh86/articles/67c1408d6ef950)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["vim"]},"/blog/%E8%87%AA%E5%AE%85%E3%81%A8%E8%81%B7%E5%A0%B4%E3%81%A7proxy%E8%A8%AD%E5%AE%9A%E3%82%92%E5%88%87%E3%82%8A%E6%9B%BF%E3%81%88%E3%81%9F%E3%81%84":{"title":"自宅と職場でproxy設定を切り替えたい","content":"\n出社時と在宅時で、プロキシの接続情報を変更する必要がある。\n手で切り替えるのを忘れて社内システムにつながらない…ということがよく発生するので、自動化することにした。\n\n## 切り替えたい対象\n\n* プロキシ設定\n* git proxyの設定を環境に応じて変更\n\n## 実現方法\n\n* proxy.pac をローカルのhttpサーバーで配布\n* Macのネットワーク設定 \u003e Location で自宅と職場でproxy.pacのURLをそれぞれ設定\n* git proxyをset,unsetするコマンドを実行\n* wifiのSSIDが家か職場を判定して分岐する\n* トリガーはスリープからの復帰時\n\n### プロキシ設定について\n\nプロキシの設定はproxy.pacを使って行う。\n職場では社内で配布されるproxy.pacのURLを入力すればいいが、\n自宅では、自前のproxy.pacを作って設定したい。\n\nしかし、Mojaveからローカルのproxy.pacを `file://` で設定することができなくなった\n\n[macOS 10.14 Mojave 以降で pac ファイルを使って proxy の設定を行いたいけど出来なかった話 - Qiita](https://qiita.com/orange634nty/items/9ef5cadd039592e8344a)\n\n \u003e \n \u003e #### Deprecations\n \u003e \n \u003e The `ftp://` and `file://` URL schemes for Proxy Automatic Configuration (PAC) are deprecated. HTTP and HTTPS are the only supported URL schemes for PAC. This affects all PAC configurations including, but not limited to, configurations set via Settings, System Preferences, profiles, and [`URLSession`](https://developer.apple.com/documentation/foundation/urlsession) APIs such as [`connectionProxyDictionary`](https://developer.apple.com/documentation/foundation/urlsessionconfiguration/1411499-connectionproxydictionary), and [`CFNetworkExecuteProxyAutoConfigurationURL(_:_:_:_:)`](https://developer.apple.com/documentation/cfnetwork/1426392-cfnetworkexecuteproxyautoconfigu). (37811761)\n\nそのため、ローカルにhttpサーバーを立てて `http://localhost` を設定する方法をとる\n\n## proxy.pacをローカルのhttpサーバーで配布\n\n### httpdをインストール、自動起動\n\n````shell\n$ brew install httpd\n\n# M1 Macの場合 /opt/homebrew/etc に設定ファイルがある\n$ vim /opt/homebrew/etc/httpd/httpd.conf\n=\u003e Listenポートを任意に設定する(私は80に設定)\n\n$ brew services start httpd\n==\u003e Successfully started `httpd` (label: homebrew.mxcl.httpd)\n\n# `brew services start` するとlaunchdに登録され、自動起動するようになる (`brew services stop` すると停止、自動起動も解除される)\n$ launchctl list | rg brew\n63000   0       homebrew.mxcl.httpd\n$ cat ~/Library/LaunchAgents/homebrew.mxcl.httpd.plist\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e\n\u003c!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"\u003e\n\u003cplist version=\"1.0\"\u003e\n\u003cdict\u003e\n        \u003ckey\u003eEnvironmentVariables\u003c/key\u003e\n        \u003cdict\u003e\n                \u003ckey\u003ePATH\u003c/key\u003e\n                \u003cstring\u003e/opt/homebrew/bin:/opt/homebrew/sbin:/usr/bin:/bin:/usr/sbin:/sbin\u003c/string\u003e\n        \u003c/dict\u003e\n        \u003ckey\u003eLabel\u003c/key\u003e\n        \u003cstring\u003ehomebrew.mxcl.httpd\u003c/string\u003e\n        \u003ckey\u003eProgramArguments\u003c/key\u003e\n        \u003carray\u003e\n                \u003cstring\u003e/opt/homebrew/opt/httpd/bin/httpd\u003c/string\u003e\n                \u003cstring\u003e-D\u003c/string\u003e\n                \u003cstring\u003eFOREGROUND\u003c/string\u003e\n        \u003c/array\u003e\n        \u003ckey\u003eRunAtLoad\u003c/key\u003e\n        \u003ctrue/\u003e\n\u003c/dict\u003e\n\u003c/plist\u003e\n````\n\n### proxy.pacを配置\n\n`/opt/homebrew/var/www/` にproxy.pacを置く\n\n\u003chttp://localhost/proxy.pac\u003e で取得できるようになる\n\n## Macのネットワーク設定 \u003e Location で自宅と職場でproxy.pacのURLをそれぞれ設定\n\n![Pasted-image-20211008123230](blog/Pasted-image-20211008123230.png)\n\nそれぞれのLocationで、proxy.pacのURLを入力する\n\n自宅: `http://localhost/proxy.pac`\n職場: `社内のproxy.pacのURL`\n![Pasted-image-20211008124722](blog/Pasted-image-20211008124722.png)\n\n## ネットワーク切り替え時に実行するスクリプトを作成\n\n[ネットワークに応じて処理を振り分けるスクリプト](blog/ネットワークに応じて処理を振り分けるスクリプト.md)\n\n## sleep復帰時にスクリプトを実行する\n\n### sleepwatcherをインストール\n\n[Macスリープ時・復帰時に処理を動かす](blog/Macスリープ時・復帰時に処理を動かす.md)\n\nスリープ前や復帰時にスクリプトを実行できるようになる\n\n````shell\nbrew install sleepwatcher\n````\n\n### plistファイルを作成する\n\n`~/Library/LaunchAgents` 以下にファイルを作成\n\n````xml:~/Library/LaunchAgents/sleepwatcher.plist\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e\n\u003c!DOCTYPE plist PUBLIC \"-//Apple Computer//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"\u003e\n\u003cplist version=\"1.0\"\u003e\n\u003cdict\u003e\n    \u003ckey\u003eLabel\u003c/key\u003e\n    \u003cstring\u003esleepwatcher\u003c/string\u003e\n    \u003ckey\u003eProgramArguments\u003c/key\u003e\n    \u003carray\u003e\n        \u003cstring\u003e/usr/local/sbin/sleepwatcher\u003c/string\u003e\n        \u003cstring\u003e-V\u003c/string\u003e\n        \u003cstring\u003e-w /path/to/switch_location.sh\u003c/string\u003e\n    \u003c/array\u003e\n    \u003ckey\u003eRunAtLoad\u003c/key\u003e\n    \u003ctrue/\u003e\n    \u003ckey\u003eKeepAlive\u003c/key\u003e\n    \u003ctrue/\u003e\n\u003c/dict\u003e\n\u003c/plist\u003e\n````\n\n* `-w` スリープ復帰（Wake Up）時に実行するコマンド\n* `-s` スリープ（Sleep）時に実行するコマンド\n\n### launchdに登録\n\n````shell\n$ launchctl load ~/Library/LaunchAgents/sleepwatcher.plist\n````\n\n## 参考\n\n[Mac のスリープ／復帰時にスクリプトを実行する - Qiita](https://qiita.com/fiftystorm36/items/5fe936a92445cbf4ad9a)\n[Macの起動/スリープ復帰時に自動でVPNに接続する / LOG](https://log.brdr.jp/post/887)\n[Mac でネットワーク環境を使う方法 - Apple サポート (日本)](https://support.apple.com/ja-jp/HT202480)\n[macOS 10.14 Mojave 以降で pac ファイルを使って proxy の設定を行いたいけど出来なかった話 - Qiita](https://qiita.com/orange634nty/items/9ef5cadd039592e8344a)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Mac","Network","shell"]},"/blog/Mac%E3%82%B9%E3%83%AA%E3%83%BC%E3%83%97%E6%99%82%E5%BE%A9%E5%B8%B0%E6%99%82%E3%81%AB%E5%87%A6%E7%90%86%E3%82%92%E5%8B%95%E3%81%8B%E3%81%99":{"title":"Macスリープ時・復帰時に処理を動かす","content":"\n[macOSのスリープ時にEC2を落とそう - サーバーワークスエンジニアブログ](https://blog.serverworks.co.jp/tech/2019/08/17/sleepwatcher/)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Mac"]},"/blog/Neovim%E3%81%A8VSCode-Neovim%E3%81%A7%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8B%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3%E3%82%84%E8%A8%AD%E5%AE%9A%E3%82%92%E5%88%86%E3%81%91%E3%82%8B":{"title":"NeovimとVSCode-Neovimで使用するプラグインや設定を分ける","content":"\nhttps://zenn.dev/r57ty7/articles/accd3014e22366 に投稿した内容と同じです。\n\nこれは [Vim駅伝](https://vim-jp.org/ekiden/) 5/15 の記事です。\n\n## はじめに\n\n私は普段 [Neovim](note/Neovim.md) をメインにしていますが、\n他の人と環境を合わせたいときなど [VS Code](note/Visual%20Studio%20Code.md) もときどき使っています。\n\nVimの機能を利用するため [VSCodeVim](https://github.com/VSCodeVim/Vim) を入れている方も多いと思いますが、Undoの挙動が不安定だったりもっさりしていたりで不満があったため、 [VSCode Neovim](https://marketplace.visualstudio.com/items?itemName=asvetliakov.vscode-neovim) を使っています。\n\nこれはバックグラウンドでNeovimが動作するため、共通の設定ファイル(`init.lua`)が利用できて、Neovimのプラグインも動くところが嬉しいのですが、\nVS Codeにはデフォルトで備わっている機能や、うまく動作しないプラグイン、一部のoptionや衝突するkey mappingは除外したいです。\n\nこの記事では、そうしたNeovimとVSCode Neovimを併用していて、プラグインや設定を使い分けたい！という方向けに、\n私が設定してうまくいっている方法について紹介しようと思います。\n\nプラグインマネージャとして [packer.nvim](https://github.com/wbthomason/packer.nvim) と[lazy.nvim](https://github.com/folke/lazy.nvim) のそれぞれについて紹介します。\n\nちなみに私の設定はこちらのようになっています。\nhttps://github.com/ikorihn/dotfiles/blob/master/.config/nvim\n\n## packerの場合\n\n`init.lua` とpluginはこちらのように設定しています。\n\n`~/.config/nvim/init.lua`\n\n````lua\nrequire(\"options\")\nrequire(\"keymaps\")\nrequire(\"plugins\")\nrequire(\"packer_compiled\")\n````\n\n`~/.config/nvim/lua/plugins.lua`\n\n````lua\nlocal fn = vim.fn\n\n-- Automatically install packer\nlocal install_path = fn.stdpath \"data\" .. \"/site/pack/packer/start/packer.nvim\"\nif fn.empty(fn.glob(install_path)) \u003e 0 then\n  PACKER_BOOTSTRAP = fn.system {\n    \"git\",\n    \"clone\",\n    \"--depth\",\n    \"1\",\n    \"https://github.com/wbthomason/packer.nvim\",\n    install_path,\n  }\n  print \"Installing packer close and reopen Neovim...\"\nend\n\nvim.cmd [[packadd packer.nvim]]\n\nlocal packer = require(\"packer\")\nlocal util = require(\"packer.util\")\npacker.init {\n  compile_path = util.join_paths(vim.fn.stdpath('config'), 'lua', 'packer_compiled.lua'),\n}\n\nreturn packer.startup(function(use)\n  use { \"wbthomason/packer.nvim\" }\n\n  -- plugins...\n\nend)\n\n````\n\n### cond でロードする条件を設定する\n\n`cond` でプラグインをロードする条件を設定することができます。\nVS Codeと併用するときによく紹介されるやり方はこちらだと思います。\n\nたとえば次のように書くと、VS Codeのときにはdisableにするといったことができます。\n\n````lua\nlocal nocode = function()\n  -- VSCode Neovimのときには1が設定される\n  return vim.g.vscode == nil\nend\n\nreturn packer.startup(function(use)\n  use { \"wbthomason/packer.nvim\" }\n\n  use { \"phaazon/hop.nvim\", config = function() require(\"hop\").setup() end }\n\n  -- vscodeでないときだけロードする\n  use { \"kylechui/nvim-surround\", config = function() require(\"nvim-surround\").setup() end, cond = { nocode } }\n\nend)\n\n````\n\nこれには以下の問題がありました。\n\n* vscodeのときにロードしたくないプラグイン一つずつに書く必要があり面倒な上、数が多いとどれがロードされる/されないのかが視認しづらかった\n* condを書くと`~/.local/share/nvim/site/pack/packer/opt` にプラグインがダウンロードされるが、colorschemeなど一部のプラグインをoptionalにすると、ロードのタイミングがずれるためか正しく動作しなかった\n  * 例 [Question: what to use to make plugin inactive if condition · Issue #288 · wbthomason/packer.nvim](https://github.com/wbthomason/packer.nvim/issues/288)\n\nそこで、次のようにして解決しました。\n\n### `init.lua` で読み込む設定ファイルを分ける\n\nVS Codeのときだけ利用したいプラグインや設定をかいたファイル(`vscode.lua`)を別で作り、 `init.lua` で読み込むファイルを分けるようにしました。\n\n`~/.config/nvim/init.lua`\n\n````lua\n-- 共通の設定\nrequire(\"options\")\nrequire(\"keymaps\")\n\nif vim.g.vscode == 1 then\n  -- VS Code用の設定\n  require(\"vscode\")\n  return\nend\n\nrequire(\"plugins\")\nrequire(\"packer_compiled\")\n````\n\nまた、VS Codeのときもpackerを使いたかったのですが、競合してしまってうまくいかなかったので [vim-plug](https://github.com/junegunn/vim-plug) を使うことにしました。\nエレガントな方法ではないと思いますが、結局これが一番安定しました。\n\n`~/.config/nvim/lua/vscode.lua`\n\n````lua\n-- ~/.local/share/nvim/site/pack/*/start/* を読み込ませない\nvim.opt.packpath:remove(vim.fn.stdpath('data')..\"/site\")\n\n-- Plug\n-- Automatically install plug\nlocal plugpath = vim.fn.stdpath(\"data\") .. \"/plugged/vim-plug\"\nif not vim.loop.fs_stat(plugpath) then\n  vim.fn.system({\n    \"curl\",\n    \"-fLo\",\n    plugpath .. \"/autoload/plug.vim\",\n    \"--create-dirs\",\n    \"https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\",\n  })\nend\nvim.opt.rtp:prepend(plugpath)\n\n-- packerでダウンロード済みのプラグインを利用する\nvim.cmd [[ call plug#begin(stdpath('data') . '/site/pack/packer/start') ]]\n\nvim.cmd [[ Plug 'phaazon/hop.nvim' ]]\nvim.cmd [[ Plug 'junegunn/vim-easy-align' ]]\nvim.cmd [[ Plug 'jeetsukumaran/vim-indentwise' ]]\nvim.cmd [[ Plug 'haya14busa/vim-asterisk' ]]\nvim.cmd [[ Plug 'kevinhwang91/nvim-hlslens' ]]\nvim.cmd [[ Plug 'kylechui/nvim-surround' ]]\n\nvim.cmd [[ call plug#end() ]]\n\nrequire(\"pluginconfig/hop\")\nrequire(\"pluginconfig/nvim-surround\")\nrequire(\"pluginconfig/nvim-hlslens\")\n````\n\n### packpathについて\n\n2行目の `vim.opt.packpath:remove(vim.fn.stdpath('data')..\"/site\")` がハックっぽいですが、これを書いていないと `vscode.lua` に書いていないプラグインもロードされてしまいます。\n\nruntimepathを見てみると、追加した覚えのない `~/.local/share/nvim/site/pack/*/start/*` があります。\n\n````\n:se runtimepath\nruntimepath=~/.config/nvim,/opt/homebrew/etc/xdg/nvim,/etc/xdg/nvim,~/.local/share/nvim/site,~/.local/share/nvim/site/pack/*/start/*,...\n````\n\nこれは [packages](https://neovim.io/doc/user/repeat.html#packages) の仕組みによって [packpath](https://neovim.io/doc/user/options.html#'packpath') で指定されたディレクトリ配下に配置されたプラグインを起動時に読み込むためです。\n私の環境では以下のように設定されていました。\n\n````\n:se packpath\npackpath=~/.config/nvim,/opt/homebrew/etc/xdg/nvim,/etc/xdg/nvim,~/.local/share/nvim/site,...\n````\n\npackerはデフォルトで `vim.fn.stdpath('data')..'/site/pack/packer/start'` にプラグインをダウンロードするため、こちらに置かれたプラグインがVS Codeでも読み込まれていたというわけです。\nそのため、`vim.fn.stdpath('data')..\"/site\"` をpackpathから除外するようにしました。\n\n## lazyの場合\n\n最近lazy.nvimに移行したので、その場合の設定も載せておきます。こちらのほうが簡単でした。\n\n`~/.config/lua/plugins.lua`\n\n````lua\n-- Automatically install lazy\nlocal lazypath = vim.fn.stdpath(\"data\") .. \"/lazy/lazy.nvim\"\nif not vim.loop.fs_stat(lazypath) then\n  vim.fn.system({\n    \"git\",\n    \"clone\",\n    \"--filter=blob:none\",\n    \"https://github.com/folke/lazy.nvim.git\",\n    \"--branch=stable\", -- latest stable release\n    lazypath,\n  })\nend\nvim.opt.rtp:prepend(lazypath)\n\nlocal plugins = {\n  -- plugins...\n  { \"nvim-lua/plenary.nvim\"  },\n}\n\nrequire('lazy').setup(plugins, {\n})\n````\n\nlazyではpackpath配下にダウンロードされないため、`vscode.lua` は次のようになります。\n\n````diff\n--- a/.config/nvim/lua/vscode.lua\n+++ b/.config/nvim/lua/vscode.lua\n@@ -1,6 +1,3 @@\n--- ~/.local/share/nvim/site/pack/*/start/* を読み込ませない\n-vim.opt.packpath:remove(vim.fn.stdpath('data')..\"/site\")\n-\n -- Plug\n -- Automatically install plug\n local plugpath = vim.fn.stdpath(\"data\") .. \"/plugged/vim-plug\"\n@@ -15,7 +12,7 @@ if not vim.loop.fs_stat(plugpath) then\n end\n vim.opt.rtp:prepend(plugpath)\n\n-vim.cmd [[ call plug#begin(stdpath('data') .. '/site/pack/packer/start') ]]\n+vim.cmd [[ call plug#begin(stdpath('data') .. '/lazy') ]]\n\n vim.cmd [[ Plug 'phaazon/hop.nvim' ]]\n````\n\nあるいはもっと簡単に、`vscode.lua` に分けずに `plugins.lua` 内で完結することもできます。\n\n````lua\nlocal plugins;\nif vim.g.vscode == 1 then\n  plugins = {\n    { \"phaazon/hop.nvim\", config = function() require(\"pluginconfig/hop\") end },\n    { \"junegunn/vim-easy-align\" },\n    { \"kylechui/nvim-surround\", config = function() require(\"pluginconfig/nvim-surround\") end },\n  }\nelse\n  -- Neovimで利用するプラグイン\n  plugins = {\n    { \"nvim-lua/plenary.nvim\"  },\n    { \"windwp/nvim-autopairs\", config = function() require(\"pluginconfig/autopairs\") end },\n  }\nend\n\nrequire('lazy').setup(plugins, {\n})\n````\n\n## おわりに\n\n数ヶ月ほど使っていますが、今のところ特に問題は発生せず、必要なプラグインだけを活かして満足のいく操作ができています。\n\nVS Codeをメインで使っているが、Vimプラグインの機能を使いたい！というようなユースケースにも刺されば幸いです。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Neovim","vscode"]},"/blog/Quartz%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6Obsidian%E3%82%92%E7%84%A1%E6%96%99%E3%81%A7%E5%85%AC%E9%96%8B%E3%81%97%E3%81%A6%E3%81%BF%E3%81%9F":{"title":"Quartzを使ってObsidianを無料で公開してみた","content":"\n私は普段 [Obsidian](note/Obsidianとは.md) でメモを取るようにしています。\nある程度まとまった内容ができたら都度 [Zenn](https://zenn.dev/) やブログに書くようにしていたのですが、記事にするぞ！と思うときちんと書かないといけないと思い腰が重くてなかなかできていませんでした。\n\nそこで、取ったメモを雑なままでいいから公開しようと思いました。\n\nまず選択肢としてあがるのは [Obsidian Publish](https://obsidian.md/publish) ですが、月$8(2023/06現在)が自分には高く、機能もそこまで必要としていないので、多少手間がかかっても無料で公開できる方法を調べました。\n\n## できたもの\n\n{{\u003c card-link \"https://ikorihn.github.io/digitalgarden\" \u003e}}\n\n* [brandonkboswell/obsidian-export](https://github.com/brandonkboswell/obsidian-export/tree/title_frontmatter) を使って、公開していいファイルだけをexportするようにしました\n* [Quartz](https://quartz.jzhao.xyz/) のテンプレートを使って、マークダウンをHTMLで表示するだけでなくバックリンクやグラフも生成されるようにしました\n\n### 参考にしたサイト\n\n* [Publishing your Obsidian Vault Online with Quartz](https://brandonkboswell.com/blog/Publishing-your-Obsidian-Vault-Online-with-Quartz/)\n* [Quartz: Create and publish your Obsidian Vault for free! : r/ObsidianMD](https://www.reddit.com/r/ObsidianMD/comments/onflb9/quartz_create_and_publish_your_obsidian_vault_for/)\n\n### 同様のことをしているサイト\n\n* https://jzhao.xyz\n* https://nick.groenen.me\n* https://elaraks.github.io/dampcapital/\n* https://blu3mo.github.io/blu3mo-quartz\n\n## Quartz のセットアップ\n\n{{\u003c card-link \"https://quartz.jzhao.xyz/\" \u003e}}\n\n* Obsidian VaultをWebサイトにするツール\n* バックリンクやマップに対応している\n* [Hugo](note/Hugo.md) を使っている\n\nセットアップは基本的にドキュメントに書いてあるとおりですが、以下のように進めました。\n\n### リポジトリの作成\n\nObsidian Vaultを直接公開するのではなく、公開用リポジトリを別途作ってそちらにコピーすることにします。そうすることで、公開範囲を絞ったり、Vault側にはなるべく影響を与えないようにしています。\n\nhttps://github.com/jackyzha0/quartz をForkして作成しました。\nこのとき、 `Copy the `hugo` branch only` のオプションはチェックを外します。\n\nリポジトリ名は `digitalgarden` としました。これを[GitHub Pages](https://docs.github.com/ja/pages/getting-started-with-github-pages/about-github-pages) で公開すると`https://ikorihn.github.io/digitalgarden/` でアクセスできるようになります。\n\n#### GitHub Pages で公開するための設定\n\n* Branchをmain、ディレクトリを/rootに設定\n* `.github/workflows/deploy.yaml` の `name: Deploy` を修正します\n  * `hugo` ブランチにpushすると、GitHub Actionsでビルドしたファイルが `main` ブランチの `/public` ディレクトリに置かれるようになっています\n  * `publish_branch` をmain、 `cname` を `ikorihn.github.io` にしました\n* GitHubリポジトリのSettings \u003e Pagesで公開対象を設定します\n\n![Pasted-image-20230504103549](note/Pasted-image-20230504103549.png)\n\n## Obsidian Vaultから公開したいファイルのみをコピーする\n\n公開したいファイルのみを [Hugo](note/Hugo.md) で扱えるファイルに変換して、公開用リポジトリにコピーします。\nそれにはこちらを使いました。\n\n{{\u003c card-link \"https://github.com/zoni/obsidian-export\" \u003e}}\n\n* Rust製\n* Obsidian Vault内のファイルを標準的なMarkdownに変換して別のディレクトリにコピーする(`[[]]` を標準のリンクに変えるなど)\n* `.export-ignore` を置くことで、export対象から除外することができる\n\ngit cloneして `cargo install --path .` して `~/.cargo/bin` にPATHを通したら、\n公開用リポジトリのルートで以下を実行して、 `./content` 配下にObsidianの中身をコピーします。\n\n````shell\n$ obsidian-export --frontmatter=always ${OBSIDIAN_VAULT_DIR} ./content\n````\n\n`content` は [HugoでWebサイトのコンテンツを配置するディレクトリ](https://gohugo.io/getting-started/directory-structure/) です。\n\nコピーができたら `hugo` ブランチにcommitしてpushしましょう。\nこれでGitHub Actionsが動いて、少し経つとGitHub Pagesのドメインで見れるようになっているはずです。\n\n## 公開フローを整える\n\nObsidian Vaultからファイルをコピーする → commitしてpushする\nのをそれぞれmakeで実行できるようにしておきます。\n自分の場合は、Obsidianを `~/memo` においているのでこちらのようになります。\n\n````Makefile\nexport: ## Convert Obsidian markdown to common markdown using obsidian-export\n\tls content | grep -v -E \"(_index.md|private|templates)\" | xargs -i rm -rf content/{}\n\tobsidian-export --frontmatter=always ~/memo content\n\npublish: ## Publish content\n\tgit add content\n\tgit commit -m \"update contents: $(shell date +%Y-%m-%dT%H:%M:%S)\"\n\tgit push\n````\n\n## その他やったこと\n\n基本的に公開するために必要なことはここまでとなります。\n\n自分の場合、過去作成してきたマークダウンファイルの書き方がよろしくなかったりHugoの都合に合わなかったりしたため、まとめて修正を行いました。\n\n### ファイル修正\n\n* [Hugo](note/Hugo.md) のためにfrontmatterを整備しました\n  * `title` (ページタイトル) `date` (作成日) `lastmod` (更新日) を各ファイルに入れました\n  * `title` は元々入れていたので、抜けているファイルに手動で追加\n    * https://github.com/brandonkboswell/obsidian-export/tree/title_frontmatter を使って `--add-titles` オプションによってexport時に付与するのもアリ\n  * `date` をyyyy-MM-ddTHH:mm:ssZの形式に変換\n    * 元々 `yyyy-MM-dd HH:mm` っていう変な形式にしちゃってた\n    * `fd -e md | xargs -i sed -i -r 's/^date: (.*) (.*)$/date: \"\\1T\\2:00+09:00\"/' {}`\n  * `date updaed` を `lastmod` に変換\n    * `fd -e md | xargs -i sed -i -r 's/^date updated: (.*) (.*)$/lastmod: \"\\1T\\2:00+09:00\"/' {}`\n* 画像ファイル名のスペースを除去\n  * [Hugo](note/Hugo.md) で埋め込むときにスペースがある場合、`![Pasted image 22222222222.png](\u003c/images/Pasted image 22222222222.png\u003e)` のように `\u003c\u003e` で囲む必要がある\n  * `rename 's/ /-/g' *`\n  * https://github.com/reorx/obsidian-paste-image-rename を使って、今後画像を貼り付けるときにはスペース除去するようにする\n  * [obsidian-export](https://github.com/zoni/obsidian-export) がスペースを％エンコードしてくれたので結果的には不要だったが、取り扱いはしやすいのでこのままにする\n\n### サブディレクトリにあるファイルへのリンクが貼られない\n\nVaultのルート直下にあるファイルについてはちゃんとリンクが機能するのですが、ディレクトリの下のファイルに関しては遷移できませんでした。\n\n#### 最初に試したこと\n\n* [Hugo relative link](note/Hugo%20relative%20link.md) で説明してくれている内容をrender-links.html, render-images.htmlに書いたらOKだった\n* ただgraphやbacklinkの方は、ノードをクリックするとルートからの相対に遷移してしまい、サブディレクトリには遷移しなかった。\n  * [Better support for relative/absolute paths · Issue #99 · jackyzha0/quartz](https://github.com/jackyzha0/quartz/issues/99)\n\n#### 直した\n\n絶対パスでないとだめと公式に書いてありました…\n\n{{\u003c card-link \"https://quartz.jzhao.xyz/notes/obsidian/\" \u003e}}\n\n1. Set the **New link format** to **Absolute Path in vault**. If you have a completely flat vault (no folders), this step isn’t necessary.\n1. Turn **on** the **Automatically update internal links** setting.\n\nWikilink(`[[note/xxxx]]`)でも問題なさそうなのですが、自分の環境ではリンクされなかったため、Markdownの絶対パスでのリンク(`[xxxx](note/xxxx.md)`)に変えたところ、graphが正しく表示されるようになりました。\n\nこれのために、全ファイルのWikilinkをMarkdown Linkに変更しました。。\n\n[Obsidian WikilinkをMarkdown linkに変更した](note/Obsidian%20WikilinkをMarkdown%20linkに変更した.md)\n\n### 外部リンクをカードで表示する\n\nZennとかで見るやつ\n\n[Hugo 外部リンクをカードで表示する](note/Hugo%20外部リンクをカードで表示する.md)\n\n## 感想\n\n無事Obsidianを公開できるようになりました。\n更新の手間が若干ありますが、簡単なコマンドで更新できるのでさほど苦ではないでしょう。\n\n今までブログを書いたりするのは億劫でなかなかできていなかったのですが、メモのついでに公開しているというスタンスであれば気軽に続けられそうです。\n\nObsidian Publishと比べてどうかというと、\nまず自分でいろいろ調べて作るのが面白かったので個人的にはよかったです。\nQuartzのベースはHugoですので、テーマやテンプレートのカスタマイズも自分で行えます。\n\nただし万人にはおすすめしません…\nまず構築がそこそこ手間でしたし、こういうことやっている人自体が少ないので情報があまりなく、トラブルシューティングが結構たいへんです。\n自力で解決するのが難しいという場合は、素直にObsidian Publishを使うのが便利ですし機能も十分に備わっていると思います。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/04/23","obsidian","blog"]},"/blog/Raycast%E3%81%A7%E3%83%9E%E3%82%A4%E3%82%AF%E3%81%AE%E3%83%9F%E3%83%A5%E3%83%BC%E3%83%88%E3%82%92%E5%88%87%E3%82%8A%E6%9B%BF%E3%81%88%E3%82%8B":{"title":"Raycastでマイクのミュートを切り替える","content":"\n[Raycast](note/Raycast.md) を使ってマイクのミュートを切り替えます\n\nRaycastの設定 \u003e Extensions \u003e +ボタン \u003e Create Script Command \u003e templateをApple Scriptにして任意の場所に作成\n\n![Pasted-image-20220311122221](blog/Pasted-image-20220311122221.png)\n\n````applescript:mute.applescript\n#!/usr/bin/osascript\n\n# Required parameters:\n# @raycast.schemaVersion 1\n# @raycast.title mic mute\n# @raycast.mode compact\n\n# Optional parameters:\n# @raycast.icon 🤖\n\nset micVolume to muteMic()\ndisplay notification micVolume with title \"Mic\"\nreturn micVolume\n\non muteMic()\n\tset inputVolume to 0\n\tset micVal to \"🔇 muted\"\n\tset volume input volume inputVolume\n\treturn micVal\nend muteMic\n````\n\n同様にして、 `unmute.applescript` を作成\n\n````applescript:mute.applescript\n#!/usr/bin/osascript\n\n# Required parameters:\n# @raycast.schemaVersion 1\n# @raycast.title mic unmute\n# @raycast.mode compact\n\n# Optional parameters:\n# @raycast.icon 🤖\n\nset micVolume to unmuteMic()\ndisplay notification micVolume with title \"Mic\"\nreturn micVolume\n\non unmuteMic()\n\tset inputVolume to 80\n\tset micVal to \"🔈 unmuted\"\n\tset volume input volume inputVolume\n\treturn micVal\nend unmuteMic\n````\n\nRaycastの設定 \u003e Extensions から、コマンドにショートカットを設定することができます。\n私はアンミュートを `Cmd + Opt + m` , ミュートを `Cmd + Shift + Opt + m` に設定しています。\n\nトグルのほうがいい場合は [マイクのミュート・アンミュートを切り替える](blog/マイクのミュート・アンミュートを切り替える.md) のスクリプトを作成する。\n自分は現在の状態がミュートアンミュートのどちらであっても同じ動作をさせたいためそれぞれのコマンドを登録しています。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Mac","Raycast"]},"/blog/build-typescript-on-netlify":{"title":"TypeScriptのGatsbyをNetlifyでビルドしたときのエラーに対応した","content":"\n## 事象\n\nTypeScript化したGatsbyをNetlifyでビルドした際に以下のエラーが発生しました。\n\n````shell\n$ gatsby build\nerror Error in \"/opt/build/repo/gatsby-node.js\": Unexpected token '.'\n\n\n  Error: /opt/build/repo/src/gatsby-node/index.ts:28\n      const posts = result.data?.allMarkdownRemark.nodes;\n                                ^\n  SyntaxError: Unexpected token '.'\n````\n\n## 対応\n\nNetlifyのビルドログに `Now using node v12.18.0 (npm v6.14.4)` とあるようにデフォルトではv12.18.0が使われるようです。\nOptional ChainingはNode.js v14から使用できる機能のため、v14以上が使用されるように設定します。\n\n[Manage build dependencies | Netlify Docs](https://docs.netlify.com/configure-builds/manage-dependencies/)\n\n環境変数 `NODE_VERSION` で指定できるため以下のように設定しました。\n\n![2021-10-31-17-31-50](blog/2021-10-31-17-31-50.png)\n\nこれでビルドが通るようになりました。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Gatsbyjs","frontend"]},"/blog/chromedp%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6Go%E3%81%A7Chrome%E3%82%92%E8%87%AA%E5%8B%95%E6%93%8D%E4%BD%9C%E3%81%99%E3%82%8B":{"title":"chromedpを使ってGoでChromeを自動操作する","content":"\n普段の業務でWebページを開いてグラフをキャプチャしたり、勤怠入力をしたりといったルーチンの作業を自動化できないかなと思いました。\n\nこうしたブラウザの操作を自動化する分野では [Selenium](https://www.selenium.dev/ja/documentation/) や [Puppetter](https://pptr.dev) が有名ですが、環境構築が面倒だったのでGopherな自分としてはGoでスクリプトを書きたいと思います。\n\n[chromedp](https://github.com/chromedp/chromedp) はChromeをGoで操作することのできるライブラリです。\n[Chrome DevTools Protocol](https://chromedevtools.github.io/devtools-protocol/) をサポートしていて、スクレイピングでDOMを操作する以外にもこのプロトコルでスクリーンショットを取ったりすることもできます。\n\n{{\u003c card-link \"https://github.com/chromedp/chromedp\" \u003e}}\n\nHeadless Chromeを新規で立ち上げることもできるし、起動済みのChromeを操作することもできます。\n\nPure Goなので当然シングルバイナリでどこでも動かせますので、サーバーにおいてcronで実行するのも用意です。\n\n## 使い方\n\nhttps://github.com/chromedp/examples に利用例がいくつかあるので、まずはそちらを見てイメージを掴むのがおすすめです。\n\n### headlessモードで起動する\n\nデフォルトではこちらで起動します。\n\n````go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n\n\t\"github.com/chromedp/chromedp\"\n)\n\nfunc main() {\n\tdir, err := os.MkdirTemp(\"\", \"chromedp-example\")\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer os.RemoveAll(dir)\n\n\t// オプションを指定する\n\topts := append(chromedp.DefaultExecAllocatorOptions[:],\n\t\tchromedp.DisableGPU,\n\t\tchromedp.UserDataDir(dir),\n\t)\n\n\t// Headless Chromeを起動する\n\tctx, cancel := chromedp.NewExecAllocator(context.Background(), opts...)\n\tdefer cancel()\n\n\t// Chromeを起動する\n\tif err := chromedp.Run(ctx,\n\t\tchromedp.Navigate(\"https://example.com/\"),\n\t\tchromedp.Sleep(time.Second),\n\t); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tpath := filepath.Join(dir, \"DevToolsActivePort\")\n\tbs, err := os.ReadFile(path)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlines := bytes.Split(bs, []byte(\"\\n\"))\n\tfmt.Printf(\"DevToolsActivePort has %d lines\\n\", len(lines))\n\n}\n````\n\n起動したり操作をする際は、context.Contextを渡すようにします。\n\n### 起動済みのChromeを操作する\n\nSSOや2要素認証が必要なサイトを操作したい場合に、認証を突破するコードを書くのが面倒なので、予めログインまでしてある状態のChromeを操作することにした。\n\nまず、ChromeをDevTools protocolを有効にした状態で起動します。\n\n````shell\n$ open -a 'Google Chrome' --args --remote-debugging-port=9222\n````\n\nそれを指定してchromedpを実行するコードを書きます。\n\n````go\nfunc main() {\n\tdevtoolsWsURL := flag.String(\"-ws-url\", \"ws://localhost:9222\", \"DevTools WebSocket URL\")\n\tflag.Parse()\n\tif *devtoolsWsURL == \"\" {\n\t\tlog.Fatal(\"must specify -ws-url\")\n\t}\n\n\tctx := context.Background()\n\tctx, cancel := context.WithTimeout(ctx, 120*time.Second)\n\tdefer cancel()\n\n\t// NewRemoteAllocatorにWebSocketのURLを指定して起動する\n\tallocatorContext, cancel := chromedp.NewRemoteAllocator(ctx, *devtoolsWsURL)\n\tdefer cancel()\n\n\tctx, cancel = chromedp.NewContext(allocatorContext)\n\tdefer cancel()\n\n\tvar img []byte\n\tquality := 100\n\tif err := chromedp.Run(ctx,\n\t\tchromedp.Navigate(\"https://secure.example.com\"),\n\t\tchromedp.WaitVisible(\"#footer\"),\n\t\tchromedp.FullScreenshot(\u0026img, quality),\n\t); err != nil {\n\t\tlog.Fatalf(\"Failed: %v\", err)\n\t}\n\n}\n````\n\n### Docker上で実行する\n\nhttps://github.com/chromedp/chromedp#frequently-asked-questions\n\nこちらで紹介されている `chromedp/headless-shell` を使います。\n\nhttps://github.com/chromedp/docker-headless-shell\n\nchromedpを使ったアプリケーションをビルドして、 `chromedp/headless-shell` 上で実行するには以下のようにします。\n\n````dockerfile\nFROM golang:1.20 as build-env\nWORKDIR /work\nCOPY go.mod go.sum .\nRUN go mod download\n\nCOPY . .\nRUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags '-s -w' -trimpath -o /work/app\n\nFROM chromedp/headless-shell:latest\n\nCOPY --from=build-env /work/app /usr/local/bin/app\nENTRYPOINT [\"app\"]\n````\n\n````shell\n$ docker build -t myimage .\n$ docker run -d -p 9222:9222 --rm --name headless-shell --shm-size 2G myimage\n````\n\n## サンプル\n\n### スクリーンショットを撮る\n\n未指定の場合pngで保存されます。\n\n````go\nvar img []byte\nerr := chromedp.Run(taskCtx,\n\tchromedp.Navigate(url),\n\tchromedp.CaptureScreenshot(\u0026img),\n)\n\nf, err := os.Create(\"tmp.png\")\nif err != nil {\n\tlog.Fatal(err)\n}\ndefer f.Close()\nf.Write(img)\n````\n\n### formに入力する\n\n要素を選択するselectorは、 [XPath](note/XPath.md) やCSSセレクタが使用可能です。\nCSSセレクタの場合は引数に `chromedp.ByQuery` を指定してください。\n\n````go\nerr := chromedp.Run(taskCtx,\n\tchromedp.Navigate(url),\n\n\tchromedp.SetValue(`//*[@id=\"signInFormUsername\"]`, `user`),\n\tchromedp.SetValue(`//*[@id=\"signInFormPassword\"]`, `password`),\n\tchromedp.Submit(`//*[@id=\"signInForm\"]`),\n)\n\n````\n\n### 複雑なActionを定義する\n\n`chromedp.Run` の引数のactionsには、`chromdp.Tasks` を渡すこともできます。\nなので以下のようにTasksを生成する関数を切り出すといったことが可能です。\n\n````go\nfunc tasks(url string) chromedp.Tasks {\n\ttasks := chromedp.Tasks{\n\t\tchromedp.Navigate(url),\n\t\tchromedp.Sleep(3 * time.Second),\n\t}\n\treturn tasks\n}\n\n\nerr := chromedp.Run(taskCtx, tasks())\n````\n\nまた、`chromedp.ActionFunc` に任意の処理を記述することが可能です。\nその際は、各処理の末尾に `.Do(ctx)` を渡します。\n\n````go\nchromedp.ActionFunc(func(ctx context.Context) error {\n\tchromedp.Sleep(5 * time.Second).Do(ctx)\n\treturn nil\n}),\n````\n\n### ある要素のロードを待つ\n\n````go\nchromedp.ActionFunc(func(ctx context.Context) error {\n\tvar err error\n\tqueryLoading := `//div[@class=\"loading\"]`\n\t// 表示されるのを待つ\n\terr = chromedp.WaitVisible(queryLoading).Do(ctx)\n\tif err != nil {\n\t\tif errors.Is(err, context.DeadlineExceeded) {\n\t\t\tfmt.Println(\"timeout\")\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\t// 表示されなくなるのを待つ\n\tchromedp.WaitNotPresent(queryLoading).Do(ctx)\n\n\t// 要素が4つ表示されるまで待つ\n\tqueryChartContainer := `//div[@class=\"graph\"]`\n\tvar nodes []*cdp.Node\n\tfor len(nodes) \u003c 4 {\n\t\terr = chromedp.Nodes(queryChartContainer, \u0026nodes).Do(ctx)\n\t\tif err != nil {\n\t\t\tif errors.Is(err, context.DeadlineExceeded) {\n\t\t\t\tfmt.Println(\"timeout\")\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\ttime.Sleep(1 * time.Second)\n\t}\n\n})\n````\n\n### ある要素のtextを取得する\n\n````go\nvar users []string\nchromedp.ActionFunc(func(ctx context.Context) error {\n\tfor i := 0; i \u003c 10; i++ {\n\t\tvar t string\n\t\tchromedp.Text(`//li[@class=\"users\"]`, \u0026t).Do(ctx)\n\t\tusers = append(users, t)\n\t}\n\treturn nil\n})\n````\n\n### JavaScriptを実行する\n\nJavaScriptを実行するには、`chromdp.Evaluate` を使います。\n\n````go\n// #users直下の要素数を出力する\nchromedp.ActionFunc(func(ctx context.Context) error {\n\tvar res int\n\tchromedp.Evaluate(`document.getElementById('users').childElementCount`, \u0026res).Do(ctx)\n\tfmt.Printf(\"users count: %d\\n\", res)\n\treturn nil\n}),\n````\n\n## Tips\n\n### Docker上で実行したときにスクリーンショットが取れない場合\n\n`Unable to capture screenshot (-32000)` というエラーでスクリーンショットの取得に失敗する場合があります。\n\nhttps://github.com/chromedp/chromedp/issues/1215\n\nその場合は、[--shm-size](https://docs.docker.jp/engine/reference/run.html)で `/dev/shm` (共有メモリ)のサイズを増やしてください。\n\n````shell\ndocker run --shm-size 2g chromedp\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Go"]},"/blog/fish-history-to-zsh-history":{"title":"fishのhistoryをzshに移行する","content":"\n一年くらいfishを使っていたが、文法があまりにbash/zshと異なり辛いため、zshに戻すことにした。\nコマンド履歴に頼る人間なので、直近1年の履歴がなくなってしまうのは困る。\nそこでfishのhistoryファイルをzshのhistoryファイルに移行することにした。\n\n````toc\n# This code block gets replaced with the TOC\n````\n\n## 移行ツール\n\n移行するためのツールを作った。\n\n\u003chttps://github.com/ikorihn/zhistconv\u003e\n\n使い方\n\n````shell\n# fish_hisoryをzsh_historyに変換して追記(事前にバックアップを取ることを推奨)\n$ zhistconv fish fish_hist \u003e\u003e ~/.zsh_history\n$ history -E 1\n=\u003e 結合されたhistoryが表示される\n````\n\n以下詳細\n\n## fishのhistoryファイルをzshのhistoryファイルの形式に変換する\n\n### fishのhistoryファイル\n\n`~/.local/share/fish/fish_history`\n\n````yaml\n- cmd: echo hello\n  when: 1621067042\n- cmd: git pull\n  when: 1621067359\n````\n\nyaml形式で保存されているので、yamlをロードして変換してあげればいい\n\n### zshのhistoryファイル\n\n`~/.zsh_history`\n\n````txt\n: 1621066935:0;echo hello\n: 1621066935:0;cd\n````\n\n`: \u003cunix timestamp\u003e:0:\u003ccommand\u003e` 形式(真ん中の0が何を意味しているかは調べてない)\n\n## zshのマルチバイト文字の扱いについて\n\n一つ問題があった。移行ツールをわざわざ作ったのはほとんどこの仕様のため\n\n`~/.zsh_history` をUTF-8で開くと、日本語が文字化けしていた。\nhistoryコマンドの結果は文字化けしていない。\n\nどうやらマルチバイト文字が特殊な扱いをされているらしい。\n\n[.zsh_historyにおける非ASCII文字の扱いについて - 生涯未熟](https://syossan.hateblo.jp/entry/2017/10/09/181928)\n[unmetafy unicode when zsh by rogerdehe · Pull Request #416 · dvorka/hstr](https://github.com/dvorka/hstr/pull/416)\n\nmetafy/unmetafyという処理をしているらしく、\nメタなバイトがあったら直前に `0x83` を挿入して、`0x20`とのxorを取り6bit目を反転させているようだ。\n\n\u003chttps://github.com/zsh-users/zsh/blob/master/Src/utils.c#L4921-L4933\u003e\n\n````c\nmod_export char *\nunmetafy(char *s, int *len)\n{\n    char *p, *t;\n\n    for (p = s; *p \u0026\u0026 *p != Meta; p++);\n    for (t = p; (*t = *p++);)\n\tif (*t++ == Meta \u0026\u0026 *p)\n\t    t[-1] = *p++ ^ 32;\n    if (len)\n\t*len = t - s;\n    return s;\n}\n````\n\n単純にfish_historyを変換してzsh_historyに貼り付けるだけでは、日本語部分が文字化けしてしまう。\n\n### 文字化けしたzsh_historyファイルを読めるようにする\n\n`ぁあぃいぅうぜそぞただちぢっつづ` という文字列を使って調べていく。\nこれらは頭2バイトが `e381`、末尾1バイトがそれぞれいかのようになる。\n\n* `ぁ`: `81`\n* `あ`: `82`\n* `ぃ`: `83`\n* `い`: `84`\n* `ぅ`: `85`\n* `う`: `86`\n* `ぜ`: `9c`\n* `そ`: `9d`\n* `ぞ`: `9e`\n* `た`: `9f`\n* `だ`: `a0`\n* `ち`: `a1`\n* `ぢ`: `a2`\n* `っ`: `a3`\n* `つ`: `a4`\n* `づ`: `a5`\n\nzsh_historyで見ると以下のようなバイト列になっている(わかりやすいよう適宜スペースを入れている)\n\n````txt\nE38181 E38182 E38183A3 E38183A4 E38183A5 E38183A6 E38183BC E38183BD E38183BE E38183BF E3818380 E3818381 E3818382 E381A3 E381A4 E381A5\n````\n\nzsh_historyの文字コードはlatin1なのでほぼUTF-8と同じ。\n文字コード表をもとに当てはまる文字に戻すと、 `0x83-0xA2` のとき、直前に `0x83` を入れてから6bit目を反転させていることがわかる。\n\n````txt\nE38181 E38182 E38183A3 E38183A4 E38183A5 E38183A6 E38183BC E38183BD E38183BE E38183BF E3818380 E3818381 E3818382 E381A3 E381A4 E381A5\n````\n\n`0x83` を消して、直後の6bit目を反転させると以下のようになる\n\n````txt\nE38181 E38182 E38183 E38184 E38185 E38186 E3819C E3819D E3819E E3819F E381A0 E381A1 E381A2 E381A3 E381A4 E381A5\n````\n\nこれがもとの文字列のバイト列に一致する。\n\nマルチバイト文字をzsh_historyの形式に変換するには上と逆のことをすればいい。\nつまり、`0x83-0xA2` のとき、直前に `0x83` を入れてから6bit目を反転させる。\n\n### Goでzsh_historyをパースするプログラムを書いてみる\n\n````go\npackage zhistconv\n\nconst (\n\t// zsh_historyの仕様で、各バイトが0x83~0xA2のとき、その前に0x83を入れて6bit目を反転させる\n\tx83 = 131\n\txA2 = 162\n\tx20 = 32\n)\n\nfunc ParseZshHistory(latin1Byte []byte) []byte {\n\tisMarking := false\n\tvar byteBuffer []byte\n\n\tfor _, codePoint := range latin1Byte {\n\t\tif codePoint == x83 {\n\t\t\tisMarking = true\n\t\t\tcontinue\n\t\t}\n\n\t\tif isMarking {\n\t\t\t// 6bit目を反転させるために0x20をXORする\n\t\t\tinvertCodePoint := codePoint ^ x20\n\t\t\tbyteBuffer = append(byteBuffer, invertCodePoint)\n\t\t\tisMarking = false\n\t\t} else {\n\t\t\tbyteBuffer = append(byteBuffer, codePoint)\n\t\t}\n\t}\n\n\treturn byteBuffer\n}\n\nfunc ConvertToZshHistory(latin1Byte []byte) []byte {\n\tvar byteBuffer []byte\n\n\tfor _, codePoint := range latin1Byte {\n\t\t// 131は0metacharの10進数表現\n\t\tif x83 \u003c= codePoint \u0026\u0026 codePoint \u003c= xA2 {\n\t\t\t// 6bit目を反転させるために0x20をXORする\n\t\t\tinvertCodePoint := codePoint ^ x20\n\t\t\tbyteBuffer = append(byteBuffer, x83)\n\t\t\tbyteBuffer = append(byteBuffer, invertCodePoint)\n\t\t} else {\n\t\t\tbyteBuffer = append(byteBuffer, codePoint)\n\t\t}\n\t}\n\n\treturn byteBuffer\n}\n````\n\n## 作ったツールについて\n\n[urfave/cli: A simple, fast, and fun package for building command line apps in Go](https://github.com/urfave/cli)\n\nこちらを使ってcliツールを作った。\n\n* `zhistconv fish`: fish_historyをzsh_historyの形式に変換して標準出力する\n* `zhistconv parse`: zsh_historyをUTF-8に変換する\n* `zhistconv reverse`: UTF-8で書かれたzsh_historyのマルチバイト文字をzsh_historyの仕様に変換する\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["fish","zsh"]},"/blog/jenkins-ui-customize":{"title":"Jenkinsの見た目をカスタマイズ","content":"\n\n````toc\n# This code block gets replaced with the TOC\n````\n\n## モチベーション\n\nJenkins のデフォルトの見た目は古臭いので、好きなテーマに変更したい。\nまた、環境ごとの違いをひと目でわかりやすくすることで事故を防ぐ。\n\n## jenkins-material-theme をダウンロード\n\n\u003chttp://afonsof.com/jenkins-material-theme/\u003e\nから色とロゴを指定してテーマをダウンロードする。\n\n## プラグインを設定\n\n\\[Jenkinsの管理\\] -\u003e \\[プラグインの管理\\] -\u003e \\[利用可能\\] -\u003e [Simple Theme Plugin](https://plugins.jenkins.io/simple-theme-plugin/) をインストール\n\nダウンロードしたスタイルシートのファイル（jenkins-material-theme.css）を Jenkins フォルダの userContent フォルダへ配置する\n\n* Jenkinsを置いてあるサーバにSSHログイン\n* `\u003cドキュメントルート(/var/lib/jenkins/など)\u003e/userContent/jenkins-material-theme.css`\n\nJenkinsの管理のシステムの設定でダウンロードしたテーマを指定する。\n\nURL of theme CSSにこちらを入力して保存: `/userContent/jenkins-material-theme.css`\n\n## material-theme を適用したときに、pipelineエディタでカーソル位置と実際に編集される位置がずれる\n\n`:not(div.ace_editor)` に `font-family: Roboto, sans-serif!important` が設定されているため等幅フォントになっていない。\n\n[Main Script -- Replay -- the cursor in the editor is out of phase · Issue #184 · afonsof/jenkins-material-theme](https://github.com/afonsof/jenkins-material-theme/issues/184)\n\n等幅フォントを設定してあげればよい。\n自分でカスタマイズできるのが利点\n\n````css:jenkins-material-theme.css\n#main-panel\u003epre *,\n.ace_editor .ace_scroller .ace_content * {\n  font-family: Roboto Mono, monospace !important;\n}\n\ndiv.ace_editor.ace-tomorrow,\ndiv.ace_editor.ace-tomorrow * {\n  font: 12px/normal Roboto Mono, monospace !important;\n}\n````\n\n## 参考\n\n[Jenkinsのテーマ(UI)を変えてみた | レコチョクのエンジニアブログ](https://techblog.recochoku.jp/2021)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Jenkins"]},"/blog/karabiner-elements-recommend":{"title":"Karabiner-Elementsで個人的におすすめのキーバインド","content":"\n\n````toc\n# This code block gets replaced with the TOC\n````\n\n## Karabiner-Elements とは\n\nMacのキーボードをカスタマイズするためのツールです。\nこれを使えばUSキーボードでもJIS配列のようにかな/英数キーを割り当てるなどが可能になります。\n\nここでは個人的に使っているキーバインドを紹介します。\nインストールや設定方法については色々なサイトで紹介されているので省略します。\n\nルールについては \u003chttps://ke-complex-modifications.pqrs.org/\u003e から探すことができます。\nKarabiner-ElementsのPreferences -\u003e Complex modifications -\u003e Import more rules from the Internet から飛べます。\n\n![2021-08-15-16-28-21](blog/2021-08-15-16-28-21.png)\n\n## Change spacebar to left_shift if pressed with other keys (Post spacebar when pressed alone)\n\n[Change spacebar](https://ke-complex-modifications.pqrs.org/#spacebar)\n\nスペースキーにShiftを割り当て、スペースキー単独で押したときにはスペースが入力されます。\nいわゆる `SandS (Space and Shift)` というものです。\n\n特にShift+数字の入力が遠く感じてミスが多かったのが、かなり改善されました。\n\n注意としては、スペース押しっぱなしにしても1つしか入力されないので、連続入力したい場合連打が必要になります。\n\n## Post escape if left_control is pressed alone\n\n[Change control key](https://ke-complex-modifications.pqrs.org/#control)\n\nCtrlキーを単独で押したときにECSが入力されます。\n\n自身がvimmerであり、vim以外のエディタにもvimキーバインドを設定しているので、ECSをよく押すのですが、\n指を動かす距離が減って楽になりました。\n\nvimでECSを `jj` や `C-[` などにバインドしている人や、vimmer以外には恩恵を感じにくいかもしれません。\n\n## Quit application by holding command-q\n\n[Prevent unintended command-q (rev 2)](https://ke-complex-modifications.pqrs.org/#command_q)\n\nCmd+q を長押しでアプリケーションを終了するようになります。\n\nタブを閉じようとしてしょっちゅう `Cmd+w` と `Cmd+q` を打ち間違えるため導入しました。\n\n## コマンドキーを単体で押したときに、英数・かなキーを送信する。（左コマンドキーは英数、右コマンドキーはかな）\n\n[For Japanese （日本語環境向けの設定）](https://ke-complex-modifications.pqrs.org/#japanese)\n\n記号の配置の好みや、リターンキーの押しやすさからUS配列を使用しています。\nUS配列のキーボードでは、英数やかなのキーがなく、日本語切り替えは `Cmd+Space` や `Ctrl+Space` で行います。\n\n切り替えの場合、現在の入力状態を把握している必要があるので、できればJIS配列と同じように単一のキーを押すと必ず英数/ローマ字入力に変わってほしいところです。\n\nこの設定を行うと、左Commandが英数キー、右Commandがかなキーに割り当てられます。\nCommandのmodifierとしての機能は維持され、コピーやペーストなどのショートカットも利用できます。\n\n## Vonng/Capslock\n\n\u003chttps://github.com/Vonng/Capslock\u003e\n\nCapsLockキーを、いろいろなことができるmodifierに変化させる設定です。\n*Make CapsLock Great Again!* と銘打つだけあって、アプリ起動のホットキーを作ったり、矢印キーでマウスカーソルを移動させたりといったことができるようになります。\n\n`karabiner://karabiner/assets/complex_modifications/import?url=https://vonng.com/capslock.json` からインストールできます。\n\n### Application\n\nアプリケーション起動のホットキーを登録できます。\n例: `CapsLock+e` でSafariが起動する(起動済みだったらウィンドウが切り替わる)\n\nCmd+Tabでアプリを切り替えたり、Mission ControlやDockで探したりといった手間がなくなります。\n\n私はkarabinerの設定ファイル(`~/.config/karabiner/karabiner.json`) を書き換えて、よく使うアプリを左手のキーに登録しています。\n\n* `CapsLock+s`: Slack\n* `CapsLock+g`: Chrome\n* `CapsLock+v`: Visual Studio Code\n* `CapsLock+f`: iTerm2\n* `CapsLock+Cmd+f`: Finder\n\n### Functional\n\n`CapsLock+数字列` をFunctionキーにします。\nFunctionキーのないキーボードを使っている場合に便利です。\n\n### Navigation\n\nVimスタイルの移動が可能になります。どんな場所でも `hjkl` で移動できるようになります。\nほかにも `u` が `PgUp`、`i` が `Home` になったり、\n`CapsLock+Opt+hjkl` がマウスカーソル移動になったりします。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Mac","keyboard"]},"/blog/look-back-2021":{"title":"2021年振り返り","content":"\n## 2021年にやったこと\n\n### Kotlin + Spring Boot\n\n1月〜3月ごろはKotlin + Spring Boot を触っていました。\nKotlinで初めてサーバーサイドを1から作れていい経験になりました。\nSpring BootはWebサーバーつくるにあたってほしい機能が一通り揃っていて助かりました。\nSpringもほぼ初めてで悩むことはありましたが、Kotlinだから詰まったということはなかったように思います。\n\nMockKできっちりテスト書きながら進められたのもよかったです。\nSpringがとにかくDI周りのことを何も考えなくてもやってくれるので、\nとくにハマることもなくinjectionしてmockしたらテストがかけてストレスが少なかったです。\n\nこの時期は技術的には楽しいことをやれていましたが、負荷も高くて疲れてもいました。\n\n### Go + Lambda\n\nAWS Lambdaでバッチを書いたりAPIサーバー作ったりと、何かと触る機会が多かったです。\n何回か書いていくうちにテストのしやすさやメンテしやすさを考慮した設計ができるようになったと思います。\n\nリリースされたばかりの[aws-sdk-go-v2](https://github.com/aws/aws-sdk-go-v2)も使いながら、知見を貯めることができました。\n\n### 競プロ\n\n計算量とかアルゴリズムをちゃんと意識できるようにならなきゃいかんと思って、\n2月〜3月ごろは競プロにハマってC++を勉強したり\n[問題解決力を鍛える！アルゴリズムとデータ構造](https://www.amazon.co.jp/dp/B08PV83L3N) を読んだりしていました。\n\nAtCoder茶色になったくらいで離れてしまいましたが、また再開したいと思っています。\n\n業務上はそんなに活かせてないですが、データ量が大きいときにループしているコードを見て「これ1秒以上かかるけど大丈夫？」のような勘が働くようになったのは良かったと思います。\n\n### Obsidian\n\n[Obsidian](https://obsidian.md/) でメモを取るようになりました。\nmarkdownで全て管理できるのが気に入ってます。\nあまり使いこなせてる気はしませんが、markdownなので特定のツールにロックインされることがないのが嬉しいです。\n\nGoogle KeepメモやEvernoteにためていたノート類もエクスポートして、markdown管理にしています。\n一発でmarkdownにすることができなかったので、一度Notionにインポートしてからmarkdownでエクスポートしました。\n\n作業記録やタスクもObsidian上で管理するようになりました。\nいままでもTogglやTodoistは使っていましたが、ぜんぜん続かず思い出したときにだけ書くからあまり意味がなかったのですが、\nObsidianは書くことのストレスが少なく、フォーマットも自由にいじれるので自分にあっているようです。\n\n[Day Planner](https://pouhon.net/obsidian-planner/6033/)の機能を使っています。\n\n細かく記録をつけようと思うならTogglなどをきっちり使ったほうがいいんだと思いますが、\n大雑把に何時間くらい何をしていたか程度の把握にしか使っていないので十分でした。\n\nあとからこの日何をしていたか振り返ることができるので今後も続けていきたいです。\n\n### 今年見て良かったもの\n\n#### 映画\n\n* 閃光のハサウェイ\n* シン・エヴァンゲリオン\n* 映画大好きポンポさん\n* 子供はわかってあげない\n* フリーガイ\n* コングvsゴジラ\n* ディパーテッド\n* ノクターナル・アニマルズ\n* リチャードジュエル\n* アップグレード\n* 新感染 ファイナル・エクスプレス\n* ブラック・レイン\n\n#### アニメ\n\n* 呪術廻戦\n* 無職転生\n* ODD TAXI\n* ブルーピリオド\n\n#### ドラマ\n\n* クイーンズ・ギャンビット\n* ファルコン\u0026ウィンターソルジャー\n* 浅草キッド\n\n#### 漫画\n\n* 推しの子\n* 左利きのエレン\n* チェンソーマン\n\n### マラソン\n\n月間100kmを目標に概ね達成しました。\n\n![2022-01-01-00-16-08](blog/2022-01-01-00-16-08.png) \n\n合計: 1260km\n平均ペース: 5分1秒\n\nピクミンブルームの花植えが捗りました。\n\n## 2022年\n\n* インプット・アウトプットを増やす(小並感)\n  * 最近本を読んだり技術習得したりできていないので、もっとアウトプットを意識したインプットをしていく\n  * レガシーコードを頑張って読み解いて、長年積み重なった山を崩さないようにしながらどうにか動かすみたいな仕事が多かったので、来年はもっと大幅にきれいにしたい\n* 引っ越し\n  * 今後も毎日出社にはならないであろうと信じて、多少遠くても住みやすくて広いところに住みたい\n* マラソン\n  * 2年ほど大会に出れていないので、ハーフ 1:40、フル サブ3.5 を目標にして大会にでたい\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["振り返り"]},"/blog/open-google-meet-at-time":{"title":"Googleカレンダーの予定時刻になったらMeetを自動で開くようにする","content":"\n\n````toc\n# This code block gets replaced with the TOC\n````\n\n## モチベーション\n\nオンラインミーティングをGoogle Meetでやっているのですが、気づいたら開始時間を過ぎていることがあります(本当によくない)\n通知が来たときに開始までに少し時間があるので別な作業をしてしまうパターンが多いです。\n\n時間になったらMeetの画面を自動で開いて、強制的に作業を中断すればそんなことがなくなる気がします。\n\n## 方針\n\nGoogleカレンダーから予定を取得して、時間になったらそのMeetのURLをブラウザで開くようにしたいと思います。\n\nやり方はいろいろあると思います。\nChrome拡張でカレンダーにアクセスする、Calendar APIでスケジュール一覧を取得する、…\n\n今回は諸般の事情でCalendar APIを直接使えなかったため、以下の方針にしました。\nOSはMacです。\n\n* Google Apps Script(GAS) でカレンダーから一日のスケジュールをJSONで取得する\n* このGASをWebアプリとして公開して、HTTP GETで取得できるようにする\n* スケジュールの時刻に `at` コマンドをセットして、`open \u003cMeetのURL\u003e` を実行する\n\nターミナルで `at` をセットするのは今のところ手で朝に実行しています。\n\nもっといいやり方がある気はしますが、とりあえずこれでやりたいことは出来ました。\n以下、各手順となります。\n\n## スケジュール取得GASを作成する\n\n\u003chttps://script.google.com/home\u003e から新しいスクリプトを作成する\n\n### GASのCalendar APIを有効化\n\n標準の [CalendarApp](https://developers.google.com/apps-script/reference/calendar) では取れる情報が少なくMeetのURLがとれないため、[Calendar API](https://developers.google.com/apps-script/advanced/calendar) を使用する\n\nGASのエディタ \u003e サービス \u003e Calendar を有効化\n\n### dayjs を使えるようにする\n\n標準の [Utilities.formatDate](https://developers.google.com/apps-script/reference/utilities/utilities) でも日付フォーマットはできるが、もう少し日付をうまく扱うためにライブラリを入れる。\nMoment.jsは開発が止まっているので、dayjsを使う。\n\nGASのエディタ \u003e ライブラリを追加 \u003e dayjs のスクリプトID `1ShsRhHc8tgPy5wGOzUvgEhOedJUQD53m-gd8lG2MOgs-dXC_aCZn9lFB` を入力\n\n#### 余談\n\nライブラリのスクリプトIDを検索する方法がわからない…\n仕方なく個人ブログやQiitaから情報を得たけど、公式情報じゃないので気持ち悪い\n\nスクリプトIDのエディタのURLを開くと、たしかにdayjsのコードのよう\n\u003chttps://script.google.com/home/projects/1ShsRhHc8tgPy5wGOzUvgEhOedJUQD53m-gd8lG2MOgs-dXC_aCZn9lFB/edit\u003e\n\n### カレンダーから予定を取得してJSONで返却する実装\n\nWebアプリとして使えるようにするため、`doGet` 関数をエントリーポイントに実装する\n\n````javascript:code.gs\nfunction doGet(e) {\n    return ContentService.createTextOutput(JSON.stringify(getSchedule()));\n}\n\nfunction getSchedule() {\n  const now = new Date();\n  const begin = dayjs.dayjs(now);\n  const end = dayjs.dayjs(now).endOf('day');\n    \n  // デフォルトカレンダーのID\n  const calendarId = CalendarApp.getDefaultCalendar().getId();\n\n  // Calendar APIで本日の予定を取得する\n  const events = Calendar.Events.list(calendarId, {\n    timeMin: begin.toISOString(),\n    timeMax: end.toISOString(),\n    singleEvents: true,\n    orderBy: 'startTime',\n  })\n\n  const todayEvent = events.items.map(event =\u003e {\n    let start;\n    if (event.start.date) {\n      // All-day event.\n      start = new Date(event.start.date);\n    } else {\n      start = new Date(event.start.dateTime);\n    }\n\n    // atコマンドで扱いやすい時間形式にフォーマット\n    return {\n      title: event.summary,\n      start: dayjs.dayjs(start).subtract(1, 'minute').format(\"YYYYMMDDHHmm\"),\n      meetUrl: event.hangoutLink,\n    }\n  })\n\n  return todayEvent;\n}\n````\n\n### Webアプリとして公開\n\nデプロイ \u003e 新しいデプロイ \u003e 説明を入力してデプロイ \u003e WebアプリのURLを取得\n\n## atコマンドを有効化\n\nMacのatコマンドはデフォルトでは無効になっているので有効化する。\n\n[Macでatコマンドが実行できないときの対処法 - Qiita](https://qiita.com/shge/items/6c43947a77abd9d2d1b2)\n[MacOS で at コマンドを有効化して使ってみる - Neo's World](https://neos21.net/blog/2019/09/13-02.html)\n\n````shell\nsudo launchctl load -w /System/Library/LaunchDaemons/com.apple.atrun.plist\n````\n\n`/usr/libexec/atrun` にフルディスクアクセスをつける\n\n## ターミナルで予定一覧を取得して、atコマンドで設定\n\n````shell\ncurl -L \"\u003cGASのWebアプリURL\u003e\" | jq -r '.[] | .title + \",\" + .start + \",\" + .meetUrl' | awk -F ',' '{ print system(\"echo open \" $3 \" | at -t \" $2 ) }'\n````\n\n## まとめ\n\n毎朝手動でatコマンドを仕込むようにしていて、そこだけは手間だがいまのところこれのおかげで時間になったら作業を止めることができている。\n\natコマンドはデフォルトで無効になっていて、Macでスケジュール実行のコマンドはlaunchdを使ったほうがいいのではという気がしている。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["GAS","shell"]},"/blog/start-blog-with-gatsby":{"title":"Gatsbyでブログを作ったので、構築ログを残す","content":"\n## Gatsby.js について\n\n\u003chttps://www.gatsbyjs.com/\u003e\n\nReactでつくられた静的サイトジェネレータ\n\nReactをビルド時に1回だけ実行し、HTML,JSを生成する。\n生成されたファイルをホスティングサービスにデプロイするだけで見られるようになる。\n\n### GraphQL\n\n* Gatsby.jsではビルド時のさまざまなデータをGraphQLで取得する。\n* Markdown形式で書いた情報を、ファイルシステムから読み込んで、GraphQL経由で取得し、Reactコンポーネント内で表示する。\n* GatsbyではMarkdownファイルに限らず、様々なデータを `data source`, `data transformer` という枠組みで一般化することで、多様な処理を統一的にかつ簡潔に記述することができている。\n* クライアントはビルド時に形成されたGraphQL DBの全体は必要ないので、「クエリの結果」のみをJSONとして合わせてデプロイする。\n\n## starterを使ってblogを作成\n\nテンプレートを利用してブログを構築しました。\n\n````shell\nnpx gatsby new gatsby-starter https://github.com/gatsbyjs/gatsby-starter-blog\n````\n\n※最初、[Leonids](https://www.gatsbyjs.com/starters/renyuanz/leonids/) で構築しましたがいまいち気に入らなかったので、[gatsby-starter-blog](https://www.gatsbyjs.com/starters/gatsbyjs/gatsby-starter-blog) で作り直しました。\n作り直すにあたっては、別ディレクトリでstarterから作成 → ファイル一式をコピー → TypeScriptへの変換等で地道に行いました。\n\n## TypeScript化する\n\ntsxに変更\nGraphQLのクエリ結果を型解決する\n\n## TailwindCSS\n\nTailwindCSSのユーティリティを組み合わせる思想が好きでよく使用するので、本ブログでも\n\u003chttps://www.gatsbyjs.com/docs/how-to/styling/tailwind-css/\u003e\nに沿って設定していきます。\n\n### インストール、初期設定\n\n````shell\nyarn add -D tailwindcss@npm:@tailwindcss/postcss7-compat autoprefixer\nnpx tailwindcss init\n````\n\n### PostCSSで適用する\n\n````shell\nyarn add postcss gatsby-plugin-postcss\n````\n\n````javascript:title=gatsby-config.js\nplugins: [`gatsby-plugin-postcss`],\n````\n\n````javascript:title=postcss.config.js\nmodule.exports = () =\u003e ({\n  plugins: [require(\"tailwindcss\")],\n})\n````\n\n### base CSSを追加する\n\n`@tailwind` ディレクティブを使用してTailwindの `base`, `components`, `utilities` をCSSに挿入します。\n\n````css:title=src/index.css\n@tailwind base;\n@tailwind components;\n@tailwind utilities;\n````\n\nカスタムCSSにTailwindのクラスを適用したい場合以下のように書ける\n\n````css:title=src/index.css\n@tailwind base;\n@tailwind components;\n@tailwind utilities;\n\n@import popup.css body {\n  @apply bg-purple-200;\n}\n````\n\n`gatsby-browser.js` で読み込む\n\n````javascript:title=gatsby-browser.js\nimport \"./src/index.css\"\n````\n\n### Purge を設定する\n\nデフォルトではTailwindCSS全体がビルドに含まれるため、ファイルサイズ削減のために必要なclassのみにpurgeする。\n\n````javascript:title=tailwind.config.js\nmodule.exports = {\n  purge: [\"./src/**/*.{js,jsx,ts,tsx}\"],\n  theme: {},\n  variants: {},\n  plugins: [],\n}\n````\n\n## TOCを追加\n\n[gatsby-remark-autolink-headers](https://www.gatsbyjs.com/plugins/gatsby-remark-autolink-headers/) で見出しにアンカーがつくようにする\n\n````shell\nyarn add gatsby-remark-autolink-headers\n````\n\n````javascript:title=gatsby-config.js\nmodule.exports = {\n  plugins: [\n    {\n      resolve: `gatsby-transformer-remark`,\n      options: {\n        plugins: [\n          {\n            resolve: `gatsby-remark-autolink-headers`,\n            options: {\n              offsetY: 80,\n              icon: false,\n              maintainCase: false,\n            },\n          },\n        ],\n      },\n    },\n  ],\n}\n````\n\n### TOCコンポーネントを作成してページのコンポーネントに追加\n\n````typescript:toc.tsx\nimport * as React from 'react'\n\ntype Props = {\n  tocHtml?: string\n}\nconst Toc: React.FC\u003cProps\u003e = ({tocHtml}) =\u003e {\n  if (tocHtml === undefined) {\n    return \u003c\u003e\u003c/\u003e\n  }\n  return (\n    \u003cdiv className=\"toc bg-code-block px-4 py-1 my-2\"\u003e\n      \u003ch4 className=\"toc__title mt-2\"\u003e目次\u003c/h4\u003e\n      \u003cdiv\n        className=\"toc__content\"\n        dangerouslySetInnerHTML={{\n          __html: tocHtml,\n        }}\n      /\u003e\n    \u003c/div\u003e\n  )\n}\n\nexport default Toc\n````\n\n````typescript:bolg-post.tsx\n// ....\n  return (\n    \u003cLayout location={location} title={siteTitle}\u003e\n\n      \u003carticle\n        className=\"blog-post\"\n        itemScope\n        itemType=\"http://schema.org/Article\"\n      \u003e\n        \u003cheader\u003e\n          \u003ch1 itemProp=\"headline\"\u003e{post.frontmatter.title}\u003c/h1\u003e\n          \u003cp\u003e{post.frontmatter.date}\u003c/p\u003e\n        \u003c/header\u003e\n        \u003csection\n          className=\"blog-post__description\"\n        \u003e\n          {post.frontmatter.description}\n        \u003c/section\u003e\n        \u003cToc\n          tocHtml={post.tableOfContents}\n        /\u003e\n// ...\n    \u003c/Layout\u003e\n  )\n````\n\n## コードブロックにタイトルを設定\n\n参考: [Gatsbyにシンタックスハイライトを入れてコードをきれいに表示する | littlebylittle](https://littlebylittle.work/2020/01/gatsby-syntax-highlighting/)\n\n[gatsby-remark-code-titles](https://www.gatsbyjs.com/plugins/gatsby-remark-code-titles/) を使って、コードブロックにタイトルをつけます\n\n````shell\nyarn add gatsby-remark-code-titles\n````\n\n````javascript:title=gatsby-config.js\nmodule.exports = {\n  plugins: [\n    {\n      resolve: `gatsby-transformer-remark`,\n      options: {\n        plugins: [\n          'gatsby-remark-code-titles',\n          `gatsby-remark-prismjs`,\n        ],\n      },\n    },\n  ],\n}\n````\n\nコードタイトル用のスタイルを追加\n\n````css:title=index.css\n.gatsby-code-title {\n  @apply bg-code-block text-text-light;\n  margin-bottom: -0.6rem;\n  padding: 6px 12px;\n  font-size: 0.8em;\n  line-height: 1;\n  font-weight: bold;\n  display: table;\n  border-radius: 4px 4px 0 0;\n}\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Gatsbyjs","blog","frontend"]},"/blog/zplug-to-zinit":{"title":"zplugをzinitに移行する","content":"\n\n````toc\n# This code block gets replaced with the TOC\n````\n\n## 移行理由\n\n自分がターミナルで使用しているシェルの変遷\n\n* 2016 ~ 2020/04 zsh zplug\n* 2020/04 ~ 2021/04 fishに移行した\n* 2021/04 ~ zshに戻った\n\nzshのカスタマイズが面倒なのと、シェルの起動が遅かったので、カスタマイズが簡単なfishに移行したが、以下の理由でまたzshに戻ってきた\n\n* fishはPOSIX非互換なのでコマンドを調べるのが手間\n* bash/zshで作ったスクリプトを書き換える必要がある\n\nzinitは起動が早いと聞いたので、zplugからzinitに移行する\n\n## インストール\n\n[公式の推奨手順](https://github.com/zdharma/zinit#automatic-installation-recommended)\n\n````shell\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/zdharma/zinit/master/doc/install.sh)\"\n````\n\n`~/.zinit` (`$ZDOTDIR` が設定されていれば `$ZDOTDIR/.zinit`) にインストールされる。\nまた、 `~/.zshrc` にzinitの設定が追記されるので、リロードし、Zinitをコンパイルする。\n\n````shell\nsource ~/.zshrc\nzinit self-update\n````\n\n## プラグインの設定\n\n完全な例\n\n````shell\n### Added by Zinit's installer\nif [[ ! -f $ZDOTDIR/.zinit/bin/zinit.zsh ]]; then\n    print -P \"%F{33}▓▒░ %F{220}Installing %F{33}DHARMA%F{220} Initiative Plugin Manager (%F{33}zdharma/zinit%F{220})…%f\"\n    command mkdir -p \"$HOME/.zsh/.zinit\" \u0026\u0026 command chmod g-rwX \"$HOME/.zsh/.zinit\"\n    command git clone https://github.com/zdharma/zinit \"$HOME/.zsh/.zinit/bin\" \u0026\u0026 \\\n        print -P \"%F{33}▓▒░ %F{34}Installation successful.%f%b\" || \\\n        print -P \"%F{160}▓▒░ The clone has failed.%f%b\"\nfi\n\nsource \"$ZDOTDIR/.zinit/bin/zinit.zsh\"\nautoload -Uz _zinit\n(( ${+_comps} )) \u0026\u0026 _comps[zinit]=_zinit\n\n# Load a few important annexes, without Turbo\n# (this is currently required for annexes)\nzinit light-mode for \\\n    zinit-zsh/z-a-rust \\\n    zinit-zsh/z-a-as-monitor \\\n    zinit-zsh/z-a-patch-dl \\\n    zinit-zsh/z-a-bin-gem-node\n\n### End of Zinit's installer chunk\n\nzinit ice wait'1' lucid; zinit light \"zdharma/fast-syntax-highlighting\"\nzinit light \"zsh-users/zsh-autosuggestions\"\nzinit light \"zsh-users/zsh-completions\"\nzinit light \"zsh-users/zsh-history-substring-search\"\nbindkey '^[[A' history-substring-search-up\nbindkey '^[[B' history-substring-search-down\n\nzinit ice wait'1' lucid pick'init.sh'; zinit light \"b4b4r07/enhancd\"\nzinit ice wait'1' lucid; zinit light \"reegnz/jq-zsh-plugin\"\n\nzinit ice wait'1' lucid; zinit light \"b4b4r07/emoji-cli\"\nzinit ice wait'1' lucid; zinit light \"mollifier/cd-gitroot\"\nzinit light \"Aloxaf/fzf-tab\"\n\nzinit ice wait'1' lucid; zinit light \"lukechilds/zsh-better-npm-completion\"\n\n#######\n# https://github.com/Aloxaf/fzf-tab\n#######\nenable-fzf-tab\n# zstyle ':fzf-tab:*' fzf-command ftb-tmux-popup\nzstyle ':fzf-tab:complete:cd:*' fzf-preview 'exa -1 --color=always $realpath'\nzstyle ':fzf-tab:*' fzf-bindings 'ctrl-j:accept' 'ctrl-a:toggle-all' 'ctrl-space:toggle+down'\n# disable sort when completing `git checkout`\nzstyle ':completion:*:git-checkout:*' sort false\n# set descriptions format to enable group support\nzstyle ':completion:*:descriptions' format '[%d]'\n# set list-colors to enable filename colorizing\nzstyle ':completion:*' list-colors ${(s.:.)LS_COLORS}\n# preview directory's content with exa when completing cd\nzstyle ':fzf-tab:complete:cd:*' fzf-preview 'exa -1 --color=always $realpath'\n# switch group using `,` and `.`\nzstyle ':fzf-tab:*' switch-group ',' '.'\n````\n\n`End of Zinit's installer chunk` までは、インストーラが追記した部分。\n\n### プラグインのダウンロード、有効化\n\n````shell\nzinit ice wait'1' lucid\nzinit light \"zdharma/fast-syntax-highlighting\"\n\nzinit load \"zdharma/history-search-multi-word\"\n````\n\nzinitには2つのプラグインロード方法がある\n\n* `zinit load`\n  * トラッキング機能を有効にする。zinit report で一覧表示ができたり、zinit unload でプラグインを無効化できるなどの利点があるが、ロードは遅くなる\n* `zinit light`\n  * トラッキング機能が無効になる。一覧等の機能が使えない代わりに高速\n\nめったにトラッキング機能を使わないため、基本的に `zinit light` でロードすることにした\n\n### zinit ice\n\n後続の `zinit load`, `zinit light` の挙動を制御する\n\n````shell\nzinit ice wait'1' lucid pick'init.sh'\nzinit light \"b4b4r07/enhancd\"\n# zinit ice wait'1' lucid pick'init.sh'; zinit light \"b4b4r07/enhancd\" と同義\n````\n\n* wait\n  * zshが起動したあとにプラグインを遅延ロードする秒数を指定する\n* lucid\n  * 遅延ロードしたときに、コンソールにロード情報が出力されるのを抑制する\n* pick\n  * sourceするファイルを指定する。pluginが `*.plugin.zsh` ファイルを起点にしていない場合、明示的に指定する\n\n## 結果\n\n2秒くらいかかっていた起動時間が0.6秒前後くらいになった。\nまた、zplugだと複数シェルを同時に起動すると競合して状態がおかしくるのか、同じプラグインが複数回ロードされることがまれにあったが、\nこういった問題も起こらなくなった。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["zsh"]},"/note/%E3%82%BB%E3%83%9E%E3%83%95%E3%82%A9":{"title":"セマフォ","content":"\n[セマフォとは - 意味をわかりやすく - IT用語辞典 e-Words](https://e-words.jp/w/%E3%82%BB%E3%83%9E%E3%83%95%E3%82%A9.html)\nセマフォはコンピュータ上の共有資源について、利用可能な資源の数を指し示している。プログラムが資源を占有するときはセマフォの値から1を減じ、処理が終わって解放する際には1を加える。セマフォが0のときは空いている資源がないため正の値になるまで待機する。セマフォの値を同じ資源に同時にアクセスできるプロセスの数として扱う場合もある。\n\n排他制御のための仕組み\n\n## Linux上でセマフォの数を確認する\n\n`ipcs -s`\n\n````shell\n$ ipcs -s \n\n------ Semaphore Arrays --------\nkey        semid      owner      perms      nsems     \n0x0052e2c1 0          postgres  600        17        \n0x0052e2c2 32769      postgres  600        17        \n0x0052e2c3 65538      postgres  600        17        \n0x0052e2c4 98307      postgres  600        17        \n0x0052e2c5 131076     postgres  600        17        \n0x0052e2c6 163845     postgres  600        17        \n0x0052e2c7 196614     postgres  600        17        \n0x00000000 629047303  apache    600        1         \n0x036c6761 588447766  root      600        17        \n0x036c6762 588480535  root      600        17\n````\n\n削除 `ipcrm -s \u003csemid\u003e`\n\n````shell\n$ ipcrm -s 588447766\n$ ipcs -s | grep 588447766\n=\u003e 削除される\n````\n\n## 上限\n\nデフォルトの上限は120\n`sysctl -a` で確認できる\n\n````shell\n$ /sbin/sysctl -a | grep semid\nkernel.sem = 250        32000   32      128\n````\n\nApacheがセマフォ不足で起動しないことがある。\n`No space left on device` というエラーが出るのでミスリーディングだが、セマフォを減らしてやることで起動できるようになる\n\n[セマフォ不足でApacheが起動できないときセマフォをまとめて削除する - M.C.P.C. (Mamesibori Creation Plus Communication)](https://cl.hatenablog.com/entry/apache-rm-semaphore)\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["2023/03/14","Linux"]},"/note/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%90%8C%E5%A3%AB%E3%81%AE%E6%AF%94%E8%BC%83%E3%82%92vimdiff%E3%81%A7%E5%8F%96%E3%82%8B":{"title":"ファイル同士の比較をvimdiffで取る","content":"\n## ファイル同士の比較をvimdiffで取る\n\n````shell\n$ vimdiff text.txt another.txt\n# またはvim -d\n$ vim -d text.txt another.txt\n````\n\n## 現在vimで開いているファイルと指定したファイルとの差分\n\n````vim\n:vertical diffsplit 差分を取りたいファイル\n````\n\n## 2つのファイルの差分をマージする\n\nVimでは，「diffモード」の状態で，2つのファイルの差分のマージを行うこともできる。\nもう一方のファイルの差分を取り込むには、差分ハイライトされている場所で次のコマンド\n\n````vim\n:do\n````\n\n逆にもう一方に取り込ませるには\n\n````vim\n:dp\n````\n\ndoは「diff obtain」，dpは「diff put」と覚える。\n\n## 次の差分へカーソルを移動する\n\nノーマルモードで `]c` を入力すると次の差分へ、`[c` で前の差分へ\n\n[2つのテキストファイルの差分を取る — 名無しのvim使い](http://nanasi.jp/articles/howto/diff/diff_text.html)\n[2つのテキストファイルの差分をマージする — 名無しのvim使い](http://nanasi.jp/articles/howto/diff/merge_diff.html)\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["vim"]},"/note/%E3%83%96%E3%83%AD%E3%82%B0%E3%81%AB%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%A0%E3%83%89%E3%83%A1%E3%82%A4%E3%83%B3%E3%82%92%E8%A8%AD%E5%AE%9A%E3%81%99%E3%82%8B":{"title":"ブログにカスタムドメインを設定する","content":"\n\\#blog\n\nNetlifyでデプロイしたサイトにカスタムドメインを設定したい。\n\n## ドメインの発行\n\n[お名前.com](https://www.onamae.com/)や[ムームードメイン](https://muumuu-domain.com/) 等あるがムームードメインにした。(Whois情報公開代行のオプションが無料のため)\n\n`ikorihn.com` を取得した。\nオプションはWhois情報公開代行のみを設定しほかは使用しない。\n\n## Netlifyの独自ドメイン化の設定\n\nNetlifyの対象サイトのページへ移動し、`Set up a custom domain` からドメインを指定する。\n\n`blog.ikorihn.com` を指定したところ、ドメインが登録済みのようなメッセージがでるので\n`Add domain` を押す。\n\n![Pasted-image-20211231160203](note/Pasted-image-20211231160203.png)\n\n次の画面で `Check DNS Configuration` を押して出る説明の通り、DNSプロバイダーでCNAMEを登録する\n\n![Pasted-image-20211231160919](note/Pasted-image-20211231160919.png)\n\n## ムームードメインの設定\n\nコントロールパネル \u003e ドメイン操作 \u003e ムームーDNSの画面から、\nドメインの変更ボタンを押す\n\nカスタム設定を押して、注意がでるがOKを押す。\n\n* サブドメイン: `blog`\n* 種別: `CNAME`\n* 内容: `***.netlify.app`\n\nセットアップ情報変更を押して完了する。\n\n## 反映確認\n\nNetlifyの画面で、`Check DNS Configuration` が消えたら反映されたことになり、サイトが開けることも確認できる。\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["blog"]},"/note/%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E5%8A%B9%E7%8E%87%E3%81%A8%E3%83%95%E3%83%AD%E3%83%BC%E5%8A%B9%E7%8E%87":{"title":"リソース効率とフロー効率","content":"\n[フロー効率性とリソース効率性について](https://www.slideshare.net/i2key/xpjug)\n\n* リソース効率がいい\n  * 稼働率が100%、暇な人がいない\n* フロー効率がいい\n  * 機能リリースまでのリードタイムが短い\n  * 一つのタスクに複数人でとりくむ\n  * 一時的に手持ち無沙汰な人がいる状態\n  * タスクが得られるリソースの時間を最大化する\n  * ペアプロ・モブプロ、クロスファンクショナルチーム\n\n同じ作業に複数人で取り組んでも、時間の浪費だ！って考えるのはリソース効率\nフローとリソースはトレードオフになりやすい\nフロー=流れを止めずに小さいサイクルを素早く回す\n\n余裕がある状態で機能リリース時期も変わらないんだったらフロー効率のがよくない？いいところばっかり言うけどデメリットは？銀の弾丸はないんですよね？\n-\u003e すべての機能をリリースするまでの稼働時間は増える。同じタスクに複数で取り組むんだからそれはそうだよね\nただ全機能出揃ってからリリース！じゃなくて一つできたらリリース！のアジャイル開発の考え方だから、順番に価値を届けられる\n\n大きい塊を渡して、スコープを削ることなく全部必要っていうのはリソース効率\n1st、2ndと順に出していきましょうよっていうのはフロー効率\nどんとでかいアイテムをこなそうとすれば稼働は100%になるからリソース効率はよくなるよ、それを選んだんだから当然\n\ntoB案件だと結局、一つの完成品をお届けしようってなってでかい塊になることが多いよね…\nアジャイルは顧客の理解もないとできないってそういうこと\n\nフロー効率重視で開発プロセスを組んだものの、知らず識らずのうちにリソース効率にフォーカスしてしまうっていうのはよくある\nリリース日が固定されていて、途中で大きな要件追加が舞い込んでくると、そういう考えになっちゃいがち\n\n## [フロー効率とリソース効率について思うこと - タマネギプログラマーの雑記](https://gaopin1534.hatenablog.com/entry/2017/12/10/003122)\n\n \u003e \n \u003e 曰く、「リソース効率は悪でフロー効率こそが目指すべき姿」であるとか、「フロー効率こそが価値を最大限に発揮できる方法」であるとかそういう声である。  \n \u003e これはリソース効率というコンセプトの理解として正しくない。\n\nですよね\nいい話ばっかり聞かされるしウォーターフォールは悪、アジャイルが最強って感じになっちゃって偏っちゃうけど違うよね\n\n \u003e \n \u003e この図だけを見た人は必ずこう思うはずである。  \n \u003e 「全てのアイテムが同じ期間で完了するのなら、トータルのリードタイムが短くなるフロー効率の方が良いに決まっているじゃないか」と。\n\nまさにこれ、この図の書き方はよくない\n実際にはフロー効率では時間はもっとかかる\n一つのアイテムは素早くリリースできるけど\n\n \u003e \n \u003e リソース効率は、フィードバックを入れて方向転換することには弱いが、予め決められたアイテム群をより早く完了することができる。  \n \u003e よって、いわゆるプロジェクト型の開発に向いていると言える。  \n \u003e プロジェクト型の開発では、プロジェクト完了までアイテムが価値を発揮する必要がないため、個々のリードタイムの長さは問題にならない。\n\n納期と要件がすでに決まっているときにフロー効率がいいんだってねじ込むのは違うよ\nつかいどきというものがあるので\n仮説検証型のプロジェクトで小さく作って反応を見たいっていうときには有効だよ\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["agile"]},"/note/%E6%95%B0%E6%99%82%E9%96%93%E3%81%A7%E5%AE%8C%E5%85%A8%E7%90%86%E8%A7%A3%E3%82%8F%E3%82%8A%E3%81%A8%E3%82%B4%E3%83%84%E3%81%84Kubernetes%E3%83%8F%E3%83%B3%E3%82%BA%E3%82%AA%E3%83%B3%E3%82%92%E3%82%84%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B":{"title":"数時間で完全理解！わりとゴツいKubernetesハンズオン！！をやってみる","content":"\n[数時間で完全理解！わりとゴツいKubernetesハンズオン！！ - Qiita](https://qiita.com/Kta-M/items/ce475c0063d3d3f36d5d)\n\nちょっと古いけど一通り体験するのによさそう\n\n## 下準備\n\ndocker-desktopに名前が変わっているみたい\n\nいきなり躓いた。`github.com/~~` の書き方はdeprecatedになっていた\n\nhttps://kubernetes.github.io/ingress-nginx/deploy/#quick-start\n\n````shell\n$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.1/deploy/static/provider/cloud/deploy.yaml\n````\n\n````shell\n$ git clone git@github.com:kubernetes/examples.git\n$ vim examples/guestbook/all-in-one/frontend.yaml\n# replicasを1に変える\n\nk apply -f ./examples/guestbook/all-in-one/guestbook-all-in-one.yaml\n````\n\n### kind: Ingress はdeprecated\n\nhttps://kubernetes.io/docs/reference/using-api/deprecation-guide/#ingress-v122\n\n* `networking.k8s.io/v1` API version に変更\n* `serviceName` を `service.name` など細かい変更\n* `ingressClassName: nginx` は `kubernetes/ingress-nginx` で作成したIngressClassを指定する\n\n````shell\n$ k get ingressclass \nNAME    CONTROLLER             PARAMETERS   AGE\nnginx   k8s.io/ingress-nginx   \u003cnone\u003e       18m\n````\n\n````yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: guestbook-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType: Exact\n        backend:\n          service:\n            name: frontend\n            port:\n              number: 80\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["Kubernetes"]},"/note/%E7%B7%AF%E5%BA%A6%E7%B5%8C%E5%BA%A6%E3%81%A72%E5%9C%B0%E7%82%B9%E9%96%93%E3%81%AE%E8%B7%9D%E9%9B%A2%E3%82%92%E8%A8%88%E7%AE%97%E3%81%99%E3%82%8B":{"title":"緯度経度で2地点間の距離を計算する","content":"\nいろいろな計算式があり、精度と速度の一長一短\n[緯度経度を用いた3つの距離計算方法](https://orsj.org/wp-content/corsj/or60-12/or60_12_701.pdf)\n[測地線距離計算式・計算ライブラリの精度評価 - 330k info](https://www.330k.info/essay/geodesic_distance_formula_comparison_2/)\n\n* Haversine: 完全球体とみなした計算。Great-circle distance(大円距離)\n* Hubeny (Simple): ヒュベニの式の簡易版。カシミール3Dという地図ソフトで使われている\n* Hubeny (Full): ヒュベニの式のオリジナル版\n* Vincenty: Vincentyによる式。回転楕円体上の測地線\n* Lambert: Lambertによる式。Geographical distance\n* Andoyer-Lambert: Andoyerが補正を加えたもの。測地線航海算法(Geodesic Sailing)\n* Andoyer-Lambert-Thomas: さらにThomasが補正を加えたもの。\n\n## Go言語での実装\n\n有名所\nhttps://pkg.go.dev/github.com/golang/geo\n\n[S2 Geometryライブラリで遊んでみる - taiyoh's memorandum](https://taiyoh.hatenablog.com/entry/2019/12/17/181928)\n\nJavaのGeographicLibをポートしたもの\nhttps://github.com/geographiclib/geographiclib-java\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["2023/03/30","Go"]},"/note/%E7%B7%AF%E5%BA%A6%E7%B5%8C%E5%BA%A6%E3%81%AE%E5%BA%A6%E5%88%86%E7%A7%92%E3%81%A8%E3%83%9F%E3%83%AA%E7%A7%92%E3%82%92%E5%A4%89%E6%8F%9B%E3%81%99%E3%82%8B":{"title":"緯度経度の度分秒とミリ秒を変換する","content":"\nhttp://www.geosense.co.jp/map/tool/geoconverter.php\n[緯度経度変換ツール](https://www.ipentec.com/utils/LatLongPlot/LatLongConvert.aspx)\n[日本の東西南北端点の経度緯度 | 国土地理院](https://www.gsi.go.jp/KOKUJYOHO/center.htm)\n[日本測地系のミリ秒を世界測地系の度に変換する計算 - Qiita](https://qiita.com/wildspin/items/02ef89f762d97965337c)\n[緯度経度 －単位変換－](http://jkl.sakura.ne.jp/labs/archives/27)\n\n## ミリ秒から度への変換\n\n元データを3,600,000で割る\n\n128544000 -\u003e 35.70666667  \n503329984 -\u003e 139.8138844\n\n## 世界測地変換\n\n````\nlat = jp_lat - jp_lat * 0.00010695 + jp_lon * 0.000017464 + 0.0046017;\nlon = jp_lon - jp_lat * 0.000046038 - jp_lon * 0.000083043 + 0.010040;\n````\n\n## DMS形式\n\n・度/分/秒.秒表記(度/分/ミリ秒表記)　秒の表現は10進\n35/39/15.152(35/39/15152)　139/45/27.932(139/45/27932)\n\n・ミリ秒換算\n128355152　503127932\nミリ秒単位→度単位　　3600000で割る\n\n## DEG形式(Degree) dddd.ddddd\n\n・度.度(10進)、緯度経度を単位”度”のみで表現\n136.6694786\n\nDEGとDMSの変換\n136.6694786を136°40′10.123に変換\n\n136と0.6694786に分ける\n0.6694786に60を掛ける\n40.168716 → 40分\n0.168716に60を掛ける\n10.12296 → 10.12296秒\n\n(度 * 3600 + 分 * 60 + 秒) * 1000　＝　分\n\nphpだと・・・こんな感じ？\n$Japan_Lat\\[$i\\] = (int)$JapanLat\\[$i\\] * 3600 + (int)( ($JapanLat\\[$i\\] – (int)$JapanLat\\[$i\\]) * 60 ) \\*60 + ( (int)( ($JapanLat\\[$i\\] – (int)$JapanLat\\[$i\\]) * 60 ) – ( ($JapanLat\\[$i\\] – (int)$JapanLat\\[$i\\]) * 60 ) ) * 60;\n$Japan_Lng\\[$i\\] = (int)$JapanLng\\[$i\\] * 3600 + (int)( ($JapanLng\\[$i\\] – (int)$JapanLng\\[$i\\]) * 60 ) \\*60 + ( (int)( ($JapanLng\\[$i\\] – (int)$JapanLng\\[$i\\]) * 60 ) – ( ($JapanLng\\[$i\\] – (int)$JapanLng\\[$i\\]) * 60 ) ) * 60;\n\nさらにミリ秒に変換する\n136°40′10.123\n136+40/60+10/(60*60)+123/(60*60\\*60)\n\nDMSからDEGへの変換\n136°40′10.123を136.6694786に変換\n$lng = spilit(‘/’,’＄LNG’);\n$lng\\[0\\] + ( $lng\\[1\\] + ( $lng\\[2\\] / 60 ) ) / 60\n\n$lat = spilit(‘/’,’＄LAT’);\n$lat\\[0\\] + ( $lat\\[1\\] + ( $lat\\[2\\] / 60 ) ) / 60\n\n測地系変換 これは簡易計算で、誤差が発生します。\n＜日本測地系⇒世界測地系＞\n世界測地系緯度 = 日本測地系緯度 – 0.00010695 * 日本測地系緯度 + 0.000017464 * 日本測地系経度 + 0.0046017\n世界測地系経度 = 日本測地系経度 – 0.000046038 * 日本測地系緯度 – 0.000083043 * 日本測地系経度 + 0.010040\n＜世界測地系⇒日本測地系＞\n日本測地系緯度 = 世界測地系緯度 + 0.00010696 * 世界測地系緯度 – 0.000017467 * 世界測地系経度 – 0.0046020\n日本測地系経度 = 世界測地系経度 + 0.000046047 * 世界測地系緯度 + 0.000083049 * 世界測地系経度 – 0.010041\n\n日本測地系（Tokyo Datum）、単位は秒、ミリ秒は小数点以下2桁以内で指定すること。\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["coord"]},"/note/%E8%A8%98%E4%BA%8B%E3%83%A1%E3%83%A2-ZOZOTOWN%E3%81%AEGo%E8%A8%80%E8%AA%9E%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E3%83%9E%E3%82%A4%E3%82%AF%E3%83%AD%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E9%96%8B%E7%99%BA%E3%81%AE%E5%85%B1%E9%80%9A%E8%A6%8F%E7%B4%84%E3%82%92%E5%AE%88%E3%82%8B%E3%81%9F%E3%82%81%E3%81%AE%E5%8F%96%E3%82%8A%E7%B5%84%E3%81%BF":{"title":"記事メモ ZOZOTOWNのGo言語におけるマイクロサービス開発の共通規約を守るための取り組み","content":"\n* [ZOZOTOWNのGo言語におけるマイクロサービス開発の共通規約を守るための取り組み - ZOZO TECH BLOG](https://techblog.zozo.com/entry/zozo-microservice-conventions-in-golang)\n  * 開発テンプレートを用意しておいて、各マイクロサービスが最低限守って欲しい規約を守らせる\n  * バックエンドの共通規約の実装例として次のようなものがあります。\n    * トレース\n    * ヘッダー処理\n    * 認証\n  * 必ず出力してほしい項目についてはロガーのライブラリを作っておいて共通化するのありだね\n  * リクエストスコープ全体で使いたいものはcontextに入れておくのがよさげ\n\n````go\nfunc RequestMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        ctx := r.Context()\n        if userAgent := r.Header.Get(constant.HeaderKeyForwardedUserAgent); userAgent != \"\" {\n            ctx = setForwardedUserAgent(ctx, userAgent)\n        }\n        if userIP := r.Header.Get(constant.HeaderKeyUserIP); userIP != \"\" {\n            ctx = setUserIPAddress(ctx, userIP)\n        }\n        if traceID := r.Header.Get(constant.HeaderKeyZozoTraceID); traceID != \"\" {\n            ctx = SetTraceID(ctx, traceID)\n        }\n        if uid := r.Header.Get(constant.HeaderKeyZozoUID); uid != \"\" {\n            ctx = setUID(ctx, uid)\n        }\n        if xForwardedFor := r.Header.Get(constant.HeaderKeyXForwardedFor); xForwardedFor != \"\" {\n            ctx = setXForwardedFor(ctx, xForwardedFor)\n        }\n        if r.RemoteAddr != \"\" {\n            ctx = setRemoteAddress(ctx, r.RemoteAddr)\n        }\n        next.ServeHTTP(w, r.WithContext(ctx))\n    })\n}\n````\n\n````go\nfunc setHeaders(ctx context.Context, request *http.Request) error {\n    if encodedInternalIDToken, err := middleware.GetEncodedInternalIDToken(ctx); err == nil {\n        request.Header.Set(constant.HeaderKeyZozoInternalIDToken, encodedInternalIDToken)\n    }\n    if ipAddress, err := middleware.GetUserIPAddress(ctx); err == nil {\n        request.Header.Set(constant.HeaderKeyUserIP, ipAddress)\n    }\n    if userAgent, err := middleware.GetForwardedUserAgent(ctx); err == nil {\n        request.Header.Set(constant.HeaderKeyForwardedUserAgent, userAgent)\n    }\n    if traceID, err := middleware.GetTraceID(ctx); err == nil {\n        request.Header.Set(constant.HeaderKeyZozoTraceID, traceID)\n    }\n    if uid, err := middleware.GetUID(ctx); err == nil {\n        request.Header.Set(constant.HeaderKeyZozoUID, uid)\n    }\n    if apiClient, err := middleware.GetAPIClient(ctx); err == nil {\n        request.Header.Set(constant.HeaderKeyAPIClient, apiClient)\n    }\n    if xForwardedFor, err := middleware.GetXForwardedFor(ctx); err == nil {\n        if remoteAddr, err := middleware.GetRemoteAddress(ctx); err == nil {\n            host, _, e := net.SplitHostPort(remoteAddr)\n            if e != nil {\n                return xerrors.Errorf(\"split remote address: %v\", e)\n            }\n            request.Header.Set(constant.HeaderKeyXForwardedFor, xForwardedFor+\", \"+host)\n        }\n    }\n    return nil\n}\n````\n\n \u003e \n \u003e 当初はサービス毎にテンプレートのリポジトリをコピーする方式でしたが、プロジェクト開始時のバージョンのコードがコピーされ、テンプレートの変更をサービス側で取り込む運用を想定していました。 しかし利用プロジェクトが増えるとそれぞれに反映してもらう手間、実装タイミング、プロジェクト毎に反映の有無が別れるなど運用の手間（負荷）が懸念されました。\n\nわかる\n\n \u003e \n \u003e SDK化することで機能のつながりがわかりづらくなったり、インポートの手間が増えたりと障壁がゼロなわけではありません。 そこで、テンプレートの位置付けをSDKの利用方法を示したサンプルアプリケーションと改めることでSDKの理解が進むようにし、各サービスに展開しやすくしています。\n\nライブラリにしてインポートしてもらうのが良さげで、テンプレートはモデルケースみたいな感じにする\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["Go","article"]},"/note/%E8%B2%A0%E8%8D%B7%E8%A9%A6%E9%A8%93-k6%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6":{"title":"負荷試験 k6について","content":"\n[locust](Locust.md) を使っているが、パフォーマンスがあまりよくなくてslaveを起動しないといけないのが微妙に思ったので他のツールがないかを調べてみた。\n要件としてはパフォーマンスが高くてデプロイが簡単なこと\n\n[k6](https://k6.io) が良さそうだった。\n\n[負荷テストツール K6 について調べてみた | sreake.com | 株式会社スリーシェイク](https://sreake.com/blog/learn-about-k6/)\n[k6使ったら今までで一番負荷テストが捗った - Qiita](https://qiita.com/hajimeni/items/40c0fd6a86e758be43d5#%E9%A0%85%E7%9B%AE)\n[k6で始める負荷テスト](https://zenn.dev/shorter/articles/e52c0047c4f0c5)\n\n## ローカルで動かす\n\nローカルに負荷試験対象のサーバーを立てる\n\n````go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n)\n\nfunc main() {\n\thttp.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tfmt.Fprintf(w, \"Hello\")\n\t})\n\tlog.Fatal(http.ListenAndServe(\":3000\", nil))\n}\n````\n\n````shell\ngo run main.go\n````\n\n### Docker上で動かす\n\nk6をbrew等でインストールしてもよいが、dockerで実行してみる。\n\n`script.js` を作成\n\n````javascript\nimport http from 'k6/http';\n\nexport default function () {\n  http.get('http://host.docker.internal:8080/');\n}\n````\n\nイメージをpull\n\n````shell\ndocker pull grafana/k6\n````\n\n実行\n\n````shell\ndocker run --rm -i grafana/k6 run - \u003ck6s_test.js\n````\n\nVU(実行ユーザー数)、duration(実行時間)を指定する場合\n\n````shell\ndocker run --rm -i grafana/k6 run --vus 10 --duration 30s - \u003ck6s_test.js\n````\n\n## Kubernetes上で動かす\n\n[Running distributed k6 tests on Kubernetes](https://k6.io/blog/running-distributed-tests-on-k8s/)\n\nこれの通りにやればできる\n\n````shell\ngit clone https://github.com/grafana/k6-operator \u0026\u0026 cd k6-operator\nkubectl config get-contexts\nmake deploy \n````\n\n````javascript\nimport http from 'k6/http';\nimport { check } from 'k6';\n\nexport const options = {\n  stages: [\n    { target: 200, duration: '30s' },\n    { target: 0, duration: '30s' },\n  ],\n};\n\nexport default function () {\n  const result = http.get('https://test-api.k6.io/public/crocodiles/');\n  check(result, {\n    'http response status code is 200': result.status === 200,\n  });\n}\n````\n\n````shell\nkubectl create configmap crocodile-stress-test --from-file /path/to/our/test.js\n````\n\n````yaml\napiVersion: k6.io/v1alpha1\nkind: K6\nmetadata:\n  name: k6-sample\nspec:\n  parallelism: 4\n  script:\n    configMap:\n      name: crocodile-stress-test\n      file: test.js\n````\n\n````shell\nkubectl apply -f /path/to/our/k6/custom-resource.yml\n````\n\nそういえばLocustにもHelm Chartがあった\n\u003chttps://github.com/deliveryhero/helm-charts/tree/master/stable/locust\u003e\n\n## その他\n\n* \u003chttps://github.com/grafana/k6-jslib-aws\u003e でS3の操作ができる\n* influxdbにデータを転送してGrafanaで見る\n* \n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["loadtest"]},"/note/AWS":{"title":"AWS","content":"\n\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["AWS"]},"/note/AWS-Dev-Day-2022-1109-1110":{"title":"AWS Dev Day 2022 1109-1110","content":"\n## EKS on Fargate スタートアップの ‘次の3年’ を支えるためのインフラ技術\n\nmBaaSからEKS on Fargateに移行した\n\n* Go\n* gRPC、Protocol Buffers\n* サーバー管理したくないのでFargate\n* Aurora Serverless\n* AWS Cloud Development Kit (CDK)\n* GitHub Actions\n* ArgoCD\n\nマイクロサービス化はしていないのにEKS使うメリット？\n\n* k8sのエコシステムに乗っかる\n* 構築できてしまえば運用は大変ではない\n\n### AWS CDK\n\n* 脱yaml TypeScriptやPythonなどコードで書けるようになる\n* https://github.com/aws-quickstart/cdk-eks-blueprints を元にするとWell-ArchitectedなEKSを構築できる\n\n### gRPC\n\n* ALB関連オプションをgRPC向けにする\n* ヘルスチェックへの応答をアプリケーションに作る\n\n### Fargate用のDeployment\n\n* 1 Pod = 1 Fargate Node\n* Daemon Setは未対応\n* Gravitonプロセッサ未対応\n* シークレット管理のスマートな解決策が用意されていない\n* Secrets Store CSI DriverはDaemon Setの使えないFargateでは使えない\n* External Secrets Operatorを採用\n\n## NewsPicksの「最高の開発者体験」への挑戦 〜Amazon ECSによる全面コンテナ化の軌跡〜\n\n5,6人のSREチームで社内全体のSREなのうちと同じだ\n\nもともとEC2(Auto Scaling Group)で運用していたが管理が大変\nコンテナ化してECS管理したい\n\nAWS CDKをTypeScriptで書いた\nConstructという概念があって、インフラの構成を部品化して再利用できる\n単体テストも書ける\n\nEC2とECSを並行稼動\nALBで振り分け\nリスナールールでターゲットグループの重みを調整して段々ECSに変えていく\n\nCodeDeployでデプロイを行っていた\nchat opsで、Lambdaを叩いてデプロイできるようになった\n\n## AWS CDKでECS on FargateのCI/CDを実現する際の理想と現実\n\nECSとCDKのBlue/Greenデプロイが当時は不安定だったのでローリングアップデートを選択\nカスタマイズも多い\n\nECSデプロイ高速化の手法はいくつかある\nAWS SDKではhotswap deploymentがある\nhotswapでは一時的にタスク数が0になるので検証でしか使えない\n\nCDK + ECS on Fargateの良質なコンテンツはある\n\ncdk-ecs-deploymentかカスタムリソース+CodeBuildが有力\n\n## ２１年夏・２２年冬の国際的スポーツ大会の報道をサーバーレス化で乗り越えた！\n\n時事通信社\nオリンピックってワードは勝手に使っちゃいけないんだっけw\n\n30,000PV/秒のリクエストに耐える負荷耐性\nLambdaのバースト同時実行数が上限を超えた場合のハンドリング\n\n記者、カメラマン、パートナーからの情報を受信 -\u003e CMSに格納 -\u003e Webアプリケーションで表示、顧客サーバーに配信\n\n### PHP Symfonyをサーバーレス化\n\nServerless Framework\nスパイクアクセスが発生しやすいシステムでスケーリングから解放されるためサーバーレス化したかった\nAuto Scalingでチューニングするのも難しい\n\n### [LamdbaEdge](note/LamdbaEdge.md) を用いた [CloudFront](note/CloudFront.md) での応答性能改善\n\nキャッシュ用のS3バケットを配置する\nOrigin Request時に実行する [LamdbaEdge](note/LamdbaEdge.md)\nUserが [CloudFront](note/CloudFront.md) にリクエストすると [LamdbaEdge](note/LamdbaEdge.md) でS3バケットのキャッシュコンテンツかWebアプリのコンテンツを取得し返す\n\n### 実行状態の可視化 [Lambda](note/AWS%20Lambda.md) から [Step Functions](note/Step%20Functions.md) への移行\n\n一定条件のリトライ、状態による条件分岐、例外やエラー制御\n1つのLambdaで実装したときに実行状態が見えづらい、タイムアウトに引っかかる可能性がある\n\n### [AWS Lambda](note/AWS%20Lambda.md) のバースト同時実行数が上限に達した場合の対処\n\nクウォータ引き上げでもバースト制限の初期値は上限緩和できない\n同時実行数を引き上げていても、突発的に増えた場合はバーストの制限に引っかかる\n\n* メモリサイズ別に実行時間を計測して、最適なメモリを割り当てる\n* Lambdaのマルチリージョン化\n\n## AWS LambdaにWebフレームワークを載せる\n\nそもそもLambdaでWebフレームワークを動かすのはいいことなのか？\n\n* Lambda関数の実装はシンプルに\n  \n  * API GatewayでANY Method / Proxy resourceを使ったモノリスになりがち\n  * 最小権限の原則も破壊される\n* cold start latencyの増加\n  \n  * 起動時間にかけるコストに見合わない\n* 慣れ親しんだ開発体験\n  \n  * 社内でも開発経験者の確保が容易\n* ポータビリティのため\n  \n  * ECSなどコンテナサービスに移植がしやすい\n\n### LambdaにWAFを載せるためにされてきたこと\n\n* 模倣体験の提供\n  * Chaliceなど\n* Runtime埋め込み系Adapter\n  * Serverless Java\n* Ahead-of-time Compilation\n\n#### Runtime埋め込み系Adapter\n\nLambda Handlerはeventを引数に取る必要がある\neventオブジェクトとHTTPリクエストのgap\nHandlerにAdapterを混入させてeventをhttp objectに変換してWAFにわたす\n\n* 開発者がAdapterを意識する必要がある\n* handler内にAdapterが存在するため、Artifactへのインストールが必要\n* 完全なフレームワーク機能が使えない\n* ポータビリティがない\n\n#### Ahead-of-time Compilation(AOT)\n\nGraalVM\nAOT向けのフレームワークであるため使い慣れたフレームワークではない\n\n### フレームワーク必要？\n\n使い慣れた以外のメリットはあるの\nリクエスト単位のisolationを持つLambdaでフレームワークを動かすとき、cold startのオーバーヘッドは無視できない\ncold startにおけるリソース確保\n\nLambdaはリクエストごとに独立した実行環境 isolation ノイジーネイバー問題が発生しない\n\nAWS Lambda Powertools がシンプル実装に対する非機能要件に対応している\n\nそれでも載せたいなら\n\n* runtimeによらない\n* レイテンシへの影響を最小限に\n* Lambdaのイベント形式へのアダプターである\n\nアダプターをRustで実装する\nサイドカーパターンで実現\n\n### AWS Lambdaでサイドカーパターンを利用する\n\nサイドカーでロギング、リバースプロキシなど\nLambda Extensionを使用して、Lambda関数を拡張可能でこれをサイドカーパターンっぽく使える\nExtensionをアダプターとして、eventをhttpオブジェクトに変換してhandlerにわたす\n\n### AWS Lambda Web Adapter\n\nLambdaでWebアプリを実行するためのツール\nhttps://github.com/awslabs/aws-lambda-web-adapter\n\n## DMMプラットフォームのマイクロサービス戦略 オーナーシップの落とし穴\n\n* PHP、Java、JavaScript、Goなどなど\n* テクノロジースタックがばらばら…あるある\n* 他チームのアプリケーションログを見るために各AWSアカウントのログ閲覧権限が必要\n* 各チームがオーナーシップをもっていて究極にサイロ化していた\n\nサイロ化をなくすために…\n全体最適化\nテクノロジースタックの統一\n開発ルールの標準化\n\nそっかあ、技術領域はある程度決めてしまったほうがいいのか…うちはある程度そうなっているか。Apache + Tomcatな\n全体最適化を満たそうとすると各チームの要件を満たせなくなってしまう\n共通のテクノロジースタックを決めつつ、オーナーシップをどの程度持たせるか\n\n### 全体最適化\n\nオーナーシップの設計 = ガードレール\n\nAmazonの例\n社内に共通のビルドシステムやデプロイシステムが存在し、それを活用することで機械的にベストプラクティスを浸透させる\n\n全体最適化を進めるには\n専門チームがフルコミットしないと難しい\n全員の承認を得ていくのは難しいのである程度トップダウンで進める\n\n未来に向けた最適化なので、短期的には効率は下がる\n\n### SREチームの最適化\n\n運用モデル\nアプリケーションチームがインフラも面倒見る体制から、\nSREチームが各チームに向けて必要な仕組みを提供して、共通インフラを用意する\n\nログ/メトリクスの共通ルールを定義\nDatadogを導入した\n\nオンプレからクラウドへの移行プロジェクトが動いていた\nそこにk8sを導入した\nマルチクラウドなのでAWSではEKS、他のパブリッククラウドでもk8sを構築\nCDツールはArgoCD、コンテナレジストリも共通\n\n### 各チームの独立性が失われる\n\n共通インフラに統一すると、各チームの独立性が失われる\n\n共通インフラの利用者は単一のGitリポジトリでTerraform管理\nk8sのマニフェストについても単一リポジトリで管理\nGitHubにはコードオーナーというのがあって、ほかチームのマニフェストファイルを変更することはない\nマニフェストの管理はアプリケーション開発者のほうで行っている\nSREチームではドキュメントの整備\n仕組みを提供して自由に使ってもらう\n\n### オーナーシップ vs 共通化\n\n性善説ベースで権限管理している\n技術の詳細をどこまで隠蔽するか？\n\n* k8sのマニフェストファイルの隠蔽 kustomize等で開発者は少しだけ変更すれば使えるようにするのか、詳細を隠蔽すると細かい要件を満たしにくくなる\n* DMMでは隠蔽しないで開発者に素の状態で使ってもらってる\n* 自分たちが使う技術は抽象化せずきちんと身につけてもらうという方針\n\n開発チームが解決してほしい課題もSREチームに頼ってしまうケースがある\n開発者が自立して対処できるようになってもらおうとしている\n\n### 状況\n\nバックエンドはGo、フロントエンドはTypeScript\nCI、DB選定、クラウド選定は開発者\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2022/11/09","meetup"]},"/note/AWS-Lambda":{"title":"AWS Lambda","content":"\n\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["AWS","Lambda"]},"/note/AWS-Lambda%E3%81%A7Go%E3%81%AEWeb%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC%E3%82%92%E5%8B%95%E4%BD%9C%E3%81%95%E3%81%9B%E3%82%8B":{"title":"AWS LambdaでGoのWebサーバーを動作させる","content":"\n\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Draft","AWS","Lambda","Go"]},"/note/AWS-Lambda%E3%81%A7tmp%E3%82%92%E4%BD%BF%E3%81%86%E3%81%A8%E3%81%8D%E3%81%AE%E6%B3%A8%E6%84%8F":{"title":"AWS Lambdaでtmpを使うときの注意","content":"\n\\#Go #Lambda\n\n\u003chttps://aws.amazon.com/jp/about-aws/whats-new/2022/03/aws-lambda-configure-ephemeral-storage/\u003e\n\u003chttps://cloud5.jp/lambda_tmp_directory/\u003e\n\n`/tmp` を一時領域として10GBまで使うことができる。\nLambdaは一定期間同じインスタンスが再利用され、`/tmp` 領域も使い回される。\nzipファイルを `/tmp/` に解凍するようなことをしたとき気をつける必要がある。\n前回実行時のファイルが残っている可能性があるので、\n\n* ランダムな名称で作成する\n* 処理が終わったら削除する\n\n````\nimport (\n\t\"log\"\n\t\"os\"\n)\n\nfunc createFile(text string) (*os.File, error) {\n\tf, err := os.CreateTemp(\"/tmp\", \"W020.nc\")\n\tif err != nil {\n\t\tlog.Fatalln(err)\n\t}\n\tdefer f.Close()\n\n\tf.WriteString(text)\n\n\treturn f, err\n}\n\nfunc handler() error {\n\tf, err := createFile(\"hello\")\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tdefer os.Remove(f.Name())\n\n}\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Go","Lambda"]},"/note/Alacritty":{"title":"Alacritty","content":"\n[Alacritty](https://github.com/alacritty/alacritty) はRust製の高速なターミナルエミュレータ。\n\n* OpenGLでGPUレンダリングを用いて描画するためとても高速\n* クロスプラットフォームに対応している\n* 設定がすべて[YAML](note/YAML.md) (`~/.config/alacritty/alacritty.yml`) なため管理がしやすい\n  * GUIがないため初心者には難しい\n* スクロールバー、タブなどもない。[tmux](note/tmux.md) と組み合わせて使うのが前提となっていそう。\n\n## インストール\n\n\u003chttps://github.com/alacritty/alacritty/blob/master/INSTALL.md\u003e\n\n* [cargo](note/cargo.md) でインストールする\n* macの場合 `brew install --cask alacritty`\n* ソースコードからビルドする\n\n[Homebrew](note/Homebrew.md) や [cargo](note/cargo.md) でインストールする場合、 terminfo やdesktop entry、manual page、シェル補完が利用できないが、\nRustの環境を構築せず（cargoを利用する場合は必要）、簡単にAlacrittyをインストールできる。\n\n最新を使いたいので、ソースコードからビルドする([Rust](note/Rust.md) を事前にインストールしておく)\n\n````bash\ngit clone https://github.com/jwilm/alacritty.git\ncd alacritty\nmake app\ncp -r target/release/osx/Alacritty.app /Applications/\n````\n\n## 日本語のインライン入力ができない\n\n日本語入力に難点がある\n\n* 変換確定前の段階だとターミナル上に字が出てこない\n* 変換の際に矢印キーで選択したりbackspaceを押すと、ターミナル側の操作(ヒストリーバック、文字削除など)になってしまう\n\nこちらの方が直してくれて、マージされているのでおそらく0.10.0で解消されている。\n[Alacrittyが日本語入力がおかしいのを直した](https://komi.dev/post/2021-07-20-enabling-ime-in-alacritty/)\n\n…と思ったら中国語の入力でデグレがあったため戻っていた。逆にいうと中国語圏の人の問題が解消されれば日本語も直るのかな…？\n\u003chttps://github.com/rust-windowing/winit/pull/2119\u003e\n\n## 設定\n\n### テーマ\n\n\u003chttps://github.com/eendroroy/alacritty-theme\u003e にテーマがまとまっている。\n\n`git clone https://github.com/eendroroy/alacritty-theme.git` して、 `alacritty.yml` に以下を設定する\n\n````yml\nimport:\n  - /path/to/alacritty-theme/themes/\u003cテーマ\u003e.yml\n````\n\n### [True color](note/True%20color.md) を有効にする\n\n有効になっているか確認\n[iTerm2のテスト用コード](https://github.com/gnachman/iTerm2/blob/master/tests/24-bit-color.sh) で確認できる\n\n````bash\ncurl -s https://github.com/gnachman/iTerm2/blob/master/tests/24-bit-color.sh\n````\n\n色がなめらかにグラデーション表示されていればOK。\n段差が明らかに見て取れる場合は対応されていない。\n\nAlacrittyでtmux, NeovimのTrue colorを有効にするためには、それぞれ以下の設定が必要\n\n\u003chttps://github.com/alacritty/alacritty/issues/109\u003e\n\n````yml:$HOME/.config/alacritty/alacritty.yml\nenv:\n  TERM: alacritty\n````\n\n````conf:$HOME/.tmux.conf\nset -g default-terminal \"screen-256color\"\nset-option -sa terminal-overrides ',alacritty:RGB'\n````\n\n````vim:$HOME/.config/nvim/init.vim\nset termguicolors\n````\n\n### \n\n````yml:$HOME/.config/alacritty/alacritty.yml\n# テーマ\nimport:\n  - ~/.config/alacritty/alacritty-theme/themes/gruvbox_material.yml\n  \nenv:\n  TERM: alacritty\n\nwindow:\n  dimensions:\n    # Alacrittyを開いたときのウィンドウサイズ\n    columns: 140\n    lines: 40\n  padding:\n    # Macだと角が丸くて見切れるため余白を入れる\n    x: 8\n    y: 4\nfont:\n  normal:\n    family: \"HackGenNerd Console\"\n    style: Regular\n  bold:\n    family: \"HackGenNerd Console\"\n    style: Bold\n    family: \"HackGenNerd Console\"\n    style: Italic\n    family: \"HackGenNerd Console\"\n    style: Bold Italic\n  size: 16.0\n  \nshell:\n  # 起動時にtmuxを開く(セッションがすでにあればアタッチする)\n  program: zsh\n  args:\n    - -c\n    - \"tmux a -t 0 || tmux\"\n\nkey_bindings:\n  # modifierを使ったキーバインドがAlacrittyに奪われるため、もとのキーバインドで上書きする\n  - { key: Q, mods: Control, chars: \"\\x11\" }\n  - { key: Space, mods: Control, chars: \"\\x00\" }\n  - { key: A, mods: Alt, chars: \"\\x1ba\" }\n  - { key: B, mods: Alt, chars: \"\\x1bb\" }\n  - { key: C, mods: Alt, chars: \"\\x1bc\" }\n  - { key: D, mods: Alt, chars: \"\\x1bd\" }\n  - { key: E, mods: Alt, chars: \"\\x1be\" }\n  - { key: F, mods: Alt, chars: \"\\x1bf\" }\n  - { key: G, mods: Alt, chars: \"\\x1bg\" }\n  - { key: H, mods: Alt, chars: \"\\x1bh\" }\n  - { key: I, mods: Alt, chars: \"\\x1bi\" }\n  - { key: J, mods: Alt, chars: \"\\x1bj\" }\n  - { key: K, mods: Alt, chars: \"\\x1bk\" }\n  - { key: L, mods: Alt, chars: \"\\x1bl\" }\n  - { key: M, mods: Alt, chars: \"\\x1bm\" }\n  - { key: N, mods: Alt, chars: \"\\x1bn\" }\n  - { key: O, mods: Alt, chars: \"\\x1bo\" }\n  - { key: P, mods: Alt, chars: \"\\x1bp\" }\n  - { key: Q, mods: Alt, chars: \"\\x1bq\" }\n  - { key: R, mods: Alt, chars: \"\\x1br\" }\n  - { key: S, mods: Alt, chars: \"\\x1bs\" }\n  - { key: T, mods: Alt, chars: \"\\x1bt\" }\n  - { key: U, mods: Alt, chars: \"\\x1bu\" }\n  - { key: V, mods: Alt, chars: \"\\x1bv\" }\n  - { key: W, mods: Alt, chars: \"\\x1bw\" }\n  - { key: X, mods: Alt, chars: \"\\x1bx\" }\n  - { key: Y, mods: Alt, chars: \"\\x1by\" }\n  - { key: Z, mods: Alt, chars: \"\\x1bz\" }\n\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["terminal"]},"/note/Alpine%E3%81%ABglibc%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%99%E3%82%8B":{"title":"Alpineにglibcをインストールする","content":"\n\\#Docker\n\nAlpine Linuxにインストールされているのは glibc ではなくて musl-libc なので、適当にソフトウェアをインストールしても動かないということがたびたび発生する。\n例: AWS CLI v2、Androidのビルド\n\n## glibcをalpineにインストールする\n\n[sgerrand/alpine-pkg-glibc: A glibc compatibility layer package for Alpine Linux](https://github.com/sgerrand/alpine-pkg-glibc)\nをインストールする。\n基本的にはREADMEの通りに。\n\nalpineにglibcをインストールしたdockerイメージがあるので、そのDockerfileを参考にするとよいかも\n\n[docker-alpine-glibc/Dockerfile at master · Docker-Hub-frolvlad/docker-alpine-glibc](https://github.com/Docker-Hub-frolvlad/docker-alpine-glibc/blob/master/Dockerfile)\n\n2.35 ではバグがあり、/lib64にglibcではなくmuslのまま配置されるので、インストールしたものが動かないことがある。\n解決していなさそうなので、2.34 にバージョンを下げることで対処。\n[2.35-r0: glibc compatibility regression due to removal of /lib64 · Issue #181 · sgerrand/alpine-pkg-glibc · GitHub](https://github.com/sgerrand/alpine-pkg-glibc/issues/181)\n\n### AlpineでAndroidビルドする\n\n[GitHub - alvr/alpine-android: 🐋 Small docker image for building \u0026 testing Android applications.](https://github.com/alvr/alpine-android)\n\nhttps://github.com/bell-sw/Liberica/blob/master/docker/repos/liberica-openjdk-alpine/11/Dockerfile\n\n````Dockerfile\nARG JDK_VERSION=8\nFROM amazoncorretto:${JDK_VERSION}-alpine-jdk as jdk\n\nFROM alpine:3.16\n\n# copy jdk\nARG JDK_VERSION=8\nRUN mkdir /usr/lib/jvm\nCOPY --from=jdk /usr/lib/jvm/java-${JDK_VERSION}-amazon-corretto /usr/lib/jvm/default-jvm\n\nENV ANDROID_SDK_VERSION=8512546\n\nENV LANG=C.UTF-8\nENV ANDROID_SDK_ROOT=/opt/android-sdk\nENV JAVA_HOME=/usr/lib/jvm/default-jvm\nENV PATH=$PATH:${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin:${JAVA_HOME}/bin\n\nRUN apk --update add \\\n        bash \\\n        jq \\\n        curl\n\n# 参考: https://github.com/Docker-Hub-frolvlad/docker-alpine-glibc\n# install alpine-pkg-glibc apk and set C.UTF-8 locale as default\nRUN BASE_URL=\"https://github.com/sgerrand/alpine-pkg-glibc/releases/download\" \u0026\u0026 \\\n    VERSION=\"2.34-r0\" \u0026\u0026 \\\n    BASE_FILE=\"glibc-$VERSION.apk\" \u0026\u0026 BIN_FILE=\"glibc-bin-$VERSION.apk\" \u0026\u0026 I18N_FILE=\"glibc-i18n-$VERSION.apk\" \u0026\u0026 \\\n    wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub \u0026\u0026 \\\n    wget \"$BASE_URL/$VERSION/$BASE_FILE\" \"$BASE_URL/$VERSION/$BIN_FILE\" \"$BASE_URL/$VERSION/$I18N_FILE\" \u0026\u0026 \\\n    apk add --no-cache \"$BASE_FILE\" \"$BIN_FILE\" \"$I18N_FILE\" \u0026\u0026 \\\n    rm \"/etc/apk/keys/sgerrand.rsa.pub\" \u0026\u0026 \\\n    /usr/glibc-compat/bin/localedef --force --inputfile POSIX --charmap UTF-8 \"$LANG\" || true \u0026\u0026 \\\n    echo \"export LANG=$LANG\" \u003e /etc/profile.d/locale.sh \u0026\u0026 \\\n    apk del glibc-i18n \u0026\u0026 \\\n    rm \"$BASE_FILE\" \"$BIN_FILE\" \"$I18N_FILE\"\n\n# install Android SDK\nRUN FILE=commandlinetools-linux-${ANDROID_SDK_VERSION}_latest.zip \u0026\u0026 \\\n    mkdir -p ${ANDROID_SDK_ROOT} \u0026\u0026 \\\n    mkdir -p /tmp \u0026\u0026 \\\n    cd ${ANDROID_SDK_ROOT} \u0026\u0026 \\\n    wget https://dl.google.com/android/repository/${FILE} \u0026\u0026 \\\n    unzip ${FILE} \u0026\u0026 \\\n    rm ${FILE} \u0026\u0026 \\\n    cd cmdline-tools \u0026\u0026 \\\n    mkdir latest \u0026\u0026 \\\n    mv * latest/ \u0026\u0026 \\\n    mkdir -p ~/.android \u0026\u0026 \\ touch ~/.android/repositories.cfg \u0026\u0026 \\\n    (yes || true) | sdkmanager --licenses\n    \n````\n\n## 参考\n\n[AWS CLI v2 で alpine glibc 問題に遭遇 - vague memory](https://htnosm.hatenablog.com/entry/2020/05/04/090000)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Docker"]},"/note/AmasonSNS%E3%81%A7%E9%85%8D%E4%BF%A1":{"title":"AmasonSNSで配信","content":"\n\\#AWS\n\n[AWS Lambdaを使ったAmazon SNSへのメッセージ送受信](https://business.ntt-east.co.jp/content/cloudsolution/column-try-29.html)\nAmazon Simple Notification Service(SNS)へメッセージを送信するLambdaとAmazon SNSから配信されるメッセージを受信するLambdaの作成手順を解説します。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["AWS"]},"/note/Amazon-EFS":{"title":"Amazon EFS","content":"\n[Amazon EFS パフォーマンス - Amazon Elastic File System](https://docs.aws.amazon.com/ja_jp/efs/latest/ug/performance.html)\n\n## スループットモードについて\n\n[NEW – Amazon EFS Elastic Throughput の発表 | Amazon Web Services ブログ](https://aws.amazon.com/jp/blogs/news/new-announcing-amazon-efs-elastic-throughput/)\n\n \u003e \n \u003e 新しいスループットモードで、アプリケーションに必要なだけのスループットを従量制料金で提供するように設計されています。この新しいスループットモードでは、プロビジョニングやキャパシティ管理を必要としない共有ファイルストレージを提供することで、AWS でのワークロードとアプリケーションの実行をさらに簡素化できます。\n \u003e Elastic Throughput は、予測が困難なパフォーマンス要件を伴い、かつ、急激に増減する予測不可能なワークロードに最適です。\n\n2022/11に新しいスループットモード Elastic Throughputが発表された。プロビジョニングしなくても、アプリケーションが必要とするスループットパフォーマンスを自動で決定してくれる。予測が難しいときにはこれを選ぶのがいいみたい。\n\n \u003e \n \u003e アプリケーションのスループットが Bursting モードで制限されている場合 (例えば、許容スループットの 80% 超を使用している、またはバーストクレジットを使い果たしている)、Provisioned モード ([2018 年に発表](https://aws.amazon.com/blogs/aws/new-provisioned-throughput-for-amazon-elastic-file-system-efs/)) または新しい Elastic Throughput モードの使用をご検討ください。\n\n[Amazon EFS バーストクレジットを理解する](https://aws.amazon.com/jp/premiumsupport/knowledge-center/efs-burst-credits/)\n\n### Bursting Throughput\n\nFile-based workloads are typically spiky, driving high levels of throughput for short periods, but driving lower levels of throughput for longer periods. Amazon EFS is designed to burst to high throughput levels for periods of time.\n\nAmazon EFS uses a credit system that determines when file systems can burst. If the credit balance of your file system drops to zero, then your permitted throughput rate drops to your baseline throughput. When driving at baseline throughput, you use credits at the same rate you earn them.\n\nEFSの読み書きの高低差が激しい利用方法の場合に、利用されているスループットがベースラインを下回っている期間、クレジットとして性能を蓄積していく。スループットが大きいときは蓄積したクレジットを使って性能を上げる\nCloudWatch の BurstCreditBalance のメトリクスで見ることができる。\n\nbaseline rate is 50 MiBps per tebibyte \\[TiB\\] of storage (equivalent to 50 KiBps per GiB of storage). Amazon EFS meters read operations up to one-third the rate of write operations, permitting the file system to drive a baseline rate up to 150 KiBps per GiB of read throughput, or 50 KiBps per GiB of write throughput.\n\nベースラインはデータ量に応じて決まる。データ量1GiBあたり50KiB/sの読み書きがベースラインとなる。\nただしreadはwriteの1/3で計算される。\n\n### Provisioned Throughput\n\nWith Provisioned Throughput mode, you can instantly provision the throughput of your file system independent of the amount of data stored\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/02/09","AWS"]},"/note/AmazonSNS":{"title":"AmazonSNS","content":"\n\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["AWS"]},"/note/AmazonSNS%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E9%85%8D%E4%BF%A1":{"title":"AmazonSNSを使った配信","content":"\n\\#AWS \n\n[Amazon SNSでプッシュ通知を送るための基礎知識 | UNITRUST](https://www.unitrust.co.jp/6182)\n\nAmazon Simple Notification Serviceの略。\n\nAWS内のモバイル通知サービスで、iOSやAndroidの端末にPUSH通知が可能。\n\n一回のリクエストで大量のユーザーに配信でき、実行速度も速い。\n\n## エンドポイント\n\nAmazonSNSにおいては、配信対象端末を識別するためのデータ。メールアドレスのようなもの。\n\nデバイストークン（PUSHトークン）から作られる、端末を識別するためのARN。\n\nデバイストークンを登録すると、エンドポイントが作成される。\n\n配信の際には、作成されたエンドポイントを指定して対象の端末へ配信する。\n\nエンドポイントには「デバイストークン」「エンドポイントのARN」「通知の許可が下りているか」などの情報が含まれる。\n\n## トピック\n\n配信対象をグルーピングし、一斉に通知を配信するための機能。\nトピックにはエンドポイントを登録できる。\nトピックを作成し、エンドポイントを登録した後、トピックに対して送信したいメッセージを発行すると、トピックに登録されているエンドポイントへ一斉にPUSH配信できる。\n\n## サブスクリプション\n\nトピックと配信対象のエンドポイントを結びつけるデータ。\n\n（サブスクリプションを作成 ＝ トピックにエンドポイントを登録）\n\nサブスクリプションによってトピックにエンドポイントが紐付けられることで、トピックに対してメッセージを送信すると、そのトピックに紐づく配信対象のエンドポイントへメッセージが配信される。\n\n「トピックに発行されたメッセージをエンドポイントが購読できる」というイメージ。\n\n## パブリッシュ（発行）\n\nPUSHを配信すること。\n\nAmazonSNSにおいてPUSH配信は、エンドポイントやトピックに対してメッセージを発行する形をとっている。\n\n## アプリケーションプラットフォーム\n\nアプリごとの、PUSH通知に利用するプラットフォームの設定。\n\niOSなら「Apple Production」、「Apple Development」。\n\nAndroidなら「Google Cloud Messaging(GCM)」。\n\nエンドポイントはアプリケーションに紐づいて登録・管理される。\n\nアプリケーションからエンドポイントを選択して個別にPUSH配信できる。\n\n個別のエンドポイントへ配信はアプリケーションで可能だが、配信の度に対象を選択するのは手間がかかる。この手間を解消するのがトピック。\n\n## フロー\n\n1. アプリ起動時にプラットフォームへプッシュ通知の許可を送る\n1. アプリはプラットフォームから発行されたトークンを受け取る\n1. アプリは受け取ったトークンをコンテンツへ送信\n1. サーバーはAPIを利用してトークンをAmazonSNSに登録し、エンドポイントを作成する\n1. エンドポイントが作成されたら、サーバーからAPIを利用 or AmazonSNSから直接、トピックにエンドポイントをサブスクライブし、トピックにメッセージを発行\n1. PUSH通知が配信される\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":[]},"/note/AmazonSQS":{"title":"AmazonSQS","content":"\n\\#AWS\n\n# Amazon Simple Queue Service (Amazon SQS)\n\n\u003chttps://docs.aws.amazon.com/ja_jp/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html\u003e\n\nフルマネージドのキューサービス\n\nキューを使った非同期処理の実現\n\n## 標準キューとFIFOキュー\n\n[AWS — Difference between SQS Standard and FIFO Queues | by Ashish Patel | Awesome Cloud | Medium](https://medium.com/awesome-cloud/aws-difference-between-sqs-standard-and-fifo-first-in-first-out-queues-28d1ea5e153)\n\n \u003e \n \u003e FIFO queues have essentially the same features as standard queues, but provide the added benefits of supporting ordering and exactly-once processing and ensure that the order in which messages are sent and received is strictly preserved.\n\n* 標準キュー\n  * スループットが高い\n  * At-Least-Once Delivery: 一回の実行が保証される。ただし、複数回実行される可能性がある\n  * Best effort ordering\n  * 120,000件まで\n* FIFOキュー\n  * 先入れ先出し\n  * Exactly-Once Delivery\n  * Limited Throughput\n  * 20,000件まで\n\nキューの処理が以下の場合は標準キューを採用、それ以外はFIFOキューを採用\n\n* 順序性に依存しない\n* 処理の重複を許容できる\n\n## メッセージ\n\nサイズ上限は256KBまで\n\n## 遅延キュー\n\nhttps://docs.aws.amazon.com/ja_jp/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html\n\nキューへの新しいメッセージを0~900秒遅延できる\n遅延時間の間、コンシューマには表示されなくなる\n\nメッセージ個別の `DelaySeconds` も設定できるが、FIFOキューでは使用不可\n\n## 用語\n\n### 可視性タイムアウト\n\n設定した期間、重複したメッセージ配信が行われないようにする機能\nベストプラクティスとして、後続処理時間+アルファを設定すると良い\n\n### ショートポーリングとロングポーリング\n\nキューからのメッセージ取得(サブスクライブ)の際、対象のキューがない場合、\n一定時間キューに新規登録されるメッセージを待機かどうかの機能\n\n待機を行うことをロングポーリング、待機を行ないことをショートポーリングと言う\n「メッセージ受信待機時間」にて設定\n\n### デットレターキュー\n\nバグったデータを別キューに格納する機能\nCloudwatchと連携し、デバッグに使用できる。\n「最大受信数」にて設定したメッセージを受信数後、デッドレターキューに移動される\n※最大メッセージサイズ：値は 1～256 KB の間である必要があります\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["AWS"]},"/note/Argo-Rollouts%E3%81%A7%E9%80%9A%E7%9F%A5%E3%81%95%E3%81%9B%E3%82%8B":{"title":"Argo Rolloutsで通知させる","content":"\n* argo-rollouts 1.4.0 で、デプロイ失敗時にslack通知が来なかった\n* argo-rolloutsのバージョンを以前の1.2.1に戻してもslack通知がこないのでアップデート起因ではない。\n* 「エラーになったカラーのPodが落ちてくれない」みたいなことがconfluenceに書いてあったが、落ちてくれてそう。0.10.2時点の調査内容っぽいので今は挙動が変わったか\n* argocd-notificationsのApplicationが残っていてややこしかったので削除しよう\n* \u003chttps://argocd-notifications.readthedocs.io/en/stable/triggers/#avoid-sending-same-notification-too-often\u003e 通知減らしたいなあ\n* `manifest/argocd/install/overlays/prod/appproject.yaml` で `notifications.argoproj.io/subscribe.` に `on-degraded` が設定されていないから通知こないんだな\n\n## Argo CD Notifications\n\nhttps://argocd-notifications.readthedocs.io/en/stable/\n\n* 以前はArgo CDとは別でNotifications用のhelmをインストールしていたが、現在はArgo CD本体のhelmに取り込まれている\n* Triggerは、自分で `argocd-notifications-cm` ConfigMapに `trigger.on-XXX` の形で定義する\n  * カタログがこちらに https://argocd-notifications.readthedocs.io/en/stable/catalog/\n* statusがDegradedになったらargocd-notificationsで通知が来るよう設定するには、Triggerを作ってApplicationのsubscriptionに登録する\n\n````\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  annotations:\n    notifications.argoproj.io/subscribe.on-sync-succeeded.slack: my-channel1;my-channel2\n    notifications.argoproj.io/subscribe.on-degraded.slack: my-channel1;my-channel2\n````\n\n### ConfigMap\n\nhttps://github.com/argoproj/argo-rollouts/blob/master/manifests/notifications-install.yaml\nこちらをインポートし、 `argo-rollouts-notification-configmap` ConfigMapでtriggerやtemplateを設定する\n\noverlaysや、上記yamlをダウンロードして追記する形でslackのトークンを設定する\n\n````yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argo-rollouts-notification-configmap\ndata:\n  service.slack: |\n    token: $slack-token\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: argo-rollouts-notification-secret\nstringData:\n  slack-token: \u003cmy-slack-token\u003e\n````\n\nRolloutのannotationsに、subscribeを設定する\n\n````yaml\napiVersion: argoproj.io/v1alpha1\nkind: Rollout\nmetadata:\n  name: solr\n  annotations:\n    notifications.argoproj.io/subscribe.on-analysis-run-error.slack: \"#bot_alert\"\n    notifications.argoproj.io/subscribe.on-analysis-run-failed.slack: \"#bot_alert\"\n    notifications.argoproj.io/subscribe.on-analysis-run-running.slack: \"#bot_alert\"\n    notifications.argoproj.io/subscribe.on-rollout-aborted.slack: \"#bot_alert\"\n    notifications.argoproj.io/subscribe.on-rollout-completed.slack: \"#bot_info\"\n    notifications.argoproj.io/subscribe.on-rollout-paused.slack: \"#bot_info\"\n    notifications.argoproj.io/subscribe.on-rollout-step-completed.slack: \"#bot_info\"\n    notifications.argoproj.io/subscribe.on-rollout-updated.slack: \"#bot_info\"\nspec:\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/02/28","Kubernetes"]},"/note/Atomic-Notes":{"title":"Atomic Notes","content":"\nhttps://jmatsuzaki.com/archives/26915\n\n \u003e \n \u003e Atomic Notesとは何かを端的に説明すると、**1枚のノートをこれ以上不可分な単位と考えられる極小のサイズまで削り、原子性（Atomic）を保つこと**です。\n\nAtomic Designぽくて好き\n\n原子性を保つことで再利用性が高まることは理解しやすい\n\n再利用しやすいとノート同士のリンクがしやすくなる。参照が頻繁に行われ、定着しやすくなる。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["memo"]},"/note/Automator":{"title":"Automator","content":"\nMacの操作を自動化するワークフローなどが作れる。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/05/09","Mac"]},"/note/Aws%E3%81%AE%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%83%90%E3%83%83%E3%83%81%E5%87%A6%E7%90%86%E3%81%99%E3%82%8B":{"title":"Awsのサービスを使ってバッチ処理する","content":"\n\\#AWS\n\n[AmazonSQS](note/AmazonSQS.md), [AWS Lambda](note/AWS%20Lambda.md), [AmazonSNS](note/AmazonSNS.md) を使ってバッチ処理によるPUSH送信を実現する\n\n* [AWSでバッチ処理を実装する際の選択肢とサービス比較](https://zenn.dev/faycute/articles/fb310e3ccd783f)\n* [\\[レポート\\] SNSとSQSとLambdaによるスケーラブルでサーバーレスなイベント駆動アーキテクチャ \\#reinvent \\#svs303 | DevelopersIO](https://dev.classmethod.jp/articles/reinvent2020-svs303-scalable-serverless-event-driven-architectures-with-sns-sqs-lambda/)\n* [SQSトリガーを使って15分ごとに繰り返し実行する運用ジョブを作成する – サーバーワークス サポートセンター](https://support.serverworks.co.jp/hc/ja/articles/360009321134-SQSトリガーを使って15分ごとに繰り返し実行する運用ジョブを作成する)\n* [【AWS】lambdaとSQSを利用してバッチ処理が可能か試してみました | eyeon -アイオン-](https://www.k-friendly.com/541)\n* [Amazon SNSでプッシュ通知を送るための基礎知識 | UNITRUST](https://www.unitrust.co.jp/6182)\n  \\[\\[\\]\\]\n\n## SQSを遅延実行する\n\n\u003chttps://docs.aws.amazon.com/ja_jp/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html\u003e\n\u003chttps://docs.aws.amazon.com/ja_jp/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-message-timers.html\u003e\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["AWS"]},"/note/Bash%E3%83%87%E3%83%90%E3%83%83%E3%82%B0%E5%AE%9F%E8%A1%8C":{"title":"Bashデバッグ実行","content":"\nhttps://qiita.com/mashumashu/items/ee436b770806e8b8176f\n\n````shell\n#!/bin/bash\n\ntrap 'read -p \"$0($LINENO) $BASH_COMMAND\"' DEBUG\n\necho foo\necho bar\nif [ \"$1\" = \"yes\" ]; then\n  echo bazz\nfi\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":[]},"/note/Bazel":{"title":"Bazel","content":"\nGoogleが開発したビルドツール\n\nStarlark というBazelのためにデザインされた [Python](note/Python.md) の方言を用いてビルドのルールを記述するのが特徴で、\nコンパイラの呼び出しのような低レベルな処理を記述する [Make](note/Make.md) などの既存のビルドツールに比べて、高レベルな言語を用いてルールを記述できるのが強みの1つです。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":[]},"/note/Bitbucket-Pipelines%E3%81%A7master%E3%83%96%E3%83%A9%E3%83%B3%E3%83%81%E3%81%A8%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E6%AF%94%E8%BC%83%E3%82%92%E3%81%97%E3%81%9F%E3%81%84":{"title":"Bitbucket Pipelinesでmasterブランチとファイル比較をしたい","content":"\npipelineで、masterブランチとのファイル比較をしようとして、masterをcheckoutした\n\n````yaml\ndefault:\n  step:\n    - git remote -v\n    - git branch -a\n    - git fetch origin\n    - git checkout master\n    - git diff master...${BITBUCKET_BRANCH}\n````\n\nするとエラーになった。masterブランチがfetchできていない\n\n````\norigin  git@bitbucket.org:foo/repo (fetch)\norigin  git@bitbucket.org:foo/repo (push)\n\nfeature/bar\nremote/origin/feature/bar\n\nerror: pathspec 'master' did not match any file(s) known to git.\n````\n\n解決策は2つ\n[Solved: Can't checkout master on a branch pipeline](https://community.atlassian.com/t5/Bitbucket-questions/Can-t-checkout-master-on-a-branch-pipeline/qaq-p/1004778)\n\n`clone.depth: full` をつける\n\n````yaml\nclone:\n  depth: full\n  \npipelines:\n  default:\n    - step:\n        name: Cloning\n        script:\n          - echo \"Clone all the things!\"\n````\n\n`git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\"` をstep内で行う\n\n````yaml\nclone:\n  depth: full\n  \npipelines:\n  default:\n    - step:\n      script:\n        - git config remote.origin.fetch \"+refs/heads/*:refs/remotes/origin/*\"\n        - git fetch origin\n        - git checkout --track origin/master\n\n````\n\nこれでファイル比較できるようになった\n\n````yaml\nclone:\n  depth: full\n\npipelines:\n  default:\n    step:\n      - git remote -v\n      - git branch -a\n      - git fetch origin\n      - git checkout master\n      - git diff master...${BITBUCKET_BRANCH}\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/03/28"]},"/note/CI%E3%83%97%E3%83%A9%E3%83%83%E3%83%88%E3%83%95%E3%82%A9%E3%83%BC%E3%83%A0%E3%81%AEDagger%E3%82%92%E8%A9%A6%E3%81%99":{"title":"CIプラットフォームのDaggerを試す","content":"\n\\#CICD\n\n[Overview | Dagger](https://docs.dagger.io/)\n[CI・CD界隈期待の星!!Daggerに入門してローカルとGithubActionsでCIを動かしてみた | DevelopersIO](https://dev.classmethod.jp/articles/dagger_cicd_get_started/)\n\nポータブルなCI/CDパイプライン devkit\nDockerコンテナ上で実行されて、どこでも動かすことができる\n\n* CI/CDサービス固有の記法を学習する必要があり、移行の際には書き換えが必要\n* ローカルで試しにくく、commit \u0026 pushしては動くか確認する作業が発生\n* YAMLが辛い\n\nDagger はプラットフォーム非依存でCUE言語を使って書けるのが良さそう。\nローカルで実行できるっていうのも大きい\n\n* CUE言語がそんなにまだメジャーでない\n  * IaCでたまに見るかな？Go には公式のparserがある\n* まだメジャーバージョン0系で開発途上\n\n## インストール\n\nmacはHomebrewでもインストールできる\n\ninstall.sh を使ってインストールすることもできる\n\n````shell\ncurl -L https://dl.dagger.io/dagger/install.sh | DAGGER_VERSION=0.2.19 sh\n\n./bin/dagger version\ndagger 0.2.19 (GIT_SHA) darwin/arm64\n````\n\n## サンプル\n\n````shell\ngit clone https://github.com/dagger/todoapp\ncd todoapp\ndagger project update\ndagger do build\n````\n\n## 使ってみる\n\nhello.cue\n\n````go\npackage main\n\nimport (\n    \"dagger.io/dagger\"\n    \"dagger.io/dagger/core\"\n)\n\n// Write a greeting to a file, and add it to a directory\n#AddHello: {\n    // The input directory\n    dir: dagger.#FS\n\n    // The name of the person to greet\n    name: string | *\"world\"\n\n    write: core.#WriteFile \u0026 {\n        input: dir\n        path: \"hello-\\(name).txt\"\n        contents: \"hello, \\(name)!\"\n    }\n\n    // The directory with greeting message added\n    result: write.output\n}\n\ndagger.#Plan \u0026 {\n    // Say hello by writing to a file\n    actions: hello: #AddHello \u0026 {\n        dir: client.filesystem.\".\".read.contents\n        name: \"hey\"\n    }\n    client: filesystem: \".\": {\n        read: contents: dagger.#FS\n        write: contents: actions.hello.result\n    }\n}\n````\n\n````shell\ndagger project init\ndagger project update\n\ndagger do hello\n````\n\n`dagger project update` を実行すると、 `./cue.mod` が更新される\ngo get したときに `$GOPATH/pkg/mod` にソースがダウンロードされるが、それと同じように `./cue.mod` に置かれる\n\n## Actions\n\nActions が基本的な要素となる\n4つのライフサイクルがある\n\n* Definition\n* Integration\n* Discovery\n* Execution\n\npipelines と steps のような区別がなく、全てをActionで定義できる\n定義済みのActionを他のActionからサブアクションとして呼び出せる\n\n公式の説明で使われているDefinition\n\n````go\n// Write a greeting to a file, and add it to a directory\n#AddHello: {\n    // The input directory\n    dir: dagger.#FS\n\n    // The name of the person to greet\n    name: string | *\"world\"\n\n    write: core.#WriteFile \u0026 {\n        input: dir\n        path: \"hello-\\(name).txt\"\n        contents: \"hello, \\(name)!\"\n    }\n\n    // The directory with greeting message added\n    result: write.output\n}\n````\n\nここでは `core.#WriteFile` という core で定義済みの Action を `#AddHello` の中で呼び出している\n\n## Integration\n\n全てのパイプラインは `dagger.#Plan` definition で定義される\n\n`dagger do --help` を実行すると、定義済みの Action 一覧が出力される\n\n````shell\n$ ./dagger do --help\nUsage:\n  dagger do \u003caction\u003e [subaction...] [flags]\n\nOptions\n\n\nAvailable Actions:\n hello Say hello by writing to a file\n````\n\n## AWS SAMのデプロイのサンプル\n\n\u003chttps://docs.dagger.io/1248/aws-sam\u003e\nsam用のActionがimportして使用できる\n\nzipをデプロイするパターン\n\n````go\npackage samZip\n\nimport (\n    \"dagger.io/dagger\"\n    \"universe.dagger.io/alpha/aws/sam\"\n)\n\ndagger.#Plan \u0026 {\n    _common: config: sam.#Config \u0026 {\n        accessKey: client.env.AWS_ACCESS_KEY_ID\n        region:    client.env.AWS_REGION\n        bucket:    client.env.AWS_S3_BUCKET\n        secretKey: client.env.AWS_SECRET_ACCESS_KEY\n        stackName: client.env.AWS_STACK_NAME\n    }\n\n    client: {\n        filesystem: \"./\": read: contents: dagger.#FS\n        env: {\n            AWS_ACCESS_KEY_ID:     string\n            AWS_REGION:            string\n            AWS_S3_BUCKET:         string\n            AWS_SECRET_ACCESS_KEY: dagger.#Secret\n            AWS_STACK_NAME:        string\n        }\n    }\n\n    actions: {\n        build: sam.#Package \u0026 _common \u0026 {\n            fileTree: client.filesystem.\"./\".read.contents\n        }\n        deploy: sam.#DeployZip \u0026 _common \u0026 {\n            input: build.output\n        }\n    }\n}\n````\n\nDockerイメージをデプロイするパターン\n\n````go\npackage samImage\n\nimport (\n    \"dagger.io/dagger\"\n    \"universe.dagger.io/alpha/aws/sam\"\n)\n\ndagger.#Plan \u0026 {\n    _common: config: sam.#Config \u0026 {\n        accessKey:    client.env.AWS_ACCESS_KEY_ID\n        region:       client.env.AWS_REGION\n        secretKey:    client.env.AWS_SECRET_ACCESS_KEY\n        stackName:    client.env.AWS_STACK_NAME\n        clientSocket: client.network.\"unix:///var/run/docker.sock\".connect\n    }\n\n    client: {\n        filesystem: \"./\": read: contents: dagger.#FS\n        network: \"unix:///var/run/docker.sock\": connect: dagger.#Socket\n        env: {\n            AWS_ACCESS_KEY_ID:     string\n            AWS_REGION:            string\n            AWS_SECRET_ACCESS_KEY: dagger.#Secret\n            AWS_STACK_NAME:        string\n        }\n    }\n\n    actions: {\n        build: sam.#Build \u0026 _common \u0026 {\n            fileTree: client.filesystem.\"./\".read.contents\n        }\n        deploy: sam.#Deployment \u0026 _common \u0026 {\n            input: build.output\n        }\n    }\n}\n````\n\n## Jenkins上で利用する\n\nJenkinsにdocker、daggerをインストールしておく\n\n````groovy\npipeline {\n  agent any\n  environment {\n    NAME='John'\n  }\n  stages {\n    stage(\"setup\") {\n      steps {\n        sh '''\n          # インストールずみなら不要\n          curl -L https://dl.dagger.io/dagger/install.sh | sh\n        \n          ./bin/dagger project init\n          ./bin/dagger project update\n        '''\n      }\n    }\n    stage(\"do\") {\n      steps {\n        sh '''\n        cat \u003c\u003c EOF \u003e dagger.cue\n        package main\n        \n        import (\n            \"dagger.io/dagger\"\n            \"dagger.io/dagger/core\"\n        )\n        \n        // Write a greeting to a file, and add it to a directory\n        #AddHello: {\n            // The input directory\n            dir: dagger.#FS\n            \n            name: string | *\"world\"\n\n            write: core.#WriteFile \u0026 {\n                input: dir\n                path: \"hello-\\\\(name).txt\"\n                contents: \"hello, \\\\(name)!\"\n            }\n        \n            // The directory with greeting message added\n            result: write.output\n        }\n        \n        dagger.#Plan \u0026 {\n            // Say hello by writing to a file\n            actions: hello: #AddHello \u0026 {\n                dir: client.filesystem.\".\".read.contents\n                name: client.env.NAME\n            }\n            client: {\n                filesystem: \".\": {\n                    read: contents: dagger.#FS\n                    write: contents: actions.hello.result\n                }\n                env : {\n                    NAME: string\n                }\n            }\n        }\n\n        EOF\n        \n        ./bin/dagger do hello\n        '''.stripIndent()\n      }\n    }    \n  }\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["CICD"]},"/note/CORS":{"title":"CORS","content":"\n[CORSの仕様はなぜ複雑なのか](https://zenn.dev/qnighy/articles/6ff23c47018380)\n\nSame-origin policy (SOP)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["frontend"]},"/note/CPU%E3%81%AEx86%E3%82%84arm%E3%81%A3%E3%81%A6%E3%81%AA%E3%81%AB":{"title":"CPUのx86やarmってなに","content":"\n[CPU と命令セットってなに？｜M1 Mac ってなに？ ぼくにも使える？](https://zenn.dev/suzuki_hoge/books/2021-07-m1-mac-4ede8ceb81e13aef10cf)\n\n* アーキテクチャ、命令セット\n  * x86: Intel,AMDの32bitアーキテクチャ\n  * x64(x86_64): x86を64bitに拡張したもの\n  * arm: ARM社のアーキテクチャ\n* x86, x86_64\n  * Intel: Core i7\n  * AMD: Ryzen\n    * AMD社の64bit命令セットはAMD64\n* ARM \n  * ARM社のアーキテクチャの総称\n  * 安価で省電力\n  * 64bit拡張のARMv8がある\n  * ARMv8の実行モードにAArch32とAArch64がある\n  * AArch64 = ARM64\n* Apple Silicon\n  * Apple社が開発したARMアーキテクチャのチップ\n\n## [Graviton](https://aws.amazon.com/jp/ec2/graviton/)\n\n* AWS Graviton プロセッサは、Amazon EC2 で実行されるクラウドワークロードに最高の料金パフォーマンスを提供するために AWS によって設計されています\n* AWS EC2 のインスタンスで Arm アーキテクチャーを使用している\n* コスト面やパフォーマンス面でも従来のインスタンスを上回る\n* M6gやC6gなどのインスタンスタイプがある\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":[]},"/note/CSS%E3%81%A7%E3%83%89%E3%83%83%E3%83%88%E7%B8%A6%E7%B7%9A%E3%82%92%E3%81%A4%E3%81%8F%E3%82%8B":{"title":"CSSでドット縦線をつくる","content":"\n\\#css\n\n\u003chttps://developer.mozilla.org/ja/docs/Web/CSS/radial-gradient()\u003e\n\u003chttps://www.esz.co.jp/blog/2766.html\u003e\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["css"]},"/note/CentOS7%E3%81%A8AmazonLinux2%E3%81%AEDocker%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%81%A7%E6%97%A5%E6%9C%AC%E8%AA%9E%E3%83%AD%E3%82%B1%E3%83%BC%E3%83%AB%E3%82%92%E8%A8%AD%E5%AE%9A%E3%81%99%E3%82%8B":{"title":"CentOS7とAmazonLinux2のDockerコンテナで日本語ロケールを設定する","content":"\nJavaのDateFormatterで、曜日を日本語表示しようとしたときに、ja_JPロケールが入っておらずできなかったので、方法を調べた。\n\n## CentOS7\n\n参考:\n\n* [CentOS 7 コンテナに消えない日本語ロケールを追加する - Qiita](https://qiita.com/teruo-oshida/items/08cb84efc2b581b0a439)\n* [CentOSで日本語ロケール設定にするDockerfile - BLOG - siwa32.com](https://blog.siwa32.com/docker_centos_ja/)\n\nDockerのcentos7はデフォルトではja_JPのロケールが入っていない。\n\n````shell\n$ locale -a | grep ja | wc -l\n0\n````\n\n`/etc/yum.conf` に以下の設定が入っていることで、localeがen_US.utf8に制限されているためこれをいじればよい。\n\n````conf\noverride_install_langs=en_US.utf8\n````\n\n`override_install_langs` の設定を消すか、 ja_JP.utf8 を追加するのだが、消すと使わないロケールもすべて入ってしまうので、追加するほうがいいだろう\n\n````shell\n$ sed -i -e '/override_install_langs/s/$/,ja_JP.utf8/g' /etc/yum.conf\n````\n\nこの設定をしたあとでglibcを更新すると、ja_JPが使えるようになる\n\n````shell\n$ yum reinstall -y glibc-common\n$ locale -a | grep ja\nja_JP\nja_JP.eucjp\nja_JP.ujis\nja_JP.utf8\njapanese\njapanese.euc\n````\n\nDockerfile\n\n````Dockerfile\nFROM centos:7\n\nRUN sed -i -e '/override_install_langs/s/$/,ja_JP.utf8/g' /etc/yum.conf\nRUN yum reinstall -y glibc-common \u0026\u0026 yum clean all\n\nENV LANG ja_JP.UTF-8\n\nCMD [\"bash\"]\n````\n\nときどき `yum update -y \u0026\u0026 yum reinstall -y glibc-common` をしているDockerfileを見かけて、どういう意味があるんだろーと思っていたので謎がとけた\n\n## AmazonLinux2\n\n現在のLocaleを確認\n\n````shell\n$ localectl status\nSystem Locale: LANG=en_US.UTF-8×Dismiss this alert.\n````\n\nLocaleで設定できる値を確認\n\n````shell\n$ localectl list-locales\n````\n\nLocaleを変更\n\n````shell\n$ localectl set-locale LANG=ja_JP.utf8\n````\n\n### Dockerコンテナ\n\n参考:\n\n* [AmazonLinux2のDockerイメージに日本語ローケルを設定してみました。 - Qiita](https://qiita.com/yuyj109/items/a56e562599972eb37abd)\n\nDockerコンテナ内でlocalectlを打つと、privilegedでないと `Failed to create bus connection` というエラーが出るので、別のやり方でインストールする。\n\nyumで `glibc-langpack-ja` があるので、こちらをインストールする\n\n````shell\n$ yum install -y glibc-langpack-ja\n...\nInstalled:\n  glibc-langpack-ja.x86_64 0:2.26-27.amzn2.0.4                                                                                                                                                              \n\nComplete!\n\n$ locale -a | grep ja\nja_JP.eucjp\nja_JP.utf8\n\n$ export LANG='ja_JP.utf8'\n$ locale\nLC_CTYPE=\"ja_JP.utf8\"\nLC_NUMERIC=\"ja_JP.utf8\"\nLC_TIME=\"ja_JP.utf8\"\nLC_COLLATE=\"ja_JP.utf8\"\nLC_MONETARY=\"ja_JP.utf8\"\nLC_MESSAGES=\"ja_JP.utf8\"\nLC_PAPER=\"ja_JP.utf8\"\nLC_NAME=\"ja_JP.utf8\"\nLC_ADDRESS=\"ja_JP.utf8\"\nLC_TELEPHONE=\"ja_JP.utf8\"\nLC_MEASUREMENT=\"ja_JP.utf8\"\nLC_IDENTIFICATION=\"ja_JP.utf8\"\nLC_ALL=\n\n````\n\nDockerfile\n\n````Dockerfile\nFROM amazonlinux:2\n\nRUN yum install -y glibc-langpack-ja \u0026\u0026 yum clean all\nENV LANG ja_JP.utf8\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/04/04","Linux"]},"/note/CloudFront":{"title":"CloudFront","content":"\n\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["AWS"]},"/note/Confluence-REST-API%E3%81%A7%E3%83%9A%E3%83%BC%E3%82%B8%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E7%A7%BB%E5%8B%95":{"title":"Confluence REST APIでページをまとめて移動","content":"\n2022-10-20現在、Confluenceのページを一括で移動するような機能はないみたい\n\nhttps://community.atlassian.com/t5/Confluence-questions/How-do-I-bulk-delete-or-move-pages-in-cloud-Confluence/qaq-p/1634378\n\nなので作った\n\n````shell\nparent_page_id=$1\ntarget_page_id=$2\nchild_pages=$(curl -u ${user_email}:${password} \"${CONFLUENCE_BASE_URL}/content/${parent_page_id}/child/page\")\necho $child_pages | jq -c '.results[]' | while read -r arr; do\n  page_id=$(echo $arr | jq -r '.id')\n  curl -u ${user_email}:${password} -XPUT \"${CONFLUENCE_BASE_URL}/content/${page_id}/move/append/${target_page_id}\"\ndone\n\n````\n\nページのコピーはこちら\n[Confluence REST APIでページをコピー](note/Confluence%20REST%20APIでページをコピー.md)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":[]},"/note/Confluence-REST-API%E3%81%A7%E3%83%9A%E3%83%BC%E3%82%B8%E3%82%92%E3%82%B3%E3%83%94%E3%83%BC":{"title":"Confluence REST APIでページをコピー","content":"\n\\#confluence\n\n定期開催されるミーティングの議事録を作るのを簡略化したかった。\n前回の議事録をコピーして追記していくスタイルだったため、\nあるページ配下の最新のページ(=前回の議事録)をコピーしてタイトルを変えるスクリプトをREST APIを使って作った。\n\nhttps://developer.atlassian.com/cloud/confluence/rest/v1/api-group-content---children-and-descendants/#api-wiki-rest-api-content-id-copy-post\n\n````shell\nfunction copy_latest_page() {\n  local parent_page_id=$1\n  local page_title=$2\n\n  # parent_page配下の最新のページタイトル、IDを取得 (ページネーションは考えず雑に)\n  local previous_page=$(curl -u ${user_email}:${password} \"https://${YOUR_CONFLUENCE_DOMAIN}/wiki/rest/api/content/${parent_page_id}/child/page\" | jq -r '.results[] | .title + \",\" + .id' | sort | tail -n 1)\n  local previous_page_id=$(echo $latest_page | cut -d ',' -f 2)\n  if [[ -z \"${previous_page_id}\" ]]; then\n    echo \"previous page is not found\"\n    exit 1\n  fi\n\n  local copy_body=$(cat \u003c\u003c EOS\n{\n  \"pageTitle\": \"${page_title}\",\n  \"copyAttachments\": true,\n  \"destination\": {\n    \"type\": \"parent_page\",\n    \"value\": \"${parent_page_id}\"\n  }\n}\nEOS\n  )\n  copy_body=$(echo $copy_body | jq -c)\n\n  local copy_result=$(curl -u ${user_email}:${password} -XPOST -f -H 'X-Atlassian-Token: no-check' -H 'Content-Type: application/json' \"https://${YOUR_CONFLUENCE_DOMAIN}/wiki/rest/api/content/${previous_page_id}/copy\" -d \"${copy_body}\" )\n\n  local retval=$?\n\n  # copyAttachments=true にすると画像が多いページではコピーに時間がかかりタイムアウトするので、その場合はコピー完了したかをポーリングで確認する\n  if [[ ! $retval -eq 0 || -z $copy_result ]]; then\n    i=0\n    while [[ $i -lt 10 ]]; do\n      echo \"waiting... $i\"\n      local latest_page=$(curl -u ${user_email}:${password} \"https://${YOUR_CONFLUENCE_DOMAIN}/wiki/rest/api/content/${parent_page_id}/child/page\" | jq -r '.results[] | .title + \",\" + .id' | sort | tail -n 1)\n      local latest_page_title=$(echo $latest_page | cut -d ',' -f 1)\n      local latest_page_id=$(echo $latest_page | cut -d ',' -f 2)\n\n      if [[ \"${latest_page_title}\" = \"${page_title}\" ]]; then\n        copied_page_id=${latest_page_id}\n        break\n      fi\n      \n      sleep 30s\n      i=$((i+1))\n    done\n\n  else\n    copied_page_id=$(echo $copy_result | jq -r '.id')\n  fi\n\n\n  echo \"Copied from '${previous_page_id}' -\u003e '${copied_page_id}' (parent: '${parent_page_id}')\"\n}\n\n````\n\n* 簡単にBasic認証にした。OAuth等も使える\n* 添付ファイルの多いページでコピーに時間がかかりタイムアウトする部分の解決が一番苦労した。タイムアウト値は設定できそうになかったので、作成されたかを何回か見に行く方式を取った。ブラウザ上でページをコピーしてもやはり時間がかかるので、添付ファイルが多い場合は注意が必要だ\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":[]},"/note/DBUnit%E3%81%A7Potential-problem-found%E3%81%AEWARN%E3%81%8C%E5%87%BA%E3%82%8B":{"title":"DBUnitでPotential problem foundのWARNが出る","content":"\n\\#Java\n\nDBUnit を実行すると `Potential problem found: The configured data type factory 'class org.dbunit.dataset.datatype.DefaultDataTypeFactory' might cause problems with the current database` と怒られるのを解決した\n\n## 事象\n\n````txt\n[main] WARN org.dbunit.dataset.AbstractTableMetaData - Potential problem found: The configured data type factory 'class org.dbunit.dataset.datatype.DefaultDataTypeFactory' might cause problems with the current database 'H2' (e.g. some datatypes may not be supported properly). In rare cases you might see this message because the list of supported database products is incomplete (list=[derby]). If so please request a java-class update via the forums.If you are using your own IDataTypeFactory extending DefaultDataTypeFactory, ensure that you override getValidDbProducts() to specify the supported database products.\n````\n\nDefaultDataTypeFactory だと DBMS 依存の型が解決できない可能性があるから、使ってる DBMS 用の DataTypeFactory を使えという趣旨\n\n## 解決策\n\n\u003chttp://dbunit.sourceforge.net/faq.html#typefactory\u003e\n\nconfigのDATATYPE_FACTORYに、使っているDBのFactoryをセットしてあげればよい\n\n````java\nIDatabaseConnection connection = new DatabaseConnection(jdbcConnection, schema);\nDatabaseConfig config = connection.getConfig();\nconfig.setProperty(DatabaseConfig.PROPERTY_DATATYPE_FACTORY, new OracleDataTypeFactory());\n````\n\n## JdbcDataTesterを使っている場合\n\nこんな感じでDBのセットアップをしていた\n\n````java\nvoid cleanlyInsert(final IDataSet dataSet) throws Exception {\n    final IDatabaseTester databaseTester = new JdbcDatabaseTester(JDBC_DRIVER, JDBC_URL, JDBC_USER, JDBC_PASSWORD);\n    databaseTester.setSetUpOperation(DatabaseOperation.CLEAN_INSERT);\n    databaseTester.setDataSet(dataSet);\n    databaseTester.onSetup();\n}\n````\n\n最初、こうしたらいいんじゃない？と思って適当にセットしたが反映されなかった。onSetup()時に同じWARNが出る\n\n````java\nvoid cleanlyInsert(final IDataSet dataSet) throws Exception {\n    final IDatabaseTester databaseTester = new JdbcDatabaseTester(JDBC_DRIVER, JDBC_URL, JDBC_USER, JDBC_PASSWORD);\n    databaseTester.getConnection().getConfig().setProperty( config.setProperty(DatabaseConfig.PROPERTY_DATATYPE_FACTORY, new OracleDataTypeFactory());\n    databaseTester.setSetUpOperation(DatabaseOperation.CLEAN_INSERT);\n    databaseTester.setDataSet(dataSet);\n    databaseTester.onSetup();\n}\n````\n\n内部でconnectionを作るときにconfigをnewしているので、上記では反映されない。\nこうするといい\n\n````java\nimport org.dbunit.JdbcDatabaseTester;\nimport org.dbunit.database.DatabaseConfig;\nimport org.dbunit.database.IDatabaseConnection;\nimport org.dbunit.ext.h2.H2DataTypeFactory;\n\npublic class H2JdbcDatabaseTester extends JdbcDatabaseTester {\n    public H2JdbcDatabaseTester(String driverClass, String connectionUrl, String username, String password) throws ClassNotFoundException {\n        super(driverClass, connectionUrl, username, password);\n    }\n\n    @Override\n    public IDatabaseConnection getConnection() throws Exception {\n        IDatabaseConnection connection = super.getConnection();\n        DatabaseConfig dbConfig = connection.getConfig();\n        // DBアクセス時に出るWARNを抑制\n        dbConfig.setProperty(DatabaseConfig.PROPERTY_DATATYPE_FACTORY, new H2DataTypeFactory());\n        return connection;\n    }\n}\n\n\nvoid cleanlyInsert(final IDataSet dataSet) throws Exception {\n    final IDatabaseTester databaseTester = new H2JdbcDatabaseTester(JDBC_DRIVER, JDBC_URL, JDBC_USER, JDBC_PASSWORD);\n    databaseTester.setSetUpOperation(DatabaseOperation.CLEAN_INSERT);\n    databaseTester.setDataSet(dataSet);\n    databaseTester.onSetup();\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Java"]},"/note/DBeaver":{"title":"DBeaver","content":"\nDBクライアント\n\n\u003chttps://dbeaver.io/\u003e\n\n[DBeaver使い方メモ - Qiita](https://qiita.com/12345/items/48f6856e32fd618ea307)\n\n* Eclipseベース\n* アップデートが頻繁\n* さまざまなDBに対応している\n\n## プラグイン\n\nEclipseのプラグインがそのまま入れられる。\nHelp \u003e Install New Software から、 `Work with` にsiteのurlをいれてチェックしていく。\n\n### vrapper\n\n\u003chttp://vrapper.sourceforge.net/update-site/stable/\u003e\n\n### Eclipse Color Theme\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["DB"]},"/note/Docker-build%E6%99%82%E3%81%ABhost%E3%81%AEssh%E3%82%AD%E3%83%BC%E3%82%92%E4%BD%BF%E3%81%86":{"title":"Docker build時にhostのsshキーを使う","content":"\n\\#Docker #git\n\n## 参考\n\n[BuildKit でイメージ構築 — Docker-docs-ja 20.10 ドキュメント](https://docs.docker.jp/develop/develop-images/build_enhancements.html)\n[docker buildする際にhost側のssh keyを使ってbuildする - Qiita](https://qiita.com/toyama0919/items/190eb19298e523094ba2)\n[Docker の BuildKit を使ってセキュアなビルドを試す - Qiita](https://qiita.com/takasp/items/56e1399a484ed5bfaade)\n\n## デフォルトのssh keyを使う場合\n\n````dockerfile\n# syntax=docker/dockerfile:1\nFROM alpine\n\n# ssh クライアントと git をインストール\nRUN apk add --no-cache openssh-client git\n\n# github.com のための公開鍵をダウンロード\nRUN mkdir -p -m 0600 ~/.ssh \u0026\u0026 ssh-keyscan github.com \u003e\u003e ~/.ssh/known_hosts\n\n# プライベート・リポジトリのクローン\nRUN --mount=type=ssh git clone git@github.com:myorg/myproject.git myproject\n````\n\n````shell\n$ export DOCKER_BUILDKIT=1\n$ docker build --ssh default .\n````\n\n## ファイルを指定する場合\n\n`type=secret` を使うと以下のようにできる\n\n````dockerfile\n# syntax = docker/dockerfile:1\n\nFROM alpine\n\n# デフォルトのシークレットの場所から、シークレットを表示\nRUN --mount=type=secret,id=mysecret cat /run/secrets/mysecret\n\n# 任意のシークレットの場所から、シークレットを表示\nRUN --mount=type=secret,id=mysecret,dst=/foobar cat /foobar\n````\n\n````shell\n$ docker build --secret id=mysecret,src=mysecret.txt .\n````\n\nこれを使ってssh keyを渡す\n\n````dockerfile\n# syntax=docker/dockerfile:1\nFROM alpine\n\n# ssh クライアントと git をインストール\nRUN apk add --no-cache openssh-client git\n\n# github.com のための公開鍵をダウンロード\nRUN mkdir -p -m 0600 ~/.ssh \u0026\u0026 ssh-keyscan github.com \u003e\u003e ~/.ssh/known_hosts\n\n# プライベート・リポジトリのクローン\nRUN --mount=type=secret,id=ssh,dst=/root/.ssh/id_rsa git clone git@github.com:myorg/myproject.git myproject\n````\n\n````shell\n$ docker build --secret id=ssh,src=~/.ssh/id_rsa_github .\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Docker","git"]},"/note/Dockerfile%E5%86%85%E3%81%A7%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B2%90%E3%81%99%E3%82%8B":{"title":"Dockerfile内で条件分岐する","content":"\n[docker - Dockerfile if else condition with external arguments - Stack Overflow](https://stackoverflow.com/questions/43654656/dockerfile-if-else-condition-with-external-arguments)\n[Dockerfile 内で条件に応じて処理を変えたかったので試行錯誤したメモ - ようへいの日々精進XP](https://inokara.hateblo.jp/entry/2021/01/02/165315)\n\n前提として、Dockerfile内で制御構文は使えない。使わずシンプルにするっていう思想になっている\n\n## 1. shell scriptで分岐\n\n````dockerfile\nFROM centos:7\nARG arg\nRUN if [[ -z \"$arg\" ]] ; then echo Argument not provided ; else echo Argument is $arg ; fi\n````\n\nこれだとshell内でできることは分岐できるがCOPYなどDockerfile内のコマンドには使えない。\n\n## 2. マルチステージビルドを使う\n\n````dockerfile\nARG my_arg\n\nFROM centos:7 AS base\nRUN echo \"do stuff with the centos image\"\n\nFROM base AS branch-version-1\nRUN echo \"this is the stage that sets VAR=TRUE\"\nENV VAR=TRUE\n\nFROM base AS branch-version-2\nRUN echo \"this is the stage that sets VAR=FALSE\"\nENV VAR=FALSE\n\nFROM branch-version-${my_arg} AS final\nRUN echo \"VAR is equal to ${VAR}\"\n````\n\n`docker build -t my_docker . --build-arg my_arg=2`\n\nbaseを基準のイメージとして、複数種類のstageを定義してglobalなARGでstage名を指定する\n\n## 2'. targetを指定する\n\n`--build-arg` で指定するのではなく、マルチステージビルドの `--target` で指定する方法。こちらのほうがtargetが明確になっていいと思った。\n\n````dockerfile\nFROM foo as base\nRUN ...\nWORKDIR /opt/my-proj\n\nFROM base as npm-ci-dev\n# invalidate cache\nCOPY --chown=www-data:www-data ./package.json /opt/my-proj/package.json\nCOPY --chown=www-data:www-data ./package-lock.json /opt/my-proj/package-lock.json\nRUN npm ci\n\nFROM base as npm-ci-prod\n# invalidate cache\nCOPY --chown=www-data:www-data ./package.json /opt/my-proj/package.json\nCOPY --chown=www-data:www-data ./package-lock.json /opt/my-proj/package-lock.json\nRUN npm ci --only=prod\n\nFROM base as proj-files\nCOPY --chown=www-data:www-data ./ /opt/my-proj\n\nFROM base as image-dev\n# Will mount, not copy in dev environment\nRUN ...\n\nFROM base as image-ci\nCOPY --from=npm-ci-dev /opt/my-proj .\nCOPY --from=proj-files /opt/my-proj .\nRUN ...\n\nFROM base as image-stage\nCOPY --from=npm-ci-prod /opt/my-proj .\nCOPY --from=proj-files /opt/my-proj .\nRUN ...\n\nFROM base as image-prod\nCOPY --from=npm-ci-prod /opt/my-proj .\nCOPY --from=proj-files /opt/my-proj .\nRUN ...\n````\n\n`docker build --target image-dev -t foo .`\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Docker"]},"/note/EC2%E3%81%AEuserdata-%E3%81%AE%E5%86%85%E5%AE%B9%E3%82%92%E7%A2%BA%E8%AA%8D%E3%81%99%E3%82%8B":{"title":"EC2のuserdata の内容を確認する","content":"\n\n````shell\n$ cd /var/lib/cloud/instances/i-\u003cインスタンスID\u003e/\n$ ls -al\ntotal 68\ndrwxr-xr-x 5 root root   218 Jul 14 18:00 .\ndrwxr-xr-x 3 root root    33 Jul 14 17:59 ..\n-rw-r--r-- 1 root root    59 Jul 14 18:00 boot-finished\n-rw------- 1 root root     0 Jul 14 17:59 cloud-config.txt\n-rw-r--r-- 1 root root    29 Jul 14 17:59 datasource\ndrwxr-xr-x 2 root root     6 Jul 14 17:59 handlers\n-r-------- 1 root root 25855 Jul 14 17:59 obj.pkl\ndrwxr-xr-x 2 root root    22 Jul 14 17:59 scripts\ndrwxr-xr-x 2 root root  4096 Jul 14 18:00 sem\n-rw------- 1 root root  9945 Jul 14 17:59 user-data.txt\n-rw------- 1 root root 10288 Jul 14 17:59 user-data.txt.i\n-rw------- 1 root root     0 Jul 14 17:59 vendor-data.txt\n-rw------- 1 root root   345 Jul 14 17:59 vendor-data.txt.i\n$ cat user-data.txt\n=\u003e userdataのスクリプト\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["EC2","AWS"]},"/note/ECS%E3%81%AEtomcat%E3%82%92%E6%89%8B%E3%81%A7%E5%B7%AE%E3%81%97%E6%9B%BF%E3%81%88%E3%82%8B":{"title":"ECSのtomcatを手で差し替える","content":"\n## やりたいこと\n\n[Elastic Container Service](note/Elastic%20Container%20Service.md) に対して、検証環境のリリースの際に通常通りtomcatコンテナビルド〜Rolling updateすると5分くらいはかかってしまう。\nちょっと設定を変えたいだけのときに時間がかかりすぎるので、オンプレのように手動でアップロードして手軽に変更したい。\n\n## 手順\n\n事前にECSタスクが実行されているEC2インスタンスを調べる\n\n````shell\n# warをローカルビルド\n$ mvn package\n# scp\n$ scp target/app.war \u003cEC2インスタンス\u003e:\n$ ssh \u003cEC2インスタンス\u003e\n\n# dockerコンテナ内にコピー\n[user@ip-xx-xx-xx-xx ~]$ docker cp app.war $(docker ps -f 'name=app' -q):/tmp\n# dockerコンテナ内に入る\n[user@ip-xx-xx-xx-xx ~]$ docker exec -it $(docker ps -f 'name=app' -q) bash\n\nbash-4.2$ cp /tmp/app.war $TOMCAT_HOME/webapps/\n# =\u003e デプロイされるのを待つ\n\n````\n\n#### 注意\n\n`conf/server.xml` に `autoDeploy=\"true\"` の設定が入っていないと、再読み込みされない\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/04/30","AWS"]},"/note/Elastic-Container-Service":{"title":"Elastic Container Service","content":"\nhttps://aws.amazon.com/jp/ecs/\n\nフルマネージドコンテナオーケストレーションサービスであり、コンテナ化されたアプリケーションを簡単にデプロイ、管理、およびスケーリングできます。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/05/04","AWS"]},"/note/Evergreen-Notes":{"title":"Evergreen Notes","content":"\nhttps://jmatsuzaki.com/archives/27412\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["obsidian","memo"]},"/note/GAS":{"title":"GAS","content":"\n## Google Apps Script とは？\n\n* \u003chttps://developers.google.com/apps-script/overview\u003e\n* Google社が提供するプログラミング言語\n* JavaScriptベースのスクリプト言語\n  * 基本構文はJavaScriptと同じ\n\n## Google Apps Script とは？\n\n* Googleの各サービスと連携して、閲覧編集できる\n  * Gmail\n  * Googleカレンダー\n  * Googleスプレッドシート\n  * Googleドキュメント\n  * Googleフォーム\n* インストール不要でブラウザ上で編集できる\n  * サーバレス\n  * クラウド上で実行される\n* 更新情報\n  * \u003chttps://developers.google.com/apps-script/releases/\u003e\n\n## GASでできること\n\n* 時間指定やイベントをトリガーにしてスクリプトを実行できる\n* カスタムメニューやダイアログなどをDocs,Sheets,Formsに追加できる\n* 独自関数をSheetsに追加する\n* Webアプリケーションを公開\n\n## 利用できる機能\n\n* Googleのアプリケーションやデータを操作したり、外部と連携する機能が提供されている\n* G Suite Service\n  * Googleが提供する基本的なサービスの操作\n* Script Service\n  * ユーティリティサービス\n  * Base, Utilities, URLFetch, Properties など\n* Advanced Google Service\n  * 拡張サービス\n  * BigQuery, Analytics\n\n## Good and Bad\n\n### Good\n\n* 環境構築不要\n  * ローカル開発環境構築は後述\n* アカウントとブラウザがあれば編集、実行ができる\n* サーバレス\n* 無料\n\n### Bad\n\n* スクリプトエディタの使い勝手が微妙\n* Gitでのバージョン管理ができない\n\n-\u003e 2018年のリリースで対応された(後述)\n\n* イントラにアクセスできない\n  * Jenkinsを直接実行できない\n* 実行に回数制限がある\n  * ちょっとした運用ツールにはいいが外部向きには難しい\n\n## 使ってみる\n\n* プロジェクトを開くには2通りの方法がある\n  * スプレッドシート、フォームなどを開いて\\[ツール→スクリプトエディタ\\]をクリックする\n    * サービスに紐付いたスクリプトが作成される\n  * [ダッシュボード](https://script.google.com/home)やドライブから直接新規作成する\n* function の中に処理を書く\n  * `ctrl + space` で補完される\n* 関数を選択して実行、デバッグ\n  * 承認が必要\n    * 使用するサービスに応じて権限を許可する必要がある\n    * 初回はGASの実行許可のダイアログが出るかもしれない\n      * TODO: 図\n        \u003chttps://www.virment.com/step-allow-google-apps-script/\u003e\n    * アクセス権限の情報は、ユーザの\\[アカウント情報\\]-\u003e\\[ログインとセキュリティ\\]-\u003e\\[接続済みのアプリとサイト\\]-\u003e\\[アカウントに接続されているアプリ\\]で確認できる\n\n## ログ\n\n* `Logger.log` を関数内に書く\n  * 値をそのまま表示する、フォーマットを指定する方法ができる\n  * Logger.log(object)\n  * Logger.log(format, string)\n* 実行後 \\[表示\\]-\u003e\\[ログ\\] で開くまたは `[cmd] + [Enter]`\n* \\[表示\\] -\u003e \\[実行トランスクリプト\\] で各関数の呼び出し順が表示される\n\n## デバッグ\n\n* ブレークポイントを設置\n* 虫マークでデバッグ実行\n* IDEと同じような使い方でステップ実行や、オブジェクトの中身表示などができる\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["GAS"]},"/note/GAS%E3%81%ABjest%E3%82%92%E5%B0%8E%E5%85%A5%E3%81%99%E3%82%8B":{"title":"GASにjestを導入する","content":"\nclasp + TypeScriptであることが前提\n\n* [GASをclaspでローカルで書く](GASをclaspでローカルで書く.md)\n* [GASをTSで書けるようにする](GASをTSで書けるようにする.md)\n\n````shell\n$ npm install -D @types/jest jest ts-jest\n````\n\n`jest.config.js`\n\n````javascript\nmodule.exports = {\n    preset: 'ts-jest',\n    testMatch: ['**/__tests__/**/*.+(ts|tsx|js)'],\n    globals: { SpreadsheetApp: {}, UrlFetchApp: {}, Utilities: {} },\n}\n````\n\n### globalsとは\n\nGAS固有の型定義をmockするための設定\n\nGAS上ではSpreadsheetAppが使えたりするが、ローカルで実行するときには当然存在しないため、window.SpreadsheetAppを定義している\n\nメソッド数の多いinterfaceを実装するのは大変なので、\n\u003chttps://github.com/marchaos/jest-mock-extended\u003e\nなどを使う\n\n````javascript\nimport { mock } from 'jest-mock-extended'\n\ndescribe('test', () =\u003e {\n    const values = [\n        ['Bob', new Date('2021-01-02T15:04:05')]\n        ['Alice', new Date('2021-02-03T15:04:05')]\n    ]\n\n    // SpreadsheetAppをmockする\n    const mockRange = mock\u003cGoogleAppsScript.Spreadsheet.Range\u003e()\n    mockRange.getValues.mockReturnValue(values)\n    const mockSheet = mock\u003cGoogleAppsScript.Spreadsheet.Sheet\u003e()\n    mockSheet.getRange.mockReturnValue(mockRange)\n    const mockSpreadsheet = mock\u003cGoogleAppsScript.Spreadsheet.Spreadsheet\u003e()\n    mockSpreadsheet.getSheetByName.mockReturnValue(mockSheet)\n    SpreadsheetApp.getActiveSpreadsheet = jest.fn(() =\u003e {\n        return mockSpreadsheet\n    })\n\n    // Utilitiesをmockする\n    Utilities.formatDate = jest.fn((date: Date) =\u003e {\n        return `${date.getFullYear()}-${date.getMonth() \u003c 9 ? '0' + (date.getMonth() + 1) : date.getMonth() + 1}-${\n            date.getDate() \u003c 10 ? '0' + date.getDate() : date.getDate()\n        }T${date.getHours() \u003c 10 ? '0' + date.getHours() : date.getHours()}:${\n            date.getMinutes() \u003c 10 ? '0' + date.getMinutes() : date.getMinutes()\n        }:${date.getSeconds() \u003c 10 ? '0' + date.getSeconds() : date.getSeconds()}`\n    })\n\n    const actual = doFormat()\n\n    expect(mockSheet.getRange).toHaveBeenCalledTimes(1)\n    expect(actual).toBe('2021-01-02T15:04:05')\n}\n\nexport function doFormat() {\n    // sheetを取得\n    const mysheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName('mysheet')\n    // セルの値を配列で取得\n    const values = mysheet.getRange(1, 1, 2, 2).getValues()\n    // 日付フォーマット\n    const formatted = Utilities.formatDate(values[0][1])\n    return formatted\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["GAS","TypeScript","unittest"]},"/note/GAS%E3%82%92TS%E3%81%A7%E6%9B%B8%E3%81%91%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%99%E3%82%8B":{"title":"GASをTSで書けるようにする","content":"\n[clasp](note/clasp.md) を使うと、[GAS](note/GAS.md) をTypeScriptで書くことができる。\nclasp 1.5.0 でサポートされるようになった。\n\n\u003chttps://github.com/google/clasp/blob/master/docs/typescript.md\u003e\n\nローカルでtsファイルで書いたGASをpushすると、自動でトランスパイルしてからアップロードしてくれる\n\n### GASをTSで書けるようにする\n\nclaspのプロジェクトで、google-apps-scriptの型定義を追加\n\n````shell\n$ npm install -D @types/google-apps-script\n````\n\nこれによって、IDE上でSpreadsheetAppなどGAS固有の定義も補完されるようになる\n\n### tsconfig.jsonを追加する\n\n`tsconfig.json`\n\n````json\n{\n  \"compilerOptions\": {\n    \"lib\": [\n      \"esnext\"\n    ],\n    \"target\": \"ES2019\",\n    \"experimentalDecorators\": true,\n    \"esModuleInterop\": true\n  }\n}\n````\n\n### tsファイルを作ってpushする\n\n`hello.ts`\n\n````typescript\nconst greeter = (person: string) =\u003e {\n    return `Hello, ${person}!`;\n}\n\nfunction testGreeter() {\n    const user = 'Grant';\n    Logger.log(greeter(user));\n}\n````\n\npush\n\n````shell\n$ clasp push\n````\n\nプロジェクトを開く\n\n````shell\n$ clasp open\n````\n\n.gsファイルに変換されたファイルが作成されている\n\n### 注意\n\n* `clasp pull` すると、変換されたjsファイルがダウンロードされる\n* 基本的にはローカルでTypeScriptで開発してpushするという一方通行になるので、複数人で開発するときにもそのフローを徹底する\n* よくわからずにWeb上で編集する人がいると、大変なことになる(実体験)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["GAS","TypeScript"]},"/note/GAS%E3%82%92clasp%E3%81%A7%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB%E3%81%A7%E6%9B%B8%E3%81%8F":{"title":"GASをclaspでローカルで書く","content":"\n\\#GAS\n\n[GAS](GAS.md)をローカルで開発するために [clasp](https://github.com/google/clasp) を使う\n\n## clasp\n\n* 2018年1月から使えるようになったGoogle公式のCLIツール\n* できること\n  * プロジェクトの新規作成、クローン\n  * GASファイルのアップロード/ダウンロード\n  * バージョン一覧の取得\n  * 新規バージョンを作成\n  * デプロイ\n  * デプロイ一覧の取得\n  * スクリプトエディタを開く\n* GASがローカル開発できる\n* TypeScriptでかける\n* コードラボが用意されているのでこちらで学べる\n\n\u003chttps://codelabs.developers.google.com/codelabs/clasp/#0\u003e\n\n### インストール\n\n[NodebrewでNode.jsのバージョンを管理する](NodebrewでNode.jsのバージョンを管理する.md) でNodeを入れる\n\nグローバルにインストールしても、ローカルにnpm initしてからインストールしてもよい。\n\n````shell\n$ npm i @google/clasp -g\n$ clasp help\n````\n\n### Google Apps Script APIを有効化\n\n\u003chttps://script.google.com/home/usersettings\u003e\n\n### ログイン\n\nWeb上のエディタにアップロードするにもダウンロードするにも認証が必要なので、以下コマンドでログインする\n\n````shell\n$ clasp login\n🔑  Authorize clasp by visiting this url:\nhttps://accounts.google.com/o/oauth2/v2/auth?access_type=offline\u0026scope=https%3A%2F%...\n````\n\nブラウザが開き、アカウントの選択と、APIの承認画面が表示されるので、承認する\n\nログイン情報は、`$HOME/.clasprc.json` に保存されている\n\n### 既存のプロジェクトを編集したい場合\n\ngit clone と同じような感覚でローカルにダウンロードできる\n\n````shell\n$ clasp clone ${scriptId}\n````\n\nscriptIdは、スクリプトエディタで開いたときの以下の部分\n\n* 旧エディタ `https://script.google.com/d/\u003cscriptId\u003e/edit`\n* 新エディタ `https://script.google.com/home/projects/\u003cscriptId\u003e/edit`\n\n※2020年の年末ごろにエディタが新しくなり、URLも変わった\n\n* GASのプロジェクトがダウンロードされる\n  * .clasp.json\n    * プロジェクト設定ファイル\n    * scriptId (必須): \u003chttps://script.google.com/d/\u003e\\\u003cSCRIPT_ID\u003e/edit のSCRIPT_ID部分\n    * rootDir: プロジェクトを保存するディレクトリを指定\n  * appsscript.json\n    * マニフェストファイル\n    * GAS実行時の設定など\n  * 作成済みのスクリプトファイル\n    * なお、.gsではなく.jsでダウンロードされる\n\n### 新規作成の場合\n\n````shell\n$ clasp create --title \u003cprojectName\u003e --rootDir \u003cソースファイルを置くディレクトリ\u003e\n````\n\nプロジェクトタイプを聞かれる\n\n* standalone: スクリプト単体で作成される\n* docs,sheets,...: 選択したドキュメントと、それに紐づくスクリプトとして作成される\n\n### リモートの修正をローカルに反映する\n\n````shell\n$ clasp pull\n````\n\n* ブラウザ上で修正したものがローカルに反映される\n* 強制的に上書きされるので注意が必要\n\n### ローカルの修正をリモートに反映する\n\n````shell\n$ clasp push\n````\n\n* rootDirで指定したすべてのファイルがpushされる\n* 特にquestionもなく強制上書きになるので、Web上で編集している場合は注意する\n* Git関連のファイルなどは反映したくない\n\n=\u003e claspignore を作成\n\n### claspignore\n\nカレントディレクトリに `.claspignore` ファイルを作成して、clasp管理外にするファイルを記載すると、push,pullから管理外になる\n\n記法はgitignoreと同様\n\n### ディレクトリ構成\n\n以下のようにディレクトリを分けることができる\n\n````shell\n./\n├── appsscript.json\n└── src\n│   └── Code.js\n└── test\n    └── Code.js\n````\n\n* これを `clasp push` すると、 `/` 区切りでファイルが登録される\n* pull してもディレクトリは保持される\n\n### その他できること\n\n#### プロジェクトを開く\n\nブラウザで開くには以下のコマンドを実行\n\n````shell\n$ clasp open\n````\n\n#### 関数を実行\n\n````shell\n$ clasp run [functionName]\n````\n\n#### ログを見る\n\n````shell\nclasp logs \n````\n\n事前にProjectIDを設定しておく\n\nスクリプトエディタから`リソース \u003e Cloud Platform Project`を開いて、`project-id-xxxxxxxxxxxxxxxxxxx` をコピーして.clasp.jsonに貼り付ける\n\n````json\n    {\n      \"scriptId\":\"\u003cSCRIPT_ID\u003e\",\n      \"projectId\": \"project-id-xxxxxxxxxxxxxxxxxxx\"\n    }\n````\n\n### バージョン管理\n\nGitのバージョン管理ではなくて、GASのバージョン管理\n\n````shell\n$ clasp version [バージョンの説明]\nCreated version x\n````\n\nするとスクリプトエディタ上でバージョンが作られているのを確認できる\nコマンドで確認する場合は `clasp versions`\n\n### Git管理\n\n* clasp でローカルにGASプロジェクトを作成できるようになったため、Gitで管理できる\n* gitignoreに、Node.gitignoreを書いておくとよい\n\n他の人も git clone から開発できるようになる(スクリプトへのアクセス権限はもっている必要がある)\n\n````shell\n$ git clone [スクリプトのリポジトリ]\n(ファイルに変更を加える)\n$ clasp push\n(Gitへもcommit, push する)\n````\n\n## CIとの連携\n\n* Jenkinsにclasp を設定しておけば、例えば以下のようなことが可能\n  ローカルで開発\n  ↓\n  BitbucketにPush\n  ↓\n  Jenkinsで`git clone`\n  ↓\n  テスト、静的解析\n  ↓\n  `clasp push`\n\n* 注意\n  \n  * リモートかローカルか決めたほうでのみ開発する\n  * スクリプトエディタからであれば開発環境構築なしで作れるというメリットもあるので、どちらを取るかはそのときに合わせる\n\n### 参考\n\n[詳解！ Google Apps Script完全入門 ～Google Apps \u0026 G Suiteの最新プログラミングガイド～](https://www.amazon.co.jp/dp/B07BNB1Z9L)\n\n[リファレンス](https://developers.google.com/apps-script/reference/)\n\n[Google Apps Scriptの新しい3つの機能 その① Dashboard](https://qiita.com/soundTricker/items/59979d0bb065fdd8d536)\n[Google Apps Scriptの新しい3つの機能 その② Apps Script API](https://qiita.com/soundTricker/items/13719acd2628ed87894c)\n[Google Apps Scriptの新しい3つの機能 その③ CLI Tool Clasp](https://qiita.com/soundTricker/items/354a993e354016945e44)\n\n\u003chttps://codelabs.developers.google.com/codelabs/clasp/#0\u003e\n[Command Line Interface using clasp](https://developers.google.com/apps-script/guides/clasp)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["GAS"]},"/note/GAS%E3%82%92clasp%E3%81%A7%E4%BD%9C%E3%81%A3%E3%81%A6V8%E3%83%A9%E3%83%B3%E3%82%BF%E3%82%A4%E3%83%A0%E3%81%AB%E5%AF%BE%E5%BF%9C%E3%81%95%E3%81%9B%E3%82%8B":{"title":"GASをclaspで作ってV8ランタイムに対応させる","content":"\n\u003chttps://qiita.com/r57ty7/items/77ea0a3dc5c2200b6f1d\u003e\n\n[GAS](note/GAS.md) でV8ランタイムが利用できるようになった。\n\nclaspで管理しているGASのプロジェクトをV8に対応させたい。\n\n`tsconfig.json`\n\n````json\n{\n    // ...\n    \"compilerOptions\": {\n        \"target\": \"ES2019\"\n    }\n}\n````\n\n`appsscript.json`\n\n````json\n{\n    // ...\n    \"runtimeVersion\": \"V8\"\n}\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["GAS","TypeScript"]},"/note/GAS%E3%82%B9%E3%83%8B%E3%83%9A%E3%83%83%E3%83%88":{"title":"GASスニペット","content":"\n\\#GAS\n\n# Spreadsheetの操作\n\n## クラス\n\n|||\n|:-|:-|\n|SpreadsheetApp|Spreadsheetサービスの基底クラス|\n|Spreadsheet|Spreadsheetを操作する機能を提供する|\n|Sheet|シートを操作する機能を提供する|\n|Range|セル範囲を操作する機能を提供する|\n\n## データ操作\n\n\u003chttps://developers.google.com/apps-script/guides/sheets\u003e\n\n### データ読み取り\n\n````javascript\nfunction logProductInfo() {\n  var spreadSheet = SpreadsheetApp.openById('XXXXXXX'); // スプレッドシートのIDを入力\n  var sheet = spreadSheet.getSheetByName('sheet name');\n  var data = sheet.getDataRange().getValues();\n  for (var i = 0; i \u003c data.length; i++) {\n    Logger.log('Product name: ' + data[i][0]);\n    Logger.log('Product number: ' + data[i][1]);\n  }\n}\n````\n\n* スプレッドシートのID\n  * \u003chttps://docs.google.com/spreadsheets/d/{ID}/edit\u003e\n  * URLのID部分\n\n### データ操作\n\n\u003chttps://developers.google.com/apps-script/guides/sheets\u003e\n\n#### データ書き込み\n\n````javascript\n    function addProduct() {\n      var sheet = SpreadsheetApp.getActiveSheet();\n      sheet.appendRow(['Cotton Sweatshirt XL', 'css004']);\n    }\n````\n\n## スプレッドシートマクロ\n\n\u003chttps://developers.google.com/apps-script/guides/sheets/macros\u003e\n\n* Excelマクロのような感じ\n* UIの一連の操作を記録して、同じ操作を再現できるような機能\n\n## カスタム関数\n\n````javascript\n    function GETRESULT(value) {\n      if (value \u003e= 80) {\n        return 'OK';\n      } else {\n        return 'NG';\n      }\n    }\n````\n\nセルに `=GETRESULT(A1)` とすると結果が出力される\n\n## Slack との連携\n\n* SlackのAPIトークンを取得する\n* UrlFetchでPOST送信する\n* [Slack BotをGASでいい感じで書くためのライブラリを作った](https://qiita.com/soundTricker/items/43267609a870fc9c7453)\n\n## ライブラリを作成\n\n\u003chttps://qiita.com/t_imagawa/items/47fc130a419b9be0b447\u003e\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["GAS"]},"/note/GCP-Deployment-Manager":{"title":"GCP Deployment Manager","content":"\nAWSのCloudFormationみたいなもの\n設定ファイルに従ってリソースが作成される\n\n[Deployment Manager の最初の一歩 - Qiita](https://qiita.com/yhiraki/items/646d015caa3d5a1c2e6b)\n\nサポートされるリソースの一覧\n\u003chttps://cloud.google.com/deployment-manager/docs/configuration/supported-resource-types\u003e\n\nリンクから飛ぶと設定できるパラメータがJSON Schemaで確認できる\n\nNodePoolの定義を確認したければこちら\nhttps://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/projects.zones.clusters.nodePools\n\nconfig は [NodeConfig](https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/NodeConfig) というようにリンクをたどっていく\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/02/03","GCP"]},"/note/GKE":{"title":"GKE","content":"\nGoogle Kubernetes Engine\n\n## \n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/02/03"]},"/note/Garmin%E3%82%A2%E3%83%97%E3%83%AA%E3%82%92%E4%BD%9C%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B":{"title":"Garminアプリを作ってみる","content":"\n## 作るもの\n\n[Apple Watchの「Tapticタイム」で現在時刻を振動で確認する方法 | Apple Watch Wave](https://www.ipodwave.com/applewatch/howto/taptic_time.html)\nTapticタイムみたいに、現在時刻を振動で知りたい\n\nhttps://github.com/ikorihn/gtaptic\n\n## 環境構築\n\nvscodeで作ってみる\n[Visual Studio CodeでGarmin Connect IQの開発 | Take4-blue](https://take4-blue.com/program/garmin/visual-studio-code%E3%81%A7garmin-connect-iq%E3%81%AE%E9%96%8B%E7%99%BA/)\nhttps://developer.garmin.com/connect-iq/reference-guides/visual-studio-code-extension/\nこちらに沿ってすすめる\n\nMonkey Cという言語らしい\n\n[Monkey C - Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=garmin.monkey-c) をインストール\n\nコマンドパレットから `Monkey C: Verify Installation` を選ぶと、ブラウザでConnect IQ SDK Managerインストール画面が開く\n\n[Connect IQ Basics](https://developer.garmin.com/connect-iq/connect-iq-basics/getting-started/)\n\nConnect IQ SDK Managerをダウンロードして実行\n画面にそってセットアップを行う。\n自動アップデートの有無などを聞かれる。一旦OFFにした。\n\nSDK Managerが開くので、SDK一覧から Connect IQ 4.1.7 をインストール\n\n![Pasted-image-20230107171859](note/Pasted-image-20230107171859.png)\n\nDevices から対象にしたいデバイスもインストール\n\nSDKやDeviceはMacの場合こちらにダウンロードされる。\n`~/Library/Application Support/Garmin/ConnectIQ/`\n\nもう一度vscodeに戻って、Verify Installation するとdeveloper keyを入力するボックスが出る。\nまだ持っていないはずなので、generateの方を選ぶ。\n作成先のディレクトリを聞かれるので、適当な場所を選択\n\nJRE 1.8以上が入っていない場合、それもインストールする。\n\n### プロジェクト作成\n\n環境構築が済んだら、 `Monkey C: New Project` でプロジェクトを作成できる\n\nName (gtaptic) \u003e Watch App \u003e 最低バージョン 4.0.0 で作成\nWatch Faceなどもここで選べる。\n\n## コマンド\n\n* `Edit Products` 対象デバイスを選択\n* `Edit Application` アプリケーションを編集\n* `Edit Permissions` 必要な権限を編集\n* `Edit Language` 言語選択\n\n## シミュレーターで実行する\n\nhttps://developer.garmin.com/connect-iq/connect-iq-basics/your-first-app/\n\n`~/Library/Application Support/Garmin/ConnectIQ/Sdks/{インストールしたSDK}/samples` にいくつかサンプルがあるのでそれを開く\n`Run and Debug` \u003e `Run` をするとアプリをビルドしてシミュレーターが開いて実行される\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/01/07"]},"/note/Garmin-%E3%82%B9%E3%83%9E%E3%83%9B%E3%81%AE%E6%A9%9F%E7%A8%AE%E3%82%92%E5%A4%89%E3%81%88%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AB%E3%83%9A%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%8C%E3%81%86%E3%81%BE%E3%81%8F%E8%A1%8C%E3%81%8B%E3%81%AA%E3%81%84":{"title":"Garmin スマホの機種を変えたときにペアリングがうまく行かない","content":"\nスマホの機種変更時に、何度やってもペアリングに成功しなかった。\npinの入力まではできるけど、そのあと failed to pairing と出てエラーとなる。そしてその後はTry againとかをしても即失敗になる。\n\n少し特殊なことをしていて、もともとはPixel 3aとペアリングしていたのだが、Pixel 6(レンタル)に機種変更をして、レンタル期限が来たので再度Pixel 3aに戻そうとしたときにペアリングができなくなってしまった。\nなので、完全に新しい機種に変更しようというときにはこんな問題にはならないかもしれない。\n昔ペアリングしていた機種に戻そうとするとハマるのかもしれない。\n\n### 公式の手順(失敗)\n\nhttps://support.garmin.com/ja-JP/?faq=j5tfDRFRWT7q82ipep3bO7\n元の機器でペアリングを解除、Garminアプリを削除したあと、新しい機種でペアリングするとだけ書いてあるが、全然解決にならなかった。\n\n### デバイスの削除(失敗)\n\n元の機器でペアリングしなおすのはすんなりできたので、ペアリングしたあとGarmin Connectでデバイスを削除し、新しい機種でペアリング\n→ これもうまくいかない\n\n### Bluetoothのキャッシュ削除\n\nBluetoothの設定上はGarminが消えているが、キャッシュが残っているせいでペアリングできないことがあるみたいなので、きれいにする\n\n* 設定 \u003e アプリ \u003e 右上の3点リーダ \u003e システムアプリを表示\n* Bluetooth アプリを開く\n* ストレージを削除(ペアリング済みの機器はきえないので安心)\n\nhttps://www.reddit.com/r/Garmin/comments/pm9vlu/can_no_longer_connect_to_phone_pairing_failed/\n\n### Garminのソフトリセット\n\nLightボタンを10秒長押しするとソフトリセットして再起動する\n\n### すべての権限を許可\n\nGarmin Connectのアプリ設定を開いて、すべての必要な権限許可にする\n\n## 結果\n\n上の3つをやって何度かペアリングしなおしたところ成功した。\nちょっとどれが効いたのか、すべてが揃って効いたのかわからない。。\n\nとりあえず暫定の手順としてはこう。\n\n* 元の機種でペアリングを解除\n* 新しい機種でBluetoothのキャッシュクリア\n* Garminをペアリング状態にする(UP長押し \u003e Phone \u003e Pair phone)\n* Garmin Connectを開いて「デバイスを追加」\n* Pinを入力\n* (これを成功するまで何回か)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/06/28","Garmin"]},"/note/Gatekeeper":{"title":"Gatekeeper","content":"\n[Kubernetes](note/Kubernetes.md) でリソースが作成される際にポリシーに適合するかどうかをチェックし、違反する場合は作成させないことができる機構。\nポリシーはRego言語で定義する\n\n* ConstraintTemplateリソースで制約テンプレートを定義 → CRDが作られる\n* パラメータを指定してCRDから制約リソースを作成\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/04/26","Kubernetes"]},"/note/Gatsby%E3%81%A8Netlify%E3%81%A7%E3%83%96%E3%83%AD%E3%82%B0%E4%BD%9C%E6%88%90":{"title":"GatsbyとNetlifyでブログ作成","content":"\nGatsby.jsとNetlifyでブログを作成して公開する手順\n\n## Netlify\n\nNetlify、GitHubリポジトリを設定する\n\n[NetlifyとGitHubで静的サイトを公開する](note/NetlifyとGitHubで静的サイトを公開する.md)\n\n## Gatsby.js\n\n[Gatsby.js](note/Gatsby.js.md)\n\n### CLIインストール\n\n````sh\nnpm install -g gatsby-cli\n````\n\n### プロジェクト作成\n\n`gatsby new \u003c名前\u003e \u003cスターター\u003e` で作成できる。\n\n````sh\ngatsby new ikorihn-blog https://github.com/renyuanz/leonids\n````\n\nスターターは [leonids](https://www.gatsbyjs.com/starters/renyuanz/leonids) を使用した。\n\n* シンプル、固定のサイドバー\n* TailwindCSSを使用\n* Light/Darkモード\n* GitHub actionsでGitHub pagesにデプロイ\n\n### 動作確認\n\n````sh\ncd ikorihn-blog\ngatsby develop\n````\n\n`http://localhost:8000/` を開く\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Gatsbyjs","blog"]},"/note/Gatsby.js":{"title":"Gatsby.js","content":"\nReactの静的サイトジェネレータ\n\nhttps://www.gatsbyjs.com/\n\n## 動作\n\nReactアプリをビルド時に1回実行し、HTML,JSを生成する。\n生成されたファイルをホスティングサービスにデプロイするだけで見られるようになる\n\n## ビルド時GraphQL\n\nGatsby.jsではビルド時のさまざまなデータをGraphQLで取得する。\n\nMarkdown形式のテキスト情報を、ファイルシステムから読み込んで、GraphQL経由で取得し、Reactコンポーネント内で表示する。\nGatsbyではMarkdownに限らず様々なデータを、 `data source`, `data transformer` という枠組みで一般化することで、多様な処理を統一的にかつ簡潔に記述することができている。\n\nクライアントはビルド時に形成されたGraphQL DBの全体は必要ないので、「クエリの結果」のみをJSONとして合わせてデプロイする。\n\n## プラグイン\n\nデータを作成するために、 [data transformer](https://www.gatsbyjs.org/plugins/?=tranformer), [data source](https://www.gatsbyjs.org/plugins/?=source)がプラグインとして利用できる。\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Gatsbyjs"]},"/note/Gatsbyjs%E3%81%A7Tailwind%E3%82%92%E3%81%A4%E3%81%8B%E3%81%86":{"title":"GatsbyjsでTailwindをつかう","content":"\n\\#Gatsbyjs #TailwindCSS\n\n\u003chttps://www.gatsbyjs.com/docs/how-to/styling/tailwind-css/\u003e\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Gatsbyjs","TailwindCSS"]},"/note/Gatsbyjs%E3%81%AB%E7%9B%AE%E6%AC%A1%E3%82%92%E8%BF%BD%E5%8A%A0%E3%81%99%E3%82%8B":{"title":"Gatsbyjsに目次を追加する","content":"\n各ページに目次を追加したい\n\n## 前提条件\n\n目次ボタンは`h`タグ内に`#`を使った「ページ内リンク」となるので\n\nページ内リンクを取り扱うプラグインとの併用がほぼ必須となっている。\n\n私が合わせて使っているページ内リンクプラグインは次\n\n[gatsby-remark-autolink-headers | GatsbyJS](https://www.gatsbyjs.org/packages/gatsby-remark-autolink-headers/)\n\nこちらの設置方法も記事にしてある。\n\n[【Gatsby.js】見出しにページ内リンクを設定するプラグイン「gatsby-remark-autolink-headers」 | Blog](https://www.ultra-noob.com/blog/2020-08-14-%E3%80%90Gatsby_js%E3%80%91%E8%A6%8B%E5%87%BA%E3%81%97%E3%81%AB%E3%83%9A%E3%83%BC%E3%82%B8%E5%86%85%E3%83%AA%E3%83%B3%E3%82%AF%E3%82%92%E8%A8%AD%E5%AE%9A%E3%81%99%E3%82%8B%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3%E3%80%8Cgatsby-remark-autolink-headers%E3%80%8D/)\n\n# [](https://www.ultra-noob.com/blog/2020/2020-08-15-%E3%80%90Gatsby_js%E3%80%91%E8%A8%98%E4%BA%8B%E3%81%AB%E3%80%8C%E7%9B%AE%E6%AC%A1%E3%80%8D%E3%82%92%E8%BF%BD%E5%8A%A0%E3%81%99%E3%82%8B%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3%E3%80%8Cgatsby-remark-table-of-contents%E3%80%8D%E3%81%AE%E4%BD%BF%E3%81%84%E6%96%B9/#gatsby-remark-table-of-contents)\n\n[gatsby-remark-autolink-headers](https://www.gatsbyjs.org/packages/gatsby-remark-autolink-headers/)\n\n## プラグインを追加\n\n[gatsby-remark-table-of-contents](https://www.gatsbyjs.com/plugins/gatsby-remark-table-of-contents/)\n\n````sh\nyarn add gatsby-remark-table-of-contents\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Gatsbyjs"]},"/note/Gatsbyjs%E3%81%ABSNS%E3%82%A2%E3%82%A4%E3%82%B3%E3%83%B3":{"title":"GatsbyjsにSNSアイコン","content":"\n## FontAwesomeをインストール\n\nhttps://fontawesome.com/how-to-use/on-the-web/using-with/react\n\n````bash\nyarn add @fortawesome/fontawesome-svg-core @fortawesome/free-solid-svg-icons @fortawesome/react-fontawesome @fortawesome/free-brands-svg-icons\n````\n\n## コンポーネントを利用する\n\n````\nimport { FontAwesomeIcon } from '@fortawesome/react-fontawesome'\nimport {\n  faGithubSquare,\n  faTwitterSquare,\n} from '@fortawesome/free-brands-svg-icons'\n\n// ...\n\n      \u003ca\n        href={`https://github.com/${social.github}`}\n        style={{ boxShadow: `none` }}\n      \u003e\n        \u003cFontAwesomeIcon\n          color=\"#aeaeae\"\n          icon={faGithubSquare}\n          style={{\n            width: `32px`,\n            height: `32px`,\n            marginRight: `4px`,\n          }}\n        /\u003e\n      \u003c/a\u003e\n      \u003ca\n        href={`https://twitter.com/${social.twitter}`}\n        style={{ boxShadow: `none` }}\n      \u003e\n        \u003cFontAwesomeIcon\n          color=\"#3eaded\"\n          icon={faTwitterSquare}\n          style={{\n            width: `32px`,\n            height: `32px`,\n            marginRight: `4px`,\n          }}\n        /\u003e\n      \u003c/a\u003e\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Gatsbyjs"]},"/note/Gatsbyjs%E3%81%AE%E8%A6%8B%E5%87%BA%E3%81%97%E3%81%AB%E3%83%9A%E3%83%BC%E3%82%B8%E5%86%85%E3%83%AA%E3%83%B3%E3%82%AF%E3%82%92%E3%81%A4%E3%81%91%E3%82%8B":{"title":"Gatsbyjsの見出しにページ内リンクをつける","content":"\n\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":[]},"/note/Gatsbyjs%E3%81%AETypeScript%E5%8C%96":{"title":"GatsbyjsのTypeScript化","content":"\n[Gatsby.js](note/Gatsby.js.md) を [TypeScript](note/TypeScript.md) 化する\n\n## tsconfig.jsonを追加\n\ntsconfig.json\n\n````json\n````\n\n## GraphQL Schema, リクエストの型生成\n\nGatsby はリソースに対して GraphQL でリクエストを送りデータを取得する\nGraphQL リクエストのレスポンスの型を、[gatsby-plugin-typegen](https://github.com/cometkim/gatsby-plugin-typegen) を使い生成する。\n\n````bash\nyarn add gatsby-plugin-typegen\n````\n\n`gatsby-config.js`の plugins に`gatsby-plugin-typegen`を追記する。\n\nsrc/components/index.ts\n\n````js\nmodule.exports = {\n  siteMetadata: {\n    // ...\n  },\n  plugins: [\n    // ...\n    `gatsby-plugin-typegen`\n  ],\n}\n````\n\n次に、各コンポーネントの query にクエリ名を追加していきます。  \nこの変更をすることでそのクエリ専用の型が生成されます。\n\n（例： src/components/index.js `query BlogIndex`の部分を追記している）\n\n[🔗 src/components/index.ts](https://github.com/kawamataryo/gatsby-typescript-sample/blob/master/src/src/components/index.ts)\n\n````js\n//...\nexport const pageQuery = graphql`\n  query BlogIndex {\n    site {\n      siteMetadata {\n        title\n      }\n    }\n    allMarkdownRemark(sort: { fields: [frontmatter___date], order: DESC }) {\n      nodes {\n        excerpt\n        fields {\n          slug\n        }\n        frontmatter {\n          date(formatString: \"MMMM DD, YYYY\")\n          title\n          description\n        }\n      }\n    }\n  }\n`\n````\n\n最後に`yarn build`を実行すると、`src/__generated__/gatsby-types.ts`が生成されているはずです。  \nここに GraphQL リクエストの型定義があります。  \n先ほど追加した BlogIndex クエリの型を見てみると、、\n\n[🔗 src/pages/index.ts](https://github.com/kawamataryo/gatsby-typescript-sample/blob/master/src/src/__generated__/gatsby-types.ts)\n\n````ts\n//...\ntype BlogIndexQueryVariables = Exact\u003c{ [key: string]: never; }\u003e;\n\n\ntype BlogIndexQuery = { readonly site: Maybe\u003c{ readonly siteMetadata: Maybe\u003cPick\u003cSiteSiteMetadata, 'title'\u003e\u003e }\u003e, readonly allMarkdownRemark: { readonly nodes: ReadonlyArray\u003c(\n      Pick\u003cMarkdownRemark, 'excerpt'\u003e\n      \u0026 { readonly fields: Maybe\u003cPick\u003cFields, 'slug'\u003e\u003e, readonly frontmatter: Maybe\u003cPick\u003cFrontmatter, 'date' | 'title' | 'description'\u003e\u003e }\n    )\u003e } };\n//...\n````\n\nちゃんと生成されてますね！　最高便利。\n\n## 各コンポーネントファイルのTypeScript化\n\nこれで準備ができたので、各ファイルを TypeScript 化していきます。  \n[gatsby-plugin-typescript](https://github.com/gatsbyjs/gatsby/tree/master/packages/gatsby-plugin-typescript)の追加から入る記事が多いのですが、2020 年 10 月現在、Gatsby には`gatsby-plugin-typescript`がすでに組み込まれているので、何もせずで大丈夫です。\n\n何か TypeScript のビルド関連で追加の設定をしたい場合は、gatsby-config.js の plugins で`gatsby-plugin-typescript`を追加して、option を設定してください。\n\n各コンポーネントのファイル拡張子を`.js`から`.tsx`に書き換えましょう。  \nそして、StaticQuery の戻り値など型エラーとなっている箇所に型をつけていきます。\n\n例えば、`src/pages/index.ts`の型付けは以下のようになります。\n\n[🔗 src/pages/index.ts](https://github.com/kawamataryo/gatsby-typescript-sample/blob/master/src/pages/index.ts)\n\n````ts\nimport React from \"react\"\nimport { Link, graphql } from \"gatsby\"\nimport { PageProps } from \"gatsby\"\n\nimport Bio from \"../components/bio\"\nimport Layout from \"../components/layout\"\nimport SEO from \"../components/seo\"\n\nconst BlogIndex:React.FC\u003cPageProps\u003cGatsbyTypes.BlogIndexQuery\u003e\u003e = ({ data, location }) =\u003e {\n  const siteTitle = data.site?.siteMetadata?.title || `Title`\n  const posts = data.allMarkdownRemark.nodes\n\n  // ... 以下略\n}\n````\n\nポイントは以下のように`React.FC`、`PageProps`などのジェネリクス型を使うことと、`gatsby-plugin-typegen`で生成した型を使うことです。\n\n````ts\nconst BlogIndex:React.FC\u003cPageProps\u003cGatsbyTypes.BlogIndexQuery\u003e\u003e = ({ data, location }) =\u003e { /* -- */ }\n````\n\nこれで`data`の型が`BlogIndexQuery`の型で推論されます。  \nあとは、適宜 Optional Chaining や、Non null Assertion を使って型エラーを解決しましょう。\n\n# [](https://zenn.dev/ryo_kawamata/articles/gatsby-ts-2020#4.-gatsby-node.js%E3%81%AEtypescript%E5%8C%96)4. gatsby-Node.jsのTypeScript化\n\n`gatsby-node.js`でも TypeScrip で書けるようにしていきます。ここでは[ts-node](https://github.com/TypeStrong/ts-node)を追加ます。\n\nここの書き方は[@Takepepe](https://twitter.com/takepepe?lang=en)さんの以下の記事を参考にさせていただきました。良記事ありがとうございます🙏  \n[Gatsby.js を完全TypeScript化する - Qiita](https://qiita.com/Takepepe/items/144209f860fbe4d5e9bb)\n\n````\nyarn add -D ts-node\n````\n\nそして、`gatsby-config.js`を以下のように変更します。\n\n[🔗 gatsby-config.js](https://github.com/kawamataryo/gatsby-typescript-sample/blob/master/gatsby-config.js)\n\n````js\n\"use strict\"\n\nrequire(\"ts-node\").register({\n  compilerOptions: {\n    module: \"commonjs\",\n    target: \"esnext\",\n  },\n})\n\nrequire(\"./src/__generated__/gatsby-types\")\n\nconst {\n  createPages,\n  onCreateNode,\n  createSchemaCustomization,\n} = require(\"./src/gatsby-node/index\")\n\nexports.createPages = createPages\nexports.onCreateNode = onCreateNode\nexports.createSchemaCustomization = createSchemaCustomization\n````\n\nそして、今まで`gatsby-node.js`に記述していた内容を`src/gatsby-node/index.ts`に移動して、型を設定します。  \n基本的に node の API は`GatsbyNode`から型を取得できます。\n\n本当は、`allMarkdownRemark`のクエリ部分の方も`gatsby-plugin-typegen`で生成したかったのですが、上手く認識してくれませでした。やり方わかる方いたら教えてください🙏  \n（ドキュメントの `Provides utility types for gatsby-node.js.`はまだチェックがついていないので、まだ未対応なのかな？）。\n\n[🔗 src/gatsb-node/index.ts](https://github.com/kawamataryo/gatsby-typescript-sample/blob/master/src/gatsby-node/index.ts)\n\n````ts\nimport path from \"path\"\nimport { GatsbyNode, Actions } from \"gatsby\"\nimport { createFilePath } from \"gatsby-source-filesystem\"\n\nexport const createPages: GatsbyNode[\"createPages\"] = async ({ graphql, actions, reporter }) =\u003e {\n  const { createPage } = actions\n\n  const blogPost = path.resolve(`./src/templates/blog-post.js`)\n\n  const result = await graphql\u003c{ allMarkdownRemark: Pick\u003cGatsbyTypes.Query[\"allMarkdownRemark\"], 'nodes'\u003e }\u003e(\n    `\n      {\n        allMarkdownRemark(\n          sort: { fields: [frontmatter___date], order: DESC }\n          limit: 1000\n        ) {\n          nodes {\n            fields {\n              slug\n            }\n            frontmatter {\n              title\n            }\n          }\n        }\n      }\n    `\n  )\n\n  //...\n\n  }\n}\n\nexport const onCreateNode: GatsbyNode[\"onCreateNode\"] = ({ node, actions, getNode }) =\u003e {\n  const { createNodeField } = actions\n  //...\n}\n\nexport const createSchemaCustomization: GatsbyNode[\"createSchemaCustomization\"] = async ({ actions }: { actions: Actions}) =\u003e {\n  const { createTypes } = actions\n  // ...\n}\n\n````\n\nこれで`gatsby-Node.js`の TypeScript 化も完了です🎉\n\n## 参考\n\n* [Gatsby.jsのTypeScript化 2020](https://zenn.dev/ryo_kawamata/articles/gatsby-ts-2020)\n* [Gatsby.js を完全TypeScript化する - Qiita](https://qiita.com/Takepepe/items/144209f860fbe4d5e9bb)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Gatsbyjs","TypeScript"]},"/note/Git":{"title":"Git","content":"\n\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["git"]},"/note/Git%E3%82%B3%E3%83%9F%E3%83%83%E3%83%88%E3%83%AD%E3%82%B0%E3%81%ABJIRA%E3%81%AE%E3%83%81%E3%82%B1%E3%83%83%E3%83%88%E7%95%AA%E5%8F%B7%E3%82%92%E8%87%AA%E5%8B%95%E4%BB%98%E4%B8%8E%E3%81%99%E3%82%8B":{"title":"GitコミットログにJIRAのチケット番号を自動付与する","content":"\n\\#git\n\nコミットメッセージにチケット番号を入れるのはよくある運用ですが、\n手動で毎回入れると漏れがでやすいので、自動でチケット番号を入れたいです。\n`git config --global commit.template` でコミットメッセージのテンプレートを設定することもできますが、\nこちらは固定のテンプレートとなります。\n下記の手順を応用すれば、柔軟に他のメッセージを入れることもできます。\n\n### 前提\n\n* ブランチ名の命名規則が `feature/TICKET-9999_foo` であること\n* チームのルールでコミットメッセージにチケット番号を入れる(入れてもいい)こと\n\n### スクリプト作成\n\nコミットメッセージの先頭にチケット番号を付与するスクリプトを `~/.git_template/hooks/prepare-commit-msg` に配置する\n\n````bash\n$ mkdir -p ~/.git_template/hooks\n$ touch ~/.git_template/hooks/prepare-commit-msg\n# 実行権限をつける\n$ chmod 755 ~/.git_template/hooks/prepare-commit-msg\n````\n\n````bash:~/.git_template/hooks/prepare-commit-msg\n#!/bin/bash -u\n\ncurrent_branch=$(git branch | grep \"^\\*\")\n\nif [[ ! \"$current_branch\" =~ .*/[A-Z]+-[0-9]+.* ]]; then\n    exit 0\nfi\n\n# e.g. feature/AAA-123-foo_bar -\u003e AAA-123\nissue_id=$(echo \"$current_branch\" | sed -E 's/^.*\\/([A-Z]+-[0-9]+).*$/\\1/')\n\n# 先頭にissue_idを付与\nif [[ ! $(head -n 1 $1 | grep \"$issue_id\") ]]; then\n  sed -i -e '1 s@\\(.*\\)@'\"${issue_id}\"' \\1@' $1\nfi\n````\n\n### 新しくクローンするリポジトリにデフォルトで設定されるようにする\n\n````bash\n$ vim ~/.gitconfig\n````\n\n````toml:~/.gitconfig\n[init]\n  templatedir = ~/.git_template\n````\n\n### すでにクローンされているリポジトリに設定する\n\n上記設定をしただけでは、既存のリポジトリには反映されないので、\n各リポジトリのディレクトリの `.git/hooks/prepare-commit-msg` に上記スクリプトが配置されている必要がある。\n\n````bash\n$ mkdir .git/hooks/\n$ cp -p ~/.git_template/hooks/prepare-commit-msg .git/hooks/\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["git"]},"/note/Git-%E3%81%A7pull%E3%81%97%E3%82%88%E3%81%86%E3%81%A8%E3%81%97%E3%81%9F%E3%82%89fatal-cannot-lock-ref-%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E3%81%A7%E3%82%8B":{"title":"Git でpullしようとしたらfatal cannot lock ref のエラーがでる","content":"\n[Jenkinsのgit fetchでCannot lock refエラーが出た時の対応 | by eiryu | Medium](https://medium.com/@eiryu/jenkins%E3%81%AEgit-fetch%E3%81%A7cannot-lock-ref%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E5%87%BA%E3%81%9F%E6%99%82%E3%81%AE%E5%AF%BE%E5%BF%9C-f112ffd755a6)\n[Gitでブランチを作ろうとしたら「fatal: cannot lock ref ...」と怒られた - Qiita](https://qiita.com/ezawa800/items/d2c0ce0b8c47ffae0266)\n\n[Git](note/Git.md) で `feature/foo` というブランチがある状態で `feature/foo/bar` を作ろうとすると\n`error: Cannot lock ref 'refs/remotes/origin/feature/foo/bar': 'refs/remotes/origin/feature/foo' exists; cannot create 'refs/remotes/origin/feature/foo/bar'`  といったエラーが出る。\n\n## 発生手順\n\n* Aが `feature/foo` をpushする\n* Bがpullする\n* Aが `feature/foo` を消して `feature/foo/bar` をpushする\n* Bがpullしようとするときエラーになる\n\n## 対応\n\n`git remote prune` をすれば良い\n`git pull --prune` でも良さそう\n\n[note/Jenkins](Jenkins.md) で、Jenkinsfileのclone時に発生した場合は `Additional Behaviours` のところで `Prune stale remote-tracking branches` を指定するとよい。\n自分は知らなかったので、Jenkinsfileがクローンされるディレクトリ( `${JENKINS_HOME}/workspace/path/to/job@script` ) を削除するジョブを作っていた。。\n\n![Pasted-image-20230501054721](note/Pasted-image-20230501054721.png)\n\n![Pasted-image-20230501054815](note/Pasted-image-20230501054815.png)\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/05/01","Git"]},"/note/Git-fatal-detected-dubious-ownership-in-repository%E3%82%A8%E3%83%A9%E3%83%BC":{"title":"Git fatal detected dubious ownership in repositoryエラー","content":"\n\\#git\n\n## 事象\n\ngitの操作時に以下のメッセージが出て困った。\n\n````shell\n$ git fetch\nfatal: detected dubious ownership in repository at '/path/to/repo'\nTo add an exception for this directory, call:\n\n    git config --global --add safe.directory /path/to/repo\n````\n\n## 原因\n\n[CVE-2022-24765](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-24765) の脆弱性への対応としてgit 2.35.2で入った `safe.directory` 関連の変更によるもの。\n\n共有ディレクトリにリポジトリがある場合、さらに上位のディレクトリに「.git」ディレクトリを作成し、不正に設定を読み込ませることができるといった脆弱性\n\nhttps://git-scm.com/docs/git-config/2.35.2#Documentation/git-config.txt-safedirectory\n[「Git 2.35.2」が公開 ～2件の脆弱性を修正【4月14日追記】 - 窓の杜](https://forest.watch.impress.co.jp/docs/news/1402486.html)\n\ngit clone先のディレクトリのownerが現在のユーザーでない場合にこのエラーが発生する\n\nちなみに `go get` もgit cloneしているのでリポジトリから取得する際にこの事象が発生して、\nCIサーバー上で共有ディレクトリに $GOMODCACHE を置いている場合に困ってしまう\n\n## 対応\n\nディレクトリのownerをgit操作するユーザーにする。\nそれができない場合、フォルダ名がわかっているなら、エラーメッセージに出てきたとおりに `safe.directory` に追加する。\n\n`git config --global --add safe.directory /path/to/repo`\n\n`go get` する際には `$GOMODCACHE/cache/vcs/abcdef12345` のようなハッシュっぽいディレクトリにダウンロードされるので、\nこれをいちいち追加するのは辛い。\n\n`git config --global --add safe.directory *` とすることで、すべてのディレクトリを許可することができ、これで解消はできた。\nが、セキュリティ的にはすべてを許可してしまうので良くないと思う。。\n\n[bash - How to add directory recursively on git safe.directory? - Stack Overflow](https://stackoverflow.com/questions/71855882/how-to-add-directory-recursively-on-git-safe-directory)\n2.36 時点では、recursiveにディレクトリを指定する方法はなく `*` で指定するしかないようだった。\n\nなにかしら対応が出るまでは `*` 指定にする\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["git"]},"/note/Git-hunk%E3%81%AE%E3%82%B5%E3%82%A4%E3%82%BA%E3%82%92%E5%A4%89%E6%9B%B4%E3%81%99%E3%82%8B":{"title":"Git hunkのサイズを変更する","content":"\n`git diff --ignore-matching-lines=\u003cpattern\u003e` で特定のdiffを除外しようとしたがうまくいかず調べたところ、hunk単位でパターンが適用されるらしい。\nhunkのサイズを小さくできないかを調べた。\n\n[Can I modify git-add's **default** hunk size? - Stack Overflow](https://stackoverflow.com/questions/33891010/can-i-modify-git-adds-default-hunk-size)\n\nhunk sizeを [diff.context](https://git-scm.com/docs/diff-config#diff-config-diffcontext) で指定できる\n\n````\ngit config --global diff.context 0\n\n# 実行時のみ\ngit -c diff.context=0 diff\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/04/25","git"]},"/note/Git-remote%E3%81%AB%E3%83%96%E3%83%A9%E3%83%B3%E3%83%81%E3%81%8C%E5%AD%98%E5%9C%A8%E3%81%99%E3%82%8B%E3%81%8B%E3%81%A9%E3%81%86%E3%81%8B%E3%82%92%E3%83%81%E3%82%A7%E3%83%83%E3%82%AF%E3%81%99%E3%82%8B":{"title":"Git remoteにブランチが存在するかどうかをチェックする","content":"\n[Git](note/Git.md) でremoteにブランチが存在するかをチェックするには `git ls-remote` を使う\n\n````shell\nREMOTE_NAME=origin\n# URLを直接指定してもいい\n# REMOTE_NAME=https://github.com/xxx/yyy\n\nBRANCH_NAME=master\n\nif git ls-remote --exit-code $REMOTE_NAME $BRANCH_NAME \u003e/dev/null 2\u003e\u00261; then\n  echo \"Branch $BRANCH_NAME exists in remote $REMOTE_NAME.\"\nelse\n  echo \"Branch $BRANCH_NAME does not exist in remote $REMOTE_NAME.\"\nfi\n````\n\n* [--exit-code](https://git-scm.com/docs/git-ls-remote.html#Documentation/git-ls-remote.txt---exit-code) 一致するrefsがない場合はexit code 2を返す\n* [--head](https://git-scm.com/docs/git-ls-remote.html#Documentation/git-ls-remote.txt---heads) `refs/heads` `refs/tags` のみに限定する\n\nちなみにローカルのリポジトリで判定する場合はこちら\n\n````shell\nif git show-ref --quiet refs/heads/$BRANCH_NAME; then\n  echo \"Branch $BRANCH_NAME exists.\"\nelse\n  echo \"Branch $BRANCH_NAME does not exist.\"\nfi\n````\n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["2023/05/01","git"]},"/note/Go":{"title":"Go","content":"\nGoogleが開発したオープンソースのプログラミング言語\nCやC++などの言語からの影響を受けており、静的型付け、メモリ安全性、ガベージコレクション、クロスプラットフォームなどの特徴がある。\n\nシンプルで扱いやすく、高速であり、並行処理に強みを持っている。\nWebアプリケーションの開発やシステムプログラミングなどにも広く使われている。\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go%E3%81%A7JSON%E3%81%AE%E6%99%82%E5%88%BB%E3%82%92%E6%89%B1%E3%81%86%E5%A0%B4%E5%90%88":{"title":"GoでJSONの時刻を扱う場合","content":"\n\\#Go\n\n## JSONのmarshal/unmarshalで日時フォーマットを指定する\n\n[データをJSONに変換するときに任意のフォーマットを設定する - Qiita](https://qiita.com/taizo/items/2c3a338f1aeea86ce9e2)\n\n[Marshaler](https://golang.org/pkg/encoding/json/#Marshaler), [Unmarshaler](https://golang.org/pkg/encoding/json/#Unmarshaler) インターフェースを実装することで、任意のフォーマットを指定することができる\n\n````go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"time\"\n)\n\nconst (\n\tp = `{\"time\": \"2021/07/01 19:30:00\"}`\n)\n\ntype Message struct {\n\tTime JSONTime `json:\"time\"`\n}\n\ntype JSONTime struct {\n\ttime.Time\n}\n\nfunc (t JSONTime) layout() string {\n\treturn \"2006/01/02 15:04:05\"\n}\n\nfunc (t *JSONTime) UnmarshalJSON(b []byte) error {\n\tloc := loadLocation()\n\t// 囲み文字の\"をつけるのを忘れない\n\tret, err := time.ParseInLocation(`\"`+t.layout()+`\"`, string(b), loc)\n\tif err != nil {\n\t\tfmt.Println(err)\n\t\treturn err\n\t}\n\t*t = JSONTime{ret}\n\treturn nil\n}\n\nfunc (t JSONTime) MarshalJSON() ([]byte, error) {\n\treturn []byte(`\"` + t.Format(t.layout()) + `\"`), nil\n}\n\nfunc loadLocation() *time.Location {\n\t// タイムゾーンの指定\n\tloc, _ := time.LoadLocation(\"Asia/Tokyo\")\n\treturn loc\n}\n\nfunc main() {\n\tvar message Message\n\terr := json.Unmarshal([]byte(p), \u0026message)\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n\tfmt.Printf(\"Time unmarshaled: %s\\n\", message.Time)\n\n\tloc := loadLocation()\n\tnow := time.Date(2021, 8, 25, 18, 20, 0, 0, loc)\n\n\tmessage.Time = JSONTime{now}\n\tb, err := json.Marshal(\u0026message)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tfmt.Printf(\"Marshalled: %s\\n\", b)\n}\n````\n\n## タイムゾーンを扱う場合\n\nタイムゾーンを指定しない場合、 `time.Parse` はデフォルトでUTCになるためJSTなどにしたい場合は明示的に指定する\n\n[Goでtime.Parseを使うときのタイムゾーンについて](https://blog.70-10.net/2018/07/31/go-time-parse/)\n\n### `time.Parse` でタイムインジケータを含めてパースする\n\n````go\n// タイムインジケータを指定すると、そのタイムゾーンで解釈される\n// タイムインジケータを認識させたい場合はformatに含める\nt, _ := time.Parse(\"2006-01-02 15:04:05 (MST)\", \"2021-07-02 08:30:00 (JST)\")\n````\n\n## `time.ParseInLocation` でロケーションを指定する\n\n````go\n// 第3引数でtime.Locationを指定することで、タイムインジケータなしでタイムゾーンを指定できる\njst, _ := time.LoadLocation(\"Asia/Tokyo\")\nt1, _ := time.ParseInLocation(\"2006-01-02 15:04:05\", \"2021-07-02 08:30:00\", jst)\n\n// 第3引数でロケーションを指定し、かつ文字列内でタイムインジケータが指定されている場合は、\n// タイムインジケータの設定が有効になる\n// =\u003e 2021-07-02 08:30:00 UTC\nt2, _ := time.ParseInLocation(\"2006-01-02 15:04:05 (MST)\", \"2021-07-02 08:30:00 (UTC)\", jst)\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go%E3%81%A7http%E3%82%B3%E3%83%8D%E3%82%AF%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%92%E5%86%8D%E5%88%A9%E7%94%A8%E3%81%95%E3%82%8C%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E6%9B%B8%E3%81%8F":{"title":"Goでhttpコネクションを再利用されるように書く","content":"\n\\#Go\n\n* responseを捨ててしまうと、resp.Body.Close() ができなくなるのでだめ\n* 最後まで読み切ってCloseしてないとkeep-aliveしない\n* for-loopの中でリクエストする場合きっちり毎回Closeする\n\n[Goのnet/httpのclientでなぜresponseBodyをClose、読み切らなくてはいけないのか](https://zenn.dev/cube/articles/4ce18a672fc991)\n\n1. responseBodyをCloseしないとコネクションがブロックしてしまい再利用されず、古い接続が残ったまま、新しく接続するたびに新しいGoroutineとファイルディスクリプタを作ってしまう\n1. responseBodyを読み切らないとkeepAliveされずコネクションが終了してしまい再利用されず、接続のたびに新しい接続を作ってしまう。\n\n[Connection re-use in Golang with http.Client - stuartleeks.com](https://stuartleeks.com/posts/connection-re-use-in-golang-with-http-client/)\n\n* bodyを読み切り、Closeを行う\n\n`DefaultClient` を使う:\n\n````go\n    // Uses http.DefaultClient which in turn uses the same http.DefaultTransport instance\n    http.Get(\"http://example.com\")\n````\n\n`Transport` を指定しない(`DefaultTransport` が使われる):\n\n````go\n    // Transport not set, so http.DefaultTransport instance is used\n    client := \u0026http.Client{}\n    client.Get(\"http://example.com\")\n````\n\n同じ `Transport` を使う:\n\n````go\n    // Transport set to a cached value\n    client := \u0026http.Client{\n        Transport: transport, // assuming that transport is a fixed value for this example!\n    }\n    client.Get(\"http://example.com\")\n````\n\n再利用されないケース: `http.Client` ごとに `Transport` を作る\n\n````go\n    // New Transport for each client/call means that connections cannot be re-used\n    // This leads to port exhaustion under load :-(\n    client := \u0026http.Client{\n        Transport: \u0026http.Transport{\n            // insert config here\n        },\n    }\n    client.Get(\"http://example.com\")\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go%E3%81%A7zsh_history%E3%82%92%E3%83%91%E3%83%BC%E3%82%B9%E3%81%99%E3%82%8B%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E3%82%92%E6%9B%B8%E3%81%84%E3%81%A6%E3%81%BF%E3%82%8B":{"title":"Goでzsh_historyをパースするプログラムを書いてみる","content":"\n\\#zsh\n\n## Goでzsh_historyをパースするプログラムを書いてみる\n\n[zsh 文字化けしたzsh_historyファイルを読めるようにする](note/zsh%20文字化けしたzsh_historyファイルを読めるようにする.md), [zsh マルチバイト文字をzsh_historyの形式に変換する](note/zsh%20マルチバイト文字をzsh_historyの形式に変換する.md) の仕様に則って、パース処理を書いていく\n\n````go\npackage zhistconv\n\nconst (\n\t// zsh_historyの仕様で、各バイトが0x83~0xA2のとき、その前に0x83を入れて6bit目を反転させる\n\tx83 = 131\n\txA2 = 162\n\tx20 = 32\n)\n\n// zsh_historyを読める形式に変換する\nfunc ParseZshHistory(latin1Byte []byte) []byte {\n\tisMarking := false\n\tvar byteBuffer []byte\n\n\tfor _, codePoint := range latin1Byte {\n\t\tif codePoint == x83 {\n\t\t\tisMarking = true\n\t\t\tcontinue\n\t\t}\n\n\t\tif isMarking {\n\t\t\t// 6bit目を反転させるために0x20をXORする\n\t\t\tinvertCodePoint := codePoint ^ x20\n\t\t\tbyteBuffer = append(byteBuffer, invertCodePoint)\n\t\t\tisMarking = false\n\t\t} else {\n\t\t\tbyteBuffer = append(byteBuffer, codePoint)\n\t\t}\n\t}\n\n\treturn byteBuffer\n}\n\n// プレーンなテキストをzsh_historyに変換する\nfunc ConvertToZshHistory(latin1Byte []byte) []byte {\n\tvar byteBuffer []byte\n\n\tfor _, codePoint := range latin1Byte {\n\t\t// 131は0metacharの10進数表現\n\t\tif x83 \u003c= codePoint \u0026\u0026 codePoint \u003c= xA2 {\n\t\t\t// 6bit目を反転させるために0x20をXORする\n\t\t\tinvertCodePoint := codePoint ^ x20\n\t\t\tbyteBuffer = append(byteBuffer, x83)\n\t\t\tbyteBuffer = append(byteBuffer, invertCodePoint)\n\t\t} else {\n\t\t\tbyteBuffer = append(byteBuffer, codePoint)\n\t\t}\n\t}\n\n\treturn byteBuffer\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["zsh"]},"/note/Go%E3%81%AA%E3%82%89%E3%82%8F%E3%81%8B%E3%82%8B%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E7%AC%AC2%E7%89%88":{"title":"Goならわかるシステムプログラミング第2版","content":"\n## 1章\n\n* \n\n## 2章\n\n* io.Writer\n* ファイルディスクリプタに対応するモノは、通常のファイルには限られません。標準入出力、ソケット、OS や CPU に内蔵されている乱数生成の仕組みなど、本来ファイルではないものにもファイルディスクリプタが割り当てられ、どれもファイルと同じようにアクセスできます。\n* これと同じように、ファイルディスクリプタのような共通化の仕組みを言語レベルで模倣して整備し、OS による API の差異を吸収しています。その一例が、本章で取り上げる io.Writer です。\n\n## 3章 io.Reader\n\nデータ読み込みのインターフェース\n読み込んだ内容を引数に格納し、バイト数をかえす\n\n`io.Copy`\n`io.Reader` から `io.Writer` にそのままデータを渡す\n\n````go\n// すべて書き出す\nwriteSize, err := io.Copy(writer, reader)\n// 指定したサイズだけコピー\nwriteSize, err := io.CopyN(writer, reader, size)\n````\n\nファイル入力、ネットワーク通信など\n\nバイナリ解析がへーとなった\nPNGファイルの読み込み\n\nストリーム\nインターフェースをつかったデータ入出力\nGoではストリームは言わないがパイプとして使える\n\n* `io.MultiReader`\n* `io.TeeReader`\n  * Readerでreadした内容を別のio.Writerに書き出す\n* `io.Pipe` (io.PipeReader と io.PipeWriter)\n\n## 4章 チャネル\n\nバッファ付きかいなかで動作かわる\n\n````go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"strconv\"\n\t\"time\"\n)\n\nfunc sub(message chan string) {\n\n\tfor i := 0; i \u003c 5; i++ {\n\t\tmessage \u003c- \"hello \" + strconv.Itoa(i)\n\t}\n\n\tfmt.Println(\"wait close\")\n\tclose(message)\n\n}\n\nfunc main() {\n\tfmt.Println(\"start\")\n\tdone := make(chan bool, 2)\n\tgo func() {\n\t\tfmt.Println(\"sub() is finished\")\n\t\ttime.Sleep(time.Second)\n\t\tdone \u003c- true\n\t}()\n\n\t\u003c-done\n\n\tmessage := make(chan string, 5)\n\n\tgo sub(message)\n\n\tfor ch := range message {\n\t\tfmt.Println(ch)\n\t\ttime.Sleep(time.Second)\n\t}\n\n\tfmt.Println(\"end\")\n}\n\n````\n\nfor文\n\n````go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"math\"\n)\n\nfunc primeNumber() chan int {\n\tresult := make(chan int)\n\n\tgo func() {\n\t\tresult \u003c- 2\n\t\tfor i := 3; i \u003c 100000; i+=2 {\n\t\t\tl := int(math.Sqrt(float64(i)))\n\t\t\tfound := false\n\t\t\tfor j := 3; j \u003c l+1; j += 2 {\n\t\t\t\tif i%j == 0 {\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif !found {\n\t\t\t\tresult \u003c- i\n\t\t\t}\n\t\t}\n\t\tclose(result)\n\t}()\n\n\treturn result\n}\n\nfunc main() {\n\tfmt.Println(\"start\")\n\tpn := primeNumber()\n\tfmt.Println(\"...\")\n\tfor n := range pn {\n\t\tfmt.Println(n)\n\t}\n\tfmt.Println(\"end\")\n}\n````\n\n### select文\n\n複数のチャネルを待ち受けてデータが先に送信できたチャンネルのみ処理する\ntimeoutなど\n`default` を書くと何も読み込めなかったときに実行される。ブロックせずにすぐ終了してしまう。この構文はチャネルにデータが入るまでポーリングでループを回す\n\n````go\nfor {\n    select {\n    case data := \u003c- reader:\n        // データを使う\n    default:\n        break \n    }\n}\n````\n\n### context\n\nキャンセルやタイムアウトなど\n\n## 5章 システムコール\n\nシステムコール: 特権モードでOSの機能を呼ぶこと\n\nCPUの動作モード\nプロセスは自分のことだけに集中し、メモリ管理や時間管理はプロセスの外からOSがすべて行う\nCPUの仕組みに動作モードがあり、OSが動作する **特権モード** と一般的なアプリケーションが動作する **ユーザーモード**\n\n通常のアプリケーションでも、メモリ割り当てやファイル入出力、インターネット通信などの機能が必要になることは多々あります\nシステムコールを介して、特権モードでのみ許されている機能をユーザーモードのアプリから呼び出すことができる\n\nPOSIXとC言語の標準規格\nOS間で共通のシステムコールを決めることで、アプリケーションの移植性を高めるために作られたIEEE規格\n\nPOSIXのコンセプトは、「OS間のポータビリティを維持する」です。\nGo言語は、ポータビリティを自力でがんばることでクロスコンパイルが容易になり、他のOSで動くバイナリが簡単に作成できるようになっています。\n\n## 6章 TCPソケットとHTTPの実装\n\nRPCはサーバーが用意しているさまざまな機能を、ローカルコンピューター上にある関数のように簡単に呼び出そう、という仕組みです\nJSON-RPCでは、プロトコルバージョン(\"jsonrpc\"キーの値)、メソッド(\"method\")、引数(\"params\")、送受信の対応を取るためのIDの4項目を使ってリクエストを送信します\n\nアプリケーション層からトランスポート層のプロトコルを利用するときのAPIとしてソケットがある\nOSには、シグナル、メッセージキュー、パイプ、共有メモリなど、数多くのプロセス間通信機能が用意されています。ソケットも、そのようなプロセス間通信の一種です\nソケットにはTCP、UDP、Unixドメインソケットなど\nHTTPでは80番ポートに対してソケットを使ったプロセス間通信を行う\n\n### ソケット通信\n\nソケットとか全然わかっていなかったなー\n\nファイルディスクリプタを介してプロセスの通信をおこなう。\nソケットは通信用の特別なファイルのようなもの。普通のファイル同様にディスクリプタを介してデータをやりとりする\nhttp.Serveってしてたけど裏側はこうなっているんだ\n\nサーバー: ソケットを開いて待ち受ける(Goでは `Listen()`)\nクライアント: 開いているソケットに接続し通信を行う(Goでは `Dial()`)\n\n````go\n// クライアント\nconn, err := net.Dial(\"tcp\", \"localhost:8080\")\n\n// サーバー\nln, err := net.Listen(\"tcp\", \":8080\")\nconn, err := ln.Accept()\n````\n\nサーバー側はこれだと一度切りで終了してしまうのでfor loop\n\n````go\nfor {\n    conn, err := ln.Accept()\n    go func() {\n        // conn を使った読み書き\n    }\n}\n````\n\n### 低レベルAPIでサーバーを実装\n\nTCPソケットを使ったHTTPサーバー(gzip圧縮)\n\n````go\npackage main\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/http/httputil\"\n\t\"strings\"\n\t\"time\"\n)\n\n// クライアントはgzipを受け入れ可能か?\nfunc isGZipAcceptable(request *http.Request) bool {\n\treturn strings.Contains(strings.Join(request.Header[\"Accept-Encoding\"], \",\"), \"gzip\")\n}\n\n// 1セッションの処理をする\nfunc processSession(conn net.Conn) {\n\tfmt.Printf(\"Accept %v\\n\", conn.RemoteAddr())\n\tdefer conn.Close()\n\tfor {\n\t\tconn.SetReadDeadline(time.Now().Add(5 * time.Second))\n\t\t// リクエストを読み込む\n\t\trequest, err := http.ReadRequest(bufio.NewReader(conn))\n\t\tif err != nil {\n\t\t\tvar ne net.Error\n\t\t\tif errors.As(err, \u0026ne) \u0026\u0026 ne.Timeout() {\n\t\t\t\tfmt.Println(\"Timeout\")\n\t\t\t\tbreak\n\t\t\t} else if errors.Is(err, io.EOF) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tpanic(err)\n\t\t}\n\t\tdump, err := httputil.DumpRequest(request, true)\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tfmt.Println(string(dump))\n\t\t// レスポンスを書き込む\n\n\t\tresponse := http.Response{StatusCode: 200,\n\t\t\tProtoMajor: 1,\n\t\t\tProtoMinor: 1,\n\t\t\tHeader:     make(http.Header),\n\t\t}\n\t\tif isGZipAcceptable(request) {\n\t\t\tcontent := \"Hello World (gzipped)\\n\" // コンテンツをgzip化して転送\n\t\t\tvar buffer bytes.Buffer\n\t\t\twriter := gzip.NewWriter(\u0026buffer)\n\t\t\tio.WriteString(writer, content)\n\t\t\twriter.Close()\n\t\t\tresponse.Body = io.NopCloser(\u0026buffer)\n\t\t\tresponse.ContentLength = int64(buffer.Len())\n\t\t\tresponse.Header.Set(\"Content-Encoding\", \"gzip\")\n\t\t} else {\n\t\t\tcontent := \"Hello World\\n\"\n\t\t\tresponse.Body = io.NopCloser(\n\t\t\t\tstrings.NewReader(content))\n\t\t\tresponse.ContentLength = int64(len(content))\n\t\t}\n\t\tresponse.Write(conn)\n\t}\n}\nfunc main() {\n\tlistener, err := net.Listen(\"tcp\", \"localhost:8888\")\n\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tfmt.Println(\"Server is running at localhost:8888\")\n\tfor {\n\t\tconn, err := listener.Accept()\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\tgo processSession(conn)\n\t}\n\n}\n````\n\n### Keep-Alive\n\nHTTP/1.0 では、1セットの通信が終わるたびにTCPコネクションが切れる。\nHTTP/1.1 ではKeep-Aliveが規格にはいって、しばらくの間TCPコネクションを維持する。\nTCPはコネクションを確立するのに1.5RTT(Round Trip Time) がかかるぶん余計な時間がかかる。Keep-Aliveがこのぶんのオーバーヘッドをなくせる\n\n他に速度改善の手法として、gzip圧縮、チャンク形式のボディ送信、パイプライニングがあげられている\n\n## 7章 UDPソケットを使ったマルチキャスト\n\n````go\n// サーバー\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net\"\n\t\"time\"\n)\n\nconst interval = 10 * time.Second\n\nfunc main() {\n\tfmt.Println(\"start tick server at 224.0.0.1:9999\")\n\tconn, err := net.Dial(\"udp\", \"224.0.0.1:9999\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer conn.Close()\n\n\tstart := time.Now()\n\twait := start.Truncate(interval).Add(interval).Sub(start)\n\ttime.Sleep(wait)\n\tticker := time.Tick(interval)\n\n\tfor now := range ticker {\n\t\tconn.Write([]byte(now.String()))\n\t\tfmt.Println(\"Tick: \", now.String())\n\t}\n\n}\n````\n\n````go\n// クライアント\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net\"\n)\n\nfunc main() {\n\tfmt.Println(\"Listen tick server at 224.0.0.1:9999\")\n\taddress, err := net.ResolveUDPAddr(\"udp\", \"224.0.0.1:9999\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tlistener, err := net.ListenMulticastUDP(\"udp\", nil, address)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tdefer listener.Close()\n\n\tbuffer := make([]byte, 1500)\n\n\tfor {\n\t\tlength, remoteAddress, err := listener.ReadFromUDP(buffer)\n\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\n\t\tfmt.Printf(\"Server %v\\n\", remoteAddress)\n\t\tfmt.Printf(\"Now %s\\n\", string(buffer[:length]))\n\t}\n\n}\n````\n\nUDPはクライアント側がソケットをオープンして待受、サーバー側がデータを送信する。\nTCPとは逆のように見える。TCPのクライアントと同じような実装になっている\n\nクラス D の『224.0.0.0〜239.255.255.255』のレンジはマルチキャストアドレス\n\nNTPは遅延が致命的になるためTCPではなくUDP\n\n### TCPとの違い\n\n* TCPは1.5 RTTかかるがUDPは0 RTT\n* TCPには再送処理とフロー処理がある\n  * パケットの順序を受信側で並べ替えられる\n  * 応答番号を返信して送信側は正しく受け取れたのかどうか判断し、受け取れてなかったら再送する\n* ウィンドウ制御  受信側がリソースを確保できていないのに送信リクエストが集中してしまうのを防ぐ。\n  * 受信用のバッファ(TCPではウィンドウという)を決めておき、送信側ではそのサイズまでは受信側からの受信確認を待たずにデータを送信できる\n  * 受信できるウィンドウサイズを送信側につたえることで通信量を制御できる(フロー制御)\n* フレームサイズ\n  * ひとかたまりで送信できるデータサイズをMTU(最大転送単位)\n  * MTUに収まらないデータはIPレベルで複数パケットに分割する\n  * UDPを利用する場合にはデータ構造を1フレームで収まるサイズにし、フレームごとにフレームの内容を識別するヘッダーを付ける必要があるでしょう\n* 輻輳制御\n  * TCPには輻輳制御が備わっており、そのアルゴリズムにはさまざまな種類があります。どのアルゴリズムもゆっくり通信量を増やしていき、通信量の限界値を探りつつ、パケット消失などの渋滞発生を検知すると流量を絞ったり増やしたりしながら最適な通信量を探ります \n\nHTTP/2 と TCP で同じようなことを重複して行っている部分を統合し、UDP 上の QUIC を使うことでさらに無駄を減らそうというのが HTTP/3\n\n## 8章 Unixドメインソケット\n\n初めて聞いた。\n\nUnixドメインソケットでは外部インタフェースへの接続は行いません。\nその代わり、カーネル内部で完結する高速なネットワークインタフェースを作成します。\nUnixドメインソケットを使うことで、ウェブサーバーとNGINXなどのリバースプロキシとの間、あるいはウェブサーバーとデータベースとの間の接続を高速にできる場合があります。\n\nサーバーがファイルを作って、クライアントプロセスからファイルパスを使って通信相手を探す。\n単にサーバーが作成したファイルにクライアントが書き込み、その内容を他のプロセスが見に行っているだけのようだが、\nUnixドメインソケットはソケットファイルという特殊なファイルを作成する\n\n## 9章 ファイルシステムの基礎\n\nファイル操作、path/filepath の関数の紹介\n\n## 10章 ファイルシステムの最深部を扱う Go 言語の関数\n\nファイルの変更監視(syscall.Inotify)\n\n* 監視したいファイルをOS側に通知しておいて、変更があったら教えてもらう(パッシブな 方式)\n  * gopkg.in/fsnotify.v1†2 を利用したパッシブな方式\n* タイマーなどで定期的にフォルダを走査し、os.Stat()などを使って変更を探しに行く (アクティブな方式)\n\nファイルのロック(syscall.Flock())\n\nsyscall.Flock()によるロックでは、すでにロックされているファイルに対してロックをかけようとすると、最初のロックが外れるまでずっと待たされます。そのため、定期的に何度もアクセスしてロックが取得できるかトライする、といったことができません。これを可能にするのがノンブロッキングモードです\n\nファイルのメモリへのマッピング(syscall.Mmap())\nファイルの中身をそのままメモリ上に展開できますし、メモリ上で書き換えた内容をそのままファイルに書き込むこともできます。マッピングという名前のとおり、ファイルとメモリの内容を同期させます\n\n* 同期・ブロッキング: 読み込み・書き込み処理が完了するまでの間、何もせずに待ちます\n\n* 同期・ノンブロッキング: APIを呼ぶと、即座に「まだ完了していないか」どうかのフラグと、現在準備ができているデータが得られ、クライアントが完了を知る必要があるときは、完了が返ってくるまで何度もAPIを呼びます(これをポーリング)\n\n* 非同期・ブロッキング: I/O 多重化(I/O マルチプレクサー)とも呼ばれる。準備が完了したものがあれば通知してもらう、というイベント駆動モテル\n\n* 非同期・ノンブロッキング: メインプロセスのスレッドとは完全に別のスレッドでタスクを行い、完了したらその通知だけを受け取る\n\n* goroutine をたくさん実行し、それぞれに同期・ブロッキング I/O を担当させると、**非同期・ノンブロッキング** となる\n\n* goroutine で並行化させた I/O の入出力でチャネルを使うことで、他の goroutine とやり取りする箇所のみの同期ができる\n\n* このチャネルにバッファがあれば、書き込み側もノンブロッキングとなる\n\n* これらのチャネルでselect構文を使うことで **非同期・ブロッキング** のI/O多重化ができる\n\n* select 構文に default 節があると、読み込みをノンブロッキングで行えるようになり、非同期 IO 化ができる\n\n### select属\n\n非同期ブロッキング(I/O多重化)を効率よく実現するAPI\n大量の入出力をさばく手法\n\nOS の場合には、ブロックしうる複数の I/O システムコールをまとめて登録し、準備ができたものを教えてもらうのが select() の役割\nGo 言語の select 文も、この点については OS が提供する select() システムコールと同じ\n\n## 第11章 コマンドシェル101\n\n### POSIX, SUS\n\nPOSIXという用語は、「UNIX」と名乗るために必要な **Single UNIX Specification(SUS)** と呼ばれる規格の別名でもあります\n\nhttps://pubs.opengroup.org/onlinepubs/9699919799/\nこれを満たすものがPOSIX準拠を名乗れる\n\nPOSIXの規約に従って実装されたユーティリティプログラムは、使う側からすれば行儀のよいプログラムだと言えるでしょう。ユーティリティプログラムについてのPOSIXの規約には以下のようなものがあります\n\n* 入力ファイルを引数として渡す(フラグではなく)\n* 入力ファイルがなかった場合は標準入力を読み込む\n* 入力ファイルが「-」でも標準入力を読み込む\n\nUNIX を名乗れない Linux ですが、SUS をベースにしながら利便性を意識して GUI まわりのパッケージやファイルシステムの構成、プリンターサポートまわりなどを加えた ISO 規格として、 **LSB (Linux Standard Base)** というものがある\n\nPOSIX や LSB は巨大な規格であることから、それらの小さいサブセットとして、 **BusyBox** と呼ばれるソフトウェアもあります。\nAlpineはBusyBoxをベースにしている\n\n### Unix哲学\n\n小さなユーティリティを組み合わせる\n\n## 第12章 プロセスの役割とGo言語による操作\n\nOSが実行ファイルを読み込んで実行するにはそのためのリソースを用意しなければならない。リソースをまとめたプログラムの実行単位がプロセス\n\n* 実行ファイル名 : `os.Executable()`\n* プロセスID : `os.Getpid()`\n* 親プロセスID : `os.Getppid()`\n* ユーザーID: `os.Getuid()` `os.Getgid()`\n\nなどGoからプロセス情報を取る関数が用意されている\n\nOS から見たプロセスは、CPU 時間を消費してあらかじめ用意してあったプログラムに従って動く「タスク」\nプロセスごとにプロセスディスクリプタを持っている\n\n### Goプログラムからのプロセス起動\n\n他のプロセスを扱うには以下を使う\n\n* `os.Process`: 低レベル\n* `os/exec` の `exec.Cmd`: 少し高機能\n\n`exec.Command(名前, 引数, ...)` で起動できる\n`exec.CommandContext` はContextを受け取れる\nContextがキャンセルされると、os.Process.Killで強制終了される\n\n````go\nfunc main() {\n\tcmd := exec.Command(os.Args[1], os.Args[2:]...)\n\tif err := cmd.Run(); err != nil {\n\t\tpanic(err)\n\t}\n\n\tstate := cmd.ProcessState\n\tfmt.Printf(\"%s\\n\", state.String())\n\tfmt.Printf(\" Pid: %d\\n\", state.Pid())\n\tfmt.Printf(\" System: %v\\n\", state.SystemTime())\n\tfmt.Printf(\" User: %v\\n\", state.UserTime())\n}\n````\n\n`cmd.Output()` で子プロセスの出力内容を得るが、実行時間が長いプログラムで最後にしか得られないのは不便\n`StdinPipe` `StdoutPipe` でリアルタイムに通信できるパイプを取得できる\n\n`github.com/mattn/go-colorable` `github.com/mattn/go-isatty` を使って出力に色をつけられる\n\n````go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\n\t\"github.com/mattn/go-colorable\"\n\t\"github.com/mattn/go-isatty\"\n)\n\nvar data = \"\\033[34m\\033[47m\\033[4mB\\033[31me\\n\\033[24m\\033[30mOS\\033[49m\\033[m\\n\"\n\nfunc main() {\n\tvar stdOut io.Writer\n\tif isatty.IsTerminal(os.Stdout.Fd()) {\n\t\tstdOut = colorable.NewColorableStdout()\n\t} else {\n\t\tstdOut = colorable.NewNonColorable(os.Stdout)\n\t}\n\tfmt.Fprintln(stdOut, data)\n}\n````\n\n### フォーク\n\nフォークは、ネイティブスレッドが扱いやすい言語や、Go言語のようにスレッドの活用がランタイムに組み込まれている言語以外では、マルチコアCPUの性能向上を生かすうえで強力な武器となります。\nスクリプト言語では、インタプリタ内部のデータの競合が起きないようにグローバルインタプリタロック(GIL、Global Interpreter Lock)やジャイアント VMロック(GVL、Giant VM Lock)と呼ばれる機構があり、同時に動けるスレッド数が厳しく制限されて複数コアの性能が生かせないケースがあります。このときにfork() で複数のプロセスを作り、ワーカーとして並行に実行させることがよくあります。\n\nたとえばPython には、これを効率よく行うための multiprocessing パッケージがあります。Node.jsにもclusterモジュールがあります。ウェブサーバーのApacheでも、事前にフォークしておくことで並行で処理を行うPreforkが一番最初に導入され、広く使われています。\n\n親子のプロセスが作られるときは、どちらかのプロセスでメモリを変更するまではメモリの実体をコピーしない「コピーオンライト」でメモリが共有されます\nそのため、子プロセス生成時に瞬時にメモリ消費量が大きく増えることはありません。\nしかし、この仕様と言語のランタイムの相性が良くないことがあります。たとえば、Rubyにはガベージコレクタ用のフラグがObjectの内部構造体にあったことから、GCが走るタイミングでフラグの書き換えが発生して早期にメモリコピーが発生してしまうという問題がありました。\nInstagram では、このコピーオンライトの問題を回避するためにGC を停止させて処理速度を向上させる方法を紹介していましたが、PythonのGCから共有オブジェクトを隠すオプションをPython本体に追加してコピーオンライトを防いだことで、メモリの増加量が50%減少しました。この修正はPython3.7に入りました。\n\n### デーモン化\n\nPOSIX 系の OS で動き続けるサーバープロセスなどのバックグラウンドプロセスを作るための機能です\nログアウトしたりシェルをとじてもプロセスを終了させない仕組み\n\n## 第13章 シグナルによるプロセス間の通信\n\nシグナル\n\n* プロセス間通信:カーネルが仲介して、あるプロセスから、別のプロセスに対してシグナルを送ることができる。自分自身に対してシグナルを送ることも可能\n\n* ソフトウェア割り込み:システムで発生したイベントは、シグナルとしてプロセスに送られる。シグナルを受け取ったプロセスは、現在行っているタスクを中断して、あらかじめ登録しておいた登録ルーチンを実行する\n\n* SIGKILL, SIGSTOP はアプリケーションではハンドルできない\n\n* SIGTERM killコマンドがデフォルトで送信する\n\n* SIGHUP 設定ファイルの再読み込みを外部から指示する用途で使われることがデファクトスタンダード\n\n* SIGINT Ctrl+C ハンドルできるSIGKILL\n\n## 第14章 Go言語と並列処理\n\nこの本の定義では\n\n* 並行:CPU 数、コア数の限界を超えて複数の仕事を同時に行う\n* 並列:複数の CPU、コアを効率よく扱って計算速度を上げる\n\ngoroutine 間の情報共有方法としてチャネルを使うことを推奨\n\nスレッドとgoroutineの違い\n\n* スレッドとはプログラムを実行するための「もの」であり、OS によって手配されるものて\n\n* プログラムから見たスレッドは、「メモリにロードされたプログラムの現在の実行状態を持つ仮想 CPU」\n\n* OS や CPU から見たスレッドは、「時間が凍結されたプログラムの実行状態」\n\n* スレッドがCPUコアに対してマッピングされるのに対し、goroutineはOSのスレッド(Go 製のアプリケーションから見ると 1 つの仮想CPU)にマッピングされます\n\n* 「機能が少ない代わりにシンプルで起動が早いスレッド」として提供されている\n\n* M: Machine カーネルにとっての物理CPUコア\n\n* P: Process カーネルにとってのスケジューラ\n\n* G: goroutine カーネルにとってのプロセス\n\nOSのスレッド(M)ごとにタスクであるG(goroutine)のリストがあり、ランキューなどのスレッドが行う作業を束ねるのはProcess(P)\nProcess Affinity の仕組みはない\n\nruntimeパッケージで、OSのスレッドを直接操作することもできる\n\n### Race Detector\n\nデータ競合を発見する機能\nbuildやrunじに `-race` をつけて実行すると、競合が発生した箇所と、競合した書き込みを行った goroutine、その goroutine の生成場所がわかる\n\n### syncパッケージ\n\nチャネルとselectでgoroutine間の同期は事足りる。\n他の言語からの移植などでselectに書き直すのが大変なときに、syncパッケージを使う。\n\n#### sync.Mutex\n\nsync.Mutex は、実行パスに入ることが可能な goroutine を、排他制御によって制限する。\n「メモリを読み込んで書き換える」コードに入る goroutine が 1 つに制限されるため、不整合を防ぐことができる\n同時に実行されると問題が起きる実行コードの行を **クリティカルセクション** と呼びます\nマップや配列に対する操作はアトミックでないので保護が必要\n\nsync.Mutexの宣言は値でもポインタでもいいが、\n値コピーしてしまうとロックしている状態のまま別の sync.Mutex インスタンスになってしまうため、他の関数に渡すときは必ずポインタで渡すようにします\n\n````go\nvar id int\nfunc generateId(mutex *sync.Mutex) int { \n    // 多くの場合は次のように連続して書く\n    mutex.Lock()  \n    defer mutex.Unlock()\n    id++\n    return id\n}\n````\n\n#### チャネルとMutexの使い分け\n\n* チャネルが有用な用途: データの所有権を渡す場合、作業を並列化して分散する場合、非同期で結果を受け取る場合\n* Mutex が有用な用途: キャッシュ、状態管理\n\n#### sync.WaitGroup\n\n多数のgoroutineの待ち合わせに使う\n\n````go\nfunc main() {\n  var wg sync.WaitGroup \n  wg.Add(2)\n  go func() {\n    fmt.Println(\"work 1\")\n    wg.Done()\n  }()\n  go func() {\n    fmt.Println(\"work 2\")\n    wg.Done()\n  }()\n\n  wg.Wait()\n  fmt.Println(\"end\")\n}\n````\n\nチャネルよりも sync.WaitGroup のほうがよいのは、**ジョブ数が大量にあったり、可変個だったりする場合**\n100 以上の goroutine のためにチャネルを大量に作成して終了状態を伝達することもできますが、これだけ大量のジョブであれば、数値のカウントだけでスケールするsync.WaitGroup のほうがリーズナブルです。\n\n#### sync.Once\n\n一度だけ実行したい処理\n\n````go\nfunc initialize() {\n    fmt.Println(\"1回だけ初期化\")\n}\n\nvar once sync.Once\n\nfunc main() {\n    once.Do(initialize)\n    once.Do(initialize)\n    once.Do(initialize)\n}\n````\n\ninit() を使っても初期処理は書けるが、タイミングを制御したいときなどはこちらを使う\n\n#### sync.Cond\n\n条件変数\n\n* 先に終わらせなければいけないタスクがあり、それが完了したら待っているすべての goroutine に通知する(`Broadcast()` メソッド)\n* リソースの準備ができしだい、そのリソースを待っている goroutine に通知をする (`Signal()` メソッド)\n\n````go\nfunc main() {\n\tvar mutex sync.Mutex\n\tcond := sync.NewCond(\u0026mutex)\n\n\tfor _, name := range []string{\"A\", \"B\", \"C\"} {\n\t\tgo func(name string) {\n\t\t\t// ロックしてからWaitメソッドを呼ぶ\n\t\t\tmutex.Lock()\n\t\t\tdefer mutex.Unlock()\n\t\t\t// Broadcast()が呼ばれるまで待つ\n\t\t\tcond.Wait()\n\t\t\t// 呼ばれた!\n\t\t\tfmt.Println(name)\n\t\t}(name)\n\t}\n\tfmt.Println(\" よーい \")\n\ttime.Sleep(time.Second)\n\tfmt.Println(\"どん! \")\n\t// 待っているgoroutineを一斉に起こす\n\tcond.Broadcast()\n\ttime.Sleep(time.Second)\n}\n````\n\nチャネルの場合、待っているすべての goroutine に通知するとしたらクローズするしかないため、一度きりの通知にしか使えません。\nsync.Cond であれば、何度でも使えます。また、通知を受け取る goroutine の数がゼロであっても複数であっても同じように扱えます\n\n#### sync/atomic\n\n不可分操作を提供する\n途中でコンテキストスイッチが入って操作が失敗しないことが保証される\n\n````go\nvar id int64 \nfunc generateId(mutex *sync.Mutex) int64 {\n    return atomic.AddInt64(\u0026id, 1)\n}\n````\n\n## 第15章 並行・並列処理の手法と設計のパターン\n\n並行・並列処理の実現手法\n\n* マルチプロセス\n* イベント駆動\n* マルチスレッド\n* ストリーミング・プロセッシンク\n\n## 第16章 Go 言語のメモリ管理\n\n## 第17章 実行ファイルが起動するまで\n\nランタイムライブラリがカーネルへの命令などをラップしてる\n\nCの標準ライブラリをリンクしない\nGoのランタイムにすべてgoroutineやメモリ管理などをふくんでいる\n逆に、アプリケーションとランタイムを切り離すことも不可能\nOSのカーネルのようなものはGoでは作れない Biscuitのような例はある\n\nGoのランタイムに各OS用のエントリーポイントがあるためどのOSでもビルドできる\n\n## 第18章 時間と時刻\n\n低レイヤーにおけるタイマーやカウンターの仕組みと使い方\n\nOSが使う時間の仕組みは沢山の種類のタイマーやカウンターがある\n\n* OSが起動すると、リアルタイムクロック(RTC、ハードウェア) から現在時刻をよみとる\n* OSのシステムクロック(ソフトウェア)に反映する\n* ハードウェアのタイマーを設定し、一定間隔で割り込みがかかるようにする。この割り込みを受けて、システムクロックを更新したり、現在実行中のプロセスが持つ残りのタイムスライスを減らしたり、必要に応じてタスクの切り替えを行ったりします。\n\nLinux カーネルのデフォルト設定だと、このタイマー割り込みの間隔は 1 秒 あたり 250 回となっています。この割り込みのたびに、jiffies というカウンター変数が増えます。このカウンター変数が1増加することを「1 Tick」という\n\nモノトニック時刻は、OS 起動からの時間や、各プロセス起動からの時間をカウントなど巻き戻らない時刻\nウォールクロック時間は、日常生活における実時間\nCPU時間はCPUが消費した時間\n\n## 第19章 Go 言語とコンテナ\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["reading"]},"/note/Go%E3%81%AB%E4%B8%89%E9%A0%85%E6%BC%94%E7%AE%97%E5%AD%90%E3%81%8C%E6%8E%A1%E7%94%A8%E3%81%95%E3%82%8C%E3%81%AA%E3%81%84%E7%90%86%E7%94%B1":{"title":"Goに三項演算子が採用されない理由","content":"\n\\#Go\n\n### [Goに三項演算子が採用されない理由](https://zenn.dev/nobonobo/articles/09d884f1f520d6)\n\n* if-elseは長くなるが間違いない、明確\n  * 結局、分岐は行をわけて分岐が目で追えるほうがデバッグしやすい\n* カバレッジは行単位で計測されることが多く、三項演算子だとカバレッジが正しく計測できない\n* switch文もある\n* コミュニティは賛成派４０％、否定派６０％程度。しかし賛成比率が上がってもそれだけで採用されることはなさそう\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go%E3%81%AE%E3%83%A1%E3%83%88%E3%83%AA%E3%82%AF%E3%82%B9%E3%82%92Prometheus%E3%81%A7%E5%8F%8E%E9%9B%86%E3%81%99%E3%82%8B":{"title":"GoのメトリクスをPrometheusで収集する","content":"\n## http.ServerのメトリクスをPrometheusで出力する\n\nhttps://prometheus.io/docs/tutorials/instrumenting_http_server_in_go/\n\n````go\npackage main\n\nimport (\n   \"fmt\"\n   \"net/http\"\n\n   \"github.com/prometheus/client_golang/prometheus\"\n   \"github.com/prometheus/client_golang/prometheus/promhttp\"\n)\n\nvar pingCounter = prometheus.NewCounter(\n   prometheus.CounterOpts{\n       Name: \"ping_request_count\",\n       Help: \"No of request handled by Ping handler\",\n   },\n)\n\nfunc ping(w http.ResponseWriter, req *http.Request) {\n   pingCounter.Inc()\n   fmt.Fprintf(w, \"pong\")\n}\n\nfunc main() {\n   prometheus.MustRegister(pingCounter)\n\n   http.HandleFunc(\"/ping\", ping)\n   http.Handle(\"/metrics\", promhttp.Handler())\n   http.ListenAndServe(\":8090\", nil)\n}\n````\n\n### Echoの場合\n\n````go\npackage main\n\nimport (\n\t\"net/http\"\n\n\tpromMiddleware \"github.com/labstack/echo-contrib/prometheus\"\n\t\"github.com/labstack/echo/v4\"\n)\n\nfunc main() {\n\te := echo.New()\n\n\t// /metrics でメトリクス情報が取れる\n\tpm := promMiddleware.NewPrometheus(\"echo\", nil)\n\tpm.Use(e)\n\n\te.GET(\"/ping\", func(c echo.Context) error {\n\t\treturn c.String(http.StatusOK, \"pong\")\n\t})\n\n\te.Logger.Fatal(e.Start(\":1323\"))\n}\n````\n\n## 自作のExporterを作る\n\n[Golangで簡単にPrometheusのExporterを作れる。 - ry's Tech blog](https://ryo-xjsbx.hatenablog.com/entry/prometheus-exporter-with-golang)\n\n`prometheus.Collector` interfaceを満たすように作成して登録すればいい。\n\nhttps://github.com/dgraph-io/ristretto (キャッシュライブラリ)でメトリクスをとってみる\n\n````go\npackage main\n\nimport (\n\t\"github.com/dgraph-io/ristretto\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n)\n\n// CacheStatsCollector implements the prometheus.Collector interface.\ntype CacheStatsCollector struct {\n\tcache *ristretto.Cache\n\n\t// descriptions of exported metrics\n\thitsDesc                  *prometheus.Desc\n\tmissesDesc                *prometheus.Desc\n\tkeysAddedDesc             *prometheus.Desc\n\tkeysUpdatedDesc           *prometheus.Desc\n\tkeysEvictedDesc           *prometheus.Desc\n\tcostAddedDesc             *prometheus.Desc\n\tcostEvictedDesc           *prometheus.Desc\n\tgetsDroppedDesc           *prometheus.Desc\n\tgetsKeptDesc              *prometheus.Desc\n\tratioDesc                 *prometheus.Desc\n\tlifeExpectancySecondsDesc *prometheus.Desc\n}\n\n// NewCacheStatsCollector for prometheus.\nfunc NewCacheStatsCollector(cache *ristretto.Cache) *CacheStatsCollector {\n\tlabels := prometheus.Labels{\"name\": \"ristretto\"}\n\n\treturn \u0026CacheStatsCollector{\n\t\tcache:                     cache,\n\t\thitsDesc:                  prometheus.NewDesc(\"ristretto_hits_total\", \"The number of hits in the cache.\", nil, labels),\n\t\tmissesDesc:                prometheus.NewDesc(\"ristretto_misses_total\", \"The number of misses in the cache.\", nil, labels),\n\t\tkeysAddedDesc:             prometheus.NewDesc(\"ristretto_keys_added\", \"The number of keys added in the cache.\", nil, labels),\n\t\tkeysUpdatedDesc:           prometheus.NewDesc(\"ristretto_keys_updated\", \"The number of keys updated in the cache.\", nil, labels),\n\t\tkeysEvictedDesc:           prometheus.NewDesc(\"ristretto_keys_evicted\", \"The number of keys evicted in the cache.\", nil, labels),\n\t\tcostAddedDesc:             prometheus.NewDesc(\"ristretto_cost_added\", \"The number of cost added in the cache.\", nil, labels),\n\t\tcostEvictedDesc:           prometheus.NewDesc(\"ristretto_cost_evicted\", \"The number of cost evicted in the cache.\", nil, labels),\n\t\tgetsDroppedDesc:           prometheus.NewDesc(\"ristretto_gets_dropped\", \"The number of gets dropped in the cache.\", nil, labels),\n\t\tgetsKeptDesc:              prometheus.NewDesc(\"ristretto_gets_kept\", \"The number of gets kept in the cache.\", nil, labels),\n\t\tratioDesc:                 prometheus.NewDesc(\"ristretto_ratio\", \"The hit ratio of the cache.\", nil, labels),\n\t\tlifeExpectancySecondsDesc: prometheus.NewDesc(\"ristretto_life_expectancy_seconds\", \"The seconds of life expectancy of the cache.\", nil, labels),\n\t}\n}\n\n// Describe implements the prometheus.Collector interface.\nfunc (c CacheStatsCollector) Describe(ch chan\u003c- *prometheus.Desc) {\n\tch \u003c- c.hitsDesc\n\tch \u003c- c.missesDesc\n\tch \u003c- c.keysAddedDesc\n\tch \u003c- c.keysUpdatedDesc\n\tch \u003c- c.keysEvictedDesc\n\tch \u003c- c.costAddedDesc\n\tch \u003c- c.costEvictedDesc\n\tch \u003c- c.getsDroppedDesc\n\tch \u003c- c.getsKeptDesc\n\tch \u003c- c.ratioDesc\n\tch \u003c- c.lifeExpectancySecondsDesc\n}\n\n// Collect implements the prometheus.Collector interface.\nfunc (c CacheStatsCollector) Collect(ch chan\u003c- prometheus.Metric) {\n\tmetrics := c.cache.Metrics\n\n\tch \u003c- prometheus.MustNewConstMetric(c.hitsDesc, prometheus.CounterValue, float64(metrics.Hits()))\n\tch \u003c- prometheus.MustNewConstMetric(c.missesDesc, prometheus.CounterValue, float64(metrics.Misses()))\n\tch \u003c- prometheus.MustNewConstMetric(c.keysAddedDesc, prometheus.CounterValue, float64(metrics.KeysAdded()))\n\tch \u003c- prometheus.MustNewConstMetric(c.keysUpdatedDesc, prometheus.CounterValue, float64(metrics.KeysUpdated()))\n\tch \u003c- prometheus.MustNewConstMetric(c.keysEvictedDesc, prometheus.CounterValue, float64(metrics.KeysEvicted()))\n\tch \u003c- prometheus.MustNewConstMetric(c.costAddedDesc, prometheus.CounterValue, float64(metrics.CostAdded()))\n\tch \u003c- prometheus.MustNewConstMetric(c.costEvictedDesc, prometheus.CounterValue, float64(metrics.CostEvicted()))\n\tch \u003c- prometheus.MustNewConstMetric(c.getsDroppedDesc, prometheus.CounterValue, float64(metrics.GetsDropped()))\n\tch \u003c- prometheus.MustNewConstMetric(c.getsKeptDesc, prometheus.CounterValue, float64(metrics.GetsKept()))\n\tch \u003c- prometheus.MustNewConstMetric(c.ratioDesc, prometheus.CounterValue, float64(metrics.Ratio()))\n\tch \u003c- prometheus.MustNewConstMetric(c.lifeExpectancySecondsDesc, prometheus.CounterValue, float64(metrics.LifeExpectancySeconds().Count))\n}\n\nfunc main() {\n\n\tcache, _ := ristretto.NewCache(\u0026ristretto.Config{\n\t\tNumCounters: 10000,\n\t\tMaxCost:     100000,\n\t\tBufferItems: 64,\n\t\tMetrics:     true,\n\t})\n\n\tcollector := NewCacheStatsCollector(cache)\n\tprometheus.MustRegister(collector)\n\n\thttp.Handle(\"/metrics\", promhttp.Handler())\n\thttp.Handle(\"/set\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tk := r.URL.Query().Get(\"key\")\n\t\tv := r.URL.Query().Get(\"value\")\n\t\tcache.Set(k, v, 1)\n\t}))\n\thttp.Handle(\"/get\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tk := r.URL.Query().Get(\"key\")\n\t\tif v, ok := cache.Get(k); ok {\n\t\t\tvs, _ := v.(string)\n\t\t\tw.Write([]byte(vs))\n\t\t}\n\t}))\n\thttp.ListenAndServe(\":2112\", nil)\n}\n\n````\n\n````shell\n$ curl 'localhost:2112/set?key=foo\u0026value=bar'\n\n$ curl localhost:2112/metrics\n# HELP ristretto_misses_total The number of misses in the cache.\n# TYPE ristretto_misses_total counter\nristretto_misses_total{name=\"ristretto\"} 1\n# HELP ristretto_ratio The hit ratio of the cache.\n# TYPE ristretto_ratio counter\nristretto_ratio{name=\"ristretto\"} 0\n\n$ curl 'localhost:2112/get?key=foo\u0026value=bar'\nbar\n\n$ curl localhost:2112/metrics | rg 'ristretto'\n# HELP ristretto_misses_total The number of misses in the cache.\n# TYPE ristretto_misses_total counter\nristretto_misses_total{name=\"ristretto\"} 1\n# HELP ristretto_ratio The hit ratio of the cache.\n# TYPE ristretto_ratio counter\nristretto_ratio{name=\"ristretto\"} 0.5\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go","Prometheus"]},"/note/Go-%E3%82%BF%E3%83%BC%E3%83%9F%E3%83%8A%E3%83%AB%E3%81%AE%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E3%81%A7password%E3%82%92%E5%85%A5%E5%8A%9B%E3%81%99%E3%82%8B":{"title":"Go ターミナルのプロンプトでpasswordを入力する","content":"\nターミナル上でパスワードを入力するとき、画面上には表示されないようにしたい。\n\nそんなときに [golang.org/x/crypto の ssh/terminal](https://pkg.go.dev/golang.org/x/crypto) が使える\n\n````go\nfunc askCred() (string, string) {\n\treader := bufio.NewReader(os.Stdin)\n\tfmt.Print(\"Enter Username: \")\n\tusername, _ := reader.ReadString('\\n')\n\n\tfmt.Print(\"Enter Password: \")\n\tbytePassword, err := terminal.ReadPassword(0)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Println(\"\\nPassword typed: \" + string(bytePassword))\n\tpassword := string(bytePassword)\n\n\treturn strings.TrimSpace(username), strings.TrimSpace(password)\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/04/26","Go"]},"/note/Go-%E3%83%97%E3%83%A9%E3%82%A4%E3%83%99%E3%83%BC%E3%83%88%E3%83%AA%E3%83%9D%E3%82%B8%E3%83%88%E3%83%AA%E3%81%AB%E5%AF%BE%E3%81%97%E3%81%A6ssh%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6go-get%E3%81%99%E3%82%8B":{"title":"Go プライベートリポジトリに対してsshを使ってgo getする","content":"\n\\#Go #git\n\ngo get 時にはgit cloneが動いているのでgitの設定でコントロールできる。\n\n## tl;dr\n\n* 環境変数 `GOPRIVATE=\u003cprivate repository\u003e` を設定する\n  * 例 `export GOPRIVATE=github.com/PRIVATE`\n* 秘密鍵などsshの設定をしたい場合は環境変数 `GIT_SSH_COMMAND` を設定する\n  * 例 `export GIT_SSH_COMMAND=ssh -i ~/.ssh/id_rsa_privaterepo`\n* `git config --global url.\"ssh://git@github.com\".insteadOf https://github.com/` を設定する\n\n## 調べたこと\n\n### GOPRIVATE\n\ngolang 1.13で追加された設定値\nデフォルトでsum.golang.orgにある公開のGo checksum databaseと照合して検証するが、公開していないリポジトリの場合は検証が行えずダウンロード時にエラーになる。\n`GOPRIVATE` に設定したパスは検証されなくなる。\n\n### httpsでアクセストークンを使ってcloneする\n\n[GitHubのprivate repositoryを含んだ場合のGo Modules管理 | おそらくはそれさえも平凡な日々](https://songmu.jp/riji/entry/2019-07-29-go-private-modules.html)\n\ngo get は通常ではhttpsのURLでcloneしようとする。\nGitHubやBitbucketではアクセストークンを使ってhttpsでcloneできる。\n`insteadOf` でURLを上書きすることで、go get時に認証情報を使ってgit cloneされるようにできる\n\n````shell\n$ git config --global url.\"https://${USER}:${PERSONAL_TOKEN}@bitbucket.org/\".insteadOf \"https://bitbucket.org/\"\n$ cat ~/.gitconfig\n[url \"https://\u003cuser\u003e:\u003ctoken\u003e@bitbucket.org/\"]\n        insteadOf = https://bitbucket.org/\n````\n\nこれだと上記のようにgitconfigにアクセストークンが書かれてしまうので、他の人も見える環境だとあまり良くない。\n\n### go getでsshの設定をする\n\nbitbucketの例\n`https://bitbucket.org/` のかわりに `ssh://git@bitbucket.org/` が使われるようにする\n\n````shell\ngit config --global url.\"ssh://git@bitbucket.org/\".insteadOf https://bitbucket.org/\n````\n\n`~/.ssh/id_rsa` が存在して、公開鍵をホスティングサービス上に登録していれば、sshでgo getできる\n\n````shell\n$ ls -al ~/.ssh/id_rsa\n.r-------- # 存在してpermissionが適切になっている\n\n# 公開鍵をknown_hostsに登録していないと接続時にエラーになるため予め入れておく\n$ ssh-keygen -F bitbucket.org || ssh-keyscan bitbucket.org \u003e\u003e ~/.ssh/known_hosts\n\n$ go get bitbucket.org/private-repo\n=\u003e 取得できた\n````\n\nファイルがなかったり公開鍵を登録していなかったりすると `Permission denied (publickey).` のエラーが出る。\n\n### 秘密鍵のファイルパスを指定する\n\n`~/.ssh/id_rsa` 以外の鍵を指定したい場合はさらに設定が必要となる。\n\n[git clone 時に秘密鍵を指定する - Qiita](https://qiita.com/sonots/items/826b90b085f294f93acf)\n\n#### `~/.ssh/config` をいじる\n\n````ssh-config\nHost bitbucket.org\n  IdentityFile ~/.ssh/id_rsa_privaterepo\n````\n\nこれでgo getできた。\nしかし全体の設定をいじることになるためあまりやりたくない。\n\n#### `core.sshCommand` を設定する\n\n````shell\n$ git config --global core.sshCommand \"ssh -i ~/.ssh/id_rsa_privaterepo -F /dev/null\"\n````\n\nこれでgit clone時にはsshキーが使われたのだが、go get時にはなぜか使われなかった。。\n\nちなみに一時的に config 設定をしたい場合は `git -c` で設定できて、普通にgit cloneするときはこれでもいい\n\n````shell\n$ git -c core.sshCommand=\"ssh -i ~/.ssh/id_rsa_privaterepo -F /dev/null\" clone ssh://git@bitbucket.org/private.git\n````\n\n#### `GIT_SSH_COMMAND` 環境変数を設定する\n\n同じことで悩んでいる人がいた。\n[git - How can you specify which ssh key `go get` will use - Stack Overflow](https://stackoverflow.com/questions/65569280/how-can-you-specify-which-ssh-key-go-get-will-use)\n\n[GIT_SSH_COMMAND](https://git-scm.com/docs/git#Documentation/git.txt-codeGITSSHCOMMANDcode) の設定は効くということだった。\n\n````shell\nexport GIT_SSH_COMMAND=\"ssh -i ~/.ssh/id_rsa_privaterepo -o StrictHostKeyChecking=no -F /dev/null\"\n````\n\n実際これで指定した鍵を使ってgo getすることができた。\n\n### `fatal: detected dubious ownership` エラー\n\n共有ディレクトリに `GOMODCACHE` を指定していたためにこのエラーも発生した。\n[Git fatal detected dubious ownership in repositoryエラー](note/Git%20fatal%20detected%20dubious%20ownership%20in%20repositoryエラー.md)\n\nこちらを設定した\n\n````\ngit config --global safe.directory '*'\n````\n\n### Jenkins上で実行する\n\nworker上に秘密鍵を置いていない場合、credentialからssh private keyを取得して使うことになる。\n\nまずは `~/.ssh/id_rsa` に鍵を置いてみた\n\n````groovy\npipeline {\n  agent {\n    label \"worker\"\n  }\n\n  stages {\n    stage('clone'){\n      steps {\n        withCredentials([sshUserPrivateKey(credentialsId: 'git_ssh_key', keyFileVariable: 'GIT_SSH_KEY')]) {\n            sh '''\n            mkdir -p ~/.ssh\n            cp \"$BITBUCKET_SSH_KEY\" ~/.ssh/id_rsa\n            chmod 400 ~/.ssh/id_rsa\n\n            ssh-keygen -F bitbucket.org || ssh-keyscan bitbucket.org \u003e\u003e ~/.ssh/known_hosts\n            export GOPRIVATE='bitbucket.org'\n\n            git config --global url.\"ssh://git@bitbucket.org/\".insteadOf https://bitbucket.org/\n\n            go get bitbucket.org/my/repo\n            '''\n        }\n      }\n    }\n  }\n}\n````\n\nこれでも良かったが、credentialの値を別の場所にコピーして使うというのが気持ち悪かったので、 `GIT_SSH_COMMAND` を使った。\n\n#### GIT_SSH_COMMAND版\n\n````groovy\npipeline {\n\n  stages {\n    stage('clone'){\n      steps {\n        withCredentials([sshUserPrivateKey(credentialsId: 'git_ssh_key', keyFileVariable: 'GIT_SSH_KEY')]) {\n            sh '''\n            ssh-keygen -F bitbucket.org || ssh-keyscan bitbucket.org \u003e\u003e ~/.ssh/known_hosts\n            export GIT_SSH_COMMAND=\"ssh -i $GIT_SSH_KEY -F /dev/null\"\n            export GOPRIVATE='bitbucket.org'\n\n            git config --global url.\"ssh://git@bitbucket.org/\".insteadOf https://bitbucket.org/\n\n            go get bitbucket.org/my/repo\n            '''\n        }\n      }\n    }\n  }\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go","git"]},"/note/Go-%E8%A4%87%E6%95%B0%E3%81%AELambda%E3%81%A7%E5%85%B1%E9%80%9A%E3%81%A7%E5%AE%9F%E8%A1%8C%E3%81%99%E3%82%8B%E5%87%A6%E7%90%86%E3%82%92middleware%E3%81%A7%E6%9B%B8%E3%81%8F":{"title":"Go 複数のLambdaで共通で実行する処理をmiddlewareで書く","content":"\nAPI Gateway向けの [AWS Lambda](note/AWS%20Lambda.md) のハンドラーをGoで作成する場合、普通に書くとこのように、main関数から特定のシグネチャの関数を lambda.Start で呼び出す。\n\nhttps://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-handler.html\n\n````go\npackage main\n\nimport (\n        \"fmt\"\n        \"context\"\n        \"github.com/aws/aws-lambda-go/events\"\n        \"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {\n\treturn events.APIGatewayProxyResponse{\n\t\tBody:       fmt.Sprintf(\"Hello, %v\", request.QueryStringParameters[\"name\"]),\n\t\tStatusCode: 200,\n\t}, nil\n}\n\nfunc main() {\n        lambda.Start(handler)\n}\n````\n\nAPI GatewayのパスごとにFunctionを紐づけている場合に、ヘッダーからトレース用の情報を取得したり、ユーザー情報を取得したりといった各ハンドラー共通で実行する処理を書きたい。\n\nAPI Gateway -----\u003e /hello HelloFunction\n└-------\u003e  /bye ByeFunction\n\n`hello/main.go`\n\n````go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {\n\ttraceId := request.Headers[\"X-Amzn-Trace-Id\"]\n\tfmt.Println(traceId)\n\n\treturn events.APIGatewayProxyResponse{\n\t\tBody:       fmt.Sprintf(\"Hello, %v\", request.QueryStringParameters[\"name\"]),\n\t\tStatusCode: 200,\n\t}, nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n````\n\n`bye/main.go`\n\n````go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc handler(ctx context.Context, request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {\n\ttraceId := request.Headers[\"X-Amzn-Trace-Id\"]\n\tfmt.Println(traceId)\n\n\treturn events.APIGatewayProxyResponse{\n\t\tBody:       fmt.Sprintf(\"Bye, %v\", request.QueryStringParameters[\"name\"]),\n\t\tStatusCode: 200,\n\t}, nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n````\n\n各ハンドラーのコードに同じ処理を書くのは、数が増えたときに間違えやすくなるので、なんとかしたい。\n\n## http handlerのミドルウェア\n\nnet/httpでwebサーバーを作るときに、各http handlerに共通で実行したい処理を実装するパターンの一つとして、ミドルウェアを書くことがある。\n\n参考 [HTTP Middleware の作り方と使い方 - 技術メモ](https://tutuz-tech.hatenablog.com/entry/2020/03/23/220326)\n\nこれは引数に `http.Handler` をとって `http.Handler` を返す関数で、ハンドラーの前後に処理を挟み込むのと、ミドルウェア自身をミドルウェアでラップすることができる。\n\n````go\nfunc logging(next http.Handler) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    fmt.Printf(\"Request: %v\\n\", r.URL.String())\n    next.ServeHTTP(w, r)\n  })\n}\n````\n\nこれをさらにwrapして、設定値を渡すような書き方もできる。echoのミドルウェアはこのような実装になっている。\n\n````go\ntype HttpMiddlewareFunc func(next http.Handler) http.Handler\n\nfunc LoggingMiddleware(debug bool) HttpMiddlewareFunc {\n    return func (next http.Handler) http.Handler {\n        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n            if debug {\n                fmt.Printf(\"Request: %v\\n\", r.URL.String())\n            }\n            next.ServeHTTP(w, r)\n        })\n    }\n}\n````\n\n## lambda handlerのミドルウェアに応用する\n\n同様の方法でミドルウェアを書くとこんな感じになる。\n\n````go\ntype LambdaHandlerFunc func(context.Context, events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error)\ntype LambdaMiddlewareFunc func(next LambdaHandlerFunc) LambdaHandlerFunc\n\nfunc LoggingMiddleware(debug bool) HttpMiddlewareFunc {\n    return func(next LambdaHandlerFunc) LambdaHandlerFunc {\n        return LambdaHandlerFunc(func(ctx context.Context, request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {\n            if debug {\n                fmt.Printf(\"Request: %v\\n\", request)\n            }\n\n            return next(ctx, request)\n        })\n    }\n}\n````\n\n実用的な例としては以下のようになる。\n\n````go\npackage middleware\n\nimport (\n\t\"context\"\n\t\"net/http\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n)\n\ntype LambdaHandlerFunc func(context.Context, events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error)\ntype LambdaMiddlewareFunc func(next LambdaHandlerFunc) LambdaHandlerFunc\n\n// ApplyMiddlewares\nfunc ApplyMiddlewares(handler LambdaHandlerFunc) LambdaHandlerFunc {\n\tmiddlewares := []LambdaMiddlewareFunc{\n\t\tHeader(),\n\t\tAuth(),\n\t}\n\n\tfor i := len(middlewares) - 1; i \u003e= 0; i-- {\n\t\thandler = middlewares[i](handler)\n\t}\n\n\treturn handler\n}\n\n// Header contextにデフォルトのrequest/response headerをセットする\nfunc Header() LambdaMiddlewareFunc {\n\treturn func(next LambdaHandlerFunc) LambdaHandlerFunc {\n\t\treturn func(ctx context.Context, request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {\n\n\t\t\tresHeaders := http.Header{\n\t\t\t\t\"Content-Type\": []string{\"application/json\"},\n\t\t\t}\n\t\t\tctx = SetResponseHeader(ctx, resHeaders)\n\n\t\t\treturn next(ctx, request)\n\t\t}\n\t}\n}\n\nfunc Auth() LambdaMiddlewareFunc {\n\treturn func(next LambdaHandlerFunc) LambdaHandlerFunc {\n\t\treturn func(ctx context.Context, request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {\n\t\t\tauthHeader := request.Headers[\"Authorization\"]\n\t\t\t// 認証処理\n\n\t\t\tctx = SetUser(ctx, user)\n\n\t\t\treturn next(ctx, request)\n\t\t}\n\t}\n}\n\n// ----\n// ctxにセット/取得する処理\n// ----\n\ntype ctxKey string\n\nconst (\n\tctxKeyUser      ctxKey = \"ctxKeyCustomerUser\"\n\tctxKeyResHeader ctxKey = \"ctxKeyResHeader\"\n)\n\nfunc SetResponseHeader(ctx context.Context, headers http.Header) context.Context {\n\tctx = context.WithValue(ctx, ctxKeyResHeader, headers)\n\treturn ctx\n}\n\nfunc ResponseHeaderFromContext(ctx context.Context) http.Header {\n\tif v, ok := ctx.Value(ctxKeyResHeader).(http.Header); ok {\n\t\treturn v\n\t}\n\treturn http.Header{}\n}\n\nfunc SetUser(ctx context.Context, user *User) context.Context {\n\tctx = context.WithValue(ctx, ctxKeyUser, user)\n\treturn ctx\n}\n\nfunc UserFromContext(ctx context.Context) *User {\n\tif v, ok := ctx.Value(ctxKeyUser).(*User); ok {\n\t\treturn v\n\t}\n\treturn nil\n}\n\n````\n\n`hello/main.go`\n\n````go\nfunc handler(ctx context.Context, request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {\n\t// ...Handlerの処理\n}\n\nfunc main() {\n\tlambda.Start(ApplyMiddlewares(handler))\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/06/13","Go","Lambda"]},"/note/Go-Conference-2022-Spring":{"title":"Go Conference 2022 Spring","content":"\n\\#Go #meetup\n\nhttps://gocon.jp/2022spring/schedule/#day_2022-04-23\n\n資料まとめ\n[Go Conference 2022 Spring参加メモ](https://blog.hozi.dev/hozi576/articles/01g19p2b2eg3dmjfzj4qg7cywp)\n\n## 静的解析\n\ngo/ast めっちゃ便利じゃん、意外と難しくない\nファイルを読み込んでastでパースするといい感じにツリーができて、複雑度判定のコードを書いたりできる\n\n## PHPからリプレースした\n\nヤプリで創業以来のPHPをGoで書き換える\n\n「社内で導入実績があった」\nやりたかったら小さいツールからでも実績作るの大事だよなー。ワイが先駆者だ\n\n* DBが混沌としているがリプレース対象はアプリケーションのみ\n  * カラムに巨大JSONを突っ込んでいるさまをchaos jsonって命名するのすき、現場は地獄\n  * database/sql では、Scannerインターフェースを満たすように実装すれば、Selectしたときに実行されるので好きなパース処理がかける\n  * カオスを下層レイヤに閉じ込めることができた\n* 型があるのはすばらしい\n* エラーの握りつぶしが減る\n* 環境構築が楽\n* 標準パッケージが読みやすい\n* 標準パッケージをコードリーディングする会、いいね うちでもやってみてもいいのかも？\n\n## GC\n\n* Discordがパフォーマンスの理由からGoからRustに書き換えたけど、本当にそうなの？\n* Goのバージョンが古いので、現在ではもっと改善されている\n* Stop The Worldの時間にSLOが設けられていて、1ms未満\n* GCのアルゴリズムは古くからあるものに改良を加えている\n  * concurrent mark and sweep\n* 並行処理を使っている\n  * https://github.com/golang/go/blob/master/src/runtime/mgc.go\n\n## Go で RDB に SQL でアクセスするためのライブラリ Kra の紹介\n\n* sqlxはpanic使っていて、Goらしくない\n* SQLはRDB操作の基本で避けられない\n* データベースのほうがアプリケーションより長生き\n* インピーダンスミスマッチは解消しがたいもの。避けようとせずしっかり向き合う\n* ORMの誤用でN+1問題が発生しがち\n\n## protoc\n\n* コード生成をいっぱい頑張ってなんとかしてきたんだな〜ってわかる\n* enumやDB関連コード、API関連コードをそれぞれ別コマンドで生成\n* protoc pluginで拡張することで、proto定義からすべての自動生成が行えるようになった\n\n## database/sqlの実装\n\n* blank importでどうやって動いているの？\n* func initで動いている\n* mysqlだったら、sql.Registerをinitで呼んでいる\n* globalなnowFunc変数にtime.Nowを入れて、test時に入れ替えれるようにしている\n* goroutine safeな作りになっていて、同時にリクエストがきてもうまくハンドリングできる\n* connection数が膨大にならないようになっている\n\n## GoでAPI クライアントの実装\n\n* RoundTripper\n  * リトライ制御\n  * キャッシュのコントロール\n  * ユニットテスト時に外部通信を行わないようにする\n* newRequestとdoを実装するのはあるあるパターン\n* 典型パターンを紹介してくれているので大いに参考になりそうなんだけど、理解が追いつかなかったのでちゃんとみたいな\n* テスト時はhttptest.Serverを立ち上げるか、RoundTripperを差し替えるか\n  * httptest.Server立ち上げるほうがポピュラーなのかな？\n\n## testingパッケージを使ったWebアプリケーションテスト（単体テストからE2Eテストまで）\n\nBASE @budougumiさん\n\n* リポジトリ層のテスト\n  * contextは渡すよね\n  * UseCase層からコネクションをもらうようにしている。実DBを使ってテストしている\n  * sql-mockは、期待されたSQLが発行されるか？だけで実際にデータが取れたかどうかはわからない\n  * fixtureはシンプルな形で用意\n  * CI上で実行するときなどは環境変数を見てDBを立ち上げる\n  * t.Cleanupでレコードを消す\n  * UseCase層でトランザクション制御している。色々意見はあるかもだけど案件次第だよね\n* ユースケース層のテスト\n  * 実DBは使わない\n  * sql.DBやtxをmockしている\n  * commitやrollbackが呼ばれたかをチェックする\n* httpハンドラー層のテスト\n  * ユースケース層をmockして入出力見るくらい\n  * httptest pkgを使った素朴なテスト\n  * 入力/期待JSONをファイルにしている\n* t.Helper, t.Cleanupとか、shuffleオプション便利\n\n## Go x AWS Lambda\n\n* \n","lastmodified":"2023-07-29T08:18:43.019496563Z","tags":["Go","meetup"]},"/note/Go-Echo%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC":{"title":"Go Echoサーバー","content":"\n\\#Go\n\n## エラーハンドリング\n\n[Error Handling | Echo - High performance, minimalist Go web framework](https://echo.labstack.com/guide/error-handling/)\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/01/19","Go"]},"/note/Go-GORM%E3%81%A7PrepareStmt-true%E3%81%AB%E3%81%97%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AB%E3%83%A1%E3%83%A2%E3%83%AA%E3%83%AA%E3%83%BC%E3%82%AF%E3%81%8C%E7%99%BA%E7%94%9F%E3%81%97%E3%81%9F":{"title":"Go GORMでPrepareStmt trueにしたときにメモリリークが発生した","content":"\nパフォーマンス向上のため、PrepareStmtをtrueにした。\n\nhttps://gorm.io/docs/performance.html#Caches-Prepared-Statement\n\nこれは標準パッケージの `PrepareContext` の実行結果の `sql.Stmt` をキャッシュしておいて、2回目以降の実行を速くする。\n\nhttps://github.com/go-gorm/gorm/blob/206613868439c5ee7e62e116a46503eddf55a548/prepare_stmt.go#L68\n\nこれを有効にしたときにメモリリークが発生するようになったため、原因を調べた。\n\n## 再現方法\n\n以下のようなSQLを実行していた。\n\n````go\ngormDb, err := gorm.Open(\"mydb\", \u0026gorm.Config{\n    PrepareStmt: true,\n})\nif err != nil {\n    return nil, err\n}\n\n// weightは関数の引数と想定。ほぼ被ることのないバラバラの値とする\ngormDb.Order(fmt.Sprintf(\"(ranking * %s) asc\", weight)).First(\u0026result)\n````\n\nこれの問題点は、 `weight` の値ごとに異なるSQLが発行されることだった。\nPrepareStmt: true のとき、GORMの実装では発行されたSQL文をキーにmap型の値にキャッシュされるため、 `weight` の値がばらつくほどキャッシュされる量も増える。\nこれによってメモリリークが発生していた。\n\n## 解決方法\n\n解決方法は、ちゃんとprepared statementにすることだ。\n\n````go\ngormDb.Clauses(clause.OrderBy{\n\tExpression: clause.Expr{\n\t\tSQL: \"(ranking * ?) asc\",\n\t\tVars: []any{\n\t\t\tweight,\n\t\t},\n\t},\n}).Limit(1).Find(\u0026tpoint)\n````\n\n* 単純なOrderには指定ができなかったので、clauseを使って生SQLを書く\n* `First` を指定すると `ORDER BY \u003cprimary key\u003e` で上書きされてしまったため、 `Limit(1).Find` にした\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/06/08","Go"]},"/note/Go-GORM%E3%81%A7SQL%E5%AE%9F%E8%A1%8C%E5%89%8D%E5%BE%8C%E3%81%AB%E5%AE%9F%E8%A1%8C%E3%81%95%E3%82%8C%E3%82%8BHook%E3%82%92%E7%99%BB%E9%8C%B2%E3%81%99%E3%82%8B":{"title":"Go GORMでSQL実行前後に実行されるHookを登録する","content":"\n## 構造体単位で適用する\n\n## gorm.DB全体に適用する\n\n[Plugin](https://gorm.io/docs/write_plugins.html) を使ってGlobalに設定することも可能\n\n定義済みのcallbackはこちら\nhttps://github.com/go-gorm/gorm/blob/master/callbacks/callbacks.go\n\n`Query()` に対して `gorm:query` という名前で定義済みなので、それのあとに実行するPluginは以下のように書ける\n\n````go\ngormDb.Callback().Query().After(\"gorm:query\").Register(\"custom_after_query\", func(tx *gorm.DB) {\n    fmt.Printf(\"sql ==\u003e %v, var ==\u003e %v\\n\", tx.Statement.SQL.String(), tx.Statement.Vars)\n})\n````\n\n各pluginの動きを見るために以下のように書いた\n\n````go\nfunc NewDB(dialector gorm.Dialector) (*gorm.DB, error) {\n\tgormDb, err := gorm.Open(dialector, \u0026gorm.Config{\n\t\tSkipDefaultTransaction: true,\n\t\tPrepareStmt:            true,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t{\n\t\tt := \"query\"\n\t\tgormDb.Callback().Query().Before(\"gorm:\"+t).Register(\"before_\"+t, func(tx *gorm.DB) {\n\t\t\tfmt.Println(\"before_\"+t, \"sql\", tx.Statement.SQL.String(), \"var\", tx.Statement.Vars)\n\t\t})\n\t\tgormDb.Callback().Query().After(\"gorm:\"+t).Register(\"after_\"+t, func(tx *gorm.DB) {\n\t\t\tfmt.Println(\"after_\"+t, \"sql\", tx.Statement.SQL.String(), \"var\", tx.Statement.Vars)\n\t\t})\n\t}\n\t{\n\t\tt := \"preload\"\n\t\tgormDb.Callback().Query().Before(\"gorm:\"+t).Register(\"before_\"+t, func(tx *gorm.DB) {\n\t\t\tfmt.Println(\"before_\"+t, \"sql\", tx.Statement.SQL.String(), \"var\", tx.Statement.Vars)\n\t\t})\n\t\tgormDb.Callback().Query().After(\"gorm:\"+t).Register(\"after_\"+t, func(tx *gorm.DB) {\n\t\t\tfmt.Println(\"after_\"+t, \"sql\", tx.Statement.SQL.String(), \"var\", tx.Statement.Vars)\n\t\t})\n\t}\n\t{\n\t\tt := \"after_query\"\n\t\tgormDb.Callback().Query().Before(\"gorm:\"+t).Register(\"before_\"+t, func(tx *gorm.DB) {\n\t\t\tfmt.Println(\"before_\"+t, \"sql\", tx.Statement.SQL.String(), \"var\", tx.Statement.Vars)\n\t\t})\n\t\tgormDb.Callback().Query().After(\"gorm:\"+t).Register(\"after_\"+t, func(tx *gorm.DB) {\n\t\t\tfmt.Println(\"after_\"+t, \"sql\", tx.Statement.SQL.String(), \"var\", tx.Statement.Vars)\n\t\t})\n\t}\n\t{\n\t\tt := \"raw\"\n\t\tgormDb.Callback().Raw().Before(\"gorm:\"+t).Register(\"before_\"+t, func(tx *gorm.DB) {\n\t\t\tfmt.Println(\"before_\"+t, \"sql\", tx.Statement.SQL.String(), \"var\", tx.Statement.Vars)\n\t\t})\n\t\tgormDb.Callback().Raw().After(\"gorm:\"+t).Register(\"after_\"+t, func(tx *gorm.DB) {\n\t\t\tfmt.Println(\"after_\"+t, \"sql\", tx.Statement.SQL.String(), \"var\", tx.Statement.Vars)\n\t\t})\n\t}\n\t{\n\t\tt := \"row\"\n\t\tgormDb.Callback().Row().Before(\"gorm:\"+t).Register(\"before_\"+t, func(tx *gorm.DB) {\n\t\t\tfmt.Println(\"before_\"+t, \"sql\", tx.Statement.SQL.String(), \"var\", tx.Statement.Vars)\n\t\t})\n\t\tgormDb.Callback().Raw().After(\"gorm:\"+t).Register(\"after_\"+t, func(tx *gorm.DB) {\n\t\t\tfmt.Println(\"after_\"+t, \"sql\", tx.Statement.SQL.String(), \"var\", tx.Statement.Vars)\n\t\t})\n\t}\n\n\treturn gormDb, nil\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/05/19","Go"]},"/note/Go-Gin%E3%81%AB%E5%85%A5%E9%96%80%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B":{"title":"Go Ginに入門してみる","content":"\n\\#Go\n\n[Quickstart | Gin Web Framework](https://gin-gonic.com/docs/quickstart/)\n\n````shell\ngo get -u github.com/gin-gonic/gin\n````\n\n`main.go`\n\n````go\npackage main\n\nimport \"github.com/gin-gonic/gin\"\n\nfunc main() {\n\tr := gin.Default()\n\tr.GET(\"/ping\", func(c *gin.Context) {\n\t\tc.JSON(200, gin.H{\n\t\t\t\"message\": \"pong\",\n\t\t})\n\t})\n\tr.Run() // listen and serve on 0.0.0.0:8080\n}\n````\n\n### Graceful shutdownを実装する\n\n\u003chttps://gin-gonic.com/docs/examples/graceful-restart-or-stop/\u003e\n\n[Go http.ServerのGraceful shutdown](note/Go%20http.ServerのGraceful%20shutdown.md)\n\n### middleware\n\nmiddlewareには `gin.HandlerFunc` を実装している関数を渡す\n\n````go\nfunc Logger() gin.HandlerFunc {\n\treturn func(c *gin.Context) {\n\t\tt := time.Now()\n\n\t\tdefer func() {\n\t\t\telapsed := time.Since(t)\n\t\t\tfmt.Printf(\"elapsed: %v\\n\", elapsed)\n\n\t\t}()\n\n\t\tc.Next()\n\t}\n}\n\nfunc main() {\n\tr := gin.New()\n\tr.Use(Logger())\n\n\tr.GET(\"/test\", func(c *gin.Context) {\n\t\texample := c.MustGet(\"example\").(string)\n\n\t\t// it would print: \"12345\"\n\t\tlog.Println(example)\n\t})\n\n\t// Listen and serve on 0.0.0.0:8080\n\tr.Run(\":8080\")\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go-Neovim%E3%81%A7template%E3%81%AEsyntax-highlight%E3%82%92%E5%8A%B9%E3%81%8B%E3%81%9B%E3%82%8B":{"title":"Go Neovimでtemplateのsyntax highlightを効かせる","content":"\nこれを入れた\n\n{{\u003c card-link \"https://github.com/ngalaiko/tree-sitter-go-template\" \u003e}}\n\n[text/template](https://pkg.go.dev/text/template) の [nvim-treesitter](note/nvim-treesitter.md) 向けのパーサー\n\n## セットアップ\n\n公式の通りだがメモしておく\n\n1. parserに追加したあと、 `:TSInstallFromGrammar gotmpl`\n\n````lua\nlocal parser_config = require'nvim-treesitter.parsers'.get_parser_configs()\nparser_config.gotmpl = {\n  install_info = {\n    url = \"https://github.com/ngalaiko/tree-sitter-go-template\",\n    files = {\"src/parser.c\"}\n  },\n  filetype = \"gotmpl\",\n  used_by = {\"gohtmltmpl\", \"gotexttmpl\", \"gotmpl\", \"yaml\"}\n}\n````\n\n2. gotmplを検知したらfiletypeに設定されるようにする\n\nluaで書く場合はこんな感じに\n\n````lua\nvim.api.nvim_create_autocmd({ \"BufNewFile\", \"BufRead\" }, {\n  pattern = { \"*.tmpl\" },\n  callback = function()\n    if vim.fn.search(\"{{.\\\\+}}\", \"nw\") ~= 0 then\n        vim.bo.filetype = \"gotmpl\"\n    end\n  end,\n})\n````\n\n3. [queries](https://github.com/nvim-treesitter/nvim-treesitter#adding-queries) に追加する\n\n`~/.config/nvim/queries/gotmpl/injections.scm`\n\n````\n(text) @yaml\n````\n\n`~/.config/nvim/queries/gotmpl/highlights.scm`\n\n````\n; Identifiers\n\n[\n    (field)\n    (field_identifier)\n] @property\n\n(variable) @variable\n\n; Function calls\n\n(function_call\n  function: (identifier) @function)\n\n(method_call\n  method: (selector_expression\n    field: (field_identifier) @method))\n\n; Operators\n\n\"|\" @operator\n\":=\" @operator\n\n; Builtin functions\n\n((identifier) @function.builtin\n (#match? @function.builtin \"^(and|call|html|index|slice|js|len|not|or|print|printf|println|urlquery|eq|ne|lt|ge|gt|ge)$\"))\n\n; Delimiters\n\n\".\" @punctuation.delimiter\n\",\" @punctuation.delimiter\n\n\"{{\" @punctuation.bracket\n\"}}\" @punctuation.bracket\n\"{{-\" @punctuation.bracket\n\"-}}\" @punctuation.bracket\n\")\" @punctuation.bracket\n\"(\" @punctuation.bracket\n\n; Keywords\n\n[\n    \"else\"\n    \"else if\"\n    \"if\"\n    \"with\"\n] @conditional\n\n[\n    \"range\"\n    \"end\"\n    \"template\"\n    \"define\"\n    \"block\"\n] @keyword\n\n; Literals\n\n[\n  (interpreted_string_literal)\n  (raw_string_literal)\n  (rune_literal)\n] @string\n\n(escape_sequence) @string.special\n\n[\n  (int_literal)\n  (float_literal)\n  (imaginary_literal)\n] @number\n\n[\n    (true)\n    (false)\n] @boolean\n\n[\n  (nil)\n] @constant.builtin\n\n(comment) @comment\n(ERROR) @error\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/05/19","Go","Neovim"]},"/note/Go-OS%E3%81%AEcredential%E7%AE%A1%E7%90%86%E3%82%92%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B":{"title":"Go OSのcredential管理を利用する","content":"\nパスワードを使用するツールを作っていて、設定ファイルにパスワードを書きたくなかったため、GoでOSの管理ツールに保存、取得する方法を調べた。\n\nMacであればKeychain、WindowsであればCredential Managerがある\nhttps://support.apple.com/guide/keychain-access/what-is-keychain-access-kyca1083/mac\nhttps://support.microsoft.com/en-us/windows/accessing-credential-manager-1b5c916a-6a16-889f-8581-fc16e8165ac0\n\n## ライブラリ\n\n[zalando/go-keyring: Cross-platform keyring interface for Go](https://github.com/zalando/go-keyring/tree/master) が良さそう。\n\nLinux含め各OSに対応していて、OS Xは `/usr/bin/security` (OS X keychain のインターフェース)、Windowsは https://github.com/danieljoos/wincred を使用している\n\n## 実装\n\ncredentialを取得して、未指定であれば入力を促すようにした。\n\nパスワードの入力はこちらを使用する\n[Go ターミナルのプロンプトでpasswordを入力する](note/Go%20ターミナルのプロンプトでpasswordを入力する.md)\n\n````go\nfunc getPassword(service, username string) (string, error) {\n\t// get password\n\tsecret, err := keyring.Get(service, username)\n\tif err != nil {\n\t\tif errors.Is(err, keyring.ErrNotFound) {\n\t\t\tfmt.Print(\"Enter Password: \")\n\t\t\tbytePassword, err := terminal.ReadPassword(0)\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", err\n\t\t\t}\n\t\t\tfmt.Println()\n\t\t\tp := strings.TrimSpace(string(bytePassword))\n\t\t\tif p == \"\" {\n\t\t\t\treturn \"\", errors.New(\"password should not be empty\")\n\t\t\t}\n\n\t\t\terr = keyring.Set(service, username, p)\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", err\n\t\t\t}\n\n\t\t\treturn p, nil\n\t\t} else {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\n\treturn secret, nil\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/04/26","Go"]},"/note/Go-Revel%E5%85%A5%E9%96%80":{"title":"Go Revel入門","content":"\nhttps://revel.github.io/tutorial/index.html\n\n````shell\n# revelコマンドをインストール\n$ go install github.com/revel/cmd/revel@latest\n$ revel\nUsage:\n  revel [OPTIONS] \u003ccommand\u003e\n\nApplication Options:\n  -v, --debug                If set the logger is set to verbose\n      --historic-run-mode    If set the runmode is passed a string not json\n      --historic-build-mode  If set the code is scanned using the original parsers, not the go.1.11+\n  -X, --build-flags=         These flags will be used when building the application. May be specified multiple times, only applicable for Build, Run, Package, Test commands\n      --gomod-flags=         These flags will execute go mod commands for each flag, this happens during the build process\n\nAvailable commands:\n  build\n  clean\n  new\n  package\n  run\n  test\n````\n\nmyapp という名前でプロジェクトを作成\n\n````shell\n$ revel new -a myapp\n$ cd myapp\n$ revel run\nRevel executing: run a Revel application\nWARN  14:32:45 harness.go:179: No http.addr specified in the app.conf listening on localhost interface only. This will not allow external access to your application\nChange detected, recompiling\nParsing packages, (may require download if not cached)... Completed\nINFO  14:32:46    app     run.go:34: Running revel server\nINFO  14:32:46    app   plugin.go:9: Go to /@tests to run the tests.\nRevel engine is listening on.. localhost:51839\nRevel proxy is listening, point your browser to : 9000\n````\n\nhttp://localhost:9000 で画面が開く\n\n### 設定\n\n`conf/app.conf` に設定値を書く\nportなどもここ\n\n`conf/routes` にルーティングを書く\n\n### View\n\n`app/views/App/Index.html`\n\n````html\n{{set . \"title\" \"Home\"}}\n{{template \"header.html\" .}}\n\n\u003cheader class=\"jumbotron\" style=\"background-color:#A9F16C\"\u003e\n  \u003cdiv class=\"container\"\u003e\n    \u003cdiv class=\"row\"\u003e\n      \u003ch1\u003eIt works!\u003c/h1\u003e\n      \u003cp\u003e\u003c/p\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/header\u003e\n\n\u003cdiv class=\"container\"\u003e\n  \u003cdiv class=\"row\"\u003e\n    \u003cdiv class=\"span6\"\u003e\n      {{template \"flash.html\" .}}\n    \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n{{template \"footer.html\" .}}\n\n````\n\n## 感想\n\n* 古き良きMVCフレームワークという感じ。TomcatのServletの開発に体験としては近い？\n* Viewも備えていてJSPみたいに書ける\n* scaffold、サーバー起動、ディレクトリ構成、設定ファイルなど予め決められていて、こちらで決めることは少ない\n* REST APIの構築には大きすぎる感じ、Goっぽくない\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go-SQLBoiler%E3%81%AE%E4%BD%BF%E3%81%84%E6%96%B9":{"title":"Go SQLBoilerの使い方","content":"\n{{\u003c card-link \"https://github.com/volatiletech/sqlboiler\" \u003e}}\n\n[Go](note/Go.md) のORMライブラリの一つで、特徴としてはDBに接続して、予め作成ずみのテーブルからコードを生成することができる。\nよってマイグレーション機能はないのだが、自分のユースケースではその機能は使わないので便利だと思う。\n\nコードの生成は `sqlboiler` のコマンドラインツールで行う。\n\n生成されるコードは以下の特徴がある。\n\n* 静的型付けされており、リフレクションを使わないので高速で、コードも追いやすい\n* DBアクセスする関数はcontext.Contextを引数にとる\n  * GORMの場合、 `WithContext` を忘れるとcontextが渡せず、特に初心者だと忘れがち\n* テンプレートを使って生成されるコードをカスタマイズできる\n\n## 基本的な使い方\n\nここにはあまり書かない。\n\n* 接続は `database/sql` の `sql.Open`\n* 参照や更新は、生成されたコードの `models.XXX` にメソッドが生えている\n\n## Eager Loading\n\n## バルクインサート\n\n[SQLBoilerでBulk Insertを実現する方法 - Qiita](https://qiita.com/touyu/items/4b25fbf12804f12778b7)\nhttps://github.com/volatiletech/sqlboiler/issues/101\n\n## Raw SQLを書いて実行する\n\n## TIPS\n\n### mysqlでBOOLEAN (TINYINT(1)と等価) を数値型として扱いたい\n\nhttps://github.com/volatiletech/sqlboiler/issues/80\nhttps://github.com/volatiletech/sqlboiler/blob/4dd76363f68e73f9bd52ca984446db69a2282981/drivers/sqlboiler-mysql/driver/mysql.go#L516\n\n## 参考資料\n\n* [GolangのORM SQLBoilerを使ってみる - 実装編(Create/Update/Delete) - ken-aio's blog](https://ken-aio.github.io/post/2019/03/25/golang-sqlboiler-cud/)\n* [SQLBoiler（とoapi-codegen）でつくるREST APIサーバ | フューチャー技術ブログ](https://future-architect.github.io/articles/20210730a/)\n* [SQLBoiler の使い方を簡単にまとめた - くろのて](https://note.crohaco.net/2020/golang-sqlboiler/)\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/06/13"]},"/note/Go-Sentry%E3%81%AB%E9%80%81%E4%BF%A1%E3%81%99%E3%82%8B":{"title":"Go Sentryに送信する","content":"\n\\#Go\n\nGoのコードでSentryにメッセージを送信するやり方\n\n## 普通のGoのコード\n\nGoでSentryにエラーを送信する場合、 \u003chttps://github.com/getsentry/sentry-go\u003e を使う。\n以前はraven-goという名前だったので、古いページではこちらで記載されているかも。\n\nWebフレームワーク等を使わないプレーンなGoのコードの場合、 `github.com/getsentry/sentry-go` をimportして呼び出せばよい\n\n[Go | Sentry Documentation](https://docs.sentry.io/platforms/go/)\n\n````go\npackage main\n\nimport (\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/getsentry/sentry-go\"\n)\n\nfunc main() {\n\terr := sentry.Init(sentry.ClientOptions{\n\t\tDsn: \"https://examplePublicKey@o0.ingest.sentry.io/0\",\n\t\t// Enable printing of SDK debug messages.\n\t\t// Useful when getting started or trying to figure something out.\n\t\tDebug: true,\n\t})\n\tif err != nil {\n\t\tlog.Fatalf(\"sentry.Init: %s\", err)\n\t}\n\t// Flush buffered events before the program terminates.\n\t// Set the timeout to the maximum duration the program can afford to wait.\n\tdefer sentry.Flush(2 * time.Second)\n\n    sentry.CaptureMessage(\"It works!\")\n}\n````\n\n### Scope, Hub\n\n[Scopes and Hubs for Go | Sentry Documentation](https://docs.sentry.io/platforms/go/enriching-events/scopes/)\n\nイベントがキャプチャされてSentryに送信されるとき、SDKで現在のスコープ内でイベントデータに追加情報を付与する\n\n`init()` が呼ばれるとhubが作成されて、その上に空のscopeとクライアントが作成される。\nscope は、Sentryにイベント送信時に `context` と `breadcrumbs` といった情報を追加して送信する。\n親scopeから継承したデータを送信する。\n\n### Stacktraceを表示したい\n\n[\\[Go\\]Sentryに対応したcustom errorの作り方](https://zenn.dev/tomtwinkle/articles/18447cca3232d07c9f12)\n\n## httpサーバーにSentryを組み込む\n\n[net/http | Sentry Documentation](https://docs.sentry.io/platforms/go/guides/http/)\n[Echo | Sentry Documentation](https://docs.sentry.io/platforms/go/guides/echo/)\n[Gin | Sentry Documentation](https://docs.sentry.io/platforms/go/guides/gin/)\n\n各フレームワーク用にライブラリが用意されている。\nmiddlewareに設定することで、handlerでpanic発生時にイベントを送信できる。\n\n`net/http` の例\n\n````go\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\n\t\"github.com/getsentry/sentry-go\"\n\tsentryhttp \"github.com/getsentry/sentry-go/http\"\n)\n\ntype handler struct{}\n\nfunc (h *handler) ServeHTTP(rw http.ResponseWriter, r *http.Request) {\n\tif hub := sentry.GetHubFromContext(r.Context()); hub != nil {\n\t\thub.WithScope(func(scope *sentry.Scope) {\n\t\t\tscope.SetExtra(\"unwantedQuery\", \"someQueryDataMaybe\")\n\t\t\thub.CaptureMessage(\"User provided unwanted query string, but we recovered just fine\")\n\t\t})\n\t}\n\trw.WriteHeader(http.StatusOK)\n}\n\nfunc enhanceSentryEvent(handler http.HandlerFunc) http.HandlerFunc {\n\treturn func(rw http.ResponseWriter, r *http.Request) {\n\t\tif hub := sentry.GetHubFromContext(r.Context()); hub != nil {\n\t\t\thub.Scope().SetTag(\"someRandomTag\", \"maybeYouNeedIt\")\n\t\t}\n\t\thandler(rw, r)\n\t}\n}\n\nfunc main() {\n\n    // To initialize Sentry's handler, you need to initialize Sentry itself beforehand\n    if err := sentry.Init(sentry.ClientOptions{\n    \tDsn: \"https://examplePublicKey@o0.ingest.sentry.io/0\",\n    \tEnableTracing: true,\n    \t// Set TracesSampleRate to 1.0 to capture 100%\n    \t// of transactions for performance monitoring.\n    \t// We recommend adjusting this value in production,\n    \tTracesSampleRate: 1.0,\n    }); err != nil {\n    \tfmt.Printf(\"Sentry initialization failed: %v\\n\", err)\n    }\n    \n    sentryHandler := sentryhttp.New(sentryhttp.Options{\n    \tRepanic: true, // Sentryに送信したあと再度panicを発生させて上位階層でキャッチできるようにする\n    })\n    \n    http.Handle(\"/\", sentryHandler.Handle(\u0026handler{}))\n    http.HandleFunc(\"/foo\", sentryHandler.HandleFunc(\n    \tenhanceSentryEvent(func(rw http.ResponseWriter, r *http.Request) {\n    \t\tpanic(\"y tho\")\n    \t}),\n    ))\n    \n    fmt.Println(\"Listening and serving HTTP on :3000\")\n    \n    if err := http.ListenAndServe(\":3000\", nil); err != nil {\n    \tpanic(err)\n    }\n}\n````\n\nmiddlewareで `sentry.GetHubFromContext(r.Context())` を呼ぶことで、リクエストスコープでhubの設定をして他のリクエストと混ざらないようになっている。\n\n`sentryhttp.New` の中では次のような処理をしている\n\n````go\nfunc (h *Handler) handle(handler http.Handler) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tctx := r.Context()\n\t\thub := sentry.GetHubFromContext(ctx)\n\t\tif hub == nil {\n\t\t\thub = sentry.CurrentHub().Clone()\n\t\t\tctx = sentry.SetHubOnContext(ctx, hub)\n\t\t}\n\t\toptions := []sentry.SpanOption{\n\t\t\tsentry.OpName(\"http.server\"),\n\t\t\tsentry.ContinueFromRequest(r),\n\t\t\tsentry.TransctionSource(sentry.SourceURL),\n\t\t}\n\t\t// We don't mind getting an existing transaction back so we don't need to\n\t\t// check if it is.\n\t\ttransaction := sentry.StartTransaction(ctx,\n\t\t\tfmt.Sprintf(\"%s %s\", r.Method, r.URL.Path),\n\t\t\toptions...,\n\t\t)\n\t\tdefer transaction.Finish()\n\t\t// TODO(tracing): if the next handler.ServeHTTP panics, store\n\t\t// information on the transaction accordingly (status, tag,\n\t\t// level?, ...).\n\t\tr = r.WithContext(transaction.Context())\n\t\thub.Scope().SetRequest(r)\n\t\tdefer h.recoverWithSentry(hub, r)\n\t\t// TODO(tracing): use custom response writer to intercept\n\t\t// response. Use HTTP status to add tag to transaction; set span\n\t\t// status.\n\t\thandler.ServeHTTP(w, r)\n\t}\n}\n````\n\n* http.RequestのContextからhubを取得\n  * なければ生成してContextにセット\n* scopeにhttp.RequestをSetRequest\n* handlerでpanicが発生したときにrecoverする\n  * `Repanic: true` なら再度panicを発生させる\n\n### 停止時の処理\n\n[Shutdown and Draining for Echo | Sentry Documentation](https://docs.sentry.io/platforms/go/guides/echo/configuration/draining/)\n\nサーバー停止時に `sentry.Flush` を呼んで、送信途中のイベントがあったら送信されるようにする。\n\n## http.Request.HeaderをSentryに送信する\n\n`0.15.0` で入った変更でデフォルトではheaderが送信されないようになった。\n[https://github.com/getsentry/sentry-go/pull/485](https://github.com/getsentry/sentry-go/pull/485)\nHostのみが送信される。\n\n`sentry.Init` 時に `SendDefaultPII: true` をつけることで、headerも送信されるようになる。\n\n````\n\tif err := sentry.Init(sentry.ClientOptions{\n\t\tDsn:            conf.Sentry.Dsn,\n\t\tSendDefaultPII: true,\n\t}); err != nil {\n\t\tlog.Fatalf(\"Sentry initialization failed: %v\\n\", err)\n\t}\n````\n\n`0.16.0` で、プライベートな情報以外のヘッダーは送信されるよう修正した(変更者:私)\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go-checksum%E3%81%AE%E7%85%A7%E5%90%88%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6":{"title":"Go checksumの照合について","content":"\n[Go](note/Go.md) のモジュールを [JFrog Artifactory](note/JFrog%20Artifactory.md) にアップして取得する運用をしているのだが、モジュールをGitリポジトリから取得した場合とJFrogから取得した場合でハッシュ値が異なる事象があり、\ngo.sum、checksumの理解が浅いことに気づいたので調べた。\n\n## Checksum Database\n\nhttps://go.dev/blog/module-mirror-launch\n\nGo modulesで導入された go.sum ファイルには、各依存関係が最初にダウンロードされたときのソースコードとgo.modファイルのSHA-256ハッシュのリストが含まれている。\nこのハッシュ値を使用して、同じバージョンで異なるコードが提供された場合に検出することができる。\n\nでは初回ダウンロード時にどこと照合したらよいだろうか。\n依存関係のバージョンを追加する際(または既存の依存関係をアップデートする際)、goコマンドはコードを取得し、go.sumに行を追加する。\n問題は、これらの行が正しいかどうかが照合されていないことで、ここで悪意のあるコードに改ざんされていても気づくことができない。\n\nそこでGoは、checksum databaseと呼ばれるグローバルなgo.sumを、sum.golang.org で提供している。\ngoコマンドが新しいソースコードをダウンロードするとき、そのコードのハッシュをこのグローバルデータベースと照合し、ハッシュが一致することを確認する。\nこれにより、特定のバージョンのコードをみんなが同じものを使用していることが保証される。\n\n## Privateリポジトリ\n\nhttps://go.dev/doc/go1.13\n\nPrivateリポジトリは、Checksum databaseに記録されない。\nそのため普通に `go get` するとエラーになる。\n`GOPRIVATE` や `GONOSUMDB` を指定して検証対象外とすることができる。\n参考 [Go プライベートリポジトリに対してsshを使ってgo getする](note/Go%20プライベートリポジトリに対してsshを使ってgo%20getする.md)\n\n## checksumを算出する\n\n算出してくれるツールを使ってみる\n\nhttps://github.com/vikyd/go-checksum\n\n````shell\n$ go-checksum ./ github.com/ikorihn/my-module@v1.0.0\ndirectory: ./\n{\n        \"HashSynthesized\": \"abcdef11111111111111111\",\n        \"HashSynthesizedBase64\": \"xlsleituieutaiueagab=\",\n        \"GoCheckSum\": \"h1:xlsleituieutaiueagab=\"\n}\n\n````\n\n## まとめ\n\n冒頭のJFrogのハッシュ値が異なる件は、jfrog cliによって `.jfrog` ディレクトリが作成されたことが原因だった。\nこれを作成されないようにしてchecksumを算出したところ、JFrog Artifactory にアップロードする前後でハッシュ値が変わらないことが確認できた。\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/07/10","Go"]},"/note/Go-circuit-breaker%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E3%82%92%E5%AE%9F%E8%A3%85%E3%81%99%E3%82%8B":{"title":"Go circuit breakerパターンを実装する","content":"\n\\#Go\n\nhttps://learn.microsoft.com/en-us/azure/architecture/framework/resiliency/reliability-patterns\n\n[Make resilient Go net/http servers using timeouts, deadlines and context cancellation · Ilija Eftimov 👨‍🚀](https://ieftimov.com/posts/make-resilient-golang-net-http-servers-using-timeouts-deadlines-context-cancellation/)\n\nマイクロサービスにおいてサービスがダウンしているときに一定時間アクセスを行わないようにすることで回復させやすくするパターン。\n電気回路のサーキットブレーカーをオープンすることでショートするのを防ぐのに似ている\n\n## ライブラリ\n\nmetricsもとれる\nhttps://github.com/cep21/circuit/\nhttps://github.com/afex/hystrix-go 古い\n\nbulk headなどcircuit breaker以外の機能もある\nhttps://github.com/slok/goresilience metricsとれる\nhttps://github.com/eapache/go-resiliency\n\ncircuit breakerのみ\nhttps://github.com/mercari/go-circuitbreaker\nhttps://github.com/sony/gobreaker\nhttps://github.com/streadway/handy/tree/master/breaker\nhttps://github.com/rubyist/circuitbreaker\n\n[Hystrix dashboard](note/Hystrix%20dashboard.md) も使ってみると、サーキットの状態を見れておもしろい\n\n### cep21/circuit\n\n* Hystrixライクなサーキットブレーカーを提供するライブラリ\n* 設定値は https://github.com/Netflix/Hystrix/wiki/Configuration を参考にできる\n* メトリクスを取れる\n* Prometheus で収集できる\n* メモリアロケーションのコストが低い、ベンチマークがいい\n* [Hystrix dashboard](note/Hystrix%20dashboard.md) をサポートしている\n\nPrometheus で収集するにはこちらのライブラリを使う\nhttps://github.com/jiacai2050/prometrics\nこれによって、サーキットのオープン回数、実行回数などがわかる\n\n[GoのメトリクスをPrometheusで収集する](note/GoのメトリクスをPrometheusで収集する.md)\n\n実装例\n\n````go\npackage main\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/cep21/circuit/closers/hystrix\"\n\t\"github.com/cep21/circuit/v3\"\n\t\"github.com/jiacai2050/prometrics\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n)\n\ntype result struct {\n\terr error\n\tmsg string\n}\n\nfunc newCircuitBreaker() *circuit.Circuit {\n\t// circuit breakerの設定\n\thystrixConf := hystrix.Factory{\n\t\tConfigureOpener: hystrix.ConfigureOpener{\n\t\t\t// サーキットをオープンするエラー率\n\t\t\tErrorThresholdPercentage: 50,\n\t\t\t// 10回エラーになるまではサーキットをオープンしない\n\t\t\tRequestVolumeThreshold: 10,\n\t\t},\n\t\tConfigureCloser: hystrix.ConfigureCloser{\n\t\t\t// サーキットがオープンになってからハーフオープンになるまでの時間\n\t\t\tSleepWindow: 2000 * time.Millisecond,\n\t\t},\n\t}\n\n\t// Prometheusで収集できるようにする\n\tprom := prometrics.GetFactory(prometheus.DefaultRegisterer)\n\n\th := circuit.Manager{\n\t\tDefaultCircuitProperties: []circuit.CommandPropertiesConstructor{\n\t\t\thystrixConf.Configure,\n\t\t\tprom.CommandProperties,\n\t\t},\n\t}\n\t// This circuit will inherit the configuration from the example\n\tc := h.MustCreateCircuit(\"hystrix-circuit\")\n\tfmt.Println(\"This is a hystrix configured circuit\", c.Name())\n\n\treturn c\n}\n\nfunc main() {\n\tc := newCircuitBreaker()\n\n\tmux := http.NewServeMux()\n\tmux.Handle(\"/metrics\", promhttp.HandlerFor(prometheus.DefaultGatherer, promhttp.HandlerOpts{}))\n\n\tgo func() {\n\t\thttp.ListenAndServe(\":8080\", mux)\n\t}()\n\n\tresults := make(chan result)\n\n\t// Run a infinite loop executing using our runner.\n\tgo func() {\n\t\tfor {\n\t\t\ttime.Sleep(200 * time.Millisecond)\n\n\t\t\t// Execute concurrently.\n\t\t\tgo func() {\n\t\t\t\t// Execute our call to the service.\n\t\t\t\tvar msg string\n\n\t\t\t\t// Call the circuit\n\t\t\t\terr := c.Execute(context.Background(), func(ctx context.Context) error {\n\t\t\t\t\tnow := time.Now()\n\n\t\t\t\t\t// If minute is mod 3 return error directly\n\t\t\t\t\tif now.Second()%10 == 0 {\n\t\t\t\t\t\treturn fmt.Errorf(\"huge system error\")\n\t\t\t\t\t}\n\n\t\t\t\t\tvar err error\n\t\t\t\t\tswitch time.Now().UnixMilli() % 10 {\n\t\t\t\t\tcase 0:\n\t\t\t\t\t\tmsg = \"ok\"\n\t\t\t\t\tcase 2, 9:\n\t\t\t\t\t\ttime.Sleep(750 * time.Millisecond)\n\t\t\t\t\t\terr = fmt.Errorf(\"a error\")\n\t\t\t\t\tcase 7:\n\t\t\t\t\t\ttime.Sleep(5 * time.Second)\n\t\t\t\t\t\tmsg = \"ok\"\n\t\t\t\t\tdefault:\n\t\t\t\t\t\ttime.Sleep(20 * time.Millisecond)\n\t\t\t\t\t\tif rand.Intn(1000)%2 == 0 {\n\t\t\t\t\t\t\tmsg = \"ok\"\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\terr = fmt.Errorf(\"another error\")\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\treturn err\n\t\t\t\t}, func(ctx context.Context, err error) error {\n\t\t\t\t\tvar ce circuit.Error\n\t\t\t\t\tif errors.As(err, \u0026ce) {\n\t\t\t\t\t\tfmt.Println(\"circuit is open\")\n\t\t\t\t\t\treturn nil\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t})\n\n\t\t\t\t// Send the result to our receiver outside this infinite loop.\n\t\t\t\tresults \u003c- result{\n\t\t\t\t\terr: err,\n\t\t\t\t\tmsg: msg,\n\t\t\t\t}\n\t\t\t}()\n\n\t\t}\n\t}()\n\n\t// Process the received executions.\n\tfor res := range results {\n\t\tif res.err != nil {\n\t\t\tfmt.Printf(\"[!] fallback because err received: %s\\n\", res.err)\n\t\t} else {\n\t\t\tfmt.Printf(\"[*] all ok: %s\\n\", res.msg)\n\t\t}\n\t}\n\n}\n````\n\n````shell\ngo run main.go\n````\n\n`http://localhost:8080/metrics` を開くとgo_gcなど標準のメトリクスに加えてcircuitの状態が取得できるようになっている\n\n````\n# HELP circuit_failure_duration_seconds Duration of failed func run\n# TYPE circuit_failure_duration_seconds histogram\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"0.005\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"0.01\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"0.025\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"0.05\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"0.1\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"0.25\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"0.5\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"1\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"2.5\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"5\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"10\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"fallback\",name=\"hystrix-circuit\",le=\"+Inf\"} 2\ncircuit_failure_duration_seconds_sum{func=\"fallback\",name=\"hystrix-circuit\"} 1.6e-05\ncircuit_failure_duration_seconds_count{func=\"fallback\",name=\"hystrix-circuit\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"0.005\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"0.01\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"0.025\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"0.05\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"0.1\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"0.25\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"0.5\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"1\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"2.5\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"5\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"10\"} 2\ncircuit_failure_duration_seconds_bucket{func=\"run\",name=\"hystrix-circuit\",le=\"+Inf\"} 2\ncircuit_failure_duration_seconds_sum{func=\"run\",name=\"hystrix-circuit\"} 0.000570084\ncircuit_failure_duration_seconds_count{func=\"run\",name=\"hystrix-circuit\"} 2\n````\n\n### afex/hystrix-go\n\nHystrix と名前に入っている通り、JavaのHystrixと同じように使用できる\ngoroutineで実行される\nメトリクスを取る仕組みは組み込まれていない\n最終コミットは2018年\n\n````go\noutput := make(chan bool, 1)\nerrors := hystrix.Go(\"my_command\", func() error {\n\t// talk to other services\n\toutput \u003c- true\n\treturn nil\n}, nil)\n\nselect {\ncase out := \u003c-output:\n\t// success\ncase err := \u003c-errors:\n\t// failure\n}\n````\n\n### slok/goresilience\n\nサーキットブレーカーに限らず、resilliencyを高めるためのパターンをいくつか提供している\nHystrixライク\nPrometheusで収集できる\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go-cognito%E3%81%AEjwt%E3%82%92%E6%A4%9C%E8%A8%BC%E3%81%99%E3%82%8B":{"title":"Go cognitoのjwtを検証する","content":"\n\\#Go \n\nCognitoのJWTの検証は公式ドキュメントの通りに行う\n[JSON web トークンの検証 - Amazon Cognito](https://docs.aws.amazon.com/ja_jp/cognito/latest/developerguide/amazon-cognito-user-pools-using-tokens-verifying-a-jwt.html)\n\n今回は https://github.com/lestrrat-go/jwx を使う\n\n````go\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/lestrrat-go/jwx/jwk\"\n\t\"github.com/lestrrat-go/jwx/jwt\"\n)\n\nfunc ValidateJwt(tokenString string) error {\n\n\tfmt.Printf(\"%v\\n\", tokenString)\n\n    // jwkを取得する\n\tkeySet, err := jwk.Fetch(context.Background(), fmt.Sprintf(\"https://cognito-idp.%s.amazonaws.com/%s/.well-known/jwks.json\", \"region\", \"userId\"))\n\tif err != nil {\n\t\treturn err\n\t}\n\n    // 検証\n\ttoken, err := jwt.Parse([]byte(tokenString), jwt.WithKeySet(keySet), jwt.WithValidate(true))\n\tif err != nil {\n\t\tfmt.Printf(\"%v\\n\", err)\n\t\treturn err\n\t}\n\n    // aud の値がcliend_idと一致するか検証\n\tif token.Audience()[0] != \"my_client_id\" {\n\t\treturn ErrClientId\n\t}\n    // iss の値がuserpool_idと一致するか検証\n\tif token.Issuer() != \"userpoolId\" {\n\t\treturn ErrClientId\n\t}\n    // token_use の値がaccessか検証\n\tif tokenUse, ok := token.Get(\"token_use\"); ok {\n\t\tif tokenUseStr, ok := tokenUse.(string); ok \u0026\u0026 tokenUseStr != \"access\" {\n\t\t\treturn ErrTokenUse\n\t\t}\n\t}\n\treturn nil\n\n\n\treturn nil\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":[]},"/note/Go-echo%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC%E3%81%AE%E3%83%86%E3%82%B9%E3%83%88":{"title":"Go echoサーバーのテスト","content":"\n\\#Go\n\nechoのHandlerのテストは基本公式ドキュメントの通りにやればできる\nhttps://echo.labstack.com/guide/testing/\n\n## ファイルのアップロードとテキストのパラメータを同時に送る\n\n\u003chttps://stackoverflow.com/questions/7223616/http-post-file-multipart\u003e\n\n````go\nimport (\n\t\"bytes\"\n\t\"image\"\n\t\"image/color\"\n\t\"image/png\"\n\t\"mime/multipart\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"net/textproto\"\n\t\"testing\"\n\n\t\"github.com/labstack/echo/v4\"\n)\n\nfunc TestUpload(t *testing.T) {\n\t// Setup\n\te := echo.New()\n\n\tbuf := new(bytes.Buffer)\n\twriter := multipart.NewWriter(buf)\n\n\tmh := make(textproto.MIMEHeader)\n\tmh.Set(\"Content-Type\", \"text/plain\")\n\n\tfw, err := writer.CreateFormField(\"fileName\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\tfw.Write([]byte(\"my-name\"))\n\ttw, err := writer.CreateFormField(\"timestamp\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\ttw.Write([]byte(\"20220102150607\"))\n\n\t// create the form data\n\tpart, err := writer.CreateFormFile(\"file\", \"someimg.png\")\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\t// https://yourbasic.org/golang/create-image/\n\timg := createImage()\n\terr = png.Encode(part, img)\n\tif err != nil {\n\t\tt.Error(err)\n\t}\n\n\t// 忘れると終了メッセージが書かれない\n\twriter.Close()\n\n\treq := httptest.NewRequest(http.MethodPost, \"/\", buf)\n\treq.Header.Set(echo.HeaderContentType, writer.FormDataContentType())\n\n\trec := httptest.NewRecorder()\n\tc := e.NewContext(req, rec)\n\tc.SetPath(\"/upload\")\n\n\th := \u0026handler{}\n\n\terr = h.Upload(c)\n\tif err != nil {\n\t\tt.Errorf(\"Should not be error: %v\", err)\n\t}\n\n\tif rec.Code != http.StatusOK {\n\t\tt.Errorf(\"Not ok: %v\", rec.Code)\n\t}\n\tif rec.Body.String() != `{\"result\":\"success\"}` {\n\t\tt.Errorf(\"Not match: %v\", rec.Body.String())\n\t}\n\n}\n\nfunc createImage() *image.RGBA {\n\twidth := 200\n\theight := 100\n\n\tupLeft := image.Point{0, 0}\n\tlowRight := image.Point{width, height}\n\n\timg := image.NewRGBA(image.Rectangle{upLeft, lowRight})\n\n\t// Colors are defined by Red, Green, Blue, Alpha uint8 values.\n\tcyan := color.RGBA{100, 200, 200, 0xff}\n\n\t// Set color for each pixel.\n\tfor x := 0; x \u003c width; x++ {\n\t\tfor y := 0; y \u003c height; y++ {\n\t\t\tswitch {\n\t\t\tcase x \u003c width/2 \u0026\u0026 y \u003c height/2: // upper left quadrant\n\t\t\t\timg.Set(x, y, cyan)\n\t\t\tcase x \u003e= width/2 \u0026\u0026 y \u003e= height/2: // lower right quadrant\n\t\t\t\timg.Set(x, y, color.White)\n\t\t\tdefault:\n\t\t\t\t// Use zero value.\n\t\t\t}\n\t\t}\n\t}\n\n\treturn img\n}\n\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go-gomock-%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%86%E3%82%B9%E3%83%88":{"title":"Go gomock を使ったテスト","content":"\n\\#Go\n\nhttps://github.com/golang/mock\n\nGoのinterfaceからmockを生成するツール + 生成したコードをテストコード内で利用するためのライブラリ\n\n`s3api.go`\n\n````go\ntype S3Api interface {\n\tDeleteObject(ctx context.Context, params *s3.DeleteObjectInput, optFns ...func(*s3.Options)) (*s3.DeleteObjectOutput, error)\n\tGetObject(ctx context.Context, params *s3.GetObjectInput, optFns ...func(*s3.Options)) (*s3.GetObjectOutput, error)\n\tListObjectsV2(ctx context.Context, params *s3.ListObjectsV2Input, optFns ...func(*s3.Options)) (*s3.ListObjectsV2Output, error)\n}\n````\n\n````shell\n$ go install github.com/golang/mock/mockgen@latest\n$ mockgen -source=repository/s3api.go -destination=repository/mock/s3api.go\n````\n\nソースファイル内にgo:generateディレクティブを書くことで、 `go generate` コマンドで生成されるようになる\n\n````go\n//go:generate mockgen -source=$GOFILE -destination=../$GOPACKAGE/mock/$GOFILE\n````\n\n### テストコード内での使い方\n\n````go\nimport (\n\t\"context\"\n\t\"testing\"\n\n\tmock_repository \"my/repository/mock\"\n\t\"github.com/golang/mock/gomock\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestService(t *testing.T) {\n\t// gomock Controllerを初期化\n\tctrl := gomock.NewController(t)\n\tdefer ctrl.Finish()\n\n\t// モックメソッドの挙動を指定\n\tctx := context.Background()\n\trepoMock := mock_repository.NewMockS3Api(ctrl)\n\trepoMock.EXPECT().GetObject(ctx, \u0026s3.GetObjectInput{}. nil).Return(\u0026s3.GetObjectOutput{}, nil)\n\n\t// モックを注入\n\tsrv := Service{\n\t\trepo: repoMock,\n\t}\n\n\t// テストメソッドを実行\n\tok, err := srv.IsExistEntity(1)\n\tif err != nil {\n\t\tt.Errorf(\"予期せぬエラー: %v\", err)\n\t} else if !ok {\n\t\tt.Errorf(\"期待: %v, 実際: %v\", true, ok)\n\t}\n}\n````\n\n## gomockhandler\n\n[Goで大量のモックをより統一的に管理し、もっと高速に生成したい！そうだ！！gomockhandlerを使おう！！ | メルカリエンジニアリング](https://engineering.mercari.com/blog/entry/20210406-gomockhandler/)\n\n````shell\ngo install github.com/sanposhiho/gomockhandler@latest\n````\n\n## testify、mockery\n\nhttps://github.com/stretchr/testify にもmockパッケージが存在する。\n\nmockの作成は [mockery](https://github.com/vektra/mockery) を使う。\ngomockに比べた優位性を書いてくれているが正直好みでって感じ。testifyにどっぷり浸かるならこちらでいいと思う\nhttps://vektra.github.io/mockery/#why-use-mockery-over-gomock\n\n### mock作成\n\n以下のコマンドで、dir配下のすべてのinterfaceに対してmockが作成される。\n`--inpackage` をつけることでinterfaceと同じパッケージに `mock_\u003cinterface名\u003e.go` で作成される。\n\n````\n$ mockery --all --dir=src --inpackage\n````\n\n## 参考\n\n* [gomockを完全に理解する](https://zenn.dev/sanpo_shiho/articles/01da627ead98f5)\n* [go generateでモックを生成する - Carpe Diem](https://christina04.hatenablog.com/entry/use-go-generate-when-generating-mock)\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go-http.Client%E3%81%AEConnection%E8%A8%AD%E5%AE%9A%E5%80%A4%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E8%AA%BF%E6%9F%BB":{"title":"Go http.ClientのConnection設定値について調査","content":"\n\\#Go\n\n[Go言語: http.Client のコネクション管理 (HTTP/1.x) - Qiita](https://qiita.com/nozmiz/items/b4e8a48c75bf01ccc9f0)\n[\\[Go\\] 前方互換性を保ちながらhttp.DefaultTransportからチューニングしたhttp.Transportをつくる - My External Storage](https://budougumi0617.github.io/2021/09/13/how_to_copy_default_transport/)\n\n`http.Client` の `Transport` にコネクションプール関連のパラメータが設定できる。\n\n* `MaxIdleConns` Transport 全体で保持できる空きコネクション総数。デフォルトは100\n* `MaxIdleConnsPerHost` 接続先ごとに保持できる空きコネクション総数。デフォルトは2\n* `MaxConnsPerHost` 接続先ごとのコネクション総数(使用中・空き・接続中のものを含む)。デフォルトは0(無制限)\n* `IdleConnTimeout` 空きコネクションを保持できる最長時間。デフォルトは90秒\n\n## 調査用コード\n\n````go\npackage main\n\nimport (\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"net/http/httptrace\"\n\t\"sync\t\"time\"\n)\n\nvar urls = []string{\n\t\"http://httpbin.org/delay/1\",\n\t\"http://httpbin.org/delay/2\",\n\t\"http://httpbin.org/delay/3\",\n\t\"http://example.com\",\n}\n\nvar client *http.Client\n\nfunc main() {\n\ttr := http.DefaultTransport.(*http.Transport).Clone()\n    // コネクションプール関連のパラメータを設定する\n\t// tr.MaxIdleConns = 10\n\t// tr.MaxIdleConnsPerHost = 2\n\t// tr.MaxConnsPerHost = 10\n\t// tr.IdleConnTimeout = 10 * time.Second\n\tclient = \u0026http.Client{\n\t\tTransport: tr,\n\t}\n\n\tfmt.Printf(\"--- send start ---- MaxConnsPerHost: %v, MaxIdleConns: %v, MaxIdleConnsPerHost: %v, IdleConnTimeout: %v\\n\",\n\t\ttr.MaxConnsPerHost,\n\t\ttr.MaxIdleConns,\n\t\ttr.MaxIdleConnsPerHost,\n\t\ttr.IdleConnTimeout,\n\t)\n\tstart := time.Now()\n\tasyncSend()\n\tfmt.Println(\"--- sleep 3s...\")\n\ttime.Sleep(3 * time.Second)\n\tasyncSend()\n\n\tfmt.Printf(\"elapsed: %v\\n\", time.Since(start))\n\n}\n\nfunc asyncSend() {\n\tvar wg sync.WaitGroup\n\tfor _, url := range urls {\n\t\turl := url\n\n\t\twg.Add(1)\n\t\tgo func() {\n\t\t\tdefer wg.Done()\n\t\t\tsend(url)\n\t\t}()\n\t}\n\twg.Wait()\n}\n\nfunc send(url string) {\n\treq, err := http.NewRequest(\"GET\", url, nil)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tvar connStart time.Time\n\tvar connDuration time.Duration\n\tvar conninfo httptrace.GotConnInfo\n\ttrace := \u0026httptrace.ClientTrace{\n\t\tGotConn: func(connInfo httptrace.GotConnInfo) {\n\t\t\tconninfo = connInfo\n\t\t},\n\t\tConnectStart: func(network, addr string) {\n\t\t\tconnStart = time.Now()\n\t\t},\n\t\tConnectDone: func(network, addr string, err error) {\n\t\t\tconnDuration = time.Since(connStart)\n\t\t},\n\t}\n\n\treq = req.WithContext(httptrace.WithClientTrace(req.Context(), trace))\n\n\tvar resp *http.Response\n\tresp, err = client.Do(req)\n\tif err != nil {\n\t\tlog.Fatalf(\"client.Do %v\\n\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\tb, err := io.ReadAll(resp.Body)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfmt.Fprintf(io.Discard, \"res: %s\", string(b))\n\n\tlog.Printf(\"GET %s: Proto %s, TCPConnection %v, ConnectionInfo %+v\\n\", url, resp.Proto, connDuration, conninfo)\n}\n````\n\n### `net/http/httptrace` を使う\n\nGo 1.7 から入ったhttptraceパッケージで、`http events` をトレースすることができる\n\n* Connection creation\n* Connection reuse\n* DNS lookups\n* Writing the request to the wire\n* Reading the response\n\n`httptrace.ClientTrace` で、各フェーズにfuncを設定することでログを仕込んだり時間を計測したりできる\n\n````go\n\tvar connStart time.Time\n\tvar connDuration time.Duration\n\ttrace := \u0026httptrace.ClientTrace{\n\t\tTLSHandshakeDone: func(cs tls.ConnectionState, err error) {\n\t\t\tlog.Printf(\"TLSHandshake Done: %+v\\n\", cs)\n\t\t},\n\t\tGetConn: func(hostPort string) {\n\t\t\tlog.Printf(\"Get Conn: %v\\n\", hostPort)\n\t\t},\n\t\tGotConn: func(connInfo httptrace.GotConnInfo) {\n\t\t\tlog.Printf(\"Got Conn: %+v\\n\", connInfo)\n\t\t},\n\t\tDNSDone: func(dnsInfo httptrace.DNSDoneInfo) {\n\t\t\tlog.Printf(\"DNS Info: %+v\\n\", dnsInfo)\n\t\t},\n\t\tConnectStart: func(network, addr string) {\n\t\t\tconnStart = time.Now()\n\t\t},\n\t\tConnectDone: func(network, addr string, err error) {\n\t\t\tconnDuration = time.Since(connStart)\n\t\t\tlog.Printf(\"Connect Done: %v\\n\", connDuration)\n\t\t},\n\t}\n\n\treq = req.WithContext(httptrace.WithClientTrace(req.Context(), trace))\n\n````\n\n## 結果\n\n設定値をいろいろ変えながら実行してみる\n\n### デフォルト\n\n同一ホストに対して2つのコネクションは再利用された\n\n````\n$ go run *.go\n--- send start ---- MaxConnsPerHost: 0, MaxIdleConns: 100, MaxIdleConnsPerHost: 0, IdleConnTimeout: 1m30s\n2022/12/20 18:58:25 GET http://example.com: Proto HTTP/1.1, TCPConnection 21.032458ms, ConnectionInfo {Conn:0x14000010048 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 18:58:27 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 33.830875ms, ConnectionInfo {Conn:0x14000218028 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 18:58:28 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 33.052625ms, ConnectionInfo {Conn:0x14000010050 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 18:58:28 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 32.912542ms, ConnectionInfo {Conn:0x1400019e020 Reused:false WasIdle:false IdleTime:0s}\n--- sleep 3s...\n2022/12/20 18:58:31 GET http://example.com: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000010048 Reused:true WasIdle:true IdleTime:6.437538416s}\n2022/12/20 18:58:33 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000218028 Reused:true WasIdle:true IdleTime:3.80156475s}\n2022/12/20 18:58:34 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 10.771792ms, ConnectionInfo {Conn:0x14000010068 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 18:58:35 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000010050 Reused:true WasIdle:true IdleTime:3.087510208s}\nelapsed: 10.291201167s\n````\n\n### MaxIdleConns=1\n\n全体で保持できるIdle中のコネクション数を1にする\n=\u003e 全体で1つだけ再利用された\n\n````\n$ go run *.go\n--- send start ---- MaxConnsPerHost: 0, MaxIdleConns: 1, MaxIdleConnsPerHost: 0, IdleConnTimeout: 1m30s\n2022/12/20 19:01:56 GET http://example.com: Proto HTTP/1.1, TCPConnection 19.573917ms, ConnectionInfo {Conn:0x14000220018 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:01:58 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 38.706084ms, ConnectionInfo {Conn:0x14000010038 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:01:59 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 38.803583ms, ConnectionInfo {Conn:0x14000120020 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:02:00 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 39.267958ms, ConnectionInfo {Conn:0x14000010040 Reused:false WasIdle:false IdleTime:0s}\n--- sleep 3s...\n2022/12/20 19:02:03 GET http://example.com: Proto HTTP/1.1, TCPConnection 20.372584ms, ConnectionInfo {Conn:0x14000308048 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:02:05 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 22.206166ms, ConnectionInfo {Conn:0x14000220058 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:02:05 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000010040 Reused:true WasIdle:true IdleTime:3.001381s}\n2022/12/20 19:02:06 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 20.229334ms, ConnectionInfo {Conn:0x14000120038 Reused:false WasIdle:false IdleTime:0s}\nelapsed: 10.021672791s\n````\n\n### MaxIdleConnsPerHost=1\n\n接続先ごとに保持できるIdle中のコネクション数を1にする\n=\u003e 接続先ごとに1つずつ再利用された\n\n````\n$ go run *.go\n--- send start ---- MaxConnsPerHost: 0, MaxIdleConns: 100, MaxIdleConnsPerHost: 1, IdleConnTimeout: 1m30s\n2022/12/20 19:03:05 GET http://example.com: Proto HTTP/1.1, TCPConnection 19.162375ms, ConnectionInfo {Conn:0x1400012c048 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:03:06 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 23.317375ms, ConnectionInfo {Conn:0x14000010038 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:03:08 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 23.148917ms, ConnectionInfo {Conn:0x14000010030 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:03:09 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 25.611208ms, ConnectionInfo {Conn:0x14000010040 Reused:false WasIdle:false IdleTime:0s}\n--- sleep 3s...\n2022/12/20 19:03:12 GET http://example.com: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x1400012c048 Reused:true WasIdle:true IdleTime:6.369719167s}\n2022/12/20 19:03:13 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 22.194541ms, ConnectionInfo {Conn:0x1400009e058 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:03:15 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000010038 Reused:true WasIdle:true IdleTime:5.231218708s}\n2022/12/20 19:03:15 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 16.294916ms, ConnectionInfo {Conn:0x1400009e050 Reused:false WasIdle:false IdleTime:0s}\nelapsed: 10.556359875s\n````\n\n### MaxIdleConnsPerHost=3\n\n接続先ごとに保持できるIdle中のコネクション数を3にする\n=\u003e 接続先ごとに3つずつ再利用された\n\n````\n$ go run *.go\n--- send start ---- MaxConnsPerHost: 0, MaxIdleConns: 100, MaxIdleConnsPerHost: 3, IdleConnTimeout: 1m30s\n2022/12/20 19:03:35 GET http://example.com: Proto HTTP/1.1, TCPConnection 22.971458ms, ConnectionInfo {Conn:0x14000010028 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:03:37 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 24.629334ms, ConnectionInfo {Conn:0x1400032c010 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:03:38 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 22.705208ms, ConnectionInfo {Conn:0x14000010030 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:03:39 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 22.523167ms, ConnectionInfo {Conn:0x1400032c008 Reused:false WasIdle:false IdleTime:0s}\n--- sleep 3s...\n2022/12/20 19:03:43 GET http://example.com: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000010028 Reused:true WasIdle:true IdleTime:7.025793875s}\n2022/12/20 19:03:44 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000010030 Reused:true WasIdle:true IdleTime:4.847397167s}\n2022/12/20 19:03:45 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x1400032c008 Reused:true WasIdle:true IdleTime:3.001350125s}\n2022/12/20 19:03:46 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x1400032c010 Reused:true WasIdle:true IdleTime:5.766263584s}\nelapsed: 10.564832208s\n````\n\n### MaxConnsPerHost=1\n\n接続先ごとのコネクション数を1にする\n=\u003e 接続先ごとに一つだけコネクションが作成され、それが再利用された\n\n````\n$ go run *.go\n--- send start ---- MaxConnsPerHost: 1, MaxIdleConns: 100, MaxIdleConnsPerHost: 0, IdleConnTimeout: 1m30s\n2022/12/20 19:03:59 GET http://example.com: Proto HTTP/1.1, TCPConnection 10.686958ms, ConnectionInfo {Conn:0x140000aa050 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:04:01 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 15.183792ms, ConnectionInfo {Conn:0x14000120030 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:04:03 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000120030 Reused:true WasIdle:false IdleTime:0s}\n2022/12/20 19:04:06 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000120030 Reused:true WasIdle:false IdleTime:0s}\n--- sleep 3s...\n2022/12/20 19:04:09 GET http://example.com: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x140000aa050 Reused:true WasIdle:true IdleTime:10.279613416s}\n2022/12/20 19:04:13 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000120030 Reused:true WasIdle:true IdleTime:3.001459625s}\n2022/12/20 19:04:14 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000120030 Reused:true WasIdle:false IdleTime:0s\n2022/12/20 19:04:18 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000120030 Reused:true WasIdle:false IdleTime:0s}\nelapsed: 19.207177666s\n````\n\n### IdleConnTimeout=2s\n\nコネクションがIdleで待機できる時間を2秒にする\n=\u003e 2秒経過でコネクションが切断され、再利用されなかった\n\n````\n$ go run *.go\n--- send start ---- MaxConnsPerHost: 0, MaxIdleConns: 100, MaxIdleConnsPerHost: 0, IdleConnTimeout: 2s\n2022/12/20 19:04:56 GET http://example.com: Proto HTTP/1.1, TCPConnection 18.289333ms, ConnectionInfo {Conn:0x14000218030 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:04:58 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 35.073625ms, ConnectionInfo {Conn:0x14000306000 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:04:59 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 35.495083ms, ConnectionInfo {Conn:0x1400012c058 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:05:00 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 34.939209ms, ConnectionInfo {Conn:0x1400012c050 Reused:false WasIdle:false IdleTime:0s}\n--- sleep 3s...\n2022/12/20 19:05:03 GET http://example.com: Proto HTTP/1.1, TCPConnection 26.906709ms, ConnectionInfo {Conn:0x14000306038 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:05:04 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 33.716209ms, ConnectionInfo {Conn:0x1400012c088 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:05:06 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 27.599459ms, ConnectionInfo {Conn:0x14000010050 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:05:07 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 26.6985ms, ConnectionInfo {Conn:0x1400012c080 Reused:false WasIdle:false IdleTime:0s}\nelapsed: 10.808737583s\n````\n\n### MaxIdleConns \\\u003c MaxIdleConnsPerHost\n\n全体のIdleコネクション数を、接続先ごとのIdleコネクション数より少なくする\n=\u003e 全体のIdleコネクション数が上限となる\n\n````\n$ go run *.go\n--- send start ---- MaxConnsPerHost: 0, MaxIdleConns: 2, MaxIdleConnsPerHost: 3, IdleConnTimeout: 1m30s\n2022/12/20 19:05:33 GET http://example.com: Proto HTTP/1.1, TCPConnection 9.587334ms, ConnectionInfo {Conn:0x14000010040 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:05:35 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 33.300458ms, ConnectionInfo {Conn:0x1400012c038 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:05:37 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 33.856917ms, ConnectionInfo {Conn:0x14000218020 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:05:37 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 33.399125ms, ConnectionInfo {Conn:0x14000218018 Reused:false WasIdle:false IdleTime:0s}\n--- sleep 3s...\n2022/12/20 19:05:40 GET http://example.com: Proto HTTP/1.1, TCPConnection 18.400042ms, ConnectionInfo {Conn:0x1400012c050 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:05:41 GET http://httpbin.org/delay/1: Proto HTTP/1.1, TCPConnection 21.112875ms, ConnectionInfo {Conn:0x1400012c058 Reused:false WasIdle:false IdleTime:0s}\n2022/12/20 19:05:42 GET http://httpbin.org/delay/2: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000218018 Reused:true WasIdle:true IdleTime:3.001382958s}\n2022/12/20 19:05:43 GET http://httpbin.org/delay/3: Proto HTTP/1.1, TCPConnection 0s, ConnectionInfo {Conn:0x14000218020 Reused:true WasIdle:true IdleTime:3.001510458s}\nelapsed: 9.904582917s\n````\n\n|MaxConnsPerHost|MaxIdleConns|MaxIdleConnsPerHost|IdleConnTimeout|コネクション|\n|---------------|------------|-------------------|---------------|------------------|\n|0|100|2|1m30s|接続先ごとに2つまで再利用された|\n|0|1|2|1m30s|全体で1つだけ再利用された|\n|0|100|1|1m30s|接続先ごとに1つずつ再利用された|\n|0|100|3|1m30s|接続先ごとに3つずつ再利用された|\n|1|100|2|1m30s|接続先ごとに一つだけコネクションが作成され、それが再利用された|\n|0|100|2|2s|2秒経過でコネクションが切断され、再利用されなかった|\n|0|2|3|1m30s|MaxIdleConnsが上限となる|\n\n### HTTP/2.0 の場合\n\n接続先がHTTP/2.0の場合、MaxConnsPerHost=1 にしても一つのコネクションで同時に複数リクエストを処理することができる。\n\nhttps://knowledge.sakura.ad.jp/7734/\nあまり詳しくないのだが、ストリームによって1つのコネクション内で同時に並行して複数のリクエスト/レスポンスを処理できるということだろうか\n\n````\n--- send start ---- MaxConnsPerHost: 1, MaxIdleConns: 100, MaxIdleConnsPerHost: 0, IdleConnTimeout: 1m30s\n2022/12/21 10:50:15 GET https://example.com: Proto HTTP/2.0, TCPConnection 117.219375ms, ConnectionInfo {Conn:0x1400030a000 Reused:false WasIdle:false IdleTime:0s}\n2022/12/21 10:50:16 GET https://httpbin.org/delay/1: Proto HTTP/2.0, TCPConnection 0s, ConnectionInfo {Conn:0x1400030a380 Reused:true WasIdle:false IdleTime:0s}\n2022/12/21 10:50:17 GET https://httpbin.org/delay/2: Proto HTTP/2.0, TCPConnection 171.794125ms, ConnectionInfo {Conn:0x1400030a380 Reused:true WasIdle:false IdleTime:0s}\n2022/12/21 10:50:18 GET https://httpbin.org/delay/3: Proto HTTP/2.0, TCPConnection 0s, ConnectionInfo {Conn:0x1400030a380 Reused:false WasIdle:false IdleTime:0s}\n--- sleep 3s...\n2022/12/21 10:50:22 GET https://example.com: Proto HTTP/2.0, TCPConnection 0s, ConnectionInfo {Conn:0x1400030a000 Reused:true WasIdle:true IdleTime:6.22757825s}\n2022/12/21 10:50:23 GET https://httpbin.org/delay/1: Proto HTTP/2.0, TCPConnection 0s, ConnectionInfo {Conn:0x1400030a380 Reused:true WasIdle:true IdleTime:3.001377041s}\n2022/12/21 10:50:24 GET https://httpbin.org/delay/2: Proto HTTP/2.0, TCPConnection 0s, ConnectionInfo {Conn:0x1400030a380 Reused:true WasIdle:false IdleTime:0s}\n2022/12/21 10:50:25 GET https://httpbin.org/delay/3: Proto HTTP/2.0, TCPConnection 0s, ConnectionInfo {Conn:0x1400030a380 Reused:true WasIdle:true IdleTime:3.001423166s}\nelapsed: 9.895872041s\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go-http.Server%E3%81%AEGraceful-shutdown":{"title":"Go http.ServerのGraceful shutdown","content":"\n\\#Go\n\nGo 1.8 からはhttp.ServerにGraceful Shutdownを行うための仕組みが備わっている\ncontext.Contextを渡すことで猶予時間を決めてリクエスト中の処理の終了を待つことができる\n\n````go\npackage main\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"net/http\"\n\t\"os/signal\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/labstack/echo/v4\"\n)\n\nfunc main() {\n\th := echo.New()\n\th.GET(\"/ping\", func(c echo.Context) error {\n\t\tresp := map[string]string{\n\t\t\t\"msg\": \"ok\",\n\t\t}\n\t\treturn c.JSON(http.StatusOK, resp)\n\t})\n\n\tsrv := http.Server{\n\t\tAddr:    \":1323\",\n\t\tHandler: h,\n\t}\n\n\t// Graceful shutdown のため、interrupt signalをキャッチして即時終了しないようにする\n\tctx, stop := signal.NotifyContext(context.Background(), syscall.SIGINT, syscall.SIGTERM)\n\tdefer stop()\n\n\tgo func() {\n\t\tif err := srv.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlog.Fatalf(\"Failed to listen and serve: %v\\n\", err)\n\t\t}\n\t}()\n\n\t\u003c-ctx.Done()\n\tstop()\n\tlog.Println(\"Shutting down gracefully, press Ctrl+C again to force\")\n\n    // 処理中のリクエストがある場合に猶予10秒を持たせてからshutdownする\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tdefer cancel()\n\tif err := srv.Shutdown(ctx); err != nil {\n\t\tlog.Printf(\"Server forced to shutdown: %v\\n\", err)\n\t}\n\n\tlog.Println(\"Server exiting\")\n}\n````\n\n`signal.NotifyContext` ではなく `signal.Notify` を使う例も見かけるがラップしているだけなのでだいたい同じ\n\n````go\n\tquit := make(chan os.Signal, 1)\n\tsignal.Notify(quit, os.Interrupt, syscall.SIGTERM)\n\n\t\u003c-quit\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go"]},"/note/Go-oapi-codegen%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%82%B3%E3%83%BC%E3%83%89%E7%94%9F%E6%88%90":{"title":"Go oapi-codegenを使ったコード生成","content":"\n## 導入した結果\n\n1. 仕様書とコードが一致するようになった\n1. それぞれの言語向けにAPIレスポンスのコードを実装するコストが減った\n1. フロントエンドとバックエンドの実装が並行して進められるようになった\n\n1、2については、APIを変更したときにコードを再生成するとGoやTypeScriptでエラーがでるので、変更が安全に行えるようになりました。\n\nこのときの開発チームでは同じ人がフロントエンドとバックエンド両方を実装していたので、3についてはあまり影響がありませんでしたが、開発者が分かれている場合はバックエンドの開発が済んでいなくてもフロントエンドの開発を進められるのは大きな利点だと思います。\n\n一方でイマイチだった点として、生成ツールの吐き出すコードのフォーマットがプロジェクトに合わないものであっても妥協する必要がありました。\n出力されるコードのフォーマットはある程度パラメータでコントロールできるものの、その方法を調べるコストやメンテナンスコストを鑑みて、生成されたものにコードフォーマッタをかけるくらいに留めてあとは受け入れることにしました。\n\n### やらなかったこと\n\n今回はOpenAPIファイルをもとにしてコードを生成する方針で開発を行いました。\n\n一方で、コードからOpenAPIファイルを生成するアプローチもあります。\nyamlを編集するよりもコードを書きたい、コードのほうがコンパイルエラーで検知できたりIDEの恩恵を受けやすいという気持ちはあったのですが、\nライブラリ側がOpenAPI 3.0系に対応するのを待つ必要があったり、使用できるプロパティが制限されたりと不便なところがあったため、このアプローチは取りませんでした。\n例えば、Go でコードからOpenAPI(Swagger)を生成するライブラリの中でスター数の多い [swag](https://github.com/swaggo/swag) はSwagger 2.0に対応していますがOpenAPI 3.0系には未対応です。\n\n*以降はサンプルとして [OpenAPIのexamplesにあるpetstore.yaml](https://github.com/OAI/OpenAPI-Specification/blob/3.1.0/examples/v3.0/petstore.yaml) を使用して説明していきます。*\n\n## バックエンドのコード生成\n\nGoのAWS Lambdaハンドラー向けのコード生成について説明します。\n\nOpenAPIからGoのコードを生成するツールで有名なものに [go-swagger](https://github.com/go-swagger/go-swagger) がありますが、現時点(v0.30.3)ではSwagger 2.0にのみ対応しており、OpenAPI 3系が使えません。\nすでにOpenAPIファイルは3系で書いていたため、これに対応している [oapi-codegen](https://github.com/deepmap/oapi-codegen) を使用しました。\ngo-swagger と比べるとリリース頻度が低く、プルリクが滞留しがちなのが気になるところではありますが、他の選択肢がなかったためこちらを採用しています。\n\n### oapi-codegenの使い方\n\nまずは最新版をインストールして実行してみます。\n\n````shell\ngo install github.com/deepmap/oapi-codegen/cmd/oapi-codegen@latest\n\noapi-codegen -package \"openapi\" petstore.yaml \u003e petstore.gen.go\n````\n\nすると以下のような内容が書かれた petstore.gen.go が生成されます。\n\n* **components** や **parameters** のstruct定義\n* 全APIのハンドラーを持った **ServerInterface**\n* Echo用のwrapper\n* Base64エンコードされたOpenAPI spec\n\n生成対象はconfigファイルで設定することができます。\n今回はstruct定義のみ生成したかったので、以下のような設定にしました。\n\n````yaml\n# oapi-codegen.yaml\n\npackage: openapi\ngenerate:\n  models: true\n  # echo-server: true\n  # embedded-spec: true\n````\n\n````shell\noapi-codegen -config oapi-codegen.yaml petstore.yaml \u003e petstore.gen.go\n````\n\n生成されるコードはこちらです。\n\n````go\n// Package openapi provides primitives to interact with the openapi HTTP API.\n//\n// Code generated by github.com/deepmap/oapi-codegen version v1.11.0 DO NOT EDIT.\npackage openapi\n\n// Error defines model for Error.\ntype Error struct {\n\tCode    int32  `json:\"code\"`\n\tMessage string `json:\"message\"`\n}\n\n// Pet defines model for Pet.\ntype Pet struct {\n\tId   int64   `json:\"id\"`\n\tName string  `json:\"name\"`\n\tTag  *string `json:\"tag,omitempty\"`\n}\n\n// Pets defines model for Pets.\ntype Pets = []Pet\n\n// ListPetsParams defines parameters for ListPets.\ntype ListPetsParams struct {\n\t// How many items to return at one time (max 100)\n\tLimit *int32 `form:\"limit,omitempty\" json:\"limit,omitempty\"`\n}\n````\n\n※v1.10.0以前では、以下のようにコマンドラインオプションで生成対象を指定できましたがこれは使えなくなっています。\n詳しくは [v1.11.0のリリースノート](https://github.com/deepmap/oapi-codegen/releases/tag/v1.11.0) をご覧ください。\n\n````\noapi-codegen -generate \"types\" -package \"openapi\" petstore.yaml\noapi-codegen -generate \"server\" -package \"openapi\" petstore.yaml\n````\n\n### AWS Lambdaのハンドラー内で利用する\n\nハンドラーのコードについて詳細は省きますが、\nこちらのようにしてリクエストパラメータを生成コードにマッピングして、処理を行い、レスポンスを返すよう実装しました。\n\n````go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"net/http\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/mitchellh/mapstructure\"\n\n\t\"example.com/petstore/openapi\"\n)\n\nfunc handler(request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {\n\t// requestをopenapi.ListPetsParamsにマッピングする\n\tvar param openapi.ListPetsParams\n\n\tdecoderConfig := \u0026mapstructure.DecoderConfig{\n\t\tWeaklyTypedInput: true,\n\t\tResult:           \u0026param,\n\t}\n\tdecoder, err := mapstructure.NewDecoder(decoderConfig)\n\tif err != nil {\n\t\treturn events.APIGatewayProxyResponse{}, err\n\t}\n\terr = decoder.Decode(request.QueryStringParameters)\n\tif err != nil {\n\t\treturn events.APIGatewayProxyResponse{}, err\n\t}\n\n\t// do something\n\n\t// openapi.Petsを作成してJSONにして返却する\n\tpets := make(openapi.Pets, 0)\n\n\tbody, err := json.Marshal(pets)\n\treturn events.APIGatewayProxyResponse{\n\t\tStatusCode: http.StatusOK,\n\t\tBody:       string(body),\n\t}, err\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n````\n\nこうすることで、生成されたコードとリクエスト、レスポンスのマッピングが行われ、仕様書とコードが一致するようになりました。\n\n### struct tagを追加したい\n\n上記コードでは、  [mapstructure](https://github.com/mitchellh/mapstructure) を使ってLambdaのリクエストパラメータ( map\\[string\\]string 型の QueryStringParameters) を openapi.ListPetsParams 型の変数にパースしています。\nこのライブラリは、 `mapstructre:\"limit\"` のようなstruct tagを書くことで、mapのキー名とtagが一致するフィールドに値をパースさせることができます。\n\nこれは、次のようにkebab-caseでリクエストパラメータを定義したいときに役立ちます。\n\n````yaml\n  /pets:\n    get:\n      parameters:\n        - name: limit\n          in: query\n          description: How many items to return at one time (max 100)\n          required: false\n          schema:\n            type: integer\n            format: int32\n        - name: sort-by\n          in: query\n          description: How to sort items\n          required: false\n          schema:\n            type: string\n````\n\n生成されるコード\n\n````go\ntype ListPetsParams struct {\n\t// How many items to return at one time (max 100)\n\tLimit *int32 `form:\"limit,omitempty\" json:\"limit,omitempty\"`\n\n\t// How to sort items\n\tSortBy *string `form:\"sort-by,omitempty\" json:\"sort-by,omitempty\"`\n}\n````\n\nこの状態で /pets?sort-by=name でリクエストすると、SortBy には値が入らず、 /pets?sortBy=name としないといけません。\n\nこれを解消するために oapi-codegen では、**x-oapi-codegen-extra-tags** を書くことで任意のstruct tagをつけることができるようになっています。\n\n````yaml\n        - name: sort-by\n          in: query\n          description: How to sort items\n          required: false\n          schema:\n            type: string\n          x-oapi-codegen-extra-tags:\n            mapstructure: sort-by,omitempty\n````\n\n生成されるコード\n\n````go\ntype ListPetsParams struct {\n\t// How many items to return at one time (max 100)\n\tLimit *int32 `form:\"limit,omitempty\" json:\"limit,omitempty\"`\n\n\t// How to sort items\n\tSortBy *string `form:\"sort-by,omitempty\" json:\"sort-by,omitempty\" mapstructure:\"sort-by,omitempty\"`\n}\n````\n\nこれで /pets?sort-by=name が期待通り働くようになりました。\n\n他にも [go-playground/validator](https://github.com/go-playground/validator) 用のタグを追加するのにも使えそうです。\n\n## Echoで使う\n\n## 任意の型を利用する\n\n`x-go-type`\n\n`runtime.Binder`\nhttps://github.com/deepmap/oapi-codegen/blob/master/pkg/runtime/bind.go\n\n利用箇所\nhttps://github.com/deepmap/oapi-codegen/blob/a444d309616eaac712c1b1a633c0818613918e11/pkg/runtime/bindstring.go#L111\n\n````go\ntype Animal struct {\n\tvalue string\n}\n\nvar (\n\tDog = Animal{\"dog\"}\n\tCat = Animal{\"cat\"}\n)\n\nfunc (i *Animal) Bind(src string) error {\n\tswitch strings.ToLower(src) {\n\tcase \"dog\":\n\t\t*i = Dog\n\tcase \"cat\":\n\t\t*i = Cat\n\t}\n\n\treturn nil\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/05/29","Draft","Go","OpenAPI"]},"/note/Go-vscode-go%E3%81%A7goimports%E6%99%82%E3%81%ABlocal%E3%82%92%E6%8C%87%E5%AE%9A%E3%81%99%E3%82%8B":{"title":"Go vscode-goでgoimports時にlocalを指定する","content":"\nvscodeでGoのコードフォーマットに `\"go.formatTool\": \"goimports\"` を指定していて、`-local` オプションが効かなかったので調べた。\n`-local` は、`-local \"github.com/my/module\"` のように指定すると、importをサードパーティのモジュールと自身のモジュールでグループ分けしてくれるオプション\n\n````go\nimport (\n    \"fmt\"\n    \"os\"\n\n    \"github.com/other/module1\"\n    \"github.com/other/module2\"\n\n    \"github.com/my/module/client\"\n    \"github.com/my/module/service\"\n)\n\n````\n\n## `go.formatFlags`\n\nhttps://github.com/golang/vscode-go/wiki/settings#goformatflags\n\nこれは効かない\n\n \u003e \n \u003e Not applicable when using the language server.\n\n````json\n{\n  \"go.formatFlags\": [\n    \"-local\",\n    \"github.com/my/module\"\n  ],\n}\n````\n\n## `gopls.\"formatting.local\"`\n\nこちらが正しい\n\n````json\n{\n  \"gopls\": {\n    \"formatting.local\": \"github.com/my/module\"\n  },\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go","vscode"]},"/note/Google%E3%82%AB%E3%83%AC%E3%83%B3%E3%83%80%E3%83%BC%E3%81%AE%E4%BA%88%E5%AE%9A%E6%99%82%E5%88%BB%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%9F%E3%82%89Meet%E3%81%AEURL%E3%82%92%E3%83%96%E3%83%A9%E3%82%A6%E3%82%B6%E3%81%A7%E8%87%AA%E5%8B%95%E3%81%A7%E9%96%8B%E3%81%8F":{"title":"Googleカレンダーの予定時刻になったらMeetのURLをブラウザで自動で開く","content":"\n\\#GAS\n\nGoogle Meetでミーティングするときに、時間をすぎてしまうことがある。\n時間になったらMeetの画面を強制的に開いてくれれば、遅れなくなるはず。\n\nやり方はいろいろあると思う\nChrome拡張、Calendar API\n\n今回は諸般の事情でCalendar APIを直接使えなかったため、以下の方針にした\n\n## 方針\n\n* [Google Apps Script](note/Google%20Apps%20Script.md) でカレンダーから予定を取得\n* [Google Apps Script](note/Google%20Apps%20Script.md) をWebアプリとして公開して、JSONで取得できるようにする\n* 時間を指定して `at` コマンドでmacの `open \u003cMeetのURL\u003e` をセットして、ブラウザを開くようにする\n\nもっといいやり方ある気はするが、とりあえずこれでやりたいことは出来た\n\n## GASを作成する\n\nGASでWebアプリを作成する\n\n### Calendar APIを有効化\n\n[Google Apps Script](note/Google%20Apps%20Script.md) 組み込みの `CalendarApp` では情報が少なくMeetのURLがとれないため、[Calendar API](https://developers.google.com/apps-script/advanced/calendar) を使用する\n\nGASのエディタ \u003e サービス \u003e Calendar を有効化\n\n### dayjs を使う\n\n日付をうまく扱うためにMoment.jsは開発が止まっているので、dayjsを使えるようにする。\n\nライブラリを追加 \u003e dayjs のスクリプトIDを入力\n\nスクリプトID: `1ShsRhHc8tgPy5wGOzUvgEhOedJUQD53m-gd8lG2MOgs-dXC_aCZn9lFB`\n\n#### ちなみに\n\nライブラリのスクリプトIDを検索する方法がわからない…\n仕方なく個人ブログやQiitaから情報を得たけど、公式情報じゃないのであまり良くない気がする\nhttps://gas.excelspeedup.com/dayjs/\n\n### 実装する\n\nWebアプリとして使えるようにするため、`doGet` を実装する\n\n````javascript:code.gs\nfunction doGet(e) {\n    return ContentService.createTextOutput(JSON.stringify(getSchedule()));\n}\n\nfunction getSchedule() {\n  const now = new Date();\n  const begin = dayjs.dayjs(now);\n  const end = dayjs.dayjs(now).endOf('day');\n    \n  // デフォルトカレンダーのID\n  const calendarId = CalendarApp.getDefaultCalendar().getId();\n\n  // Calendar APIで本日の予定を取得する\n  const events = Calendar.Events.list(calendarId, {\n    timeMin: begin.toISOString(),\n    timeMax: end.toISOString(),\n    singleEvents: true,\n    orderBy: 'startTime',\n  })\n\n  const todayEvent = events.items.map(event =\u003e {\n    let start;\n    if (event.start.date) {\n      // All-day event.\n      start = new Date(event.start.date);\n    } else {\n      start = new Date(event.start.dateTime);\n    }\n\n    // atコマンドで使いやすい時間形式にフォーマット\n    return {\n      title: event.summary,\n      start: dayjs.dayjs(start).subtract(1, 'minute').format(\"YYYYMMDDHHmm\"),\n      meetUrl: event.hangoutLink,\n    }\n  })\n\n  console.log(todayEvent)\n\n  return todayEvent;\n}\n````\n\n### Webアプリとして公開\n\nデプロイ \u003e 新しいデプロイ \u003e 説明を入力してデプロイ \u003e WebアプリのURLを取得\n\n## shellで予定一覧を取得して、atコマンドで設定\n\natコマンドが使えない場合は設定する。\n参考: [macでatコマンドを使う](note/macでatコマンドを使う.md) \n\n````shell\ncurl -H \"Authorization: Bearer $TOKEN\" -L \"\u003cGASのWebアプリURL\u003e\" | jq -r '.[] | .title + \",\" + .start + \",\" + .meetUrl' | awk -F ',' '{ print system(\"echo open \" $3 \" | at -t \" $2 ) }'\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["GAS"]},"/note/Google-Apps-Script":{"title":"Google Apps Script","content":"\n\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["GAS"]},"/note/GooglePlay%E8%AA%B2%E9%87%91":{"title":"GooglePlay課金","content":"\n[\\[DroidKaigi 2020\\] Re:ゼロから始める Play Billing Library / Re: Zero - starting uses of Play Billing Library - Speaker Deck](https://speakerdeck.com/syarihu/re-zero-starting-uses-of-play-billing-library)\n\n[Android(Google Play)にてアプリ内定期購入を実装したときに困ったポイント - Qiita](https://qiita.com/amymd/items/f3f10a5e953d53653010)\n[【Android開発】Google Playアプリ内課金の実装方法ガイド | by DAIKI MOCHIZUKI | Medium](https://medium.com/@dkmczk/android%E9%96%8B%E7%99%BA-google-play%E3%82%A2%E3%83%97%E3%83%AA%E5%86%85%E8%AA%B2%E9%87%91%E3%81%AE%E5%AE%9F%E8%A3%85%E6%96%B9%E6%B3%95%E3%82%AC%E3%82%A4%E3%83%89-8be98331a35c)\n[【2021年版】Googleアプリ内課金の導入と運用方法(GooglePlayBilling)｜茶トラ猫のエンジニア日記](https://itneko.com/google-play-billing/)\n[【2020年版】Play Commerceアップデート対応. こんにちは、@syarihuです。 | by Taichi Sato (syarihu) | Medium](https://syarihu.medium.com/2020%E5%B9%B4%E7%89%88-play-commerce%E3%82%A2%E3%83%83%E3%83%97%E3%83%87%E3%83%BC%E3%83%88%E5%AF%BE%E5%BF%9C-682716d240fd)\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Android"]},"/note/Grafana":{"title":"Grafana","content":"\nログやメトリクスデータ可視化のオープンソースのWebアプリケーション\n\n{{\u003c card-link \"https://grafana.com/docs/grafana/latest/\" \u003e}}\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/05/16","Grafana"]},"/note/Grafana-%E3%83%80%E3%83%83%E3%82%B7%E3%83%A5%E3%83%9C%E3%83%BC%E3%83%89%E3%82%84%E3%82%A2%E3%83%A9%E3%83%BC%E3%83%88%E3%81%AEexport-import":{"title":"Grafana ダッシュボードやアラートのexport import","content":"\n[Grafana](note/Grafana.md) にて8.xから9.xへダッシュボードを移行したい。ダッシュボードはexport/importでいけるがアラートがインポートされなくて困った\n\n9.x以降のAlertは設定方法が変わった。\nexportの機能がついたが、以前のバージョンからインポートするのは簡単じゃなさそう\n\nhttps://community.grafana.com/t/ngalert-grafana-8-alert-feature-how-to-export-import-alerts-as-yml-json/51677/22\nこのコメントの通りにすればできそう\n\n## 9.0より前のバージョンではAlerting APIが使えた\n\n* [Alerting HTTP API | Grafana documentation](https://grafana.com/docs/grafana/latest/developers/http_api/alerting/)\n* [Alerting Notification Channels HTTP API | Grafana documentation](https://grafana.com/docs/grafana/latest/developers/http_api/alerting_notification_channels/)\n\n## 9.xの場合\n\n* [Create and manage alerts: 12 ways it's easier in Grafana Alerting](https://grafana.com/blog/2023/03/06/grafana-alerting-12-ways-we-made-creating-and-managing-alerts-easier-than-ever/#5-export-alert-rules-for-provisioning)\n* [Alerting | Grafana documentation](https://grafana.com/docs/grafana/latest/alerting/)\n\nアラートをSlackで通知するには以下を設定する必要がありそう\n\n* Notification Template\n* Contact Points\n* Alert\n\nこちらのAPIを使えばそれぞれ設定できる様子\n\n* [Alerting Provisioning HTTP API | Grafana documentation](https://grafana.com/docs/grafana/latest/developers/http_api/alerting_provisioning/)\n\nより詳しくはこちら [Grafana Alertを設定する](note/Grafana%20Alertを設定する.md)\n\n## Provisioning\n\n[Provision Grafana | Grafana documentation](https://grafana.com/docs/grafana/latest/administration/provisioning/)\n\n構築時にyamlで設定しておくとよいよ\n\nhelmの場合はこちらの `alerting` の項目\n\nhttps://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml\n\n[kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack) を使っている場合、subchartとしてgrafanaが定義されているので、以下のように設定できる。\n\n````yaml\ngrafana:\n  alerting:\n    rules.yaml:\n      apiVersion: 1\n      groups:\n        - orgId: 1\n    # ...\n````\n\n## ダッシュボードとアラートをexport/importするshell script\n\n以上踏まえてこんな感じに作った\n\n`import.sh`\n\n````shell\nBASE_URL=$1\n# GrafanaのAPI KEY\nTOKEN=$2\n\n# フォルダを作成\ncurl -XPOST -H \"Authorization: Bearer ${TOKEN}\" -H 'Content-Type: application/json' -Ss -d '@folders.json' \"$BASE_URL/api/folders\"\n\n# ダッシュボードを作成\ncurl -XPOST -H \"Authorization: Bearer ${TOKEN}\" -H 'Content-Type: application/json' -Ss -d \"@dashboard.json\" \"$BASE_URL/api/dashboards/db\"\n\n# Alert Ruleを作成\nfor i in $(seq $(cat alert-rules.json | jq '. | length')); do\n  rule=$(cat alert-rules.json | jq --argjson index $(($i-1)) '.[$index]')\n  echo \"$rule\" | curl -XPOST -H \"Authorization: Bearer ${TOKEN}\" -H 'Content-Type: application/json' -H 'X-Disable-Provenance: none' -Ss -d @- \"$BASE_URL/api/v1/provisioning/alert-rules\"\ndone\n````\n\n`export.sh`\n\n````shell\nBASE_URL=$1\n# GrafanaのAPI KEY\nTOKEN=$2\n\n# ダッシュボード\ncurl -XGET -H \"Authorization: Bearer ${TOKEN}\" -Ss \"$BASE_URL/api/dashboards/uid/my-board\" | jq 'del(.meta, .dashboard.id)' | jq '. |= .+ {\"folderUid\": \"solr\", \"overwrite\": true}' \u003e dashboard.json\n\n# Alert Rule\ncurl -XGET -H \"Authorization: Bearer ${TOKEN}\" -Ss \"$BASE_URL/api/v1/provisioning/alert-rules\" \u003e alert-rules.json\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/05/16","Grafana"]},"/note/Grafana-Alert%E3%82%92%E8%A8%AD%E5%AE%9A%E3%81%99%E3%82%8B":{"title":"Grafana Alertを設定する","content":"\n[Grafana](note/Grafana.md) 9.xではアラートするのにContact points、Notification policies、Alert Ruleをそれぞれ設定する必要がある。\n\n## Contact Points\n\nE-mailやSlackなどの送信先と、送信メッセージのテンプレートを設定する。\n\n### Notification Template\n\n* 公式の説明 [Create notification templates | Grafana documentation](https://grafana.com/docs/grafana/latest/alerting/manage-notifications/template-notifications/create-notification-templates/)\n* サンプルがいくつか紹介されているのでこれをコピペするのが便利 [Grafana Alerting: A guide to templating alert notifications](https://grafana.com/blog/2023/04/05/grafana-alerting-a-beginners-guide-to-templating-alert-notifications/)\n\nテンプレートの作成時には以下のReferenceを参照するとよい。\n利用できる変数が説明されている。\n\n* [Customize notifications | Grafana documentation](https://grafana.com/docs/grafana/latest/alerting/manage-notifications/template-notifications/)\n* [Reference | Grafana documentation](https://grafana.com/docs/grafana/latest/alerting/manage-notifications/template-notifications/reference/)\n\n#### 例\n\n* `Alert`: アラートの内容やダッシュボードURLなどを持ったデータ\n* `Alert.Annotations`: summaryやdescriptionなどの情報をkey-valueで保持する\n\n````go\n{{ define \"alerts.message\" -}}\n{{ if .Alerts.Firing -}}\n{{ len .Alerts.Firing }} firing alert(s)\n{{ template \"alerts.summarize\" .Alerts.Firing }}\n{{- end }}\n{{- if .Alerts.Resolved -}}\n{{ len .Alerts.Resolved }} resolved alert(s)\n{{ template \"alerts.summarize\" .Alerts.Resolved }}\n{{- end }}\n{{- end }}\n\n{{ define \"alerts.summarize\" -}}\n{{ range . -}}\n- {{ index .Annotations \"summary\" }}\n{{ end }}\n{{ end }}\n````\n\nAlert Ruleで、Summary and annotations を設定できる項目があるので、Summaryに以下のようなメッセージを設定しておくと、次のような通知が飛ぶようになる。\n\nSummary\n\n````\nThe database server {{ index $labels \"instance\" }} has exceeded 75% of available disk space. Disk space used is {{ index $values \"B\" }}%, please resize the disk within the next 24 hours\n````\n\n````\n1 firing alert(s)\n- The database server db1 has exceeded 75% of available disk space. Disk space used is 76%, please resize the disk size within the next 24 hours\n\n1 resolved alert(s)\n- The web server web1 has been responding to 5% of HTTP requests with 5xx errors for the last 5 minutes\n````\n\n## Notification policies\n\n[Manage notification policies | Grafana documentation](https://grafana.com/docs/grafana/latest/alerting/manage-notifications/create-notification-policy/)\n\n通知をAlert ruleにつけたラベルなどでグルーピングして、通知先や間隔の設定をまとめて行える。\ndefault policyを設定しておけば何もなければそれがつかわれる。\n\n## Alerting Rule\n\n通知する条件やメッセージを設定する。おそらく一番触る部分\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/05/18","Grafana"]},"/note/Grafana-database-is-locked%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E3%81%A7%E3%81%A6%E3%82%A2%E3%83%A9%E3%83%BC%E3%83%88%E8%A8%AD%E5%AE%9A%E3%81%AA%E3%81%A9%E3%81%8C%E6%9B%B4%E6%96%B0%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84":{"title":"Grafana database is lockedのエラーがでてアラート設定などが更新できない","content":"\n[Grafana](note/Grafana.md)でアラートルールを更新した際に、`database is locked` とエラーがでて更新ができない場合がある。\nこれはsqliteのDBがロックされた状態になってしまって発生している。\n\n[Grafana, SQLite, and database is locked - handle it like a pro!](https://opsverse.io/2022/12/15/grafana-sqlite-and-database-is-locked/)\n\ninitContainerで、sqliteのdbファイルを作り直すことで解消する\n\n````\n  initContainers:\n    - command:\n        - /bin/sh\n        - '-c'\n        - \u003e-\n          /usr/bin/sqlite3 /var/lib/grafana/grafana.db '.clone /var/lib/grafana/grafana.db.clone';\n          mv /var/lib/grafana/grafana.db.clone /var/lib/grafana/grafana.db;\n          chmod a+w /var/lib/grafana/grafana.db\n      image: keinos/sqlite3\n      imagePullPolicy: IfNotPresent\n      name: sqlite\n      resources: {}\n      securityContext:\n        runAsNonRoot: false\n        runAsUser: 0\n      volumeMounts:\n        - mountPath: /var/lib/grafana\n          name: storage\n````\n\n[Grafana Helm Chart](https://github.com/grafana/helm-charts/tree/main/charts/grafana)の場合、`extraInitContainers` に指定する\n\n````yaml\nextraInitContainers:\n  - name: grafanadb-clone-and-replace\n    image: keinos/sqlite3\n    command:\n    - \"/bin/sh\"\n    - \"-c\"\n    - \"/usr/bin/sqlite3 /var/lib/grafana/grafana.db '.clone /var/lib/grafana/grafana.db.clone'; mv /var/lib/grafana/grafana.db.clone /var/lib/grafana/grafana.db; chmod a+w /var/lib/grafana/grafana.db\"\n    imagePullPolicy: IfNotPresent\n    securityContext:\n      runAsUser: 0\n    volumeMounts:\n    - name: storage\n  mountPath: \"/var/lib/grafana\"\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/05/30","Grafana"]},"/note/Groovy":{"title":"Groovy","content":"\n## operator overloading\n\n[The Apache Groovy programming language - Operators](https://groovy-lang.org/operators.html#Operator-Overloading)\n\n`+` `-` などのoperatorを再定義することができる。\n\nhttps://github.com/jenkinsci/job-dsl-plugin/blob/master/job-dsl-core/src/main/groovy/javaposse/jobdsl/dsl/NodeEnhancement.groovy\n\n````groovy\n/**\n * Add div and leftShift operators to Node.\n * * div - Will return the first child that matches name, and if it doesn't exists, it creates\n * * leftShift - Take node (or configure block to create) and appends as child, as opposed to plus which appends as a\n *               peer\n */\n@Category(Node)\nclass NodeEnhancement {\n    private static final Logger LOGGER = Logger.getLogger(NodeEnhancement.name)\n\n    Node div(Node orphan) {\n        Node clonedOrphan = cloneNode(orphan)\n        LOGGER.fine(\"Looking for child node ${clonedOrphan}\")\n        String childName = clonedOrphan.name()\n        List children = this.children().findAll { child -\u003e\n\n....\n````\n\nhttps://github.com/jenkinsci/job-dsl-plugin/blob/master/docs/The-Configure-Block.md\nhttps://stackoverflow.com/questions/27931795/how-to-refactor-common-jenkins-jobdsl-code\n\n## this, owner, delegate\n\nclosure内で使うことができる変数。\n\n* this クロージャを囲んでいるクラス\n* owner クロージャを囲んでいるクラスか、クロージャを囲んでいるクロージャ\n* delegate defaultではownerがセットされている。外から与えることもできる\n  * It is a powerful concept for building domain specific languages in Groovy\n  * The delegate of a closure can be changed to any object.\n\nhttps://groovy-lang.org/closures.html#\\_delegate_of_a_closure\n[\\[Groovy\\]クロージャのthis、owner、delegateについて - Qiita](https://qiita.com/saba1024/items/b57c412961e1a2779881)\n\nJob DSLではこのようにしてdelegateを使っている\n\nhttps://github.com/jenkinsci/job-dsl-plugin/blob/master/job-dsl-core/src/main/groovy/javaposse/jobdsl/dsl/Job.groovy\n[ContextHelper.executeInContext](https://github.com/jenkinsci/job-dsl-plugin/blob/master/job-dsl-core/src/main/groovy/javaposse/jobdsl/dsl/ContextHelper.groovy) で、`closure.delegate` にContextを差し込んでいる\nContextはJob DSLで定義しているクラス(多分groovy一般てわけじゃない)\nhttps://github.com/jenkinsci/job-dsl-plugin/blob/master/job-dsl-core/src/main/groovy/javaposse/jobdsl/dsl/helpers/BuildParametersContext.groovy\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Groovy"]},"/note/Homebrew":{"title":"Homebrew","content":"\n\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["CLI"]},"/note/Hugo":{"title":"Hugo","content":"\n\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go","Hugo"]},"/note/Hugo-%E5%A4%96%E9%83%A8%E3%83%AA%E3%83%B3%E3%82%AF%E3%82%92%E3%82%AB%E3%83%BC%E3%83%89%E3%81%A7%E8%A1%A8%E7%A4%BA%E3%81%99%E3%82%8B":{"title":"Hugo 外部リンクをカードで表示する","content":"\n[Hugo](note/Hugo.md) で、ブログでよく見るリンクをカードで表示するやつをやりたい\n\n[resources.GetRemote](https://gohugo.io/hugo-pipes/introduction/#get-resource-with-resourcesget-and-resourcesgetremote) を利用することで、ビルドのタイミングで指定したURLへアクセスしてリソースを取得できる\n\n[v0.91.0](https://github.com/gohugoio/hugo/releases/tag/v0.91.0) で入った機能\n\n## 作り方\n\n`shortcode/card-link.html`\n\n### 外部リソースを取得\n\n````go-html-template\n{{ $remote := resources.GetRemote \"https://www.example.com/styles.scss\" }}\n````\n\n### スタイル\n\n[Hugoでついに外部URLのブログカードを作れるようになった【自作ショートコード】 | Hugoブログテーマ「Salt」](https://hugo-theme-salt.okdyy75.com/article/salt/blog-card/)\n\n## 使い方\n\n````\n{{\u003c card-link \"https://example.com\" \u003e}}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/05/07","Hugo","Go"]},"/note/Hugo-relative-link":{"title":"Hugo relative link","content":"\n[Relative linking in Hugo - Nick's Blog and Digital Garden](https://nick.groenen.me/notes/relative-linking-in-hugo/)\n\n[Hugo](note/Hugo.md) では相対パスでのリンクが現在サポートされていない。\nかわりに、 `ref` と `relerf` を使って他のページヘのリンクを書くことができる\n[Shortcodes | Hugo](https://gohugo.io/content-management/shortcodes/#ref-and-relref)\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/05/05","Go","Hugo"]},"/note/Hystrix-dashboard":{"title":"Hystrix dashboard","content":"\nhttps://github.com/Netflix-Skunkworks/hystrix-dashboard/wiki\n\n````\ngit clone https://github.com/cep21/circuit.git\ncd circuit\nmake run\n\ndocker run -d -p 7979:9002 --name hystrix-dashboard mlabouardy/hystrix-dashboard:latest\n````\n\nhttp://127.0.0.1:7979/hystrix\n\nhttp://host.docker.internal:8123/hystrix.stream を追加する\n\nこんなダッシュボードが見れる\n\n![Pasted-image-20221118112314](note/Pasted-image-20221118112314.png)\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["監視"]},"/note/JFrog-Artifactory":{"title":"JFrog Artifactory","content":"\nJFrogの提供するユニバーサルリポジトリ\n\nhttps://jfrog.com/ja/artifactory/\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":[]},"/note/JSDoc-VSCode%E3%81%A7%E5%9E%8B%E3%83%81%E3%82%A7%E3%83%83%E3%82%AF%E3%82%92%E3%81%99%E3%82%8B":{"title":"JSDoc VSCodeで型チェックをする","content":"\nTypeScriptを使おうとするとビルドの手間がかかるので、小さいスクリプトで手軽に型チェックだけしたいときにJSDocで簡易的に型をつけたい。\n\n1行目に `@ts-check` を書くのが重要\n\n````javascript\n// @ts-check\n````\n\n`@typedef` などを書くことで型チェックが行われてハッピーになれる\n\n````javascript\n/**\n * @typedef {Object} Payload\n * @property {string} channel - channelId\n * @property {Block[]} blocks - block\n */\n\n/**\n * @typedef {Object} Block\n * @property {('section' | 'mrkdwn')} type - block type\n * @property {(Block | string)} text - inner block or text\n */\n\n/**\n * @param {string} channelId - Slack channel ID\n * @param {string} message - message\n * @returns {Payload}\n */\nfunction slackPayload(channelId, message) {\n  // payloadを作成する処理...\n  return {\n    channel: channelId,\n    blocks: [\n      {\n        type: 'section',\n        text: {\n          type: 'mrkdwn',\n          text: message,\n        },\n      },\n    ],\n  }\n}\n\nfunction send() {\n  const payload = slackPayload('Cxxxxxx', 'hello');\n  // payloadを送信する処理....\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/04/05","JavaScript","TypeScript"]},"/note/JUni4%E3%81%AEparameterized-test%E3%82%92JUnit5%E3%81%AB":{"title":"JUni4のparameterized testをJUnit5に","content":"\n\\#Java\n\\#Kotlin\n\n## テスト対象コード\n\n````kotlin\nclass Calculator() {\n    fun add(x: Int, y: Int) = x + y\n}\n````\n\n## JUnit4\n\n````kotlin\nimport org.hamcrest.CoreMatchers\nimport org.hamcrest.MatcherAssert\nimport org.junit.Test\nimport org.junit.runner.RunWith\nimport org.junit.runners.Parameterized\n\n@RunWith(Parameterized::class)\ninternal class CalculatorTest(private val x: Int, private val y: Int, private val expected: Int) {\n\n    @Test\n    fun test() {\n        val calc = Calculator()\n        val actual = calc.add(x, y)\n        MatcherAssert.assertThat(actual, CoreMatchers.equalTo(expected))\n    }\n\n    companion object {\n        @JvmStatic\n        @Parameterized.Parameters\n        fun data() = listOf(\n                arrayOf(1, 2, 3),\n                arrayOf(9, 8, 17),\n        )\n    }\n}\n````\n\n## JUnit5\n\n````kotlin\nimport org.junit.Assert.assertEquals\nimport org.junit.jupiter.params.ParameterizedTest\nimport org.junit.jupiter.params.provider.CsvSource\n\ninternal class CalculatorTest {\n\n    @ParameterizedTest\n    @CsvSource(\n            \"1, 2, 3\",\n            \"9, 8, 17\",\n    )\n    fun test(x: Int, y: Int, expected: Int) {\n        val calc = Calculator()\n        val actual = calc.add(x, y)\n        assertEquals(expected, actual)\n    }\n\n}\n````\n\ncompanion object を使う必要がない\n簡単なテストケースであれば `@CsvSource` が使えるため、すっきりする\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Java","Kotlin"]},"/note/JUnit%E3%81%A7resource%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%82%80":{"title":"JUnitでresourceのファイルを読み込む","content":"\nユニットテスト時に、\n\n\u003chttps://www.baeldung.com/junit-src-test-resources-directory-path\u003e\n\u003chttps://stackoverflow.com/questions/3891375/how-to-read-a-text-file-resource-into-java-unit-test\u003e\n\nHoge.class.getResourceを使うとよい\n\n````java\npublic class FooTest {\n  @Test public void readXMLToString() throws Exception {\n        java.net.URL url = MyClass.class.getResource(\"test/resources/abc.xml\");\n        java.nio.file.Path resPath = java.nio.file.Paths.get(url.toURI());\n        String xml = new String(java.nio.file.Files.readAllBytes(resPath), \"UTF8\"); \n  }\n````\n\nJava 9+ではこう\n\n````java\nnew String(getClass().getClassLoader().getResourceAsStream(resourceName).readAllBytes());\n````\n\nClassLoader.getSystemResource() でもロードできるが、ときどきNullPointerExceptionでおちる\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Java"]},"/note/Jackson%E3%81%A7deserialize%E3%82%92%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%9E%E3%82%A4%E3%82%BA%E3%81%99%E3%82%8B":{"title":"Jacksonでdeserializeをカスタマイズする","content":"\n\\#Kotlin #Java\n\n## JSONの特定の値に応じてパースする型を変えたい\n\nJSONのtypeというパラメータによって、使うフィールドが異なる場合にパッと思いつくやり方は以下かなと思います。\n\n````kotlin\ndata class User(\n    // ユーザーのタイプを表す 'free' or 'payed'\n    val type: String,\n    // どちらの型でも共通\n    val name: String,\n    // freeの場合のみ存在する\n    val trialEndAt: Date,\n    // payedの場合のみ存在する\n    val purchasedAt: Date,\n)\n````\n\n````json\n{\n  \"users\": [\n    {\n      \"type\": \"free\",\n      \"name\": \"John\",\n      \"trialEndAt\": '2022-02-02T19:00:00+09:00'\n    },\n    {\n      \"type\": \"payed\",\n      \"name\": \"Alice\",\n      \"purchasedAt\": '2022-01-22T19:00:00+09:00'\n    }\n  ]\n}\n````\n\n### `@JsonTypeInfo`、`@JsonSubTypes` を使って型を振り分ける\n\n````kotlin\n@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = \"type\") // “type” というJSONのキーで型を判別する\n@JsonSubTypes(  // “type”の値に応じてどの型にパースするか\n    value = [\n        JsonSubTypes.Type(value = User.Free::class, name = \"free\"),\n        JsonSubTypes.Type(value = User.Payed::class, name = \"payed\"),\n    ]\n)\nsealed class User(val name: String) { // type はフィールドには入れない\n    data class Free(val trialEndAt: Date) : User()\n\n    data class Payed(val purchasedAt: Date) : User()\n}\n````\n\n普段は継承をあまり使いたくないが、 `sealed class` でスコープを限定することで使いやすくした。\n継承にする必要はなく別クラスに定義しても問題ないはず。\n\n## 参考\n\n[Kotlin with Jackson: Deserializing Kotlin Sealed Classes | by Sergii Prodan | Medium](https://serpro69.medium.com/kotlin-with-jackson-deserializing-kotlin-sealed-classes-c95f837e9164)\n[JsonDeserializerを使って空の時に型が配列になるプロパティに対応する - Qiita](https://qiita.com/yotama/items/1a95329a8cd87f6f0460)\n[Jacksonで独自のJSONシリアライズをする | GROUP DEV BLOG | TECHNO DIGITAL](https://www.tcdigital.jp/dev_blog/programming/jackson%E3%81%A7%E7%8B%AC%E8%87%AA%E3%81%AEjson%E3%82%B7%E3%83%AA%E3%82%A2%E3%83%A9%E3%82%A4%E3%82%BA%E3%82%92%E3%81%99%E3%82%8B/)\n[Jackson使い方メモ - Qiita](https://qiita.com/opengl-8080/items/b613b9b3bc5d796c840c#%E5%9E%8B%E5%BC%95%E6%95%B0%E3%82%92%E6%8C%81%E3%81%A4%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%92%E3%83%87%E3%82%B7%E3%83%AA%E3%82%A2%E3%83%A9%E3%82%A4%E3%82%BA%E3%81%99%E3%82%8B)\n[Parse Snake case JSON in Spring Boot | by Bhanu Chaddha | Medium](https://medium.com/@bhanuchaddha/parse-snake-case-json-in-spring-boot-66b42627a791)\n[備忘録的なblog: Jacksonでsnake caseのキーをlower camel caseのプロパティーにデシリアライズする](http://se-bikou.blogspot.com/2019/01/jacksonsnake-caselower-camel-case.html)\n[Jackson overcoming underscores in favor of camel-case](https://stackoverflow.com/questions/10519265/jackson-overcoming-underscores-in-favor-of-camel-case)\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Kotlin","Java"]},"/note/Java%E3%81%A7%E5%90%8C%E4%B8%80%E3%81%AEFQCN%E3%81%8Cclasspath%E4%B8%8A%E3%81%AB%E8%A4%87%E6%95%B0%E3%81%82%E3%82%8B%E5%A0%B4%E5%90%88%E3%81%AE%E6%8C%99%E5%8B%95":{"title":"Javaで同一のFQCNがclasspath上に複数ある場合の挙動","content":"\n\\#Java\n\n2つのライブラリに同じclassが存在するときの挙動について\n\n## 例\n\n[org:json:1.0](https://mvnrepository.com/artifact/org/json/1.0.0)\n[com.googlecode.json-simple:1.1.1](https://mvnrepository.com/artifact/com.googlecode.json-simple/json-simple/1.1.1)\n\n`org.json.simple.parser.JSONParser` が両方のライブラリに存在する\n\n* `org.json.simple.parser.JSONParser.parse(Ljava/io/String;)Ljava/lang/Object;` はjson-simpleにしかないので、org:jsonが先に読み込まれているときにこれを使おうとするとNoSuchMethodExceptionが出る\n* `org.json.simple.parser.JSONParser.parse(Ljava/io/Reader;)Ljava/lang/Object;` は org:json と json-simple 両方に存在するので、このメソッドを使う場合はどちらのライブラリが読み込まれても関係ない\n* classpathの読み込み順によって問題が発生したりしなかったりする\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":[]},"/note/Java%E3%81%AEDate%E3%81%A8DateAndTimeAPI%E3%81%A8%E3%81%AE%E7%9B%B8%E4%BA%92%E5%A4%89%E6%8F%9B":{"title":"JavaのDateとDateAndTimeAPIとの相互変換","content":"\n\\#Java\n\n\u003chttps://javazuki.com/articles/date-calendar-convert-to-datetime.html\u003e\n\n# Date/Calendar↔Date And Time API系変換のまとめ\n\nDate/Calendar↔Date And Time API系の変換は、Instantを介して行う。それぞれのクラスでInstantを直接扱えるのかどうかなどが異なるため、手順をまとめる。\n\n## Date/Calendar→Date And Time API系の変換\n\n![](https://javazuki.com/images/javase/date-and-time-api/DateOrCalendar%E3%81%8B%E3%82%89XXXDateTime%E3%81%B8%E3%81%AE%E5%A4%89%E6%8F%9B.png)\n\nDate/CalendarからDate And Time API系へ変換する場合は、まずXXXDateTimeへの変換を考える。｢LocalDate｣｢LocalTime｣｢Year｣｢YearMonth｣などはXXXDateTimeから変換メソッドが用意されているので、とりあえずXXXDateTimeにしてしまう。\n\nDate/CalendarからXXXDateTimeへの変換はInstantを介して行う。Date/CalendarにはInstantを取得できるtoInstant()メソッドが、Java8から追加された。Instantはエポック時間からの経過秒が保持されている。ただしInstantだけでは表現したい時差やタイムゾーンが不明のため、XXXDateTimeにするには｢ZoneId｣or｢ZoneOffset｣が必要になる。システムデフォルトのZoneIdはZoneId.systemDefault()で取得できる。\n\n### Date→LocalDateTime\n\nLocalDateTimeの場合、エポック秒から生成できるofEpochSecond()が用意されている。ただZoneIdからZoneOffsetを取得するのは手順が面倒なため、instantとzoneIdで生成できるofInstant()が用意されている。それを利用する。\n\nDate→LocalDateTimeへの変換\n\n````java\nDate date = new Date();\n\nInstant instant = date.toInstant();\nZoneId zone = ZoneId.systemDefault();\nLocalDateTime converted = LocalDateTime.ofInstant(instant, zone);\n````\n\n### Date→OffsetDateTime\n\nOffsetDateTimeの場合、｢ZoneId｣｢ZoneOffset｣のどちらからでも生成できる。ZoneIdはZoneOffsetの情報を取得できるので可能。\n\nOffsetDateTimeへの変換(ZoneOffset利用)\n\n````java\nDate date = new Date();\n\nInstant instant = date.toInstant();\nZoneOffset offset = ZoneOffset.ofHours(9);\nOffsetDateTime converted = instant.atOffset(offset);\n````\n\nOffsetDateTimeへの変換(ZoneId利用)\n\n````java\nDate date = new Date();\n\nInstant instant = date.toInstant();\nZoneId zone = ZoneId.systemDefault();\nOffsetDateTime converted = OffsetDateTime.ofInstant(instant, zone);\n````\n\n### Date→ZonedDateTime\n\nZonedDateTimeの場合、instantとzoneIdから生成できる。InstantクラスにもZonedDateTimeを生成できるファクトリがあるが、内部的に ZonedDateTime.ofInstant()呼び出すのでどちらでもいい。\n\nZonedDateTimeへの変換\n\n````java\nDate date = new Date();\n\nInstant instant = date.toInstant();\nZoneId zone = ZoneId.systemDefault();\nZonedDateTime converted = ZonedDateTime.ofInstant(instant, zone);\n````\n\n### Calendar→LocalDateTime,OffsetDateTime,ZonedDateTime\n\nCalendarもtoInstant()があるのでInstantを介した変換が可能。instant取得後は同様の手順。\n\nLocalDateTimeへの変換\n\n````java\nCalendar calendar = Calendar.getInstance();\n\nInstant instant = calendar.toInstant();\nZoneId zone = ZoneId.systemDefault();\nLocalDateTime converted = LocalDateTime.ofInstant(instant, zone);\n````\n\n## Date And Time API系→Date/Calendarの変換\n\n[![XXXDateTimeからDateOrCalendarへの変換](https://javazuki.com/images/javase/date-and-time-api/XXXDateTime%E3%81%8B%E3%82%89DateOrCalendar%E3%81%B8%E3%81%AE%E5%A4%89%E6%8F%9B.png)](https://javazuki.com/articles/date-calendar-convert-to-datetime.html#)\n\nFigure 2. Date And Time API系からDate/Calendarへの変換\n\nDate And Time API系からDate/Calendarへ変換する場合は、まず｢OffsetDateTime｣｢ZonedDateTime｣への変換を考える。Instantを取得することでDate/Calendarへの変換が可能になる。ただし、InstantからCalendarを直接生成することができない。Dateを生成してからCalendarへ変換する手順になる。\n\nDate/Calendarへの変換においては、LocalDateTimeが直接Instatntを作れない。LocalDateTimeが示している日時がどの時差あるいはタイムゾーンなのかの情報を持たないため、Instantは生成できないことになる。よって｢LocalDate｣｢LocalTime｣｢Year｣｢YearMonth｣などと同様に、｢OffsetDateTime｣｢ZonedDateTime｣を経由してInstantを生成する。\n\n### LocalDateTime→Date\n\nLocalDateTimeからInstantは直接生成できないので、OffsetDateTime かZonedDateTimeを経由する。\n\nLocalDateTime→Dateへの変換\n\n````java\nLocalDateTime localDateTime = LocalDateTime.now();\nZoneId zone = ZoneId.systemDefault();\nZonedDateTime zonedDateTime = ZonedDateTime.of(localDateTime, zone);\n\nInstant instant = zonedDateTime.toInstant();\nDate date = Date.from(instant);\n````\n\n### OffsetDateTime→Date\n\nOffsetDateTimeはInstantを生成できるので、そのまま変換可能。\n\nOffsetDateTime→Dateへの変換\n\n````java\nOffsetDateTime offsetDateTime = OffsetDateTime.now();\nInstant instant = offsetDateTime.toInstant();\nDate date = Date.from(instant);\n````\n\n### ZonedDateTime→Date\n\nZonedDateTimeはInstantを生成できるので、そのまま変換可能。\n\nZonedDateTime→Dateへの変換\n\n````java\nZonedDateTime zonedDateTime = ZonedDateTime.now();\nInstant instant = zonedDateTime.toInstant();\nDate date = Date.from(instant);\n````\n\n### LocalDateTime,OffsetDateTime,ZonedDateTime→Calendar\n\nCalendarはInstantを生成できるが、InstantからCalendarを生成できない。Dateを経由して、Date→Calendar変換を行う。｢OffsetDateTime｣｢ZonedDateTime｣も同様の手順。\n\nLocalDateTime→Calendarへの変換\n\n````java\nLocalDateTime localDateTime = LocalDateTime.now();\nZoneId zone = ZoneId.systemDefault();\nZonedDateTime zonedDateTime = ZonedDateTime.of(localDateTime, zone);\n\nInstant instant = zonedDateTime.toInstant();\nDate date = Date.from(instant);\n\nCalendar calendar = Calendar.getInstance();\ncalendar.setTime(date);\n````\n\n## GregorianCalendar↔ZonedDateTimeの変換\n\nCalendarの中でもGregorianCalendarのみ特殊で、ZonedDateTimeと相互変換が可能。\n\nGregorianCalendarがグレゴリオ暦かつタイムゾーンを保持しているので、ZonedDateTimeととても近いため。ただしGregorianCalendarとZonedDateTimeはユリウス/グレゴリオ暦の切換え日のサポート有無が異なるため、そこだけ注意。\n\nGregorianCalendar→ZonedDateTimeへの変換\n\n````java\nGregorianCalendar gregorianCalendar = new GregorianCalendar();\nZonedDateTime converted = gregorianCalendar.toZonedDateTime();\n````\n\nZonedDateTime→GregorianCalendarへの変換\n\n````java\nZonedDateTime zonedDateTime = ZonedDateTime.now();\nGregorianCalendar gregorianCalendar = GregorianCalendar.from(zonedDateTime);\n````\n\n## Appendix A: 参考\n\n* [Instant（Java SE 8 API仕様）](http://docs.oracle.com/javase/jp/8/docs/api/index.html?java/time/Instant.html)\n* [LocalDateTime（Java SE 8 API仕様）](http://docs.oracle.com/javase/jp/8/docs/api/index.html?java/time/LocalDateTime.html)\n* [OffsetDateTime （Java SE 8 API仕様）](http://docs.oracle.com/javase/jp/8/docs/api/index.html?java/time/OffsetDateTime.html)\n* [ZonedDateTime（Java SE 8 API仕様）](http://docs.oracle.com/javase/jp/8/docs/api/index.html?java/time/ZonedDateTime.html)\n* [Date （Java SE 8 API仕様）](http://docs.oracle.com/javase/jp/8/docs/api/index.html?java/util/Date.html)\n* [Calendar （Java SE 8 API仕様）](http://docs.oracle.com/javase/jp/8/docs/api/index.html?java/util/Calendar.html)\n* [GregorianCalendar （Java SE 8 API仕様）](http://docs.oracle.com/javase/jp/8/docs/api/index.html?java/util/GregorianCalendar.html)\n\n# 関連記事リンク\n\n* Java標準ライブラリ\n  * java.time\n    * [Date And Time APIとは](https://javazuki.com/articles/date-and-time-api-introcution.html)\n    * [Date And Time APIとISO8601](https://javazuki.com/articles/date-and-time-api-iso8601.html)\n    * [Date And Time APIの日時クラス](https://javazuki.com/articles/date-and-time-api-classes.html)\n    * Date/Calendar↔Date And Time API系変換のまとめ ← この記事\n    * [java.sql日時クラス↔Date And Time API系の変換](https://javazuki.com/articles/sql-date-conver-to-datetime.html)\n    * [Date And Time APIの和暦サポート](https://javazuki.com/articles/japanese-date-introduction.html)\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Java"]},"/note/Java%E3%81%AEFormatter":{"title":"JavaのFormatter","content":"\n[Java Check-style and Formatting using Maven | by Arushi Sharma | Medium](https://medium.com/@aru_sha4/java-check-style-and-formatting-using-maven-a1a1b4e6e10a)\n\n## google-java-format\n\n\u003chttps://github.com/google/google-java-format/\u003e\n\nmavenのpluginではなくIDEのpluginだったり、spotlessから使ったりするライブラリ\n\n## googleformatter-maven-plugin\n\n\u003chttps://github.com/talios/googleformatter-maven-plugin\u003e\n\nGoogle Java Formatを適用するプラグイン\n\n## formatter-maven-plugin\n\n[maven-formatterを使ってformatを自動化 - Qiita](https://qiita.com/daikon510/items/abb8cdc552833b5cdaf7)\n[mavenプロジェクトでフォーマッターを使う - よーぐるとのブログ](https://yoghurt1131.hatenablog.com/entry/2017/10/01/204302)\n\u003chttps://code.revelc.net/formatter-maven-plugin/\u003e\n\n独自のformat設定を行うにはEclipse形式の設定ファイルを指定する。\n\n[googleが公開しているformat](https://github.com/google/styleguide/blob/gh-pages/eclipse-java-google-style.xml)\n\nこれを書き換えればいいんだろうけど、あまり独自設定はいれたくない気もする\n\n````xml\n\u003cproject ...\u003e\n    ...\n    \u003cplugin\u003e\n      \u003cgroupId\u003enet.revelc.code.formatter\u003c/groupId\u003e\n      \u003cartifactId\u003eformatter-maven-plugin\u003c/artifactId\u003e\n      \u003cversion\u003e2.11.0\u003c/version\u003e\n      \u003cconfiguration\u003e\n        \u003cdirectories\u003e\n          \u003c!-- 対象ディレクトリ --\u003e\n          \u003cdirectory\u003e${project.build.sourceDirectory}\u003c/directory\u003e\n          \u003cdirectory\u003e${project.build.directory}/generated-sources\u003c/directory\u003e\n        \u003c/directories\u003e\n        \u003cincludes\u003e\n          \u003cinclude\u003ejp/****/****/****/formatter/\u003c/include\u003e\n        \u003c/includes\u003e\n        \u003cexcludes\u003e\n          \u003cexclude\u003ejp/relativitas/maven/plugins/formatter/special/\u003c/exclude\u003e\n          \u003cexclude\u003e**/*Test.java\u003c/exclude\u003e\n        \u003c/excludes\u003e\n        \u003cconfigFile\u003e${project.basedir}/eclipse-java-google-style.xml\u003c/configFile\u003e\n      \u003c/configuration\u003e\n    \u003c/plugin\u003e\n    ...\n\u003c/project\u003e\n````\n\n## Spotless\n\n[spotlessでコードフォーマットする](note/spotlessでコードフォーマットする.md)\n\n## Checkstyle\n\nこれは多分フォーマットチェックするだけで、チェックは上のプラグインでできるので特別不要なきがする\n\n## Kotlinの場合\n\n[KotlinのFormatter](note/KotlinのFormatter.md)\n\n## 参考\n\n* https://aru-sha4.medium.com/java-check-style-and-formatting-using-maven-a1a1b4e6e10a\n* https://google.github.io/styleguide/javaguide.html#s4.2-block-indentation\n* https://stackoverflow.com/questions/65791764/klint-and-spotless-com-pinterest-ktlint-core-parseexception-expecting-a-parame\n* https://code.visualstudio.com/docs/java/java-linting\n* https://github.com/jhipster/prettier-java\n* https://github.com/pinterest/ktlint/issues\n* https://github.com/diffplug/spotless/tree/main/plugin-maven#eclipse-jdt\n* https://github.com/diffplug/spotless/blob/main/ECLIPSE_SCREENSHOTS.md\n* https://github.com/google/styleguide\n* https://www.howtogeek.com/723144/how-to-copy-the-url-addresses-of-all-open-tabs-in-chrome/\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Java"]},"/note/Java-BigDecimal%E3%81%ABdouble%E3%82%92%E6%B8%A1%E3%81%97%E3%81%9F%E3%81%A8%E3%81%8D%E8%AA%A4%E5%B7%AE%E3%81%8C%E3%81%A7%E3%82%8B":{"title":"Java BigDecimalにdoubleを渡したとき誤差がでる","content":"\nJavaで正確な数値計算を行うため BigDecimal を使っていたが、BigDecimalをdoubleで初期化したあと、小数点以下で四捨五入したところ誤差が出てしまった。\n\n[BigDecimalで誤差が出てしまった話 - たけぼーの備忘録](https://tks-lab.hatenablog.com/entry/2017/03/03/131427)\n\n`BigDecimal`を使用して正確な数値計算を行う場合、`double`で初期化することは避けたほうが良いです。`double`は浮動小数点数であり、多くの10進数は正確に表現できません。そのため、`double`で初期化した`BigDecimal`はすでに誤差を含んでいる可能性があります。\n\n`BigDecimal`を初期化する際には、`String`型の値や`BigInteger`型の値を利用してください。例えば：\n\n````java\nBigDecimal bd = new BigDecimal(\"123.456\");\n\n````\n\nこの方法で初期化すると、`BigDecimal`は正確な10進数値を保持します。\n\n小数点以下で四捨五入を行う場合は、`setScale`メソッドを使用し、`RoundingMode`を指定します。\n\n````java\nimport java.math.BigDecimal;\nimport java.math.RoundingMode;\n\npublic class Main {\n    public static void main(String[] args) {\n        BigDecimal bd = new BigDecimal(\"123.456\");\n        BigDecimal rounded = bd.setScale(2, RoundingMode.HALF_UP);\n        System.out.println(rounded);\n    }\n}\n````\n\nこの例では、小数点以下2桁で四捨五入された結果が得られます。正確な数値計算を行うためには、`BigDecimal`の初期化と四捨五入の両方で適切な方法を使用してください。\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/03/30","Java"]},"/note/Java-Heapdump%E3%82%92MAT%E3%81%A7%E8%A7%A3%E6%9E%90%E3%81%99%E3%82%8B":{"title":"Java HeapdumpをMATで解析する","content":"\n\\#Java \n\nEclipse Memory Analyzer(MAT)\nhttps://www.eclipse.org/mat/downloads.php\n\nAmazon CorrettoのJDK 19が入っているのだが、matを開くとエラーがでて起動しなかった\n`shared library does not contain the JNI_CreateJavaVM symbol`\n\nOpenJDK 19を入れてJAVA_HOMEをこちらに変更したところ起動できた\nhttps://jdk.java.net\n\n````shell\n$ curl -LO https://download.java.net/java/GA/jdk19.0.2/fdb695a9d9064ad6b064dc6df578380c/7/GPL/openjdk-19.0.2_macos-aarch64_bin.tar.gz\n$ cd /Library/Java/JavaVirtualMachines\n$ sudo tar -zxvf /tmp/openjdk-19.0.2_macos-aarch64_bin.tar.gz\n$ export JAVA_HOME=$(pwd)/jdk-19.0.2.jdk/Contents/Home\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/04/07"]},"/note/JavaScript%E3%81%A7JSON%E3%82%92kebab-case%E3%81%AB%E3%81%99%E3%82%8B":{"title":"JavaScriptでJSONをkebab-caseにする","content":"\n\\#JavaScript\n\n````javascript\nexport const stringifyRoutePoint = (point?: QueryRoutePoint) =\u003e\n  point != null\n    ? JSON.stringify(point, (key: string, value: any) =\u003e {\n        if (value \u0026\u0026 typeof value === 'object') {\n          const replacement: { [key: string]: string } = {}\n          for (const v in value) {\n            if (Object.hasOwnProperty.call(value, v)) {\n              const key = kebabize(v)\n              console.log('kebabize---', key, value)\n              replacement[key] = value[v]\n            }\n          }\n\n          return replacement\n        }\n        return value\n      })\n    : undefined\n\nconst kebabize = (str: string) =\u003e {\n  return str\n    .split('')\n    .map((letter, idx) =\u003e {\n      return letter.toUpperCase() === letter\n        ? `${idx !== 0 ? '-' : ''}${letter.toLowerCase()}`\n        : letter\n    })\n    .join('')\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["JavaScript"]},"/note/JavaScript-xpath%E3%81%A7%E8%A6%81%E7%B4%A0%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B":{"title":"JavaScript xpathで要素を取得する","content":"\n\n````javascript\nfunction getElementByXpath(path) {\n  return document.evaluate(\n    path,\n    document,\n    null,\n    XPathResult.FIRST_ORDERED_NODE_TYPE,\n    null\n  ).singleNodeValue;\n}\n\ngetElementByXpath('(//div[@class=\"font-bold btn\"])[1]')\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/04/27","JavaScript"]},"/note/Jenkinfsfile%E3%82%92CI%E3%81%A7validate%E3%81%97%E3%81%9F%E3%81%84":{"title":"JenkinfsfileをCIでvalidateしたい","content":"\n[Jenkins: How do I lint Jenkins pipelines from the command line? - Stack Overflow](https://stackoverflow.com/questions/44703012/jenkins-how-do-i-lint-jenkins-pipelines-from-the-command-line)\nhttps://www.jenkins.io/doc/book/pipeline/development/\n\n起動中の [note/Jenkins](Jenkins.md) にcurlやsshしてvalidateのAPIを叩くとチェックできる\n\nLinting via the CLI with SSH\n\n````shell\n# ssh (Jenkins CLI)\n# JENKINS_SSHD_PORT=[sshd port on controller]\n# JENKINS_HOSTNAME=[Jenkins controller hostname]\nssh -p $JENKINS_SSHD_PORT $JENKINS_HOSTNAME declarative-linter \u003c Jenkinsfile\n````\n\nLinting via HTTP POST using curl\n\n````shell\n# curl (REST API)\n# Assuming \"anonymous read access\" has been enabled on your Jenkins instance.\n# JENKINS_URL=[root URL of Jenkins controller]\n# JENKINS_CRUMB is needed if your Jenkins controller has CRSF protection enabled as it should\nJENKINS_CRUMB=`curl \"$JENKINS_URL/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\\\":\\\",//crumb)\"`\ncurl -X POST -H $JENKINS_CRUMB -F \"jenkinsfile=\u003cJenkinsfile\" $JENKINS_URL/pipeline-model-converter/validate\n````\n\nそれをnpmコマンドでできるようにしたものがこちら\n\n[Jenkinsfileのlintで救える命がある](https://www.slideshare.net/miyajan/jenkinsfilelint)\n[jflint - npm](https://www.npmjs.com/package/jflint)\n\n## linter\n\nhttps://github.com/nvuillam/npm-groovy-lint というのもある\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins%E3%81%A7%E9%87%8D%E3%81%84%E3%83%AA%E3%83%9D%E3%82%B8%E3%83%88%E3%83%AA%E3%82%92clone%E3%81%99%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%AB%E4%BD%BF%E3%81%88%E3%82%8B%E3%83%86%E3%82%AF%E3%83%8B%E3%83%83%E3%82%AF":{"title":"Jenkinsで重いリポジトリをcloneするときに使えるテクニック","content":"\nshallow clone, sparse checkoutを使うことで、容量を軽くしてローカルに落とすことができる\n\n![Pasted-image-20220705174631](note/Pasted-image-20220705174631.png)\n\nJob DSLの場合\n\n````groovy\npipelineJob('myJob') {\n    definition {\n        cpsScm {\n            scm {\n                git {\n                    configure { git -\u003e\n                        // sparse checkout\n                        git / 'extensions' / 'hudson.plugins.git.extensions.impl.SparseCheckoutPaths' / 'sparseCheckoutPaths' {\n                            'hudson.plugins.git.extensions.impl.SparseCheckoutPath' {\n                                path('src')\n                            }\n                        }\n\n                        // shallow clone\n                        git / 'extensions' / 'hudson.plugins.git.extensions.impl.CloneOption' {\n                            shallow(true)\n                            depth(1)\n                            noTags(true)\n                        }\n                    }\n                    remote {\n                        url('https://bare.example.com/repository.git')\n                        credentials('credential')\n                    }\n                    branch('master')\n                }\n            }\n            lightweight(false)\n            scriptPath(\"Jenkinsfile\")\n        }\n    }\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins%E3%81%A7raw-html%E3%82%92%E8%AA%AC%E6%98%8E%E6%96%87%E3%81%AB%E6%9B%B8%E3%81%91%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%99%E3%82%8B":{"title":"Jenkinsでraw htmlを説明文に書けるようにする","content":"\nhtmlタグがエスケープされずに装飾できるようになる\n\n[OWASP Markup Formatter](https://plugins.jenkins.io/antisamy-markup-formatter/) をインストール\n\nグローバルセキュリティの設定 \u003e マークアップ記法 \u003e Safe HTML に変更\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins%E3%81%ABBlueOcean%E5%85%A5%E3%82%8C%E3%82%8B":{"title":"JenkinsにBlueOcean入れる","content":"\n\u003chttps://cloudbees.techmatrix.jp/blog/first-time-blue-ocean/\u003e\n\n## 始めに\n\nJenkins 2.0からパイプラインが、そしてJenkins 2.7からはBlue Oceanプラグインが利用可能となりました。\n\n## パイプラインとは\n\n従来Jenkinsはフリースタイルジョブでジョブを定義していました。ただフリースタイルジョブでは、例えば条件ロジックを組めなかったり、ジョブの途中で停止してしまった場合に最初から始めなければならなかったりと現実的にCI/CDを実現するには多くの制約がありました。\n\nそれらの問題を解消するために登場したのがパイプラインです。\n\nパイプラインとは、Jenkins2.0から登場した公式のプラグインであり、CI/CDのフローをコードとして定義するためのツールです。なお、パイプラインにはスクリプトパイプラインと宣言型パイプラインの2種類がありますが、今回はBlue Oceanを利用するために宣言型パイプラインを用います。\n\n### どういったことができる？\n\nパイプラインの特徴や、フリースタイルジョブと比べての利点について説明していきます。\n\nまずパイプラインはJenkinsfileというApache GroovyをベースにしたDSLで記載されたスクリプトファイルです。 1つのスクリプトファイルでCI/CDのフローを記載することが可能です。\n\n従来、複数のジョブをつなげていくにはビルド・トリガを用いて連結していく必要がありましたが、一目見るだけではどのようにジョブがつながっているのかがわかりませんでした。 タスクの名称をナンバリングするといった方法で運用回避されていたかと思います。 全体像がわかりづらく、業務引継ぎ等を考えると非常にネガティブな状況でした。\n\nまた、実行したいCI/CDのフローに比例してジョブの数も増えていき、管理にもコストがかかってしまいます。 比較してパイプラインは、CI/CDのフローの流れを1つのJenkinsfileで表現することが可能になります。\n\nさらに、CI/CDのフローを表現できる幅も広がりました。 従来のビルド・トリガのような順次実行は当然として、並列実行や繰り返しの実行、条件に応じたスクリプトの実行といったことが可能になります。\n\n例えば製品バージョン毎に異なるJDKのバージョン違い。従来であればJDK毎にフリースタイルジョブを作成する必要がありましたが、パイプラインでは条件に応じたスクリプトの実行が可能なので、コミットされたリポジトリに応じてJDKを分けるといった事ができます。\n\nCI/CDフロー内の承認といったことについても、パイプライン上で可能です。 フローの一時点で停止し、承認や入力を待機して、入力内容に応じて後続フローの実行を切り替えることができます。\n\n耐久性についてもパイプラインは秀でています。パイプラインの実行途中でJenkinsが再起動してフローが停止してしまった場合でも、実行途中から再開することが可能です。1回の実行が長時間なフローの場合に特に効果を発揮するでしょう。\n\n保守性という点でも優れています。パイプラインを実現するのは1つのJenkinsfileというスクリプトファイルであり、SCMでの管理が可能です。フリースタイルジョブと比較して保守性は格段に高くなります。\n\n当然AntやMaven、Gradleといったビルドツールや、メール通知、外部スクリプトファイルの呼び出しといった従来のフリースタイルジョブで実現できていたことはすべて実行が可能です。これからJenkinsの活用を始める方はもちろん、フリースタイルジョブで書かれたジョブもどこかのタイミングでパイプラインに乗せ換えることを推奨します。\n\nただこのようにメリットのあるパイプラインですが、いままでブラウザ上で操作していたクラシックジョブからいきなりApache Groovyをベースにしたスクリプトファイルというとハードルを感じる方もいると思います。\n\nそれをサポートするのが次に紹介するJenkinsの公式プラグインであるBlue Oceanです。\n\n## Blue Oceanの利用\n\n### Blue Oceanとは\n\nBlue OceanとはJenkinsの公式プラグインです。\n\n\u003chttps://www.jenkins.io/projects/blueocean/\u003e\n\nBlue Oceanを利用することで宣言型パイプラインをグラフィカルに作成できます。パイプラインの実行内容や実行結果も視覚的にわかりやすなり、従来のクラシカルなUIとは異なった新しい体験をすることが可能です。\n\nパイプラインは前述のとおりJenkinsfileというスクリプトを記載していく必要がありますが、Blue Oceanを利用することでGUIでパイプラインを作成することが可能です。そのため、Apache Groovy形式での記載が慣れていない方でもJenkinsfileの作成が可能です。\n\nBlue Ocean内でコードエディタの利用も可能です。複雑な内容のパイプラインを作成するにはJenkinsfileを編集していく必要も出てきますが、ある程度Blue Oceanでパイプラインの全体像を整え、細かい部分についてのみ修正するといった利用も可能です。\n\nBlue Oceanは実行結果を可視化することにも優れています。当然Blue Oceanを用いない場合でもクラシカルなUIで実行結果の確認はできるのですが、より可視化した状態で結果の確認が可能になります。問題が発生した場合にどこでどのような問題が発生しているのかの判断を容易にし、生産性を向上させます。\n\nBlue Oceanは「Bitbucket Cloud」「BitBucket Server」「GitHub」「GitHub Enterprise」「Git」をサポートしており、Blue Oceanで作成したJenkinsfileは上記SCMで管理することが可能です。共同編集やレビューで効果を発揮します。\n\nこういったメリットのあるBlue Oceanを利用してみましょう。\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins%E3%81%AEHTMLPublisherPlugin%E3%81%A7CSS%E3%81%8C%E9%81%A9%E7%94%A8%E3%81%95%E3%82%8C%E3%81%AA%E3%81%84":{"title":"JenkinsのHTMLPublisherPluginでCSSが適用されない","content":"\n\u003chttps://techblog.recochoku.jp/1285\u003e\n\u003chttps://stackoverflow.com/questions/35783964/jenkins-html-publisher-plugin-no-css-is-displayed-when-report-is-viewed-in-j\u003e\n\n## 原因\n\n\u003chttps://www.jenkins.io/doc/book/security/configuring-content-security-policy/\u003e\n\nContent Security Policyが設定されていて、デフォルトではブロックされる\n\n## 解決策\n\nJavaオプションで `hudson.model.DirectoryBrowserSupport.CSP` を設定すればよい\n\n### 1. JenkinsのスクリプトコンソールからCSPを設定する\n\n````shell\nSystem.setProperty(\"hudson.model.DirectoryBrowserSupport.CSP\", \"default-src https: 'unsafe-inline'\")\n````\n\nただし、一時的な設定で、再起動するともとに戻る\n\n### 2. 起動オプションに設定する\n\n設定ファイルを書き換える。\n\nrpm パッケージでインストールした場合\n`/etc/sysconfig/jenkins`\n\ndefault\n\n````shell\nJENKINS_JAVA_OPTIONS=\"-Djava.awt.headless=true\"\n````\n\n追加\n\n````shell\nJENKINS_JAVA_OPTIONS=\"-Djava.awt.headless=true -Dhudson.model.DirectoryBrowserSupport.CSP=\\\"default-src https: 'unsafe-inline'\\\"\"\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins%E3%82%B8%E3%83%A7%E3%83%96%E3%81%A7git-lfs%E3%82%92%E4%BD%BF%E7%94%A8%E3%81%97%E3%81%A6%E4%B8%80%E9%83%A8%E3%81%A0%E3%81%91pull%E3%81%97%E3%81%9F%E3%81%84":{"title":"Jenkinsジョブでgit-lfsを使用して一部だけpullしたい","content":"\n# Jenkinsとgitlfs\n\n## やりたいこと\n\nJenkinsのgit pluginで一部だけgit lfs pullしたい\n\n## わかっていること\n\n* `git lfs pull -I \"$target\"` で対象のディレクトリ・ファイルだけダウンロードできる\n* `git lfs install --skip-smudge` しておかないと、最初のcheckoutで全部`git lfs pull`しようとするっぽい\n* JenkinsのGit Pluginがcloneするより前に `git lfs install --skip-smudge`\n  git init\n  git lfs install --skip-smudge --local\n  git remote add origin https://${BITBUCKET_CREDENTIAL}@bitbucket.org/ntj-developer/passstorage.git || true\n  git pull origin master\n  git lfs pull -I \"$input\"\n\n## 結果\n\n* JenkinsのGit Pluginによるチェックアウトは無効にする\n* shellで lfs pull する\n\n````shell\n# Git Pluginのcloneだと、git lfs pullをスキップできないので、事前に--skip-sumudgeを設定してから手動でcloneする\ngit init\ngit lfs install --skip-smudge --local\ngit remote add origin https://${CREDENTIAL}@bitbucket.org/\u003cworkspace\u003e/\u003crepository\u003e.git\ngit pull origin master\n\n# 対象ディレクトリのみlfs pullすることで時間短縮、容量削減\ngit lfs pull -I \"$targetIn\"\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins","git"]},"/note/Jenkins%E3%82%B8%E3%83%A7%E3%83%96%E3%82%92curl%E3%81%A7%E3%82%A8%E3%82%AF%E3%82%B9%E3%83%9D%E3%83%BC%E3%83%88%E3%82%A4%E3%83%B3%E3%83%9D%E3%83%BC%E3%83%88":{"title":"Jenkinsジョブをcurlでエクスポートインポート","content":"\n[note/Jenkins](Jenkins.md) ジョブ設定をcurlでインポートしたい\n\n1. `crumbIssuer/api/xml` にBASIC認証でGETリクエストをなげ、`/defaultCrumbIssuer/crumbRequestField` と `/defaultCrumbIssuer//crumb/` をコロンで結合したものがcrumb\n1. cookieにcrumbを保存する\n1. cookieとBASIC認証を使って、 `http://jenkins-url.com/path/to/job/directory/createItem?name=${job_name}` にpostする\n   1. リクエストボディにエクスポートしたジョブのxmlを指定する\n\n````shell\n$ curl -O -u $user:$passwd '[http://old-jenkins/job/job_name/config.xml](http://old-jenkins/job/job_name/config.xml)'  \n$ set CRUMB (curl -s --cookie-jar /tmp/cookies -u $user:$passwd '[http://new-jenkins/jenkins/crumbIssuer/api/xml](http://new-jenkins/jenkins/crumbIssuer/api/xml)' | xmllint --xpath 'concat(/defaultCrumbIssuer/crumbRequestField/text(),\":\",/defaultCrumbIssuer//crumb/text())' -)  \n$ curl -s --cookie /tmp/cookies -u $user:$passwd '[http://new-jenkins/jenkins/job/directory/createItem?name=job_name](http://new-jenkins/jenkins/job/directory/createItem?name=job_name)' --data-binary @config.xml -H 'Content-Type:text/xml' -H \"$CRUMB\"\n````\n\nxmllintを使ったが、Jenkinsリクエストにクエリパラメータでもよいみたい\n`/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\":\",//crumb)'`\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins%E6%9C%AC%E4%BD%93%E3%81%AE%E3%83%90%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%E3%81%A8%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3%E3%82%92%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88%E3%81%A7%E6%9C%80%E6%96%B0%E5%8C%96%E3%81%99%E3%82%8B":{"title":"Jenkins本体のバージョンとプラグインをスクリプトで最新化する","content":"\njenkinsの最新バージョンを取得するURL\n\u003chttps://stackoverflow.com/questions/43857882/how-to-query-the-current-jenkins-lts-version-number\u003e\n\n* For stable (LTS) \u003chttps://updates.jenkins.io/stable/latestCore.txt\u003e\n* And for the latest \u003chttps://updates.jenkins.io/latestCore.txt\u003e\n\n[Simple groovy script to upgrade active plugins when new versions are available](https://gist.github.com/alecharp/d8329a744333530e18e5d810645c1238)\n[jenkins safe auto update plugins](https://gist.github.com/taherbs/6d03b4d56ac4f1e7a119e64cf5d17f4c)\n\n````groovy\ndef jenkins = Jenkins.get()\nUpdateCenter uc = jenkins.getUpdateCenter()\n\n// UpdateSitesのデータ更新\nuc.sites.each { site -\u003e\n    site.updateDirectlyNow()\n}\n\ndef plugins = jenkins.pluginManager.activePlugins.collect {\n    // 新しいバージョン\n    UpdateSite.Plugin updateSitePlugin = uc.getPlugin(it.shortName, it.versionNumber)\n    return [\n            name             : it.shortName,\n            installed_version: it.version as String,\n            available_version: updateSitePlugin.version as String,\n    ]\n}\n\nprintln plugins.collect { \"${it.name}:${it.available_version}\" }.join(\" \")\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/01/27","Jenkins"]},"/note/Jenkins-%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88%E3%82%B3%E3%83%B3%E3%82%BD%E3%83%BC%E3%83%AB%E3%81%A7plugin%E3%82%84%E3%82%B8%E3%83%A7%E3%83%96%E3%82%92%E4%B8%80%E8%A6%A7%E3%81%A7%E5%87%BA%E5%8A%9B%E3%81%99%E3%82%8B":{"title":"Jenkins スクリプトコンソールでpluginやジョブを一覧で出力する","content":"\n## plugin一覧を出力する\n\n````groovy\ndef pluginList = new ArrayList(Jenkins.instance.pluginManager.plugins)\npluginList.sort { it.getShortName() }.each{\n  plugin -\u003e \n    println (\"${plugin.getShortName()}:${plugin.getVersion()}\")\n}\n\n// アップデート一覧\nUpdateCenter uc = Jenkins.get().updateCenter\n\ndef plugins = Jenkins.get().pluginManager.plugins\nplugins.toSorted { l,r -\u003e l.shortName \u003c r.shortName ? -1 : 1 }.collect{ plugin -\u003e \n  UpdateSite.Plugin updateSitePlugin = uc.getPlugin(plugin.shortName, plugin.versionNumber)\n\n  if (plugin.hasUpdate() \u0026\u0026 false) {\n    return \"\"\"-- ${plugin.shortName}:${plugin.version}\n+- ${plugin.shortName}:${updateSitePlugin.version}\"\"\"\n  } else {\n        return \"\"\" - ${plugin.shortName}:${plugin.version}\"\"\"\n  }\n  \n}.each{\n  p -\u003e println(p)\n}\n\nprintln \"\"\n````\n\n````groovy\ndef plugins = Jenkins.get().pluginManager.plugins\nplugins.each {\n    println \"${it.shortName} (${it.version}) =\u003e ${it.dependencies}\"\n}\n\n// graphvizを使ってgraphで表示する\ndef plugins = Jenkins.get().pluginManager.plugins\nprintln \"digraph test {\"\nplugins.each {\n    def plugin = it.getShortName()\n    println \"\\\"${plugin}\\\";\"\n    def deps =  it.getDependencies()\n    deps.each {\n      def s = it.shortName\n      println \"\\\"${plugin}\\\" -\u003e \\\"${s}\\\";\"\n    }\n} \nprintln \"}\"\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-%E3%83%93%E3%83%AB%E3%83%89%E3%81%AE%E6%9C%80%E7%B5%82%E6%9B%B4%E6%96%B0%E6%99%82%E5%88%BB%E3%82%92%E7%A2%BA%E8%AA%8D%E3%81%99%E3%82%8B":{"title":"Jenkins ビルドの最終更新時刻を確認する","content":"\n[Jenkins](note/Jenkins.md) でビルドの最終更新時刻を確認する\n\n````groovy\nimport java.time.ZoneOffset\nimport java.time.Instant\nimport java.time.temporal.ChronoUnit\ndef builds = Jenkins.get().getAllItems(Job.class).collectMany { job -\u003e\n        job.builds\n    }.findAll { build -\u003e\n        build.building\n    }\t\n\nprintln builds.size()\nbuilds.each {\n  println \"${it.url} hasntStartedYet: ${it.hasntStartedYet()} , isInProgress: ${it.isInProgress()} , isLogUpdated: ${it.isLogUpdated()} , getTime: ${it.time} , getStartTimeInMillis: ${java.time.Instant.ofEpochMilli(it.getStartTimeInMillis()).atOffset(ZoneOffset.ofHours(9)).toString()} , logfile: ${java.time.Instant.ofEpochMilli(it.logFile.lastModified()).atOffset(ZoneOffset.ofHours(9)).toString()}\"\n  it.doStop()\n}\n\nprintln \"\"\n````\n\n````groovy\nimport java.time.ZoneOffset\nimport java.time.Instant\nimport java.time.temporal.ChronoUnit\n\npipeline {\n    agent none\n    stages {\n        stage('find') {\n            steps {\n                script {\n                    def builds = findNotStoppedJobs()\n                    if (builds.size() == 0) {\n                        println '実行中のジョブなし'\n                        return\n                    }\n\n                    // Nodeの情報をログに残す\n                    println \"---- print all Node ----\"\n                    Jenkins.get().nodes.each { node -\u003e\n                        println \"---- Node ${node.getSelfLabel()} ----\"\n                        printNodeInfo(node)\n                        println \"\"\n                    }\n\n                    def now = Instant.now()\n                    def stoppedBuilds = []\n                    builds.each { build -\u003e\n                        def lastModified = Instant.ofEpochMilli(build.logFile.lastModified())\n\n                        def matcher = build.log =~ /Cannot contact ([^:]*).*/\n                        if (lastModified.plus(5, ChronoUnit.MINUTES).isBefore(now) \u0026\u0026 matcher.size() \u003e 0 \u0026\u0026 matcher[0].size() \u003e 1) {\n                            // slaveとの通信ができなくなって一定時間経過している場合\n\n                            println \"---- ${build.url} ----\"\n\n                            def nodeLabel = matcher[0][1]\n                            def node = Jenkins.get().getNode(nodeLabel)\n                            if (node == null) {\n                                println \"Node ${nodeLabel} の情報が取得できませんでした。podが停止した可能性があるためビルドを停止します\"\n                                stopBuild(build)\n                                stoppedBuilds.add(build)\n                            } else {\n                                printNodeInfo(node)\n                                if (node.channel == null) {\n                                    println \"Node ${nodeLabel} のchannelが取得できませんでした。podが停止した可能性があるためビルドを停止します\"\n                                    stopBuild(build)\n                                    stoppedBuilds.add(build)\n                                }\n                            }\n                            return\n                        }\n\n                    }\n\n                    if (stoppedBuilds.size() == 0) {\n                        println '停止したジョブはありません'\n                        return\n                    }\n\n                }\n            }\n        }\n    }\n}\n\ndef findNotStoppedJobs() {\n    return Jenkins.get().getAllItems(Job.class).collectMany { job -\u003e\n        job.builds\n    }.findAll { build -\u003e\n        build.building\n    }\n}\n\ndef printNodeInfo(def node) {\n    println \"getAssignedLabels()          : ${node.getAssignedLabels()              }\"\n    println \"getChannel()                 : ${node.getChannel()                     }\"\n    println \"getDisplayName()             : ${node.getDisplayName()                 }\"\n    println \"getLabelString()             : ${node.getLabelString()                 }\"\n    println \"getMode()                    : ${node.getMode()                        }\"\n    println \"getNodeDescription()         : ${node.getNodeDescription()             }\"\n    println \"getNodeName()                : ${node.getNodeName()                    }\"\n    println \"getRootPath()                : ${node.getRootPath()                    }\"\n    println \"getSearchUrl()               : ${node.getSearchUrl()                   }\"\n    println \"getSelfLabel()               : ${node.getSelfLabel()                   }\"\n    println \"isAcceptingTasks()           : ${node.isAcceptingTasks()               }\"\n    println \"isHoldOffLaunchUntilSave()   : ${node.isHoldOffLaunchUntilSave()       }\"\n}\n\ndef stopBuild(def build) {\n    build.doStop()\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-%E3%83%93%E3%83%AB%E3%83%89%E3%81%AEChangeSets%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B":{"title":"Jenkins ビルドのChangeSetsを取得する","content":"\n[How to access Changelogs in a Pipeline Job?](https://docs.cloudbees.com/docs/cloudbees-ci-kb/latest/client-and-managed-masters/how-to-access-changelogs-in-a-pipeline-job)\n\n````groovy\ndef changeSets = Jenkins.get().getItemByFullName(\"myjob\").builds[0].changeSets\n\nfor (def changeSet: changeSets) {\n    for (def entry: changeSet) {\n        println \"${entry.commitId} by ${entry.author} on ${new Date(entry.timestamp)}: ${entry.msg}\"\n        def files = new ArrayList(entry.affectedFiles)\n        for (int k = 0; k \u003c files.size(); k++) {\n            def file = files[k]\n            println \"  ${file.editType.name} ${file.path}\"\n        }\n    }\n}\n\n    ```\n\n## Upstream buildを取得する\n    \n[how to get upstream build information in a script step of jenkins classic ui pipeline - Stack Overflow](https://stackoverflow.com/questions/70291635/how-to-get-upstream-build-information-in-a-script-step-of-jenkins-classic-ui-pip)\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/04/19","Jenkins"]},"/note/Jenkins-%E5%89%8D%E5%9B%9E%E3%81%AE%E3%83%93%E3%83%AB%E3%83%89%E3%81%AEarchiveArtifact%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B":{"title":"Jenkins 前回のビルドのarchiveArtifactを取得する","content":"\n前回のビルドの成果物を取得したいことがたまにあるので調べた。\n\nresult.txtをarchiveしているとして考える\n\n## ArtifactManagerを使う場合\n\nhttps://javadoc.jenkins.io/hudson/model/Run.html?is-external=true#getArtifactManager()\n\n`Run.getArtifactManager().root().child(\"relativepath/to/file\")`  で [VirtualFile](https://javadoc.jenkins-ci.org/jenkins/util/VirtualFile.html) が取得できる\n\n````\n    script {\n        def build = currentBuild.previousBuild.rawBuild\n        def am = build.artifactManager\n        def virtualFile = am.root().child('result.txt')\n        println virtualFile\n    }\n````\n\n## shell内でファイルを使いたい場合\n\nhttps://javadoc.jenkins.io/hudson/model/Run.html?is-external=true#getRootDir()\n\n`Run.getRootDir()` でビルドディレクトリを `java.io.File` として取得できる\nあとはgetAbsolutePathで絶対パスを取得するなどする\n\n````\n    script {\n        def prevBuild = currentBuild.previousBuild\n        def prevBuildPath = prevBuild.rawBuild.rootDir.absolutePath\n        \n        withEnv([\"PREV_BUILD=${prevBuildPath}\"]) {\n            sh '''\n            echo '----prev ${prevBuildPath}----'\n            cat ${PREV_BUILD}/archive/result.txt\n            '''\n        }\n\n    }\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/04/20","Jenkins"]},"/note/Jenkins-Configuration-as-Code":{"title":"Jenkins Configuration as Code","content":"\nJCasC\n\nJenkinsの設定をコード化するプラグイン\n\nhttps://github.com/jenkinsci/configuration-as-code-plugin\n\n## Kubernetesで使用する\n\nhelmを使う\nhttps://github.com/jenkinsci/helm-charts\n\n`CASC_JENKINS_CONFIG=/var/jenkins_home/casc_config` が設定されているので、ここに設定が置かれるように作る\n\n## Job DSLとの連携\n\n\u003chttps://github.com/jenkinsci/job-dsl-plugin/blob/master/docs/JCasC.md\u003e\n\nhttps://github.com/jenkinsci/configuration-as-code-plugin/blob/master/docs/seed-jobs.md\n\n* ConfigMapでjobs.yamlを作って `$CASC_JENKINS_CONFIG ` に置く\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-HTML-Publisher%E3%81%A7%E5%85%AC%E9%96%8B%E3%81%97%E3%81%9FHTML%E3%81%ABCSS%E3%81%8C%E5%BD%93%E3%81%9F%E3%82%89%E3%81%AA%E3%81%84":{"title":"Jenkins HTML Publisherで公開したHTMLにCSSが当たらない","content":"\n## 事象\n\n[Jenkins - HTML Publisher Plugin - No CSS is displayed when report is viewed in Jenkins Server](https://stackoverflow.com/questions/35783964/jenkins-html-publisher-plugin-no-css-is-displayed-when-report-is-viewed-in-j)\n\n[note/Jenkins](Jenkins.md) HTML Publisher Pluginで公開したhtmlで、CSSが読み込まれずスタイルが当たらない。\nブラウザのコンソールに以下のエラーメッセージが出ていた。\n\n````\nbecause it violates the following Content Security Policy directive: \"default-src https: 'unsafe-inline'\". Note that 'img-src' was not explicitly set, so 'default-src' is used as a fallback.\n````\n\n## 手順\n\n### HTMLを公開する\n\n[Jenkins の HTML Publisher Plugin を使って、Gauge が出したテスト結果の HTML レポートをいい感じに見れるようにする - ゆふてっく。](https://yufutech.hatenablog.com/entry/2021/03/07/201536)\n\nこちらのようにしてhtml,cssを作成した\n\n````groovy\npipeline {\n  stages {\n      stage('make html') {\n          steps {\n              sh '''\n              mkdir -p report\n              echo \"\u003chtml\u003e\u003chead\u003e \u003clink rel=\"stylesheet\" href=\"index.css\"\u003e \u003c/head\u003e \u003cbody\u003e\u003cdiv\u003eHello, world\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e\" \u003e report/index.html\n              echo \"div { font-size: \"20px\"; }\" \u003e report/index.css\n              '''\n          }\n      }\n  }\n  post {\n      always {\n          // 成果物を保存\n          archiveArtifacts artifacts: 'report/*'\n          // publish html\n          publishHTML target: [\n            allowMissing: false,\n            alwaysLinkToLastBuild: true,\n            keepAll: false,\n            reportDir: 'report',\n            reportFiles: '*',\n            reportName: 'html-report'\n          ]\n      }\n  }\n}\n````\n\n`${ジョブのURL}/${reportNameで指定した名前}` でhtmlを開くことができるが、これだけだとスタイルがあたっていないため、Jenkins のセキュリティ設定を変更する。\n\n### 一時的\n\nJenkinsの管理 \u003e スクリプトコンソール にて以下を入力して実行する\n\n````java\nSystem.setProperty(\"hudson.model.DirectoryBrowserSupport.CSP\", \"\")\n````\n\n→ Jenkins再起動するとリセットされる\n\n### 恒久的\n\nJenkinsの起動時オプションに指定することで常に適用させることができる。\n\n`sudo vi /etc/sysconfig/jenkins` を開いて、 `JENKINS_JAVA_OPTIONS` を変更する。\n空にするのは危なそうなので、必要な分だけ許可するようにする。\n\n````shell\nJENKINS_JAVA_OPTIONS=\"-Djava.awt.headless=true -Dhudson.model.DirectoryBrowserSupport.CSP=\\\"default-src 'self' 'unsafe-inline' 'unsafe-eval'; img-src 'self' 'unsafe-inline' data:;\\\"\"\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-Jenkinsfile%E3%82%92clone%E3%81%99%E3%82%8B%E3%83%87%E3%82%A3%E3%83%AC%E3%82%AF%E3%83%88%E3%83%AA%E3%82%92clean-up%E3%81%99%E3%82%8B":{"title":"Jenkins Jenkinsfileをcloneするディレクトリをclean upする","content":"\n## 経緯\n\nPipelineジョブを途中でabortしたあと再実行したら、gitのindex.lockがあるためfetchができないというエラーが出る場合がある。\n\n````\n stderr: fatal: Unable to create '/var/jenkins_home/workspace/MyJob@script/.../.git/index.lock': File exists.\n \n Another git process seems to be running in this repository, e.g.\n an editor opened by 'git commit'. Please make sure all processes\n are terminated then try again. If it still fails, a git process\n may have crashed in this repository earlier:\n remove the file manually to continue.\n````\n\nこうなってしまうと、Jenkinsfileを含んだリポジトリをcloneする先のディレクトリでgitの操作が行えない。\nJenkinsサーバーにsshして `/var/jenkins_home/workspace/` 配下のジョブのディレクトリを削除するのがすぐ思いつくが、できればsshせずに済ませたい。\n\n## やったこと1\n\nジョブを書き換えて、Jenkinsfileをcloneせず直接pipelineを書き、clean upする\n\n````groovy\npipeline {\n    agent any\n\n    stages {\n        stage('clean up') {\n            steps {\n                deleteDir()\n                cleanWs()\n            }\n        }\n    }\n}\n````\n\n=\u003e これだと `/var/jenkins_home/workspace/MyJob/` は消えてくれるが `MyJob@scipt` は消えなかった\n\n## やったこと2\n\nこちらに答えがあった。\n[continuous integration - Jenkins Pipeline Wipe Out Workspace - Stack Overflow](https://stackoverflow.com/questions/37468455/jenkins-pipeline-wipe-out-workspace)\n\n````groovy\npipeline {\n    agent any\n\n    stages {\n        stage('clean up') {\n            steps {\n                /* clean up tmp directory */\n                dir(\"${env.WORKSPACE}@tmp\") {\n                    deleteDir()\n                }\n                /* clean up script directory */\n                dir(\"${env.WORKSPACE}@script\") {\n                    deleteDir()\n                }\n            }\n        }\n    }\n}\n````\n\n要するに `/var/jenkins_home/workspace/MyJob@script` に移動して `deleteDir()` を実行しているだけ\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-Job-DSL-Plugin":{"title":"Jenkins Job DSL Plugin","content":"\n[note/Jenkins](Jenkins.md) の設定やジョブをJob DSLという [Groovy](note/Groovy.md) のDSLで定義することができるようになる\n\n\u003chttps://plugins.jenkins.io/job-dsl/\u003e\n\u003chttps://github.com/jenkinsci/job-dsl-plugin\u003e\n\n* 普通にプラグイン設定画面からインストール可能\n* GroovyのDSLで、Jenkinsのジョブやフォルダを作成可能にする\n* Groovyスクリプトなので、分岐や反復などを使って自由度高くジョブが作成できる\n* DSLを基に、Jenkinsのジョブごとの設定ファイル(xml)を生成するようなイメージ\n* [Playground](https://job-dsl.herokuapp.com/) や [コマンドライン](https://github.com/jenkinsci/job-dsl-plugin/wiki/User-Power-Moves#run-a-dsl-script-locally) でJenkinsに反映させるまえに実際どのようなXMLが生成されるか試すことができる\n  * なおPlaygroundでは自分でいれたプラグイン(listGitBranchなど)はチェックすることができない\n\n## DSLからジョブを作成する方法\n\n1. Jenkinsジョブを作成\n1. 設定でBuild stepに `Process Job DSL` があるので選択する\n1. 手で直接入力したければ、 `Use the provided DSL script` にチェックを入れてDSLを入力\n1. `Look on Filesystem` でサーバー上のファイルを指定することも可能\n1. 設定完了したら保存して、ジョブを実行する\n\n````groovy\nfolder('deplly') {\n    description('Folder for deploy')\n}\n\npipelineJob(\"deploy/server\") {\n    description(\"デプロイジョブ\")\n    parameters {\n        stringParam(\"FILE\", \"exec.tar.gz\", \"デプロイするファイル名\")\n        gitParam('sha') {\n            description('Revision commit SHA')\n            type('REVISION')\n            branch('master')\n        }\n\n    }\n\n    throttleConcurrentBuilds {\n        maxPerNode(1)\n        maxTotal(1)\n        throttleDisabled(false)\n    }\n\n    logRotator {\n        numToKeep(5)\n    }\n\n    definition {\n        cpsScm {\n            scm {\n                git {\n                    configure { git -\u003e\n                        // sparse checkoutのようなオプションをつけたい場合\n                        git / 'extensions' / 'hudson.plugins.git.extensions.impl.SparseCheckoutPaths' / 'sparseCheckoutPaths' {\n                            'hudson.plugins.git.extensions.impl.SparseCheckoutPath' {\n                                path('script')\n                            }\n                        }\n                    }\n                    remote {\n                        url('ssh://git@bitbucket.org/workspace/slug.git')\n                        credentials('bitbucket_credential')\n                    }\n                    branch('*/master')\n                }\n            }\n            lightweight(false)\n            scriptPath(\"Jenkinsfile\")\n        }\n    }\n\n}\n\n````\n\n````groovy\ndef REPOSITORY_URL = '\u003crepository URL\u003e'\ndef CREDENTIAL = '\u003ccredential\u003e'\npipelineJob(\"deploy/server\") {\n    description(\"デプロイジョブ\")\n    parameters {\n         listGitBranches {\n             name(\"REVISION\")\n             description('git branch')\n             remoteURL(REPOSITORY_URL)\n             credentialsId(CREDENTIAL)\n             defaultValue('refs/heads/master')\n             selectedValue('DEFAULT')\n             sortMode('ASCENDING_SMART')\n             quickFilterEnabled(true)\n             type('PT_BRANCH_TAG')\n             tagFilter('*')\n             branchFilter('.*')\n         }\n    }\n\n    logRotator {\n        numToKeep(5)\n    }\n\n    definition {\n        cps {\n            script(pipelineTemplate())\n            sandbox()\n        }\n    }\n\n}\n\n def pipelineTemplate() {\n   return '''\npipeline {\n  agent {\n    node {\n      label 'worker'\n    }\n  }\n\n  options {\n    ansiColor('xterm')\n    buildDiscarder logRotator(numToKeepStr: '5')\n    timestamps()\n  }\n\n  stages {\n\n    stage('prepare') {\n      steps {\n        wrap([$class: 'BuildUser']) {\n          script {\n            currentBuild.description = \"${BUILD_USER_ID} ${params.REVISION}\"\n\n            deleteDir()\n\n            def revision = params.REVISION.startsWith('refs/heads') ? params.REVISION : \"refs/tags/${params.REVISION}\"\n\n            checkout([\n                $class                           : 'GitSCM',\n                branches                         : [[name: \"$revision\"]],\n                userRemoteConfigs                : [\n                    [credentialsId: \"\u003ccredential id\u003e\", url: \"\u003crepository url\u003e\"],\n                ]\n            ])\n\n          }\n        }\n      }\n    }\n  }\n}'''.stripIndent()\n \n}\n\n````\n\n## 他のプラグインへの対応\n\nたとえばパラメータの設定時には文字列や選択値の他、Git Parameterなどメジャーなプラグインにも対応しています。\nすべてのプラグインに対応することは不可能なので、定義されていないプラグインについては [Dynamic DSL](https://github.com/jenkinsci/job-dsl-plugin/wiki/Dynamic-DSL) によって使用可能になります。\nそれでも対応不可能な場合は[Configure Block](https://github.com/jenkinsci/job-dsl-plugin/wiki/The-Configure-Block) で直接xmlを記述するようなこともできます。\n\nこの辺が拡張性高く作られているのは素晴らしいですね。\n\n### Dynamic DSL\n\nオンラインの[API Viewer](https://jenkinsci.github.io/job-dsl-plugin/)では、デフォルトで定義されているAPIが検索できますが、\nインストールしたプラグインのAPIは、自分のJenkinsのAPI Viewer(\u003chttps://JENKINS-HOST/plugin/job-dsl/api-viewer/index.html\u003e)で確認できます。\n\nGit Parameter Pluginをインストールしている場合、 `gitParam` 以外に `gitParameter` が見当たると思います。\n\u003chttps://HOST/plugin/job-dsl/api-viewer/index.html#method/javaposse.jobdsl.dsl.helpers.BuildParametersContext.gitParameter\u003e\n\nDynamic DSLの場合はAPI Viewer上では右上に紫色のアイコンで Dynamic と表示されています。\n\n````groovy\npipelineJob(\"foo\") {\n    parameters {\n        gitParameter {\n            name(\"BRANCH\")\n            description('git branch')\n            defaultValue('master')\n            selectedValue('DEFAULT')\n            sortMode('ASCENDING_SMART')\n            quickFilterEnabled(true)\n            type('Branch')\n            tagFilter('*')\n            branchFilter('refs/heads/(.*)')\n        }\n        \n        // ...\n    }\n    \n    // ...\n}\n````\n\n一点注意としては、API Viewerでパラメータを開くと `Required` がついていたり、設定可能な文字列の一覧が表示されたりします。表示されているとおりに守らないと、設定が反映されません。\n`description` いらんやろと思って書かないでいたらいつまでも反映されず、原因特定に時間がかかりました…。\n\n`gitParam` については組み込みDSLにもあるのにDynamic DSLを使う利点としては、プラグインの機能拡張に追従しておらず設定が不便な場合の補完ができる点です。\n例えば `gitParam` では `quickFilter` の設定ができませんが `gitParameter` ではできる、などです。\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-JobDSL%E3%82%92CI%E3%81%A7validate%E3%81%97%E3%81%9F%E3%81%84":{"title":"Jenkins JobDSLをCIでvalidateしたい","content":"\n[Jenkins Job DSL Plugin](note/Jenkins%20Job%20DSL%20Plugin.md)\n\n[job-dsl-plugin/Testing-DSL-Scripts.md at master · jenkinsci/job-dsl-plugin · GitHub](https://github.com/jenkinsci/job-dsl-plugin/blob/master/docs/Testing-DSL-Scripts.md)\n公式でtestの方法書いてくれたのでまずはこれを試してみる\n\n### gradle初期化\n\n````\ngradle init\n````\n\nサンプルはバージョン古くて動かなかったので上げてみたけど、testディレクトリが認識されない？のか実行されないで終了する\n\nbuild.gradle\n\n````groovy\nplugins {\n  id 'groovy'\n}\n\nsourceSets {\n    jobs {\n        groovy {\n            srcDirs 'manifest/jenkins/overlays'\n        }\n    }\n    test {\n        groovy {\n            srcDir 'src/test/groovy'\n        }\n    }\n}\n\next {\n    jobDslVersion = '1.78.1'\n    jenkinsVersion = '2.319.3'\n}\n\nrepositories {\n    mavenCentral()\n    maven {\n        url 'https://repo.jenkins-ci.org/public/'\n    }\n}\n\nconfigurations {\n    testPlugins {}\n\n    // see JENKINS-45512\n    testCompile {\n        exclude group: 'xalan'\n        exclude group: 'xerces'\n    }\n}\n\ndependencies {\n    implementation 'org.codehaus.groovy:groovy-all:3.0.11'\n\n    testImplementation platform(\"org.spockframework:spock-bom:2.1-groovy-3.0\")\n    testImplementation \"org.spockframework:spock-core\"\n    testImplementation \"org.spockframework:spock-junit4\"  // you can remove this if your code does not rely on old JUnit 4 rules\n\n    // Jenkins test harness dependencies\n    testImplementation 'org.jenkins-ci.main:jenkins-test-harness:1794.vfb_4a_4cde0824'\n    testImplementation \"org.jenkins-ci.main:jenkins-war:${jenkinsVersion}\"\n\n    // Job DSL plugin including plugin dependencies\n    testImplementation \"org.jenkins-ci.plugins:job-dsl:${jobDslVersion}\"\n    testImplementation \"org.jenkins-ci.plugins:job-dsl:${jobDslVersion}@jar\"\n    testImplementation 'org.jenkins-ci.plugins:structs:1.19@jar'\n    testImplementation 'org.jenkins-ci.plugins:script-security:1.54@jar'\n\n    // plugins to install in test instance\n    testPlugins 'org.jenkins-ci.plugins:ghprb:1.31.4'\n    testPlugins 'com.coravy.hudson.plugins.github:github:1.28.0'\n}\n\ntask resolveTestPlugins(type: Copy) {\n    from configurations.testPlugins\n    into new File(sourceSets.test.output.resourcesDir, 'test-dependencies')\n    include '*.hpi'\n    include '*.jpi'\n\n    doLast {\n        def baseNames = source.collect { it.name[0..it.name.lastIndexOf('.')-1] }\n        new File(destinationDir, 'index').setText(baseNames.join('\\n'), 'UTF-8')\n    }\n}\n\ntest {\n    dependsOn tasks.resolveTestPlugins\n    inputs.files sourceSets.jobs.groovy.srcDirs\n\n    // set build directory for Jenkins test harness, JENKINS-26331\n    systemProperty 'buildDirectory', project.buildDir.absolutePath\n}\n\n````\n\n### Spock\n\n[13. ユニットテスト - Apache Groovyチュートリアル](https://koji-k.github.io/groovy-tutorial/unit-test/index.html)\nGroovyのテスティングフレームワークのスタンダードらしい。聞いたことなかった\n\n\u003chttps://github.com/sheehan/job-dsl-gradle-example\u003e\n-\u003e 自分でこの構成を真似てファイルを作ったら動く カスタマイズしやすいのでこれが良さそう\n\n\u003chttps://github.com/AOEpeople/gradle-jenkins-job-dsl-plugin\u003e\n-\u003e gradle 6系にしたらとりあえず動く\n\n\u003chttps://github.com/johnmartel/jenkins-job-dsl-script-validator-plugin\u003e\n-\u003e バージョン古すぎて動かなかった\n\n## エラー対処\n\n./gradlew test でテスト実行できるようになった\n\n### `version 2.4 or later of plugin 'workflow-job' needs to be installed`\n\n\u003chttps://github.com/AOEpeople/gradle-jenkins-job-dsl-plugin/issues/16\u003e\nより新しいプラグインを入れてもエラーになり、ぴったりのバージョンでないとだめ 正規表現がおかしいっぽい\n\n\u003chttps://mvnrepository.com/artifact/org.jenkins-ci.plugins.workflow/workflow-job?repo=jenkins-incrementals\u003e\n\n#### `Caused by: javaposse.jobdsl.dsl.DslScriptException: (script, line 6) No signature of method: javaposse.jobdsl.dsl.helpers.BuildParametersContext.booleanParam() is applicable for argument types: (java.util.LinkedHashMap) values: [[parameterName:FOO, defaultValue:false]]`\n\n名前付き引数で書いてるところがエラーになってる\n実際にはジョブ反映されている\n\u003chttp://job-dsl.herokuapp.com\u003e で実行するとたしかにエラーになるから書き方変えるべきなのか\n\n### `Could not create item, unknown parent path in \"path/to/job\"`\n\nfoldersで親ディレクトリ作られるはずだけど、読み込み順の問題かもしれない\n\n### `Caused by: java.lang.NoClassDefFoundError: com/cloudbees/hudson/plugins/folder/Folder`\n\nFolders pluginはインストールしているのになぜ\nなぜかひとつのサブフォルダだけでテストするとうまくいく、複数のファイル一気にテストしようとすると発生する\n\n### `No signature of method: javaposse.jobdsl.dsl.helpers.BuildParametersContext.gitParameter`\n\ngit-parameterプラグインは追加しているのに解消されない\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-JobDSL-Tips-%E5%A4%96%E9%83%A8%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92import%E3%81%99%E3%82%8B%E3%81%AA%E3%81%A9":{"title":"Jenkins JobDSL Tips 外部ファイルをimportするなど","content":"\n[Jenkins Job DSL Plugin](note/Jenkins%20Job%20DSL%20Plugin.md) のTIPS\n\n## job DSLのサンプル集\n\nhttps://github.com/edx/jenkins-job-dsl\nhttps://github.com/sheehan/job-dsl-gradle-example\nhttps://github.com/unguiculus/job-dsl-sample\n\n## 上級者向けオプション\n\nhttps://github.com/jenkinsci/job-dsl-plugin/blob/master/docs/User-Power-Moves.md\n\n## JCasCとの連携\n\nhttps://github.com/jenkinsci/job-dsl-plugin/blob/master/docs/JCasC.md\n\nYou can pass values from the YAML file to the Job DSL script.\n\n### 共通で使える変数を定義する\n\n````yaml\njobs:\n  - providedEnv:\n      SUPERHERO: 'Midnighter'\n  - file: ./jobdsl/job.groovy\n````\n\n````groovy\n//job.groovy\njob('awesome-job') {\n    description(\"favorite job of ${SUPERHERO}\")\n}\n````\n\n## 別ファイルをimportする\n\nhttps://github.com/jenkinsci/job-dsl-plugin/blob/master/docs/Real-World-Examples.md#import-other-files-ie-with-class-definitions-into-your-script\n\nファイルをどこに置いたらいいのかこれを見てもよくわからない。\nGradleで作るのが前提なの？\nclasspath上に置いといたらいいんだろうか\n\n## Job DSLのFactoryを作る\n\nhttps://github.com/jenkinsci/job-dsl-plugin/blob/master/docs/Job-DSL-Commands.md#dsl-factory\n\n \u003e \n \u003e Because the engine is just Groovy, you can call other Groovy classes on the classpath\n\nclasspathどこ…\n\n[こういうクラス](https://github.com/sheehan/job-dsl-gradle-example/blob/master/src/main/groovy/com/dslexample/builder/GradleCiJobBuilder.groovy)を作って、[dslのほうで読み込ませる](https://github.com/sheehan/job-dsl-gradle-example/blob/master/src/jobs/example7Jobs.groovy)\n\nJCasCではできないかもしれない😞\nhttps://github.com/jenkinsci/configuration-as-code-plugin/issues/1355\n\n## groovyをloadする\n\n[Jenkins / Groovy language patterns](https://gist.github.com/thikade/5e68a99d611510a521ad74d5f9c88a13)\n\n## IDEで補完を効かせたい\n\nhttps://github.com/jenkinsci/job-dsl-plugin/blob/master/docs/IDE-Support.md\n\n## script consoleからJob DSLのAPIを叩いてジョブを作る\n\nこれを貼って実行するだけ\n\n````groovy\nimport javaposse.jobdsl.dsl.*\nimport  javaposse.jobdsl.plugin.*\n\nJenkinsJobManagement jm = new JenkinsJobManagement(System.out, [:], new File('.'));\nDslScriptLoader dslScriptLoader = new DslScriptLoader(jm)\ndslScriptLoader.runScript(\"folder('project-a')\")\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-Kubernetes-plugin%E3%81%A7inheritFrom%E3%82%92%E4%B8%8A%E6%9B%B8%E3%81%8D%E3%81%97%E3%81%A4%E3%81%A4pod%E5%90%8D%E3%81%ABprefix%E3%82%92%E3%81%A4%E3%81%91%E3%82%8B":{"title":"Jenkins Kubernetes pluginでinheritFromを上書きしつつpod名にprefixをつける","content":"\nconfigure cloudsの設定でpodTemplateを定義ずみで、 `inheritFrom` で継承しつつ一部だけを上書きしたいときの書き方\n\npodTemplateの設定\n\n* name `my-jenkins-agent`\n* labels `my-jenkins-agent`\n\n````groovy\npipeline {\n  agent {\n    kubernetes {\n      inheritFrom 'my-jenkins-agent'\n      label 'my-jenkins-agent'\n      yamlMergeStrategy merge()\n      yaml '''\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          labels:\n            some-label: some-label-value\n        spec:\n          containers:\n          - name: maven\n            image: maven:alpine\n            command:\n            - cat\n            tty: true\n\n        '''\n    }\n  }\n  stages {\n    stage('Run maven') {\n      steps {\n        container('maven') {\n          sh 'mvn -version'\n        }\n      }\n    }\n  }\n}\n\n````\n\nこうすると、設定済みのpodTemplateが使われて `yaml` に書いた定義は反映されない。\nlabelが完全一致していると上書きできないのかも？\n\n````groovy\n    kubernetes {\n      inheritFrom 'my-jenkins-agent'\n      // label 'my-jenkins-agent'\n      yamlMergeStrategy merge()\n      yaml '''\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          labels:\n            some-label: some-label-value\n        spec:\n          containers:\n          - name: maven\n            image: maven:alpine\n            command:\n            - cat\n            tty: true\n\n        '''\n    }\n````\n\n`label` を削除すると `yaml` の定義が反映されるが、pod名が `my-jenkins-agent-\u003crandom string\u003e` とはならず、ジョブ名がprefixについたpodが作成される\n\n````groovy\n    kubernetes {\n      inheritFrom 'my-jenkins-agent'\n      label 'my-jenkins-agent-custom'\n      yamlMergeStrategy merge()\n      yaml '''\n        apiVersion: v1\n        kind: Pod\n        metadata:\n          labels:\n            some-label: some-label-value\n        spec:\n          containers:\n          - name: maven\n            image: maven:alpine\n            command:\n            - cat\n            tty: true\n\n        '''\n    }\n````\n\nこのように `label` に podTemplate とは異なる値をつけることで、 `my-jenkins-agent-custom-\u003crandom string\u003e` というpodで作成された。\ncustom というのが入ってしまうのは気になるが仕方ない\n\npodTemplateのlabelsの設定を消すことで、  `label 'my-jenkins-agent'` としてもpod名が意図通りになりつつ上書きできたので、これでもいい。\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/02/02","Jenkins"]},"/note/Jenkins-Pipeline":{"title":"Jenkins Pipeline","content":"\n[note/Jenkins](Jenkins.md) のジョブ設定をPipelineというDSLで定義できる\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/05/04","Jenkins"]},"/note/Jenkins-Pipeline%E3%81%A7Parameter%E3%81%AEFile%E3%81%8C%E5%8B%95%E4%BD%9C%E3%81%97%E3%81%AA%E3%81%84%E3%83%90%E3%82%B0":{"title":"Jenkins PipelineでParameterのFileが動作しないバグ","content":"\n[note/Jenkins](Jenkins.md) pluginのバグ\n\n\u003chttps://issues.jenkins.io/browse/JENKINS-27413\u003e\n\u003chttps://stackoverflow.com/questions/38080876/jenkins-pipeline-job-with-file-parameter\u003e\n\npipelineじゃなくふつうのジョブでパラメータにFileを指定する分には問題ない\n\n![Pasted-image-20210921192112](note/Pasted-image-20210921192112.png)\n![Pasted-image-20210921192126](note/Pasted-image-20210921192126.png)\n\npipelineで指定するとファイルがアップロードされない\n\n````groovy\npipeline {\n  agent any\n  parameters {\n    file (\n        name: 'file.txt',\n    )\n  }\n}\n````\n\n## 対応\n\nhttps://plugins.jenkins.io/file-parameters/ プラグインを使う\n\n大きいファイルには `stashedFile`、小さいファイルには `base64File` パラメータを使用する\n\n````groovy\npipeline {\n  agent any\n  parameters {\n    base64File 'small'\n    stashedFile 'large'\n  }\n  stages {\n    stage('Example') {\n      steps {\n        withFileParameter('small') {\n          sh 'cat $small'\n        }\n        unstash 'large'\n        sh 'cat large'\n      }\n    }\n  }\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-Plugin%E3%82%92M1-Mac%E3%81%A7%E9%96%8B%E7%99%BA%E3%81%99%E3%82%8B":{"title":"Jenkins PluginをM1 Macで開発する","content":"\n[note/Jenkins](Jenkins.md) のプラグインを開発する\n\n* Java8が必要\n\n`mvn hpi:hpi` でビルドするだけならJDK8がインストールされていればOK\n\n### Jenkins上で確認したい\n\nDocker上でビルドするよろし\n\n````shell\n$ mvn hpi:hpl\n[INFO] Scanning for projects...\n[WARNING] The POM for org.jenkins-ci.tools:maven-hpi-plugin:jar:1.121 is missing, no dependency information available\n[WARNING] Failed to build parent project for org.jenkins-ci.plugins:list-git-branches-parameter:hpi:0.0.12-SNAPSHOT\n[INFO]\n[INFO] ---------\u003c org.jenkins-ci.plugins:list-git-branches-parameter \u003e---------\n[INFO] Building List Git Branches Parameter PlugIn 0.0.12-SNAPSHOT\n[INFO] --------------------------------[ hpi ]---------------------------------\n[INFO]\n[INFO] --- maven-hpi-plugin:1.121:hpl (default-cli) @ list-git-branches-parameter ---\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  2.614 s\n[INFO] Finished at: 2022-07-12T10:53:30+09:00\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.jenkins-ci.tools:maven-hpi-plugin:1.121:hpl (default-cli) on project list-git-branches-parameter: Property jenkinsHome needs to be set to $JENKINS_HOME. Please use 'mvn -DjenkinsHome=...' orput \u003csettings\u003e\u003cprofiles\u003e\u003cprofile\u003e\u003cproperties\u003e\u003cproperty\u003e\u003cjenkinsHome\u003e...\u003c/...\u003e -\u003e [Help 1]\n[ERROR]\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR]\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\n````\n\n* Jenkinsdd\n\n### hplの作成\n\n````shell\nmvn -DjenkinsHome=$JENKINS_HOME hpi:hpl\n\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-bitbucket-pipelines%E3%81%A7%E5%8B%95%E3%81%8B%E3%81%99":{"title":"Jenkins bitbucket-pipelinesで動かす","content":"\nJenkinsをhelm chartを使ってk8sで動かしていて、JCasCのコードをGitで管理していて、設定が正しいのかどうかは反映されるまでわからない\nこれをCIでチェックできるようにしたかった\n\n[Jenkins ジョブを GitHub Actions 上で動かせるようになりました](https://zenn.dev/snowcait/articles/c17b08e8f3485f)\nを参考にした\n\n## Dockerで動かせるようにする\n\n````yaml\nservices:\n  jenkins:\n    build:\n      context: .\n      args:\n        tag: ${JENKINS_IMAGE_TAG}\n    ports:\n      - 8080:8080\n      - 50000:50000\n    environment:\n      - JAVA_OPTS=\"-Djenkins.install.runSetupWizard=false\"\n      - CASC_RELOAD_TOKEN=\"reload-token\"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n      start_period: 30s\n````\n\n````Dockerfile\nARG tag=\"lts-jdk11\"\nFROM jenkins/jenkins:${tag}\nCOPY --chown=jenkins:jenkins plugins.txt /usr/share/jenkins/ref/plugins.txt\nCOPY --chown=jenkins:jenkins jcasc/jenkins.yaml /var/jenkins_home/\nCOPY --chown=jenkins:jenkins jcasc/jobdsl/ /var/jenkins_home/jobdsl/\nRUN jenkins-plugin-cli -f /usr/share/jenkins/ref/plugins.txt\n````\n\nプラグイン一覧をplugins.txtに書く\n\n`plugins.txt`\n\n````\ncloudbees-folder\ntimestamper\nws-cleanup\nworkflow-aggregator\ngit\nconfiguration-as-code\nconfiguration-as-code-groovy\njob-dsl\n````\n\nJCasCの設定をjenkins.yamlに書く\n\n````yaml\njobs:\n  - file: /var/jenkins_home/jobdsl/job1.groovy\n````\n\n`jobdsl/job1.groovy`\n\n````groovy\npipelineJob('job-dsl-groovy') {\n  definition {\n    cpsScm {\n      scm {\n        git {\n          remote {\n            url('https://github.com/jenkinsci/job-dsl-plugin.git')\n          }\n          branch('*/master')\n        }\n      }\n      lightweight()\n    }\n  }\n}\n````\n\n### やっていること\n\n* DockerfileでJenkinsを設定\n* plugins.txt、jenkins.yaml、job-dslのgroovyファイルをコピー\n* jenkins-cliでpluginをインストール\n* これをdocker composeで起動 \n\n````shell\ndocker compose -f compose.yaml up -d --wait\ncurl -O http://localhost:8080/jnlpJars/jenkins-cli.jar\njava -jar jenkins-cli.jar -s http://localhost:8080/ -webSocket reload-jcasc-configuration\n````\n\n### reload-configuration\n\n## 最終的にどうしたか\n\n一個のリポジトリで複数Jenkinsのコードをディレクトリ別で管理するような構成になっていたので、なかなかうまくできなかった\n結局それぞれのJenkins上で reload-jcasc-configuration \n\n````shell\ncurl -O http://localhost:8080/jnlpJars/jenkins-cli.jar\njava -jar jenkins-cli.jar -s http://localhost:8080/ -webSocket reload-jcasc-configuration\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-declarative-pipeline%E3%81%A7Active-Choice-Parameter%E3%82%92%E4%BD%BF%E3%81%86":{"title":"Jenkins declarative pipelineでActive Choice Parameterを使う","content":"\n[Active Choices | Jenkins plugin](https://plugins.jenkins.io/uno-choice/) をつかうと、パラメータを動的に設定できるようになる。\n\nPipeline Syntaxの画面でparametersブロックを作成できるが、そこに出てこないためscriptで書くしかなさそう。\n\n以下のようにpropertiesで作成する。\n\n````groovy\nproperties([\n    parameters([\n        [$class: 'ChoiceParameter', \n            choiceType: 'PT_SINGLE_SELECT',\n            description: 'Select a choice',\n            filterLength: 1,\n            filterable: true,\n            name: 'Target',\n            script: [\n                $class: 'GroovyScript',\n                fallbackScript: [\n                    classpath: [], \n                    sandbox: true, \n                    script: 'return [\"ERROR\"]'\n                ],\n                script: [\n                    classpath: [], \n                    sandbox: false, \n                    script: \"\"\"\n                        def lines = new File(\"/var/jenkins_home/workspace/paramlist.txt\").readLines()\n                        return lines\n                    \"\"\".stripIndent()\n                ]\n            ]\n        ]\n    ])\n])\n\npipeline {\n    agent any\n\n    stages {\n        stage(\"Run Tests\") {\n            steps {\n                sh \"echo SUCCESS on ${params.Target}\"\n            }\n        }\n    }\n}\n````\n\n他のパラメータの値に応じて選択肢を切り替える場合は `CascadeChoiceParameter` が使える\n[Active choice parameter with declarative Jenkins pipeline - Stack Overflow](https://stackoverflow.com/questions/63057793/active-choice-parameter-with-declarative-jenkins-pipeline)\n\n````groovy\nproperties([\n    parameters([\n        [$class: 'CascadeChoiceParameter', \n            choiceType: 'PT_SINGLE_SELECT',\n            description: 'Select a choice',\n            filterLength: 1,\n            filterable: true,\n            name: 'Target',\n            referencedParameters: 'ENVIRONMENT', // 依存するパラメータ名を指定\n            script: [\n                $class: 'GroovyScript',\n                fallbackScript: [\n                    classpath: [], \n                    sandbox: true, \n                    script: 'return [\"ERROR\"]'\n                ],\n                script: [\n                    classpath: [], \n                    sandbox: true, \n                    script: \"\"\"\n                        if (ENVIRONMENT == 'foo') { \n                            return['aaa','bbb']\n                        } else {\n                            return['ccc', 'ddd']\n                        }\n                    \"\"\".stripIndent()\n                ]\n            ]\n        ]\n    ])\n])\n\npipeline {\n    agent any\n\n    parameters {\n        choice(name: 'ENVIRONMENT', choices: ['foo', 'bar'])\n    }\n    stages {\n        stage(\"Run Tests\") {\n            steps {\n                sh \"echo SUCCESS on ${params.ENVIRONMENT} - ${params.Target}\"\n            }\n        }\n    }\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/05/01","Jenkins"]},"/note/Jenkins-helm-SecretsManager%E3%81%8B%E3%82%89Secret%E3%82%92%E5%8F%96%E5%BE%97%E3%81%97%E3%81%A6%E3%82%BB%E3%83%83%E3%83%88%E3%81%99%E3%82%8B":{"title":"Jenkins helm SecretsManagerからSecretを取得してセットする","content":"\n`additionalExternalSecrets` を使うのがよさそう\n\u003chttps://github.com/jenkinsci/helm-charts/tree/main/charts/jenkins#additional-secrets\u003e\n\n`additionalSecrets` は3.3.1で追加されている\n\u003chttps://github.com/jenkinsci/helm-charts/commit/f6316c95d264dbf064d0c3cc51836b364650273e\u003e\n\nドキュメントもこのタイミングで更新されている。\n\u003chttps://github.com/jenkinsci/helm-charts/commit/6773a7ff4868a579f54fd6f57d01e2fd3b81e6e6\u003e\n\n以前の書き方だと、`volumes` でsecretsを設定して、`mounts` で `/run/secrets/${KEY}` で配置するというのを自分で行っていた\n\u003chttps://github.com/jenkinsci/configuration-as-code-plugin/blob/master/docs/features/secrets.adoc#kubernetes-secrets\u003e\n\n`additionalSecrets` がExternalSecretsの変更に追従されるようなPRもマージされている(4.x)\n[https://github.com/jenkinsci/helm-charts/pull/645](https://github.com/jenkinsci/helm-charts/pull/645)\n\n## その他\n\n\u003chttps://jenkinsci.github.io/kubernetes-credentials-provider-plugin/\u003e\n\n[5 ways to inject secrets from AWS into Jenkins pipelines – Tom Gregory](https://tomgregory.com/inject-secrets-from-aws-into-jenkins-pipelines/)\nAWS Secrets Manager Credentials Provider plugin というのもある\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins","Kubernetes"]},"/note/Jenkins-job-dsl%E3%81%A7%E5%B0%91%E3%81%97%E3%81%A0%E3%81%91%E9%81%95%E3%81%86%E3%82%B8%E3%83%A7%E3%83%96%E3%82%92%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6%E5%AE%9A%E7%BE%A9%E3%81%99%E3%82%8B":{"title":"Jenkins-job-dslで少しだけ違うジョブをまとめて定義する","content":"\n[Jenkins Job DSL Plugin](note/Jenkins%20Job%20DSL%20Plugin.md) で環境ごとにジョブが分かれていて微妙にパラメータが異なる場合や、異なるサービスで似たジョブを複製したいときはままあると思いますが。\nGUI上でぽちぽちするのは時間がかかるし間違えるので、Jenkinsサーバーに入ってconfig.xmlをコピーして書き換えるみたいなことをやったりしますが、\n[Jenkins Job DSL Plugin](note/Jenkins%20Job%20DSL%20Plugin.md) を使うとこの問題が解決します。\n\n類似: [Jenkins JobDSLでclosure内からfunctionを呼ぶ](jenkins%20JobDSL%E3%81%A7closure%E5%86%85%E3%81%8B%E3%82%89function%E3%82%92%E5%91%BC%E3%81%B6.md) \n\n## Groovyスクリプトでジョブを作成する\n\n[Jenkins Job DSL Plugin](note/Jenkins%20Job%20DSL%20Plugin.md) は結局Groovyなので、ある程度自由に記述ができます。\n配列を定義して、異なる部分だけを変数にするといったやり方で、見通しもよく複製することができます。\n\nさっそくpipelineJobを作ってあげましょう\n\n````groovy\ndef services = [\n  'service-A',\n  'service-B',\n]\n\nservices.each { service -\u003e\n  pipelineJob(\"build/${service}\") {\n    definition {\n      cps {\n        script(pipelineTemplate(service))\n        sandbox()\n      }\n    }\n\n  }\n}\n\ndef pipelineTemplate(String service) {\n  def repositoryUrl = \"https://~~~~/${service}.git\"\n  return '''\n    pipeline {\n      options {\n        ansiColor('xterm')\n        buildDiscarder logRotator(artifactDaysToKeepStr: '', artifactNumToKeepStr: '', daysToKeepStr: '', numToKeepStr: '5')\n        timestamps()\n      }\n\n      parameters {\n        listGitBranches(\n            name: 'BRANCH_TAG',\n            defaultValue: 'master',\n            branchFilter: '.*',\n            credentialsId: \"\",\n            quickFilterEnabled: true,\n            remoteURL: '#repositoryUrl',\n            selectedValue: 'DEFAULT',\n            sortMode: 'ASCENDING_SMART',\n            tagFilter: '*',\n            type: 'PT_BRANCH_TAG'\n        )\n      }\n\n      stages {\n        stage('git clone') {\n          steps {\n            script {\n              currentBuild.description = \"#service - ${params.BRANCH_TAG}\"\n              checkout([\n                  $class                           : 'GitSCM',\n                  branches                         : [[name: \"${params.BRANCH_TAG}\"]],\n                  userRemoteConfigs                : [\n                      [url: \"#repositoryUrl\"],\n                  ]\n              ])\n            }\n          }\n        }\n\n      }\n    }\n    '''.stripIndent()\n      .replaceAll('#service', service)\n      .replaceAll('#repositoryUrl', repositoryUrl)\n\n}\n\n````\n\nなおここではpipelineを文字列で直接書いていて、pipeline内のparameter(`params.XXXX`)とGroovyの変数がうまく共存できなかったためGroovyの変数は `replaceAll` で置換をかけるようにしています\n\n[Jenkins Job DSL Plugin](note/Jenkins%20Job%20DSL%20Plugin.md) は公式でPlaygroundが用意されているので、まずはこちらで試すのがよいでしょう。\nhttps://job-dsl.herokuapp.com/\n\n手元で実行するのも可能です\nhttps://github.com/jenkinsci/job-dsl-plugin\n\n### 参考\n\n[ もしJenkinsでちょっとずつ違う100のジョブを管理しなくてはいけなくなったら - knjnameのブログ](https://knjname.hateblo.jp/entry/2015/01/06/025459)\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-kubernetes-plugin-3872.v760b_4a_6c126b_-%E3%81%A7agent%E8%B5%B7%E5%8B%95%E3%81%97%E3%81%AA%E3%81%84":{"title":"Jenkins kubernetes plugin 3872.v760b_4a_6c126b_ でagent起動しない","content":"\nエラーログ\n\n````\n2023-02-21 01:06:57.665+0000 [id=81]\tWARNING\to.c.j.p.k.KubernetesLauncher#launch: Error in provisioning; agent=KubernetesSlave name: jenkins-agent-x86-64-kjhkr, template=PodTemplate{id='afef69c1-5cc4-48a8-a070-fd6a6fd4f6d1', name='jenkins-agent-x86_64', namespace='staging-jenkins', runAsUser=0, runAsGroup=0, slaveConnectTimeout=600, idleMinutes=30, label='jenkins-agent-x86_64', serviceAccount='jenkins', nodeSelector='ap-type=cicd-jenkins-slave-kp-staging,arch=amd64', nodeUsageMode=NORMAL, podRetention='Never', annotations=[PodAnnotation{key='cluster-autoscaler.kubernetes.io/safe-to-evict', value='false'}]}\nio.fabric8.kubernetes.client.KubernetesClientException: name not specified for an operation requiring one.\n\tat io.fabric8.kubernetes.client.dsl.internal.BaseOperation.requireFromServer(BaseOperation.java:182)\n\tat io.fabric8.kubernetes.client.dsl.internal.BaseOperation.get(BaseOperation.java:142)\n\tat io.fabric8.kubernetes.client.dsl.internal.BaseOperation.get(BaseOperation.java:93)\n\tat org.csanchez.jenkins.plugins.kubernetes.PodTemplateUtils.parseFromYaml(PodTemplateUtils.java:611)\nCaused: java.lang.RuntimeException: Failed to parse yaml: \"apiVersion: v1\n````\n\n`kubernetes-client-api:6.4.1-208.vfe09a_9362c2c` にバージョンが上がっていた\n`kubernetes:3872.v760b_4a_6c126b_` があたっているバージョン\n\n1. `kubernetes:3845.va_9823979a_744`  に下げた -\u003e 効果なし\n1. `overwritePlugins: true` に変更 -\u003e 効果なし\n\n````shell\necho \"remove all plugins from shared volume\"\n# remove all plugins from shared volume\nrm -rf /var/jenkins_home/plugins/*\n````\n\n3. `kubernetes-client-api:6.3.1-206.v76d3b_6b_14db_b` を指定した -\u003e 起動するようになった\n3. `overwritePlugins: false` の状態で `kubernetes:3845.va_9823979a_744` を指定した -\u003e `kubernetes-client-api:6.4.1-208.vfe09a_9362c2c` に上がってしまった\n   1. \u003chttps://github.com/jenkinsci/kubernetes-plugin/blob/67c727ed5b645f1e740ca9d7236aeda20d8362a9/pom.xml#L59\u003e で指定されているので無理なのか\n3. `kubernetes:3883.v4d70a_a_a_df034` を指定 -\u003e \n\nissue 上がっていた\n\u003chttps://issues.jenkins.io/browse/JENKINS-70639\u003e\n\u003chttps://issues.jenkins.io/browse/JENKINS-70637\u003e\n\nhttps://issues.jenkins.io/browse/JENKINS-70637?focusedCommentId=435317\u0026page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-435317\nコメントで「なぜこんなメジャーなプラグインがテストもされずにリリースされているのか」「プラグインのいかれた依存関係管理にはうんざりだし、アップデートしたところで放置されているプラグインも多くて常時大量の脆弱性が出る」 …プラグイン管理に関しては本当そのとおりでなるべく使わないほうがいいんじゃないかとさえ思える\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/02/21","Jenkins"]},"/note/Jenkins-matrix%E3%83%93%E3%83%AB%E3%83%89%E3%81%A7%E5%A4%89%E6%95%B0%E3%81%8C%E5%85%B1%E6%9C%89%E3%81%95%E3%82%8C%E3%82%8B%E5%95%8F%E9%A1%8C":{"title":"Jenkins matrixビルドで変数が共有される問題","content":"\nmatrixを使ってふたつのworker上でビルドしたいとき、実行順によっては\n\n````groovy\npipeline {\n    agent none\n    stages {\n        stage('parallel') {\n            matrix {\n                agent {\n                    label \"worker-${ARCH}\"\n                }\n                axes {\n                    axis {\n                        name 'ARCH'\n                        values 'x86_64', 'armv8'\n                    }\n                }\n\n                stages {\n\n                    stage('prepare') {\n                      steps {\n                        script {\n                          env.KEY = \"key_${ARCH}\"\n                        }\n                      }\n                    }\n\n                    stage('build') {\n                        steps {\n                            sh '''\n                            echo \"${ARCH} ${KEY}\"\n                            '''\n                        }\n                    }\n                }\n            }\n        }\n\n    }\n}\n````\n\nworker-x86_64 prepare -\u003e worker-x86_64 build -\u003e worker-armv8 prepare -\u003e worker-armv8 build の順に実行されれば問題ないが、\nworker-x86_64 prepare -\u003e worker-armv8 prepare -\u003e worker-x86_64 build -\u003e worker-armv8 build の順に実行されると、あとから実行されたものに上書きされる\n\n````\nx86_64 key_armv8\narmv8 key_armv8\n````\n\nそのため別の変数で格納する必要がある\n\n````groovy\npipeline {\n    agent none\n    stages {\n        stage('parallel') {\n            matrix {\n                agent {\n                    label \"worker-${ARCH}\"\n                }\n                axes {\n                    axis {\n                        name 'ARCH'\n                        values 'x86_64', 'armv8'\n                    }\n                }\n\n                stages {\n\n                    stage('prepare') {\n                      steps {\n                        script {\n                          if (ARCH == \"armv8\") {\n                            env.KEY_ARM = \"key_arm\"\n                          } else {\n                            env.KEY_AMD = \"key_amd\"\n                          }\n                        }\n                      }\n                    }\n\n                    stage('build') {\n                        steps {\n                            sh '''\n                            if [[ \"${ARCH}\" == \"armv8\" ]]; then\n                              export KEY=${KEY_ARM}\n                            else\n                              export KEY=${KEY_AMD}\n                            fi\n                            echo \"${ARCH} ${KEY}\"\n                            '''\n                        }\n                    }\n                }\n            }\n        }\n\n    }\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/02/13","Jenkins"]},"/note/Jenkins-pipeline%E3%81%A7%E4%BB%96%E3%81%AE%E3%82%B8%E3%83%A7%E3%83%96%E3%82%92%E5%81%9C%E6%AD%A2%E3%81%99%E3%82%8B":{"title":"Jenkins pipelineで他のジョブを停止する","content":"\n[Jenkins Pipeline](note/Jenkins%20Pipeline.md) \n\n````groovy\npipeline {\n  stages {\n    stage('abort jobs') {\n      steps {\n        script {\n          Jenkins.instance.getAllItems(Job.class).collectMany { job -\u003e\n            // ビルド一覧にflattenする\n            job.builds\n          }.findAll { build -\u003e\n            // ビルド中のジョブに絞る\n            build.building\n          }.each { build -\u003e\n            // ジョブを停止する\n            build.doStop()\n          }\n\n        }\n      }\n    }\n  }\n}\n````\n\n* groovyの記法で、`.getXXX()` は `.XXX` でプロパティアクセスできる\n\n## reference\n\n* [Groovy スクリプトで Jenkins 上のすべての Job を制御する | まくまくいろいろノート](https://maku77.github.io/memo/jenkins/handle-jobs.html)\n* [Mirantis Documentation: Abort a hung build in Jenkins](https://docs.mirantis.com/mcp/q4-18/mcp-operations-guide/drive-train-operations/jenkins-abort-hung-build.html)\n* [jenkinsでジョブがチェックアウトするブランチを一括設定する · GitHub](https://gist.github.com/tckz/2835544)\n* https://javadoc.jenkins-ci.org/jenkins/model/Jenkins.html\n* https://javadoc.jenkins.io/hudson/model/Job.html#getBuilds()\n* https://javadoc.jenkins.io/hudson/model/Run.html#isBuilding()\n* https://javadoc.jenkins.io/hudson/model/AbstractBuild.html#doStop()\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkins-shared-library":{"title":"Jenkins shared library","content":"\n[note/Jenkins](Jenkins.md) で複数のプロジェクトがあって、それぞれにビルドやデプロイのジョブを作成している。\n同じようなステップを実行するので、共通処理をまとめてメンテナスしやすくしたい。\n\n## Jenkins Shared Library\n\nShared Libraryを使うとpipelineからライブラリに定義された関数や変数を使うことができる。\n[Jenkins Shared Librariesの活用事例の紹介 - DeNA Testing Blog](https://swet.dena.com/entry/2021/01/18/200000)\n\nなんと `pipeline {}` ごと定義することもできる。\n\n### 使い方\n\n[Share a standard Pipeline across multiple projects with Shared Libraries](https://www.jenkins.io/blog/2017/10/02/pipeline-templates-with-shared-libraries/)\n\n[Extending with Shared Libraries](https://www.jenkins.io/doc/book/pipeline/shared-libraries/)\n\n1. ライブラリを作成する\n\nライブラリ用のリポジトリを作成して、ディレクトリ構成を以下のようにする(srcかvarsどちらか一つは必須)\n\n`mylibrary`\n\n````\n+- src                     # Groovy source files\n|   +- org\n|       +- foo\n|           +- Bar.groovy  # for org.foo.Bar class\n+- vars\n|   +- foo.groovy          # for global 'foo' variable\n|   +- foo.txt             # help for 'foo' variable\n+- resources               # resource files (external libraries only)\n|   +- org\n|       +- foo\n|           +- bar.json    # static helper data for org.foo.Bar\n````\n\n処理を以下のように記述する。callメソッドを定義すると\n\n`mylibrary/vars/hello.groovy`\n\n````groovy\ndef call() {\n  pipeline {\n    agent any\n    stages {\n      stage('library stage') {\n        steps {\n          echo \"hello\"\n        }\n      }\n    }\n  }\n}\n````\n\n2. Jenkinsの管理 \u003e システムの設定 \u003e Global Pipeline Libraries に、ライブラリのリポジトリを設定する\n\n設定値は見ての通り\n\n3. pipelineを作成する\n\n`Jenkinsfile`\n\n````groovy\n// ライブラリ名を指定\n@Library('mylibrary') _\n\n// xxx.groovy の xxx 部分で関数を実行できる\nhello()\n````\n\n`vars` 配下に作成した場合は、globalに定義されるためimportを書かずに利用できる。\n\n````groovy\n// Global Pipeline Libraries の Default version を使用する\n@Library('mylibrary') _\n\n// ブランチやタグを指定する場合\n@Library('mylibrary@1.0') _\n\n// 複数ライブラリの読み込み\n@Library(['mylibrary', 'other@abcdef1234']) _\n````\n\n`src` 配下に作成した場合は、importしてnewでインスタンスを作成した上で利用できる。\n\n````groovy\n// 利用したい class を import する\n@Library('mylibrary') import org.foo.Sample\n\n// 利用時は script { } ブロック内で利用する\nscript {\n  def sample = new org.foo.Sample()\n  sample.hello()   // Sample 内に定義されている hello() メソッドの呼び出し\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkinsfile":{"title":"Jenkinsfile","content":"\n[Jenkins Pipeline](note/Jenkins%20Pipeline.md) を書いたファイル\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Jenkinsfile%E3%82%92%E3%83%AA%E3%83%AD%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B":{"title":"Jenkinsfileをリロードする","content":"\n[Jenkinsfile](note/Jenkinsfile.md) 内でパラメータを `parameters` ブロックで定義しても、一度実行しないと反映されない。\n\nhttps://stackoverflow.com/questions/44422691/how-to-force-jenkins-to-reload-a-jenkinsfile\nrefresh用のパラメータを定義しておくのが常套手段\n\n````groovy\npipeline {\n    agent any\n    parameters {\n        booleanParam(name: 'Refresh',\n                    defaultValue: false,\n                    description: 'Read Jenkinsfile and exit.')\n    }\n    stages {\n        stage('Read Jenkinsfile') {\n            when {\n                expression { return params.Refresh == true }\n            }\n            steps {\n              echo(\"stop\")\n            }\n        }\n        stage('Run Jenkinsfile') {\n            when {\n                expression { return params.Refresh == false }\n            }\n            stages {\n              stage('Build') {\n                  steps {\n                    echo(\"build\")\n                  }\n              }\n              stage('Test') {\n                  steps {\n                    echo(\"test\")\n                  }\n              }\n              stage('Deploy') {\n                  steps {\n                    echo(\"deploy\")\n                  }\n              }\n            }\n        }\n    }\n}\n````\n\n### Job DSLを使用している場合\n\n````groovy\npipelineJob('myJobName') {\n    // sets RELOAD=true for when the job is 'queued' below\n    parameters {\n        booleanParam('RELOAD', true)\n    }\n\n    definition {\n        cps {\n            script(readFileFromWorkspace('Jenkinsfile'))\n            sandbox()\n        }\n    }\n\n    // queue the job to run so it re-downloads its Jenkinsfile\n    queue('myJobName')\n}\n````\n\nerrorを使ってジョブを止めてしまえば、 `RELOAD==false` で囲う必要がなくなる\n\n````groovy\npipeline {\n    agent any\n    stages {\n        stage('Preparations') {\n            when { expression { return params.RELOAD == true } }\n            // Because this: https://issues.jenkins-ci.org/browse/JENKINS-41929\n            steps {\n                script {\n                    if (currentBuild.getBuildCauses('hudson.model.Cause') != null) {\n                        currentBuild.displayName = 'Parameter Initialization'\n                        currentBuild.description = 'On first build we just load the parameters as they are not available of first run on new branches.  A second run has been triggered automatically.'\n                        currentBuild.result = 'ABORTED'\n\n                        error('Stopping initial build as we only want to get the parameters')\n                    }\n                }\n            }\n        }\n\n        stage('Parameters') {\n            steps {\n                echo 'Running real job steps...'                \n            }\n        }\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Jenkins"]},"/note/Junit%E3%81%A7%E3%83%A1%E3%82%BD%E3%83%83%E3%83%89%E5%90%8D%E3%81%8C%E9%95%B7%E3%81%99%E3%81%8E%E3%81%A6%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%AB%E3%81%AA%E3%82%8B":{"title":"Junitでメソッド名が長すぎてエラーになる","content":"\n\n````txt\n[ERROR] org.jetbrains.kotlin.backend.common.BackendException: Backend Internal error: Exception during file facade code generation File being compiled: [file:///tmp/workspace/very/long/long/TestClass.java]\nThe root cause java.io.FileNotFoundException was thrown at: java.io.FileOutputStream.open0(Native Method)\n\tat org.jetbrains.kotlin.backend.common.CodegenUtil.reportBackendException(CodegenUtil.kt:239)\n\tat org.jetbrains.kotlin.codegen.PackageCodegenImpl.generate(PackageCodegenImpl.java:78)\n\tat org.jetbrains.kotlin.codegen.DefaultCodegenFactory.generatePackage(CodegenFactory.kt:77)\n\tat org.jetbrains.kotlin.codegen.DefaultCodegenFactory.generateModule(CodegenFactory.kt:62)\n\tat org.jetbrains.kotlin.codegen.KotlinCodegenFacade.compileCorrectFiles(KotlinCodegenFacade.java:35)\n    ...\nCaused by: java.io.FileNotFoundException: /tmp/workspace/very/long/long/TestClass.java$test_とてもながあああああああああああああああああああああああああああああああああああああああいテストケース名$1.class (File name too long)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)\n\tat java.io.FileOutputStream.\u003cinit\u003e(FileOutputStream.java:213)\n\t...\n````\n\nテストメソッドを説明的にしようと長くしすぎると、実行環境のファイルパス長の制限によってエラーになる\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["unittest","Java"]},"/note/Kaniko%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E8%AA%BF%E3%81%B9%E3%81%9F%E3%83%A1%E3%83%A2":{"title":"Kanikoについて調べたメモ","content":"\n[GitLab RunnerとkanikoでDockerイメージをビルドする - GeekFactory](https://int128.hatenablog.com/entry/2019/09/25/204930)\n[JenkinsとKubernetesでCIパイプラインを構築 - Qiita](https://qiita.com/MahoTakara/items/7a5018dee28ff6bae89a)\n\n[Let's make faster GitLab CI/CD pipelines](https://blog.nimbleways.com/let-s-make-faster-gitlab-ci-cd-pipelines/)\n[Amazon EKS on Fargate を使用してコンテナイメージをビルドする方法 | Amazon Web Services ブログ](https://aws.amazon.com/jp/blogs/news/how-to-build-container-images-with-amazon-eks-on-fargate/)\n[kanikoを使ったGitLab Container Registry と AWS ECRの認証方法について - デザインワン・ジャパン Tech Blog](https://tech.designone.jp/entry/2022/07/29/203342)\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/04/20","Kubernetes"]},"/note/Kaniko-assume-role%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6ECR%E3%83%AD%E3%82%B0%E3%82%A4%E3%83%B3%E3%81%99%E3%82%8B":{"title":"Kaniko assume roleを使ってECRログインする","content":"\n[kaniko が何をしているか, 何ができるか - 薄いブログ](https://orisano.hatenablog.com/entry/2019/05/20/120032)\n[Container Image Building with Kaniko](https://www.giantswarm.io/blog/container-image-building-with-kaniko)\n\n[Kaniko Image Cache in Jenkins Kubernetes Agents - Stack Overflow](https://stackoverflow.com/questions/72754983/kaniko-image-cache-in-jenkins-kubernetes-agents)\n\n* `/kaniko/.docker/config.json` に\n\n````json\n{\n  \"credsStore\": \"ecr-login\"\n}\n````\n\n````groovy\npipeline {\n    agent {\n        kubernetes {\n          label \"kaniko\"\n          yaml '''\n          spec:\n            volumes:\n              - name: cache\n                emptyDir: {}\n            containers:\n            - name: kaniko\n              image: gcr.io/kaniko-project/executor:debug\n              imagePullPolicy: IfNotPresent\n              volumeMounts:\n              - mountPath: /mnt/cache\n                name: cache\n              command:\n              - /busybox/cat\n              tty: true\n            - name: awscli\n              image: public.ecr.aws/aws-cli/aws-cli:latest\n              imagePullPolicy: IfNotPresent\n              args:\n                - \"9999999\"\n              command:\n              - sleep\n              tty: true\n          '''.stripIndent()\n\n        }\n    }\n\n    stages {\n        stage('Login'){\n            steps{\n                container(name: 'awscli') {\n                    script {\n                        def credentialText = sh(\n                          script: 'aws sts assume-role --role-arn \"$ROLE_ARN\"',\n                          returnStdout: true\n                        ).trim()\n                        def credential = new groovy.json.JsonSlurper().parseText(credentialText)\n\n                        // 環境変数にセット\n                        env.AWS_ACCESS_KEY_ID = credential['Credentials']['AccessKeyId']\n                        env.AWS_SECRET_ACCESS_KEY = credential['Credentials']['SecretAccessKey']\n                        env.AWS_SESSION_TOKEN = credential['Credentials']['SessionToken']\n                    }\n                }\n            }\n        }\n\n        stage('Warm'){\n            steps{\n                container(name: 'kaniko', shell: '/busybox/sh') {\n                    sh '''\n                    /kaniko/warmer --cache-dir=/mnt/cache --image=\u003cIMAGE_FROM_ECR\u003e -v debug\n                    '''.stripIndent()\n                }\n            }\n        }\n\n        stage('Build \u0026 Cache Image'){\n            steps{\n                container(name: 'kaniko', shell: '/busybox/sh') {\n                    sh '''\n                    echo hello \u003e tmp.txt\n\n                    cat \u003c\u003cEOF \u003e Dockerfile\n                    FROM \u003cIMAGE_FROM_ECR\u003e\n                    COPY tmp.txt /usr/local/tomcat/\n                    EOF\n\n                    /kaniko/executor --context . --dockerfile Dockerfile --destination=kaniko-sample --cache-dir=/mnt/cache --no-push --tarPath out.tar\n                    '''.stripIndent()\n                }\n            }\n        }\n    }\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/02/10","Docker","Kubernetes"]},"/note/Karabiner-elements_HyperKey":{"title":"Karabiner-elements_HyperKey","content":"\n\u003chttps://github.com/Vonng/Capslock\u003e\n\n \u003e \n \u003e Transform ⇪CapsLock into a powerful **modifier** **✱ Hyper** that miraculously increases your work productivity!\n\n## Hyper Application\n\nホットキーでアプリを起動する\n\n## Hyper Function\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Mac","keyboard"]},"/note/Kibana":{"title":"Kibana","content":"\nhttps://www.elastic.co/jp/kibana/\n\nKibanaは、Elasticsearchでインデックスされたデータの検索と可視化の機能や、Elastic Stackのプロダクトの制御の機能を提供する。\nダッシュボードを作成してデータを可視化することができる。\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Observability"]},"/note/Kotlin":{"title":"Kotlin","content":"\n## 概要\n\n* JVM言語\n* JetBrains製\n* GoogleがAndroidアプリ開発言語として正式採用\n\n## 特徴\n\n* Null Safety\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Kotlin"]},"/note/Kotlin%E3%81%AEFormatter":{"title":"KotlinのFormatter","content":"\n\\#Kotlin\n\n\u003chttps://github.com/facebookincubator/ktfmt\u003e\n\u003chttps://github.com/pinterest/ktlint\u003e\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Kotlin"]},"/note/Kotlin_Coroutines":{"title":"Kotlin_Coroutines","content":"\n\\#Kotlin\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Kotlin"]},"/note/Kotlin_Coroutines%E3%81%AE%E4%B8%A6%E5%88%97%E6%95%B0%E3%82%92%E5%88%B6%E5%BE%A1%E3%81%99%E3%82%8B":{"title":"Kotlin_Coroutinesの並列数を制御する","content":"\n\\#Kotlin\n\n## やりたいこと\n\n[Kotlin_Coroutines](Kotlin_Coroutines.md) を使って並列処理をしたときに、並列数を制御したい\nデフォルトだと、CPUのコア数？\n\n## 方法\n\n### Semaphore\n\nhttps://stackoverflow.com/questions/58428584/limiting-the-maximum-number-of-coroutines-that-can-run-in-a-scope\n\n````kotlin\n    import kotlinx.coroutines.sync.Semaphore\n\n    val requestSemaphore = Semaphore(5)\n    \n    runBlocking {\n        mDownloadJobs.map {\n            async {\n                // Will limit number of concurrent requests to 5\n                requestSemaphore.withPermit {\n                    it.loadData()\n                }\n            }\n        }\n    }\n````\n\nkotlin,kotlinx 1.3 の環境では `kotlin/KotlinNothingValueException` がでて、 SemaphoreImpl が見つからないというエラーが出てしまいだめだった\n\nkotlin-stdlib-jdk8 と kotlinx-coroutines-core だけだとだめ\nkotlin-stdlibを追加して、1.4にすると動いた\n\n### Channelを使う\n\nhttps://stackoverflow.com/questions/47686353/how-to-cap-kotlin-coroutines-maximum-concurrency\nhttps://tech.uzabase.com/entry/2019/11/05/190000\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Kotlin"]},"/note/Kubernetes":{"title":"Kubernetes","content":"\nOSSのコンテナオーケストレーションツール\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/04/26","Kubernetes"]},"/note/Kubernetes-Krew":{"title":"Kubernetes Krew","content":"\nhttps://krew.sigs.k8s.io/docs/user-guide/setup/install/\n\n[kubectl](note/kubectl.md) 向けのパッケージマネージャーツール\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Kubernetes"]},"/note/Kubernetes-configMapGenerator%E3%82%92%E4%BD%BF%E3%81%86":{"title":"Kubernetes configMapGeneratorを使う","content":"\n\\#Kubernetes\n\n[Kustomize](note/Kustomize.md) の場合、ConfigMapを直接指定する代わりにconfigMapGeneratorを使用して作成できる\n\n\u003chttps://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/\u003e\nhttps://github.com/kubernetes-sigs/kustomize/blob/master/examples/configGeneration.md\n\n* literals: key-valueを指定する\n* files: ファイルを指定する\n\n````yaml\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nnamePrefix: dev-\ncommonLabels:\n  env: dev\nresources:\n- ./../../base\nconfigMapGenerator:\n- name: config-file\n  files:\n  - application.yaml\n- name: the-map\n  literals:\n    - altGreeting=Good Morning!\n    - enableRisky=\"false\"\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Kubernetes"]},"/note/Kubernetes-limits%E3%82%92%E6%8C%87%E5%AE%9A%E3%81%97%E3%81%9FPod%E3%81%A7%E5%8B%95%E3%81%8B%E3%81%97%E3%81%A6%E3%81%84%E3%82%8B%E3%83%97%E3%83%AD%E3%82%BB%E3%82%B9%E3%81%8C%E3%83%A1%E3%83%A2%E3%83%AA%E8%B6%85%E9%81%8E%E3%81%97%E3%81%A6%E3%82%82evict%E3%81%95%E3%82%8C%E3%81%9A%E3%83%97%E3%83%AD%E3%82%BB%E3%82%B9%E3%81%8Ckill%E3%81%95%E3%82%8C%E3%82%8B":{"title":"Kubernetes limitsを指定したPodで動かしているプロセスがメモリ超過してもevictされずプロセスがkillされる","content":"\n[kubernetes resourcesの設定値について Kubernetes](note/kubernetes%20resourcesの設定値について%20Kubernetes.md)\n\n`command: ['sleep', '3600']` とかで起動したpodにexecで入って `yes` コマンド等で負荷をかけても、`yes` のプロセスがkillされるだけでpodはevictされなかった。\nドキュメント読む限りpodがevictされるのかと思ったがそうじゃない？\n\nこちらに書いてあった\nhttps://dunkshoot.hatenablog.com/entry/kubernetes_manage_resource#limits-%E3%82%92%E8%B6%85%E3%81%88%E3%81%A6%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%92%E4%BD%BF%E7%94%A8%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84%E3%83%A1%E3%83%A2%E3%83%AA\n\n起動時のコマンドのプロセスがlimitsに達したとき、podがkillされる(想定通り)\n\nkillされた理由がどこかに出力されているのかはわからなかった。\ndescribe pod すると負荷かけたコンテナのほうにOOMKilledが出ているのはわかった\n\n````yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: test-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: test-app\n  template:\n    metadata:\n      labels:\n        app: test-app\n    spec:\n      containers:\n      - name: busybox # こちらはkillされない\n        image: busybox:latest\n        command: ['sh', '-c', 'echo \"Hello, Kubernetes!\" \u0026\u0026 sleep 3600']\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"64M\"\n          limits:\n            cpu: \"200m\"\n            memory: \"128M\"\n      - name: stress # killされる\n        image: polinux/stress:latest\n        command: ['stress']\n        args: [\"--vm\", \"1\", \"--vm-bytes\", \"256M\", \"--vm-hang\", \"1\"]\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"64M\"\n          limits:\n            cpu: \"200m\"\n            memory: \"128M\"\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/01/26","Kubernetes"]},"/note/Kustomize":{"title":"Kustomize","content":"\nhttps://kustomize.io\n\n複数のKubernetesクラスターを管理する場合に、マニフェストファイルを管理しやすくするツール\n\n開発環境と本番環境など、各環境ごとにマニフェストを作成すると、全環境に共通のパラメータを変更したいときにすべてのファイルを変更する必要があり、管理が大変になる。\nそこでKustomizeを使うことで、環境ごとに共通の部分を定義したマニフェストファイル(base)と、差異がある部分だけを定義したマニフェスト(overlays)に分けることができる。\n`kustomize build` でbaseとoverlaysをマージしたマニフェストを作成できる。\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Kubernetes"]},"/note/Kustomize-patch%E3%81%A7%E7%89%B9%E5%AE%9A%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E3%81%AE%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%81%AB%E3%81%BE%E3%81%A8%E3%82%81%E3%81%A6patch%E3%82%92%E5%BD%93%E3%81%A6%E3%82%8B":{"title":"Kustomize patchで特定パターンのリソースにまとめてpatchを当てる","content":"\npatch で複数のリソースにまとめて変更を加えたい場合に使える\n\n````\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nresources:\n- github.com/argoproj/argo-cd/manifests/cluster-install?ref=v2.5.0\n\npatches:\n  - patch: |-\n      kind: any\n      metadata:\n        name: any\n      spec:\n        template:\n          spec:\n            nodeSelector:\n              ap-type: argocd-node\n    target:\n      kind: (StatefulSet|Deployment)\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["2023/04/07","Kubernetes"]},"/note/Lambda%E3%81%A7%E3%82%BF%E3%82%A4%E3%83%A0%E3%82%A2%E3%82%A6%E3%83%88%E3%81%97%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AB%E5%87%A6%E7%90%86%E3%82%92%E3%81%97%E3%81%9F%E3%81%84":{"title":"Lambdaでタイムアウトしたときに処理をしたい","content":"\n\\#Go #Lambda\n\n[Go の AWS Lambda context オブジェクト - AWS Lambda](https://docs.aws.amazon.com/ja_jp/lambda/latest/dg/golang-context.html)\n\nLambda では実行時に context.Context を受け取ることができ、\nLambda が起動した時間＋Lambdaのタイムアウト秒を DeadLine として取得することができる。\n\n````go\npackage main\n\nimport (\n        \"context\"\n        \"log\"\n        \"time\"\n        \"github.com/aws/aws-lambda-go/lambda\"\n)\n\nfunc longFunc(ctx, err chan error) {\n    time.Sleep(2 * time.Second)\n    close(err)\n}\n\nfunc LongRunningHandler(ctx context.Context) (string, error) {\n\n\tdeadline, _ := ctx.Deadline()\n\tdeadline = deadline.Add(-1 * time.Second)\n\ttimeoutChannel := time.After(time.Until(deadline))\n\n\terrChan := make(chan error)\n\n\tgo longFunc(ctx, errChan)\n\n\tselect {\n\tcase \u003c-timeoutChannel:\n\t\treturn nil, errors.New(\"timeout\")\n\tcase err := \u003c-errChan:\n        if err != nil {\n            return nil, err\n        } else {\n            return \"success\", nil\n        }\n\t}\n\n}\n\nfunc main() {\n        lambda.Start(LongRunningHandler)\n}\n````\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":["Go","Lambda"]},"/note/Lambda%E5%90%8C%E6%99%82%E5%AE%9F%E8%A1%8C%E6%95%B0":{"title":"Lambda同時実行数","content":"\n\\#AWS #Lambda \n\n* 同時実行数の上限はアカウント全体の1リージョンにつき1000\n* 関数Aで1000件実行されていると関数Bが失敗する\n* 関数ごとに同時実行数上限を設定できる\n\n[\\[アップデート\\]Lambdaの同時実行数がよりきめ細かく確認できるようになりました | DevelopersIO](https://dev.classmethod.jp/articles/aws-lambda-metric-for-concurrent-executions-now-supports-all-functions-versions-and-aliases/)\n\n[Lambda 関数に冪等にする](https://aws.amazon.com/jp/premiumsupport/knowledge-center/lambda-function-idempotent/)\n\n[Lambda 関数の同時実行数を1にしても冪等性の担保から逃れることは出来ない | by noid11 | Medium](https://medium.com/@noid11/lambda-%E9%96%A2%E6%95%B0%E3%81%AE%E5%90%8C%E6%99%82%E5%AE%9F%E8%A1%8C%E6%95%B0%E3%82%921%E3%81%AB%E3%81%97%E3%81%A6%E3%82%82%E5%86%AA%E7%AD%89%E6%80%A7%E3%81%AE%E6%8B%85%E4%BF%9D%E3%81%8B%E3%82%89%E9%80%83%E3%82%8C%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AF%E5%87%BA%E6%9D%A5%E3%81%AA%E3%81%84-24a7e414933d)\n\n \u003e \n \u003e ・冪等性はお客様のコードで確保する必要がある\n \u003e \n \u003e * AWS Lambda で保証しているのは最低1回実行することであり1回しか実行しないことではない\n \u003e \n \u003e * 同一イベントで同一 Lambda ファンクションが2回起動されることがまれに発生する\n \u003e \n \u003e * DynamoDB を利用するなどして冪等性を担保する実装を行うこと\n\n \u003e \n \u003e 1. 入力イベントの固有属性の値を抽出します。(たとえば、トランザクションまたは購入 ID など。)\n \u003e \n \u003e 1. 属性値がコントロールデータベース ([Amazon DynamoDB テーブル](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithTables.html)など) に存在するかどうかを確認します。  \n \u003e    **注:** アーキテクチャに AWS サービスを追加すると、追加費用が発生する場合があります。詳細については、「[Amazon DynamoDB 料金](https://aws.amazon.com/dynamodb/pricing/)」および「[AWS 料金](https://aws.amazon.com/pricing/)」をご参照ください。\n \u003e \n \u003e 1. 一意の値が存在する場合 (重複イベントを示す)、実行を正常に終了します (つまりエラーをスローすることがない)。一意の値が存在しない場合は、通常の実行を継続します。\n \u003e \n \u003e 1. 関数の動作が正常に終了したら、コントロールデータベースにレコードが含まれます。\n \u003e \n \u003e 1. 実行を終了します。\n","lastmodified":"2023-07-29T08:18:43.027497157Z","tags":[]},"/note/Lambda%E9%96%A2%E6%95%B0%E3%81%AB%E5%90%8C%E6%99%82%E5%AE%9F%E8%A1%8C%E6%95%B0%E3%82%92%E6%8B%85%E4%BF%9D%E3%81%99%E3%82%8B":{"title":"Lambda関数に同時実行数を担保する","content":"\n[Lambda 関数に冪等にする](https://aws.amazon.com/jp/premiumsupport/knowledge-center/lambda-function-idempotent/)\n\n[Lambda 関数の同時実行数を1にしても冪等性の担保から逃れることは出来ない | by noid11 | Medium](https://medium.com/@noid11/lambda-%E9%96%A2%E6%95%B0%E3%81%AE%E5%90%8C%E6%99%82%E5%AE%9F%E8%A1%8C%E6%95%B0%E3%82%921%E3%81%AB%E3%81%97%E3%81%A6%E3%82%82%E5%86%AA%E7%AD%89%E6%80%A7%E3%81%AE%E6%8B%85%E4%BF%9D%E3%81%8B%E3%82%89%E9%80%83%E3%82%8C%E3%82%8B%E3%81%93%E3%81%A8%E3%81%AF%E5%87%BA%E6%9D%A5%E3%81%AA%E3%81%84-24a7e414933d)\n\n \u003e \n \u003e ・冪等性はお客様のコードで確保する必要がある\n \u003e \n \u003e * AWS Lambda で保証しているのは最低1回実行することであり1回しか実行しないことではない\n \u003e \n \u003e * 同一イベントで同一 Lambda ファンクションが2回起動されることがまれに発生する\n \u003e \n \u003e * DynamoDB を利用するなどして冪等性を担保する実装を行うこと\n\n \u003e \n \u003e 1. 入力イベントの固有属性の値を抽出します。(たとえば、トランザクションまたは購入 ID など。)\n \u003e \n \u003e 1. 属性値がコントロールデータベース ([Amazon DynamoDB テーブル](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithTables.html)など) に存在するかどうかを確認します。  \n \u003e    **注:** アーキテクチャに AWS サービスを追加すると、追加費用が発生する場合があります。詳細については、「[Amazon DynamoDB 料金](https://aws.amazon.com/dynamodb/pricing/)」および「[AWS 料金](https://aws.amazon.com/pricing/)」をご参照ください。\n \u003e \n \u003e 1. 一意の値が存在する場合 (重複イベントを示す)、実行を正常に終了します (つまりエラーをスローすることがない)。一意の値が存在しない場合は、通常の実行を継続します。\n \u003e \n \u003e 1. 関数の動作が正常に終了したら、コントロールデータベースにレコードが含まれます。\n \u003e \n \u003e 1. 実行を終了します。\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["AWS","Lambda"]},"/note/LamdbaEdge":{"title":"LamdbaEdge","content":"\n\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["AWS"]},"/note/Linux%E3%81%A8Windows%E3%81%AE%E3%83%87%E3%83%A5%E3%82%A2%E3%83%AB%E3%83%96%E3%83%BC%E3%83%88%E3%82%92%E3%82%84%E3%82%81%E3%81%9F":{"title":"LinuxとWindowsのデュアルブートをやめた","content":"\n[Windows10とUbuntu16.04のデュアルブート解除](note/Windows10とUbuntu16.04のデュアルブート解除.md)\n\n[LinuxとWindowsをデュアルブートするのは止めたほうが良い | SlackNote](https://slacknotebook.com/os-dual-boot-is-a-bad-idea/)\n\nデュアルブートは不都合が起こりやすいのでやめた。\n以下があげられていた。\n\n* パーティションテーブルのカオス化\n* ブートローダーの複雑化\n* 復旧作業の面倒さ\n\n実際、WindowsアップデートしたときにGrub画面が表示されなくなったことがあるのでこれは身にしみている\n\n### 解決策\n\n物理的にもう一つ別のドライブを載せ、Linuxをインストールする。\nBIOS画面で起動順序さえ決めてしまえば、事故が起こりにくい。\n\nデュアルブート自体を学習したい、なんかかっこいいなど価値を見出しているのでなければ、仮想化で十分\nWSL2とかあるし\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Windows","Ubuntu"]},"/note/Locust":{"title":"Locust","content":"\n[Locust - A modern load testing framework](https://locust.io/)\n\nLocust はPythonで書かれた負荷試験ツール\nスクリプトもPythonで書く\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/01/05","loadtest"]},"/note/Locust%E3%81%A8Boomer%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6Go%E3%81%A7%E8%B2%A0%E8%8D%B7%E8%A9%A6%E9%A8%93%E3%81%AE%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88%E3%82%92%E6%9B%B8%E3%81%8F":{"title":"LocustとBoomerを使ってGoで負荷試験のスクリプトを書く","content":"\n[DMMプラットフォームを支える負荷試験基盤 - Speaker Deck](https://speakerdeck.com/yuyu_hf/cndt-2022-dmm-load-testing-platform-for-dmm-platform)\n[gRPC + Locust + boomerで負荷試験をしてみた - Qiita](https://qiita.com/shka0909/items/ea0ec3ddaecb3dfa8239)\n\n[Locust](note/Locust.md) はPythonでスクリプトを書く。\nGoで負荷試験の処理を書きたくなったので、\n[Boomer](https://github.com/myzhan/boomer) を調べてみた\n[k6](note/負荷試験%20k6について.md)もいいけど\n\n## シナリオを作成\n\nライブラリを取得\n\n````shell\n$ go get -u github.com/myzhan/boomer@master\n````\n\nv1.6.0時点では、masterを指定しないと次のエラーが出てlocust masterと接続できなかった。\n`An old (pre 2.0) worker tried to connect (xxx). That's not going to work`\nhttps://github.com/myzhan/boomer/issues/160\n\nシナリオ `main.go`\n\n````go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/myzhan/boomer\"\n)\n\nfunc hello(url string) func() {\n\treturn func() {\n\t\t// レスポンスタイムを計測するために、リクエストを投げる前の時刻を取得する\n\t\tstart := time.Now()\n\t\tresp, err := http.Get(url)\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"%+v\", err)\n\t\t}\n\t\tdefer resp.Body.Close()\n\n\t\tb, err := io.ReadAll(resp.Body)\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"%+v\", err)\n\t\t}\n\n\t\tif resp.StatusCode \u003e= 400 {\n\t\t\t// リクエストに失敗した場合はRecordFailureを呼びます\n\t\t\tboomer.RecordFailure(\n\t\t\t\t\"http\",\n\t\t\t\turl,\n\t\t\t\ttime.Since(start).Nanoseconds()/int64(time.Millisecond),\n\t\t\t\tfmt.Sprintf(\"failed: %+v\", err),\n\t\t\t)\n\t\t} else {\n\t\t\t// リクエストに成功した場合はRecordSuccessを呼びます\n\t\t\tboomer.RecordSuccess(\n\t\t\t\t\"http\",\n\t\t\t\turl,\n\t\t\t\ttime.Since(start).Nanoseconds()/int64(time.Millisecond),\n\t\t\t\tint64(len(b)),\n\t\t\t)\n\t\t}\n\t}\n}\n\nfunc main() {\n\ttasks := make([]*boomer.Task, 0)\n\turls := []string{\"http://localhost:3000/hello\", \"http://localhost:3000/nothing\"}\n\tfor _, url := range urls {\n\t\ttask := \u0026boomer.Task{\n\t\t\tName:   \"hello\",\n\t\t\tWeight: 10,\n\t\t\tFn:     hello(url),\n\t\t}\n\t\ttasks = append(tasks, task)\n\t}\n\tboomer.Run(tasks...)\n}\n````\n\n## masterを起動する\n\n適当なlocustfileを作成\n\n`dummy.py`\n\n````python\nfrom locust import HttpUser, task\n\nclass HelloWorldUser(HttpUser):\n    @task\n    def hello_world(self):\n        print(\"hello\")\n````\n\ndockerでlocustを実行する\n\n````shell\ndocker run -p 8089:8089 -p 5557:5557 -v $PWD:/mnt/locust locustio/locust --master -f /mnt/locust/dummy.py\n````\n\nWeb UIは8089、workerとの通信は5557\nhttps://boomer.readthedocs.io/en/latest/options.html\n\nlocalhost:8089でWeb UIが開く\n\nこの状態でworkerを実行する\n\n````shell\n$ go run main.go\n````\n\nするとWORKERSに登録される\n\n![Pasted-image-20230110180714](note/Pasted-image-20230110180714.png)\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/01/05","Go","loadtest"]},"/note/M1-Mac%E3%81%A7Node.js%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB":{"title":"M1 MacでNode.jsインストール","content":"\n\\#Nodejs \n\n* 最新のNodeバージョンで起動に失敗するプロジェクトだったのでバージョンをさげたい\n\n* `nodebrew install v15` は、`https://nodejs.org/dist/v16.0.0/node-v15.14.0-darwin-arm64.tar.gz` がないと言われるのでソースからビルドする必要がある\n\n* ついでにnodebrewをやめて、取り扱いが簡単そうなnvm (zsh plugin [https://github.com/lukechilds/zsh-nvm](https://github.com/lukechilds/zsh-nvm) ) に変更\n\n* `nvm install 15` でバイナリがなかったらソースからビルドしてくれる。ビルドに20分くらいかかる\n\n* 異なるバージョンで入れたnode_modulesだと実行に失敗したので、一度消して再度 `yarn install`\n\nもっといろいろ失敗するかと思ったけど意外とすんなり動いた\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":[]},"/note/M1-MacBook-Air":{"title":"M1 MacBook Air","content":"\n\u003chttps://www.apple.com/jp/shop/buy-mac/macbook-air/%E3%82%B9%E3%83%9A%E3%83%BC%E3%82%B9%E3%82%B0%E3%83%AC%E3%82%A4-8%E3%82%B3%E3%82%A2cpu%E3%81%A87%E3%82%B3%E3%82%A2gpu%E3%82%92%E6%90%AD%E8%BC%89%E3%81%97%E3%81%9Fapple-m1%E3%83%81%E3%83%83%E3%83%97-256gb\u003e\n\n現在のMacを下取りに出すこともできる\n2015 MacBook Air でも3万円安くなる\n\n[Apple SiliconのM1チップ](https://www.apple.com/jp/newsroom/2020/11/apple-unleashes-m1/) を搭載\n\n \u003e \n \u003e Appleが作ったものの中で最もパワフルなチップで、Macのために設計された初めてのチップです。M1は、コンパクトさと電力効率が極めて重要となるMacシステムのために最適化されています。\n \u003e CPU性能は最大3.5倍、GPU性能は最大6倍、機械学習では最大15倍高速になります。しかも、バッテリーは一世代前のMacよりも最大2倍長く持続します。パフォーマンスと効率を大幅に向上させるM1により、Macはかつてないほど大きな進化を遂げます。\n\n\u003chttps://japan.cnet.com/article/35174609/\u003e\n\n* 省電力\n* パフォーマンス改善\n* GPUも最大5倍高速化\n* ファンレス静音\n* 価格も13万円くらいでバカ高いわけじゃない\n* ポートはtype-Cが2つで物足りない\n\n## 2022-03-12\n\n半年くらいM2のAirを待っていたが、3/9のAppleイベントでM2のMacbook Proすらでず、噂では次期のAirはM1続投かもということで、もう半年は流石に待てないということで買ってしまった。\n8コアCPU,7コアGPU,メモリ16GB,SSD256GB,¥137,280にした。\nSSD512GBと迷ったけど、128GBでなんとかなっているし2倍ならなんとかなるかな…、外付けHDD使えばいいかと思った\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Mac"]},"/note/M1-Macbook-Air-%E3%82%BB%E3%83%83%E3%83%88%E3%82%A2%E3%83%83%E3%83%972022-03":{"title":"M1 Macbook Air セットアップ2022-03","content":"\n\\#Mac\n\n* US配列\n\n## karbiner\n\n## Obsidian\n\n## defaults\n\n## brew\n\n## IME\n\n## pyenvをやめた\n\npythonのバージョンを切り替えて使うことがそんなにないので、\n特定のバージョンを使いたくなったらdockerを使う\n\n````shell\n$ brew install python\n$ export PATH=\"$(brew --prefix)/opt/python/libexec/bin:$PATH\" \u003e\u003e ~/.zshrc\n````\n\n## Vivaldi\n\n* 検索エンジン、キーマップがいちいちリセットされてしまうのなんとかならんかね\n\n## [Rust](note/Rust.md)\n\nrustupでインストールする\nhttps://www.rust-lang.org/tools/install\n\n````shell\n$ curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n# もしくは brew install rustup-init \u0026\u0026 rustup-init \n1を選択\n$ rustup --version\n=\u003e インストールされていることを確認\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Mac"]},"/note/M1Mac%E3%81%A7docker%E3%81%AEvolume%E3%81%AF%E3%81%A9%E3%81%93%E3%81%AB%E3%81%82%E3%82%8B%E3%81%AE":{"title":"M1Macでdockerのvolumeはどこにあるの","content":"\n\\#Docker \n\nほぼこれの通り\n\n[Docker Desktop for MacのHyperKit VMに入る](https://uzimihsr.github.io/post/2020-12-15-docker-desktop-for-mac-hyperkit-vm/)\n\n````shell\n$ docker run -it --rm --name volume-test-container -v test-volume:/volume_dir alpine:latest /bin/ash\n````\n\n````shell\n$ docker inspect volume-test-container\n\n[\n    {\n        \"Id\": \"625a47db9275478db8235dc85f8711cc6a50fe5924f9e42f7f7ec23434f934e9\",\n        \"Mounts\": [\n            {\n                \"Type\": \"volume\",\n                \"Name\": \"test-volume\",\n                \"Source\": \"/var/lib/docker/volumes/test-volume/_data\",\n                \"Destination\": \"/volume_dir\",\n                \"Driver\": \"local\",\n                \"Mode\": \"z\",\n                \"RW\": true,\n                \"Propagation\": \"\"\n            },\n        ],\n    }\n]\n\n````\n\n`/var/lib/docker/volumes/test-volume/_data` にあるのね、とlsしてみても、そんなディレクトリはないよと怒られる。\nじゃあどこにあるのかというと、Docker Desktop for Macを使っている場合、Docker環境はHyperKitというVM(バーチャルマシン)上で実行されているためMacからは参照できない。\nnsenter1というコマンドでVMに入って確認することができる。\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":[]},"/note/Mac%E3%81%A7F8%E3%82%92%E6%8A%BC%E3%81%97%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%ABMusic%E3%82%92%E8%B5%B7%E5%8B%95%E3%81%95%E3%81%9B%E3%81%AA%E3%81%84%E3%82%88%E3%81%86%E3%81%AB%E3%81%99%E3%82%8B":{"title":"MacでF8を押したときにMusicを起動させないようにする","content":"\nたまにF8キー(再生)を誤って押してしまい、Apple Music が立ち上がるので防止したい。\n\n[MacでApple Musicが勝手に立ち上がる問題の対処法](https://zenn.dev/catnose99/scraps/9c9858cc2d9f70)\n\n````shell\nlaunchctl unload -w /System/Library/LaunchAgents/com.apple.rcd.plist\n````\n\n戻すには以下を実行すれば良さそう。\n\n````shell\nlaunchctl load -w /System/Library/LaunchAgents/com.apple.rcd.plist\n````\n\n`launchctl`の`load`と`unload`サブコマンドはレガシーなので、以下のコマンドに置き換えた方が良さそう という意見もあったが、自分の環境(MacBook Air 13-inch, Early 2015, Big Sur 11.5.2)では効かなかった\n\n無効化\n\n````shell\nlaunchctl disable gui/\"$(id -u)\"/com.apple.rcd\nlaunchctl kill SIGTERM gui/\"$(id -u)\"/com.apple.rcd\n````\n\n有効化\n\n````shell\nlaunchctl enable gui/\"$(id -u)\"/com.apple.rcd\nlaunchctl kickstart gui/\"$(id -u)\"/com.apple.rcd\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":[]},"/note/Mac%E3%81%AEdefaults%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89":{"title":"Macのdefaultsコマンド","content":"\n* [システム環境設定をターミナル（defaultsコマンド）から設定する方法（Mission Control） - OTTANXYZ](https://www.ottan.xyz/posts/2016/07/system-preferences-terminal-defaults-mission-control-4656/)\n* [Mac を買ったら必ずやっておきたい初期設定を、全て自動化してみた](https://zenn.dev/ulwlu/articles/1c3a1da12887ed)\n  * \u003chttps://github.com/ulwlu/dotfiles/blob/master/system/macos.sh\u003e\n* \u003chttps://github.com/ryuichi1208/dotfiles/blob/master/mac/macos/.macos\u003e\n\n## 現在の設定をすべて取得する\n\n````shell\n$ defaults read \n\n## domainsを使って書く場合\n$ LOGFILE=defaults_backup.log\n$ defaults domains | sed 's/, /\\n/g' | xargs -I % sh -c 'echo % \u0026\u0026 defaults read %' \u003e $LOGFILE\n$ defaults domains --currentHost | sed 's/, /\\n/g' | xargs -I % sh -c 'echo % \u0026\u0026 defaults read --currentHost %' \u003e\u003e $LOGFILE\n$ echo NSGlobaDomain \u003e\u003e $LOGFILE \u0026\u0026 defaults read NSGlobalDomain \u003e\u003e $LOGFILE\n````\n\n## 特定の設定を見る\n\n````shell\ndefaults read .GlobalPreferences_m\n````\n\n## 設定を書き込む\n\n````shell\n$ defaults write com.apple.dock mru-spaces -bool false\n````\n\n### ショートカットキーの変更\n\nショートカットキーは辞書型になっているので以下のようにする\n\n````shell\n# IME切り替えのショートカットをOFFにする\n$ defaults write com.apple.symbolichotkeys AppleSymbolicHotKeys -dict-add 61 \"\u003cdict\u003e\u003ckey\u003eenabled\u003c/key\u003e\u003cfalse/\u003e\u003c/dict\u003e\"\n# Spotlightを`option + command + space`で呼び出せるようにする\n$ defaults write com.apple.symbolichotkeys AppleSymbolicHotKeys -dict-add 64 \"\u003cdict\u003e\u003ckey\u003eenabled\u003c/key\u003e\u003ctrue/\u003e\u003ckey\u003evalue\u003c/key\u003e\u003cdict\u003e\u003ckey\u003eparameters\u003c/key\u003e\u003carray\u003e\u003cinteger\u003e32\u003c/integer\u003e\u003cinteger\u003e49\u003c/integer\u003e\u003cinteger\u003e1572864\u003c/integer\u003e\u003c/array\u003e\u003ckey\u003etype\u003c/key\u003e\u003cstring\u003estandard\u003c/string\u003e\u003c/dict\u003e\u003c/dict\u003e\"\n````\n\n## 設定をデフォルトに戻す\n\n````shell\n$ defaults delete com.apple.dock mru-spaces\n````\n\n## 設定を反映する\n\ndefaults write だけでは反映されないので、以下のコマンドを実行する\n\n````shell\nkillall Dock\nkillall Finder\nkillall SystemUIServer\n````\n\n## 設定値の見つけ方\n\n公式のドキュメントが見つからないため、自分で探すしかない…。\n方法は、GUIで一つ変更するたびに `defaults read` で取得し、差分をチェックすることでどの設定値が対応しているかを見つける。\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":[]},"/note/Mac%E7%AB%8B%E3%81%A1%E4%B8%8A%E3%81%92%E6%99%82%E3%81%AB%E3%82%A2%E3%83%97%E3%83%AA%E3%81%8C%E8%87%AA%E5%8B%95%E8%B5%B7%E5%8B%95%E3%81%99%E3%82%8B%E3%81%AE%E3%82%92%E9%98%B2%E3%81%90":{"title":"Mac立ち上げ時にアプリが自動起動するのを防ぐ","content":"\n\\#Mac \n\nEAA Clientが自動起動して、オフにする設定もないのでこまった。\n\nlaunchctlに登録されているようなので、それを削除することにした。\n\n````shell\n$ launchctl list | grep eaa\n-       78      net.eaacloop.uninstall\n-       0       net.eaacloop.eaaclient\n28947   0       application.com.akamai-access.go.eaacloop.1207957.1208116\n\n$ cat /Library/LaunchAgents/net.eaacloop.eaaclient.plist\n\u003c!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"\u003e\n\u003cplist version=\"1.0\"\u003e\n  \u003cdict\u003e\n    \u003ckey\u003eLabel\u003c/key\u003e\n    \u003cstring\u003enet.eaacloop.eaaclient\u003c/string\u003e\n    \u003ckey\u003eProgramArguments\u003c/key\u003e\n    \u003carray\u003e\n      \u003cstring\u003e/Applications/EAAClient.app/Contents/MacOS/EAAClient\u003c/string\u003e\n    \u003c/array\u003e\n    \u003ckey\u003eRunAtLoad\u003c/key\u003e\n    \u003ctrue/\u003e\n    \u003ckey\u003eKeepAlive\u003c/key\u003e\n    \u003cfalse/\u003e\n    \u003ckey\u003eversion\u003c/key\u003e\n    \u003cstring\u003e1.0.1\u003c/string\u003e\n    \u003ckey\u003eStandardErrorPath\u003c/key\u003e\n    \u003cstring\u003e/tmp/eaacTraystderr.log\u003c/string\u003e\n    \u003ckey\u003eStandardOutPath\u003c/key\u003e\n    \u003cstring\u003e/tmp/eaacTraystdout.log\u003c/string\u003e\n  \u003c/dict\u003e\n\u003c/plist\u003e\n\n# unloadする\n$ launchctl unload /Library/LaunchAgents/net.eaacloop.eaaclient.plist\n\n# ファイル自体は消えない\n$ ls /Library/LaunchAgents/net.eaacloop.eaaclient.plist\n/Library/LaunchAgents/net.eaacloop.eaaclient.plist*\n\n$ launchctl list | grep eaa\n-       78      net.eaacloop.uninstall\n28947   0       application.com.akamai-access.go.eaacloop.1207957.1208116\n````\n\n=\u003e これではPC再起動するともとに戻ってしまう。\n\nplistファイルを `sudo vim /Library/LaunchAgents/net.eaacloop.eaaclient.plist` で開いて、 `RunAtLoad` をfalseにする。\n\n````plist\n\u003c!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"\u003e\n\u003cplist version=\"1.0\"\u003e\n  \u003cdict\u003e\n    \u003ckey\u003eLabel\u003c/key\u003e\n    \u003cstring\u003enet.eaacloop.eaaclient\u003c/string\u003e\n    \u003ckey\u003eProgramArguments\u003c/key\u003e\n    \u003carray\u003e\n      \u003cstring\u003e/Applications/EAAClient.app/Contents/MacOS/EAAClient\u003c/string\u003e\n    \u003c/array\u003e\n    \u003ckey\u003eRunAtLoad\u003c/key\u003e\n    \u003cfalse/\u003e\n    \u003ckey\u003eKeepAlive\u003c/key\u003e\n    \u003cfalse/\u003e\n    \u003ckey\u003eversion\u003c/key\u003e\n    \u003cstring\u003e1.0.1\u003c/string\u003e\n    \u003ckey\u003eStandardErrorPath\u003c/key\u003e\n    \u003cstring\u003e/tmp/eaacTraystderr.log\u003c/string\u003e\n    \u003ckey\u003eStandardOutPath\u003c/key\u003e\n    \u003cstring\u003e/tmp/eaacTraystdout.log\u003c/string\u003e\n  \u003c/dict\u003e\n\u003c/plist\u003e\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":[]},"/note/Mac-screenshot%E3%81%AE%E4%BF%9D%E5%AD%98%E5%85%88%E3%82%92%E5%A4%89%E3%81%88%E3%81%A6%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%90%8D%E3%82%82%E4%BB%BB%E6%84%8F%E3%81%AE%E5%BD%A2%E5%BC%8F%E3%81%AB%E3%81%99%E3%82%8B":{"title":"Mac screenshotの保存先を変えてファイル名も任意の形式にする","content":"\nMacでスクリーンショットを撮ると、デフォルトではデスクトップに `スクリーンショット [日付] [時刻].png` といった名前で保存されます。\n\nこれはシステム設定に応じてファイル名が日本語になってしまうのと、スペースが入っていて扱いづらいので、なんとかしたいです。\n\n## 方法1 defaultsでファイル名を変更する\n\n[Macのdefaultsコマンド](note/Macのdefaultsコマンド.md) をつかって、名前の規則を変更します\n\nprefixを `screenshot` にする\n\n````shell\ndefaults write com.apple.screencapture name \"screenshot\"\n````\n\n日付、時刻を含めないようにする\n\n````shell\ndefaults write com.apple.screencapture include-date -bool false\n````\n\nただこれだと、`screenshot.png` `screenshot 1.png` のように2枚目以降連番がつくようになるので、日付時刻はスペースが入らない形で含めるようにしたいです。\nそこで次のようにしました\n\n## 方法2 Automatorを使って作成されたファイルの名前を変更する\n\n[Automator](note/Automator.md) の [Folder Action](https://macosxautomation.com/automator/folder-action/index.html) を使って、指定したフォルダに作成されたファイルを自動でリネームします。\n\nデスクトップのままだと、デスクトップに作成したファイルすべてが影響を受けるので、スクリーンショットの保存先を指定します。\n\n````shell\n# 保存先は任意です\ndefaults write com.apple.screencapture location -string \"~/Pictures/screenshot\"\n````\n\nAutomatorで次のようにして、screenshotディレクトリに作成されたファイルを `screenshot-yyyyMMddHHmmss.png` にします。\n\n![](note/Pasted-image-20230509115147.png)\n\n![](note/Pasted-image-20230509115129.png)\n\nこれでスクリーンショットを撮ると、自動でリネームされるようになります。\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/05/09","Mac"]},"/note/Make":{"title":"Make","content":"\nプログラムを実行可能にするためにソースコードをコンパイルして、外部のライブラリなどをリンクして一つの実行ファイルにする作業など、複数個のコマンドを連続して実行することがある。\nこうした作業を繰り返し行う場合に、手作業の工程をへらすため、makeコマンドで一連の手順を所定の形式でMakefileに記述しておくと、これに従ってコマンド実行などを連続して自動的に行なってくれる\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["CLI"]},"/note/MinIO":{"title":"MinIO","content":"\n{{\u003c card-link \"https://min.io\" \u003e}}\n\nS3と互換性のあるオブジェクトストレージサーバー。\n開発時にローカルでMinIOを立てて検証するのに利用できる。\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/07/04"]},"/note/MinIO%E3%82%92%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB%E3%81%AEkubernetes%E3%81%A7%E5%8B%95%E3%81%8B%E3%81%99":{"title":"MinIOをローカルのkubernetesで動かす","content":"\n[MinIO](note/MinIO.md) を [Kubernetes](note/Kubernetes.md) で動かしたい。\n\n環境は、 [Rancher Desktop](note/Rancher%20Desktop.md) のKubernetes\n\n## manifestをapplyする\n\nhttps://min.io/docs/minio/kubernetes/upstream/index.html\n\n````shell\ncurl https://raw.githubusercontent.com/minio/docs/master/source/extra/examples/minio-dev.yaml -O\n````\n\n* `spec.volumes[0].hostPath.path` を任意のローカルのパスにする\n* `spec.nodeSelector` を `kubernetes.io/os: linux` にする\n\n````shell\nkubectl apply -f minio-dev.yaml\n````\n\nローカルから疎通できるようにする\n\n````shell\nkubectl port-forward pod/minio 9000 9090 -n minio-dev\n````\n\n=\u003e localhost:9000 でコンソールが開いた。\n\nできたけどpod間通信のためにservice作ったりするのが面倒そうなので、helmにしてみる\n\n## helmでデプロイする\n\nMinIOのカスタムリソースを管理するOperatorと、オブジェクトを格納するTenantに分かれているので、まずOperatorをインストールする。\n\n{{\u003c card-link \"https://github.com/minio/operator/blob/master/helm/operator/README.md\" \u003e}}\n\n次にtenantを入れる。\n\n{{\u003c card-link \"https://github.com/minio/operator/blob/master/helm/tenant/README.md\" \u003e}}\n\nデフォルトのstorageClassNameがローカルでは存在しなかったので、values.yamlを書いてカスタマイズする。\n\nvalues_tenant.yaml\n\n````yaml\ntenant:\n  pools:\n    ## Servers specifies the number of MinIO Tenant Pods / Servers in this pool.\n    ## For standalone mode, supply 1. For distributed mode, supply 4 or more.\n    ## Note that the operator does not support upgrading from standalone to distributed mode.\n    - servers: 4\n      ## custom name for the pool\n      name: pool-0\n      ## volumesPerServer specifies the number of volumes attached per MinIO Tenant Pod / Server.\n      volumesPerServer: 4\n      ## size specifies the capacity per volume\n      size: 10Gi\n      ## storageClass specifies the storage class name to be used for this pool\n      storageClassName: local-path\n      ## Used to specify annotations for pods\n      annotations: { }\n      ## Used to specify labels for pods\n      labels: { }\n      ## Used to specify a toleration for a pod\n      tolerations: [ ]\n      ## nodeSelector parameters for MinIO Pods. It specifies a map of key-value pairs. For the pod to be\n      ## eligible to run on a node, the node must have each of the\n      ## indicated key-value pairs as labels.\n      ## Read more here: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n      nodeSelector: { }\n      ## Affinity settings for MinIO pods. Read more about affinity\n      ## here: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity.\n      affinity: { }\n      ## Configure resource requests and limits for MinIO containers\n      resources: { }\n      ## Configure security context\n      securityContext:\n        runAsUser: 1000\n        runAsGroup: 1000\n        fsGroup: 1000\n        runAsNonRoot: true\n      ## Configure container security context\n      containerSecurityContext:\n        runAsUser: 1000\n        runAsGroup: 1000\n        runAsNonRoot: true\n      ## Configure topology constraints\n      topologySpreadConstraints: [ ]\n      ## Configure Runtime Class\n      # runtimeClassName: \"\"\n````\n\n````shell\nhelm install --namespace tenant-ns -f values_tenant.yaml --create-namespace tenant minio/tenant\n\nkubectl --namespace tenant-ns port-forward svc/myminio-console 19443:9443\n````\n\n=\u003e https://localhost:19443 でコンソールが開く\nusername:passwordは、デフォルトで `minio:minio123`\n\n## aws cliでs3に接続する\n\naws-cliのPodを作成して、中からminioにアクセスしてみる。\nminioのエンドポイントは、`kubectl logs` でtenantのpodのログに出力されているのを確認する。\n`myminio-pool-0-2 minio {\"level\":\"INFO\",\"errKind\":\"\",\"time\":\"2023-07-04T03:09:43.126781416Z\",\"message\":\"S3-API: https://minio.tenant-ns.svc.cluster.local \"}`\n\n````shell\nkubectl run awscli -it --rm --image amazon/aws-cli --env=AWS_ACCESS_KEY_ID=minio --env=AWS_SECRET_ACCESS_KEY=minio123 --command -- sh\n\nsh-4.2$ aws --endpoint-url https://minio.tenant-ns.svc.cluster.local --no-verify-ssl s3 ls\nurllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio.tenant-ns.svc.cluster.local'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n\nsh-4.2$ aws --endpoint-url https://minio.tenant-ns.svc.cluster.local --no-verify-ssl s3 mb s3://my-bucket\nurllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio.tenant-ns.svc.cluster.local'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\nmake_bucket: my-bucket\n\nsh-4.2$ aws --endpoint-url https://minio.tenant-ns.svc.cluster.local --no-verify-ssl s3 ls\nurllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'minio.tenant-ns.svc.cluster.local'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n2023-07-04 03:54:53 my-bucket\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/07/04","Kubernetes"]},"/note/Mistel-BAROCCO-md650l":{"title":"Mistel BAROCCO md650l","content":"\n2019年3月に買った\n左右分離型キーボード\nロープロファイルでCherry MX\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/01/05","keyboard"]},"/note/NatureRemo":{"title":"NatureRemo","content":"\n# 2020-11-18 Nature Remo Go 勉強会\n\n## シングルバイナリにこだわる (@fujiwara)\n\n* Go で Lambda\n  * ランタイムの寿命に影響されにくい\n  * 起動が早い\n* LambdaでもCLIでも動く一個のバイナリを置いておきたい\n* `AWS_EXECUTION_ENV` の環境変数があるかどうかで判別\n* Lambdaでは起動時にコマンドライン引数を指定できないのでflagは環境変数でも指定できるようにしておく\n* Lambdaでもそうでない環境でも動くようにしておくとEC2への移植性が高まる\n\n## fluct事例 (@suzu_v)\n\n* スループット\n* ちょっとビルド・テストをしやすくしたいときにGoがちょうどいい\n\n## Nature Remo (@songmu)\n\n* github.com/Songmu/gotesplit\n* CIのテスト並列実行をかんたんに実現\n\n## Goのメリット・デメリット\n\n* HTMLを返すのは向いてない\n* JSON、HTTP、ログ出力とかはむいてる、HTML以外だったらだいたい合ってる\n* バイナリが必要なのでスクリプト的使い方はしづらい\n* goroutine使っても並行処理は大変\n* 非同期処理やりやすいしやりたくなっちゃうけど、レビュー大変なので落とし所とか局所的につかうとかが大事\n* code generationしたりtypeでswitchしたり泥臭い部分は多くなっちゃう\n\n## 開発周り\n\n* vim,vscode,ideaなんでも\n* gopls,gofmtあるからどうにでもなる\n\n## パッケージ・アーキテクチャ\n\n* パッケージ粒度\n  * 名前がしっくりくるかくらい\n  * ライブラリとして独立できそうかくらいでパッケージ切ってる\n  * loggerはログ用のパッケージで独立したほうがいいなとか\n* あんまりしっかりわけてない\n* 最初からわけるとわけすぎたってなっちゃうこともある、最初から分けておいてそれ以上わけない\n* package.run を本体として、main.mainからはそれだけ呼ぶみたいにしてる\n\n## バージョン\n\n* 随時上げちゃう\n* CI通ればいいでしょ、上げて壊れることはほとんどない\n* go mod 入って移さなきゃなーみたいなのはあっても\n* 盲目的に上げる、大きい変更だったら話題になる、release partyみたいのでわかる\n\n## 今後Goに期待すること\n\n* けっこうバランスがいいので新機能はそんなに\n* embedはいい\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Go","meetup"]},"/note/Neovim":{"title":"Neovim","content":"\n[Vim](note/Vim.md)  のフォークであり、モダンな開発環境に適した多くの新機能を提供している。\nNeovimはVimよりも柔軟性や拡張性が高い。\nまた、Neovimはマルチプロセスアーキテクチャを採用しており、Vimよりも高速で、より大規模なプロジェクトに対応できるようになっている\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Neovim"]},"/note/Neovim%E3%81%A8VSCode%E3%81%A7%E5%85%B1%E5%AD%98%E3%81%99%E3%82%8B":{"title":"NeovimとVSCodeで共存する","content":"\n\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Draft","Neovim","vscode"]},"/note/Neovim%E3%81%AE%E8%A8%AD%E5%AE%9A%E3%82%92lua%E3%81%AB%E7%A7%BB%E8%A1%8C%E3%81%99%E3%82%8B":{"title":"Neovimの設定をluaに移行する","content":"\n[Neovim](note/Neovim.md) 0.5からは `init.lua` にlua言語で書くことができるようになっている。\n最近のpluginの説明文を見るとluaで書かれていることが増えてきた。\n\nplugin managerは [packer.nvim](https://github.com/wbthomason/packer.nvim) がメジャーらしい\n\n[wezterm](note/wezterm.md) の設定もluaで書いているし、なんとなく今風な気がするのでluaに移行してみようとおもう\n\n* \u003chttps://github.com/willelz/nvim-lua-guide-ja/blob/master/README.ja.md\u003e\n* [Neovim プラグインを（ほぼ）全て Lua に移行した](https://zenn.dev/acro5piano/articles/c764669236eb0f)\n\n## 概要\n\n[NeovimとLua](https://zenn.dev/hituzi_no_sippo/articles/871c06cdbc45b53181e3)\n\n[Vimconf.live: Why is Lua a good fit for Neovim - YouTube](https://www.youtube.com/watch?v=IP3J56sKtn0)\n\n* 簡単  \n  Luaの学習コストは低く、誰でもすぐ書けます。\n* Luaのサイズが小さい  \n  バイナリサイズ（linux用）は200KB以下です。\n* 移植性  \n  ISO Cで実装されているため、OS Kernel内でもLuaは実行できます。\n* 埋め込みに適している。  \n  Vim scriptからLuaの関数を呼び出すことができます。その逆もできます。\n* Vim scriptよりスピードが早い  \n  Vim scriptなら約5.5秒かかる処理をLua(LuaJIT)は約0.003秒で処理します。\n\nVim scriptよりは書きやすいっぽい。Vim script書いたことないけど\n\n* 複数行文字列\n\n````lua\n[[\n  augroup packer_user_config\n    autocmd!\n    autocmd BufWritePost plugins.lua source \u003cafile\u003e | PackerSync\n  augroup end\n]]\n````\n\nオプションやキーマップを関数で書ける\n\n## \u003chttps://github.com/nanotee/nvim-lua-guide\u003e で勉強する\n\n* `require('modules/mymodule')` で、`./modules/mymodule.lua` をロードできる\n* luado\n\n````vim\n:luado return 'hello world'\n````\n\nとすると現在のbufferにテキストが挿入される\n\n````vim\n:luado if linenr % 2 == 0 then return line:upper() end\n````\n\nで、偶数行が大文字になる\n\n* `:luafile %` でカレントバッファをluaで実行する\n\n### vim名前空間\n\n* LuaからNeovimのAPIを使うためのエントリーポイントとして、vimグローバル変数を公開している\n  * `vim.inspect`: Luaオブジェクトを人間が読みやすい文字列に変換する(テーブルを調べるのに便利です。)\n  * `vim.regex`: LuaからVimの正規表現を使う\n* `vim.nvim_exec('%s/\\\\Vfoo/bar/g')` のようにして、vim scriptを実行できる\n\n### vim option\n\n* `vim.api.nvim_set_option()`, `vim.api.nvim_get_option()` などで読み書きできる\n* `vim.opt.{option}`: `:set`のように動作します\n* `vim.opt_global.{option}`: `:setglobal`のように動作します\n* `vim.opt_local.{option}`: `:setlocal`のように動作します\n\n### vim variable\n\n* Global variables (`g:`):\n  * [`vim.api.nvim_set_var()`](https://neovim.io/doc/user/api.html#nvim_set_var())\n  * [`vim.api.nvim_get_var()`](https://neovim.io/doc/user/api.html#nvim_get_var())\n  * [`vim.api.nvim_del_var()`](https://neovim.io/doc/user/api.html#nvim_del_var())\n\nLocal variables (l:), script variables (s:) and function arguments (a:) はVim script特有のスコープで、Luaは独自のスコープを持っているので使わない\n\n* `vim.g`: global variables\n* `vim.b`: buffer variables\n* `vim.w`: window variables\n* `vim.t`: tabpage variables\n* `vim.v`: predefined Vim variables\n* `vim.env`: environment varia\n\n### call Vimscript functions\n\n`vim.fn.{funcion}()` でVimscript functionを呼ぶ\n\n例: `print(vim.fn.printf('Hello from %s', 'Lua'))`\n\n### keymap\n\n* グローバルマッピング:\n  * [`vim.api.nvim_set_keymap()`](https://neovim.io/doc/user/api.html#nvim_set_keymap())\n  * [`vim.api.nvim_get_keymap()`](https://neovim.io/doc/user/api.html#nvim_get_keymap())\n  * [`vim.api.nvim_del_keymap()`](https://neovim.io/doc/user/api.html#nvim_del_keymap())\n\n例: `vim.api.nvim_set_keymap('n', '\u003cLeader\u003e\u003cSpace\u003e', ':set hlsearch!\u003cCR\u003e', { noremap = true, silent = true })`\n\nNeovim provides two functions to set/del mappings:\n\n* `vim.keymap.set()`\n* `vim.keymap.del()`\n\n````lua\nvim.keymap.set('n', '\u003cLeader\u003eex1', '\u003cCmd\u003elua vim.notify(\"Example 1\")\u003cCR\u003e')\nvim.keymap.set({'n', 'c'}, '\u003cLeader\u003eex2', '\u003cCmd\u003elua vim.notify(\"Example 2\")\u003cCR\u003e')\n````\n\n### user commands\n\n* Global user commands:\n  * [`vim.api.nvim_create_user_command()`](https://neovim.io/doc/user/api.html#nvim_create_user_command())\n  * [`vim.api.nvim_del_user_command()`](https://neovim.io/doc/user/api.html#nvim_del_user_command())\n\n## 参考にしたもの\n\n* [GitHub - NvChad/NvChad: An attempt to make neovim cli functional like an IDE while being very beautiful, blazing fast startuptime ~ 14ms to 67ms](https://github.com/NvChad/NvChad)\n* [GitHub - LunarVim/nvim-basic-ide: This is my attempt at a basic stable starting point for a Neovim IDE.](https://github.com/LunarVim/nvim-basic-ide)\n  * \n     \u003e \n     \u003e A Basic Stable IDE config for Neovim\n  \n  * Neovim初心者がIDEっぽい動きをさせるように便利なテンプレ\n  * \u003chttps://github.com/hisasann/neovim\u003e\n    * この人の設定が上をベースにわかりやすくなってたので真似させてもらった\n\n## 変更点\n\n### functionの書き方\n\n````lua\nfunction ToggleQuickFix()\n  if vim.fn.empty(vim.fn.filter(vim.fn.getwininfo(), \"v:val.quickfix\")) == 1 then\n    vim.cmd([[copen]])\n  else\n    vim.cmd([[cclose]])\n  end\nend\n\n-- :ToggleQuickFix で使えるようにする\nvim.cmd([[command! -nargs=0 -bar ToggleQuickFix lua require('utils').ToggleQuickFix()]])\n\n-- keymapに設定する\nvim.keymap.set(\"n\", \"\u003cLeader\u003eq\", ToggleQuickFix)\n````\n\n### plugin\n\nluaで書かれたpluginに移行した\n\n* [GitHub - wbthomason/packer.nvim: A use-package inspired plugin manager for Neovim. Uses native packages, supports Luarocks dependencies, written in Lua, allows for expressive config](https://github.com/wbthomason/packer.nvim)\n  * Neovimのplugin managerのデファクト\n* [GitHub - phaazon/hop.nvim: Neovim motions on speed!](https://github.com/phaazon/hop.nvim)\n  * easymotionをluaで書き直したもの\n* [GitHub - kylechui/nvim-surround: Add/change/delete surrounding delimiter pairs with ease. Written with in Lua.](https://github.com/kylechui/nvim-surround)\n  * surroundとかsandwichのようなもの\n* [GitHub - kyazdani42/nvim-tree.lua: A file explorer tree for neovim written in lua](https://github.com/kyazdani42/nvim-tree.lua)\n  * file explorer\n* [GitHub - nvim-lualine/lualine.nvim: A blazing fast and easy to configure neovim statusline plugin written in pure lua.](https://github.com/nvim-lualine/lualine.nvim)\n  * statuslineカスタマイズ\n* [GitHub - lukas-reineke/indent-blankline.nvim: Indent guides for Neovim](https://github.com/lukas-reineke/indent-blankline.nvim)\n  * indentline\n* [GitHub - RRethy/vim-illuminate: illuminate.vim - Vim plugin for automatically highlighting other uses of the word under the cursor. Integrates with Neovim's LSP client for intelligent highlighting.](https://github.com/RRethy/vim-illuminate)\n  * highlightをつける\n\n### colorscheme\n\n* [GitHub - EdenEast/nightfox.nvim: 🦊A highly customizable theme for vim and neovim with support for lsp, treesitter and a variety of plugins.](https://github.com/EdenEast/nightfox.nvim)\n* [GitHub - ellisonleao/gruvbox.nvim: Lua port of the most famous vim colorscheme](https://github.com/ellisonleao/gruvbox.nvim)\n\n### LSP\n\n[Neovim+LSPをなるべく簡単な設定で構築する](https://zenn.dev/botamotch/articles/21073d78bc68bf)\n\n* [neovim/nvim-lspconfig](https://github.com/neovim/nvim-lspconfig)（LSP設定）\n* [williamboman/mason.nvim](https://github.com/williamboman/mason.nvim)（LSPサーバー管理）\n  * [williamboman/mason-lspconfig.nvim](https://github.com/williamboman/mason-lspconfig.nvim)\n* [hrsh7th/nvim-cmp](https://github.com/hrsh7th/nvim-cmp)（補完）\n  * [hrsh7th/cmp-nvim-lsp](https://github.com/hrsh7th/cmp-nvim-lsp)\n\n## 結果\n\n* 起動が200ms -\u003e 100ms未満になった\n* colorschemeをnightfoxにした\n* nvim-cmpやnvim-lspに変えて、補完の見た目がかっこよくなった\n\n![Pasted-image-20220813171640](note/Pasted-image-20220813171640.png)\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Neovim"]},"/note/NerdFonts%E3%81%A8%E3%81%AF":{"title":"NerdFontsとは","content":"\n[nerd-fonts/readme_ja.md at master · ryanoasis/nerd-fonts](https://github.com/ryanoasis/nerd-fonts/blob/master/readme_ja.md#:~:text=Nerd%20Fonts%20%E3%81%AF%E3%80%81%E3%81%9F%E3%81%8F%E3%81%95%E3%82%93%E3%81%AE,%E3%82%92%E7%9B%AE%E7%9A%84%E3%81%A8%E3%81%97%E3%81%A6%E3%81%84%E3%81%BE%E3%81%99%E3%80%82)\n\n \u003e \n \u003e **Nerd Fonts** は、たくさんのグリフ (アイコン) を開発者向けのフォントに追加するためのプロジェクトです。とりわけ、著名な「アイコンフォント」からたくさんのグリフを追加することを目的としています。\n \u003e 例えば以下のようなフォントです: [Font Awesome ➶](https://github.com/FortAwesome/Font-Awesome), [Devicons ➶](https://vorillaz.github.io/devicons/), [Octicons ➶](https://github.com/primer/octicons), [その他](https://github.com/ryanoasis/nerd-fonts/blob/master/readme_ja.md#%E3%82%B0%E3%83%AA%E3%83%95%E3%82%BB%E3%83%83%E3%83%88).\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["font"]},"/note/Netlify":{"title":"Netlify","content":"\nNetlifyは、静的サイトをホスティングすることができるWebサービス。\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["frontend","blog"]},"/note/Netlify%E3%81%A8GitHub%E3%81%A7%E9%9D%99%E7%9A%84%E3%82%B5%E3%82%A4%E3%83%88%E3%82%92%E5%85%AC%E9%96%8B%E3%81%99%E3%82%8B":{"title":"NetlifyとGitHubで静的サイトを公開する","content":"\n## Netlifyの初期設定とデプロイ\n\n[Netlify](note/Netlify.md) にアカウント作成、ログイン(特に難しい手順はないので割愛)\n\n### GitHubとの連携\n\nGitHubと連携する場合、Netlifyのアカウント設定でGitHubアカウントと連携しておく\n\n1. \u003chttps://app.netlify.com/\u003e から `New site from Git` をクリック\n1. `Continuous Deployment` で GitHubを選択\n1. 公開対象リポジトリを選択\n1. 対象ブランチ、デプロイ時に実行するbuildコマンド、公開対象のディレクトリを設定\n1. `Deploy Site` をクリックするとデプロイされる\n\n### サイト名変更\n\nSite Settings \u003e General \u003e Change site name で変更\n\n### サイト更新\n\n設定したブランチにpushすると自動で更新される\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["blog","frontend"]},"/note/Node.js-Docker-build%E3%81%AE%E3%83%99%E3%82%B9%E3%83%88%E3%83%97%E3%83%A9%E3%82%AF%E3%83%86%E3%82%A3%E3%82%B9":{"title":"Node.js Docker buildのベストプラクティス","content":"\n\\#Nodejs #Docker \n\n[Node.jsのDockerfile作成のベストプラクティス](https://zenn.dev/kouchanne/articles/6485193823ecec5735d4)\n[DockerでNode.jsを動かすときのベストプラクティス](https://blog.shinonome.io/nodejs-docker/)\n\n* マルチステージビルド\n* `npm ci --production` を使う\n* [distroless/nodejs](https://github.com/GoogleContainerTools/distroless/blob/main/nodejs/README.md) を使う\n* `tini` を使い、`npm` ではなく `node` コマンドで起動してSIGTERMのシグナルが伝播するようにする\n* USERをroot以外にする\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":[]},"/note/Node.js-npm-install%E3%82%92%E6%97%A9%E3%81%8F%E3%81%97%E3%81%9F%E3%81%84":{"title":"Node.js npm installを早くしたい","content":"\n\\#Nodejs #Docker\n\n## 依存関係解決を早くしたい\n\n`npm ci` を使う\n\n[CI/CDでnpm ciする際は ~/.npm をキャッシュしよう | DevelopersIO](https://dev.classmethod.jp/articles/cicd-npm-ci-cache/)\n[npm ciを使おう あるいはより速く - Qiita](https://qiita.com/mstssk/items/8759c71f328cab802670)\n\n* `package-lock.json` のみを見て依存関係解決する(`npm install` は `package.json` も見る)\n* `npm ci` では `node_modules` は実行の都度洗い替えされる\n\n更に `npm ci --production` とすると `devDependency` のインストールが行われなくなる。\n`--production` や `--only=production` はnpm v8ではdeprecatedで、 `--omit=dev` を使う。\n\n## パッケージをキャッシュしてビルドを早くしたい\n\n`npm ci` を使うと、デフォルトでは `~/.npm` にキャッシュが作られる。\nCIサーバー上などで `~/.npm` にアクセスできない場合はcacheのpathを変更する。\n\n* `--cache \u003cpath\u003e` オプションをつける\n* `npm config set cache \u003cpath\u003e` でグローバルに設定する\n\n[node.js - Is there a way to speedup npm ci using cache? - Stack Overflow](https://stackoverflow.com/questions/55230628/is-there-a-way-to-speedup-npm-ci-using-cache)\n\u003chttps://docs.npmjs.com/cli/v8/commands/npm-cache\u003e\n\nキャッシュを使うには、 `--prefer-offline` をつける(キャッシュにない場合は取得される)\n\u003chttps://docs.npmjs.com/cli/v8/using-npm/config#prefer-offline\u003e\n\n## 結論\n\nこちらのコマンドでインストールすると次回以降もキャッシュが効くようになる\n\n````shell\nnpm ci --omit=dev --prefer-offline --cache /path/to/npm_cache/\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Nodejs","Docker"]},"/note/Nodebrew%E3%81%A7Node.js%E3%81%AE%E3%83%90%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%E3%82%92%E7%AE%A1%E7%90%86%E3%81%99%E3%82%8B":{"title":"NodebrewでNode.jsのバージョンを管理する","content":"\n\\#Nodejs\n\nプロジェクト間でNode.jsのバージョンが違う場合に、ひとつのPC内で複数のNode.jsバージョンを使い分けたいことがある。\nそんなときに [Nodebrew](https://github.com/hokaccha/nodebrew) や [nvm](https://github.com/nvm-sh/nvm) を使う\n\nGitHubのスター数的には圧倒的にnvmが人気のようだが使ったことがないのでNodebrewの使い方を紹介する\n\nMacのインストール手順となる\n\n### インストール\n\n````shell\n$ brew install nodebrew\n````\n\n### PATHに追加する\n\n`.bashrc` や `.zshrc` に追記する\n\n````shell\nexport PATH=$HOME/.nodebrew/current/bin:$PATH\n````\n\nthen reload\n\n````shell\n$ source ~/.bashrc\n````\n\n### 使いたいバージョンのNode.jsをインストール\n\n````shell\n$ nodebrew ls-remote\n=\u003e 利用できるNode.jsバージョンの一覧\n$ nodebrew install-binary \u003cversion\u003e\n$ nodebrew use \u003cversion\u003e\n$ node -v\n=\u003e インストールしたNode.jsのバージョンが表示\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Nodejs"]},"/note/Noto-Sans-JP":{"title":"Noto Sans JP","content":"\n\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["font"]},"/note/Nuxt-Bridge":{"title":"Nuxt Bridge","content":"\n\\#Nuxtjs\n\n\u003chttps://v3.nuxtjs.org/getting-started/bridge/\u003e\n\n|Feature / Version|Nuxt 2|Nuxt Bridge|Nuxt 3|\n|-----------------|------|-----------|------|\n|Vue|2|2|3|\n|Stability|😊 Stable|😌 Semi-stable|😬 Unstable|\n|Performance|🏎 Fast|✈️ Faster|🚀 Fastest|\n|Nitro Engine|❌|✅|✅|\n|ESM support|🌙 Partial|👍 Better|✅|\n|TypeScript|☑️ Opt-in|🚧 Partial|✅|\n|Composition API|❌|🚧 Partial|✅|\n|Options API|✅|✅|✅|\n|Components Auto Import|✅|✅|✅|\n|`\u003cscript setup\u003e` syntax|❌|🚧 Partial|✅|\n|Auto Imports|❌|✅|✅|\n|Webpack|4|4|5|\n|Vite|⚠️ Partial|🚧 Partial|🚧 Experimental|\n|Nuxi CLI|❌ Old|✅ nuxi|✅ nuxi|\n|Static sites|✅|✅|🚧|\n\nNuxt2をNuxt3にアップデートする準備をするためのバージョン\nVue2を使いつつ、部分的にNuxt3の機能を使えるようにして漸次的にアップデートできるようにする\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Nuxtjs"]},"/note/Nuxt-Bridge%E3%81%A7tailwindcss%E3%82%92%E4%BD%BF%E3%81%86":{"title":"Nuxt Bridgeでtailwindcssを使う","content":"\n\\#Nuxtjs\n\nNuxt2を使っているプロジェクトに、[Nuxt Bridge](note/Nuxt%20Bridge.md) をインストールすると [TailwindCSS](note/TailwindCSS.md) がうまく動かなかったのでメモを残します。\n\n## Nuxt 2に `@nuxtjs/tailwindcss` を入れる\n\n[こちら](https://tailwindcss.com/docs/guides/nuxtjs)でpostcss、autoprefixerなどを自分で入れてもいいですが、楽をするためnuxtjsのモジュールを使いました。\n\nhttps://tailwindcss.nuxtjs.org\n\n````shell\n$ npm install -D @nuxtjs/tailwindcss\n$ npx tailwindcss init\n$ cat tailwind.config.js\nmodule.exports = {\n  content: [],\n  theme: {\n    extend: {},\n  },\n  plugins: [],\n}\n````\n\n````css:assets/css/tailwind.css\n@tailwind base;\n@tailwind components;\n@tailwind utilities;\n````\n\n````js:nuxt.config.js\n   buildModules: [\n     '@nuxt/typescript-build',\n+    '@nuxtjs/tailwindcss',\n   ],\n````\n\n## [Nuxt Bridge](note/Nuxt%20Bridge.md) にアップデートする\n\n基本は https://v3.nuxtjs.org/getting-started/bridge/ に沿って行います。適宜yarnに読み替えてください。\n\n`package.json` を書き換えて `nuxt-edge` に上げて、lockファイルを消したあと `npm install` を実行する\n\n````json:package.json\n- \"nuxt\": \"^2.15.0\"\n+ \"nuxt-edge\": \"latest\"\n````\n\n[Nuxt Bridge](note/Nuxt%20Bridge.md) をインストールする\n\n````shell\n$ npm install -D @nuxt/bridge@npm:@nuxt/bridge-edge\n````\n\nnpm scriptをNuxt CLIのコマンド `nuxi`  に書き換える\n\n````json:package.json\n{\n  \"scripts\": {\n    \"dev\": \"nuxi dev\",\n    \"build\": \"nuxi build\",\n    \"start\": \"nuxi preview\"\n  }\n}\n````\n\n次に `nuxt.config` を書き換えるよう指示されていますが、こちらを行ったところ `npm run dev` 実行時に次のようなエラーで起動しなくなりました。\n\nhttps://github.com/nuxt/framework/issues/1697\n\n````\n[worker] Named export 'isWindows' not found. The requested module 'std-env' is a CommonJS module, which may not support all module.exports as named exports.\nCommonJS modules can always be imported via the default export, for example using:\n````\n\n \u003e \n \u003e Please make sure to avoid any CommonJS syntax such as `module.exports`, `require` or `require.resolve` in your config file. It will soon be deprecated and unsupported.\n\nとありますが、一旦こちらは行わないこととします。 `export default` でも同様だったため、CommonJSに書き換えます。\n\n````js:nuxt.config.js\nmodule.exports = {\n    // ...\n}\n````\n\n### `tsconfig.json` に追加\n\n````json:tsconfig.json\n{\n+ \"extends\": \"./.nuxt/tsconfig.json\",\n  \"compilerOptions\": {\n    ...\n  }\n}\n````\n\n### 互換性のない、廃止されたモジュールを削除する\n\n以下を削除、移行するよう指示されています。\n\n* @nuxt/content (1.x)\n* nuxt-vite\n* @nuxt/typescript-build\n* @nuxt/typescript-runtime and nuxt-ts\n* @nuxt/nitro\n* @vue/composition-api\n* @nuxtjs/composition-api \n\n````js:nuxt.config.js\n   buildModules: [\n-    '@nuxt/typescript-build',\n     '@nuxtjs/tailwindcss',\n],\n````\n\n### 起動！…しない\n\nここまでで一通り移行手順は踏めたので、一度 `npm run dev` します。\n\n`require() of ES Module [...] is not supported` のようなエラーがでて起動しませんでした。\n\n### 'std-env' is a CommonJS module\n\n````\n WARN  [worker] Named export 'isWindows' not found. The requested module 'std-env' is a CommonJS module, which may not support all module.exports as named exports.  12:18:27\nCommonJS modules can always be imported via the default export, for example using:\n\nimport pkg from 'std-env';\nconst { provider, isWindows } = pkg;\n\n\n  import { provider, isWindows } from 'std-env';\n  ^^^^^^^^^\n  SyntaxError: Named export 'isWindows' not found. The requested module 'std-env' is a CommonJS module, which may not support all module.exports as named exports.\n  CommonJS modules can always be imported via the default export, for example using:\n\n  import pkg from 'std-env';\n  const { provider, isWindows } = pkg;\n````\n\nhttps://github.com/nuxt/framework/issues/2026\n\n### node-fetchをダウングレードする\n\nhttps://stackoverflow.com/questions/70541068/instead-change-the-require-of-index-js-to-a-dynamic-import-which-is-available\n\nv3に上がったことでCommonJSの記法が使えなくなった。\nあえてv2を入れます。\n\n````shell\n$ npm i node-fetch@2\n````\n\n## 所感\n\nビルドが30秒くらいかかるようになりました。\nNuxt3だと5秒くらいだから遅く感じるけどまあ今までと比べると早いです\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Nuxtjs"]},"/note/Nuxt.js":{"title":"Nuxt.js","content":"\n\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Nuxtjs","Vuejs"]},"/note/Nuxt.js%E3%81%A7RepositoryFactory%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E3%82%92%E5%AE%9F%E8%A3%85%E3%81%99%E3%82%8B":{"title":"Nuxt.jsでRepositoryFactoryパターンを実装する","content":"\n[【フォースタ テックブログ】RepositoryFactoryパターンをVueのAPIリクエストに導入する - for Startups Tech blog](https://tech.forstartups.com/entry/2021/07/27/194946)\n[Nuxt.js × typescriptで実装する api repositoryFactoryパターン | スマートショッピング](https://tech.smartshopping.co.jp/nuxt_typescript_repository_pattern)\n[【Vue.js】Web API通信のデザインパターン (個人的ベストプラクティス) - Qiita](https://qiita.com/07JP27/items/0923cbe3b6435c19d761)\n\n## RepositoryFactoryパターンとは\n\nAPIを呼び出す設計のデザインパターンとして、JorgeというVueエヴァンジェリストによって紹介された。\n[Vue API calls in a smart way](https://medium.com/canariasjs/vue-api-calls-in-a-smart-way-8d521812c322)\n\n* Repositoryによって、axiosインスタンスをコンポーネントに直接書くのを避けることができる\n  * データの操作をビジネスロジックと分離する\n  * エンドポイントの変更に強くなる\n  * 再利用性が高まる\n* Factoryによって、各ケースで必要なリポジトリをインスタンス化する\n  * コンポーネントはRepositoryの実体化の方法を知らなくていい\n  * テストのためのmockがしやすくなる\n\n## 準備\n\n````typescript:~/plugins/repository-api.ts\nimport { Context } from '@nuxt/types'\nimport { Inject, Plugin } from '@nuxt/types/app'\nimport {\n  UserRepository,\n} from '~/repositories/api'\n\n/**\n * APIリクエストのインターフェース\n * グローバルに$repositoriesで呼び出すことができる\n * unit testのときはrepositoriesを差し替えることでmock可能\n */\nexport interface RepositoryApis {\n  user: UserRepository\n}\n\nconst plugin: Plugin = ({ $axios, $config }: Context, inject: Inject) =\u003e {\n  const user = new UserRepository($axios)\n\n  const repositories: RepositoryApis = {\n    user,\n  }\n  inject('repositories', repositories)\n}\n\nexport default plugin\n````\n\n````typescript:nuxt.config.ts\nimport { NuxtConfig } from '@nuxt/types'\n\nconst config: NuxtConfig = {\n    \n  // ...\n  plugins: [\n    '~/plugins/repository-api',\n  ],\n\n}\n\nexport default config\n\n````\n\n````typescript:@types/vue-shim.d.ts\nimport { NuxtAxiosInstance } from '@nuxtjs/axios'\nimport { Consola } from 'consola'\nimport { Store } from 'vuex'\nimport { RepositoryApis } from '~/plugins/repository-api'\n\n// axios, consola は関係ないが使うので入れておくとしたらこんな書き方\ndeclare module 'vue/types/vue' {\n  export interface Context {\n    $axios: NuxtAxiosInstance\n    $logger: Consola\n    $repositories: RepositoryApis\n  }\n  interface Vue {\n    $logger: Consola\n    $repositories: RepositoryApis\n  }\n}\n\ndeclare module '@nuxt/types' {\n  export interface Context {\n    $axios: NuxtAxiosInstance\n    $logger: Consola\n    $repositories: RepositoryApis\n  }\n  interface NuxtAppOptions {\n    $logger: Consola\n    $repositories: RepositoryApis\n  }\n}\n\ndeclare module 'vuex/types' {\n  interface Store\u003cS\u003e {\n    $repositories: RepositoryApis\n  }\n}\n\n````\n\n````typescript:~/repositories/user.ts\nimport type { AxiosInstance } from 'axios'\n\nexport class UserRepository {\n  private readonly axios: AxiosInstance\n\n  constructor($axios: AxiosInstance) {\n    this.axios = $axios\n  }\n\n  async search(id: string): Promise\u003cUser\u003e {\n    // this.$axios.get みたいな処理\n  }\n}\n````\n\n### 使い方\n\nVueコンポーネント内で `$repositories` で使用できる\n\n````typescript\nasync fetchUser(id: string) {\n    const data = await this.$repositories.user.search(id)\n    return data\n}\n````\n\n### テスト\n\n````typescript:~/test/hoge.spec.ts\nimport { MockProxy, mock } from 'jest-mock-extended'\nimport { Context } from '@nuxt/types'\nimport { RepositoryApis } from '~/plugins/repository-api'\nimport { UserRepository } from '~/repositories/api'\n\ndescribe('user', () =\u003e {\n  let mockContext: MockProxy\u003cContext\u003e\n  let repositories: MockProxy\u003cRepositoryApis\u003e\n\n  beforeEach(() =\u003e {\n    const mockUser = mock\u003cUserRepository\u003e()\n    repositories = mock\u003cRepositoryApis\u003e()\n    repositories.user = mockUser\n\n    mockContext.$repositories = repositories\n  })\n    \n  it('do something', () =\u003e {\n    doSomething(mockContext)\n\n    expect(repositories.user.search).toHaveBeenCalledTimes(1)\n    expect(repositories.user.search).toHaveBeenCalledWith({\n      id: 'foo',\n    })\n  })\n\n})\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["TypeScript","Vuejs"]},"/note/OPA-%E3%83%9D%E3%83%AA%E3%82%B7%E3%83%BC%E3%82%92%E3%83%86%E3%82%B9%E3%83%88%E3%81%99%E3%82%8B":{"title":"OPA ポリシーをテストする","content":"\n[Open Policy Agent OPA](note/Open%20Policy%20Agent%20OPA.md) でポリシーをテストする\n\nhttps://www.openpolicyagent.org/docs/latest/policy-testing/#getting-started\n\n`example.go`\n\n````rego\npackage mypolicy\n\nallow {\n    input.name == \"Alice\"\n}\n````\n\n`*_test.rego` という名前で作り、テストケースを `test_*` で作る\n\n`example_test.go`\n\n````rego\npackage mypolicy\n\ntest_allow_success {\n    allow with input as {\"name\": \"Alice\"}\n}\n\ntest_not_allowed {\n    not allow with input as {\"name\": \"Bob\"}\n}\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/04/27","OPA"]},"/note/Obsidian%E3%81%A7%E6%9B%B8%E3%81%84%E3%81%9Fmarkdown%E3%82%92Obsidian-Publish%E3%82%92%E4%BD%BF%E3%82%8F%E3%81%9A%E3%81%AB%E5%85%AC%E9%96%8B%E3%81%99%E3%82%8B":{"title":"Obsidianで書いたmarkdownをObsidian Publishを使わずに公開する","content":"\n## 参考\n\n* [Zenn \u0026 Hugo in Obsidian : OHZフローによるナレッジベースとアウトプットコンテンツの完全統括](https://zenn.dev/estra/articles/ohzflow-zenn-hugo-obsidian#%E3%82%84%E3%82%8A%E6%96%B9)\n\n## obsdconvを使う方法\n\n[Obsidian → Hugo の運用方法 – 公開ノート](https://qawatake.com/notes/211205-183554/)\n\nこちらは試したが結局使わなかった。\n\n## Quartzを使う方法\n\n[Quartzを使ってObsidianを無料で公開してみた](blog/Quartzを使ってObsidianを無料で公開してみた.md)\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/04/22","obsidian"]},"/note/Obsidian%E3%81%A7Vim%E3%81%AEyank%E3%81%A8OS%E3%81%AEClipboard%E3%82%92%E5%90%8C%E6%9C%9F%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95":{"title":"ObsidianでVimのyankとOSのClipboardを同期する方法","content":"\n`Obsidian Vimrc Support Plugin` で`set clipboard=unnamed`すればOK\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["obsidian"]},"/note/Obsidian%E3%81%A8%E3%81%AF":{"title":"Obsidianとは","content":"\n## 概要\n\nPC内ローカルにあるマークダウン（Markdown記法）ファイルの管理システムである。\n\n## 特徴\n\n* アカウント不要\n* markdownのみで管理できる\n* クラウドストレージと連携できる\n* LYT(Linking Your Thinking)の思想で、メモ同士のリンクが容易なこと\n  * Obsidian独自拡張部分により十分な連携が行えそう。なにしろ、明示的に「\\[\\[文書名\\]\\]」と囲むことで、自動的に候補を表示する（インクリメンタルサーチ）機能まである。さらに「#」で文書内の見出しへ、「^」で文書内のブロックへと、文書内の指定箇所へのディープリンクを貼ることも出来る。\n* [Zettelkasten](note/Zettelkastenとは.md) \n\n## 感想\n\nローカルで完結し、markdownで保管できるのでプラットフォームに依存しないのがいいところだと思った\n\nメモ同士のリンクが面白い\n\n使いこなせるかが不安\nだいたいこういうツールって最初はりきっていろいろ設定するんだけど、できることが多すぎると逆になにしたらいいかわからなくて手がとまっちゃう\n\n## リンク\n\n* [Obsidian 導入メモ | 日々のつぶやき](https://00.bulog.jp/archives/7959)\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["obsidian"]},"/note/Obsidian%E3%82%92%E3%82%B9%E3%83%9E%E3%83%9B%E3%81%A8%E5%90%8C%E6%9C%9F%E3%81%99%E3%82%8B":{"title":"Obsidianをスマホと同期する","content":"\n[Obsidianとは](note/Obsidianとは.md)\n\n## AndroidとPCでメモを同期する\n\n### 方針\n\n* git,GitHubでvaultを管理する\n* Androidでもメモをとってgit管理したい\n* daily(YYYY-mm-dd.md)が簡単につくれるといい\n* なるべくお金かけずにスタートしたい\n\n### 試したこと\n\n#### Termux\n\n[Using Obsidian with Termux and VIM - The Gadhian](https://www.thegadhian.com/posts/using-obsidian-with-termux-and-vim/)\n\nこれすき\n\n \u003e \n \u003e I don't really know if it's [zettelkasten](https://zettelkasten.de/posts/overview/#the-introduction-to-the-zettelkasten-method), [evergreen notes](https://notes.andymatuschak.org/Evergreen_notes), or [GTD](https://gettingthingsdone.com/what-is-gtd/), or [bullet journaling](https://bulletjournal.com/). It doesn't really matter.\n\n##### git,vimをインストール\n\n````sh\npkg install vim git\ngit --version\n````\n\n##### storageを使用するためのセットアップコマンド\n\n````sh\ntermux-setup-storage\n````\n\n##### ssh鍵をGitHubに登録\n\n##### vaultリポジトリをクローン\n\n````sh\ncd ~/storage/shared\nmkdir repos \u0026\u0026 cd repos\ngit clone vault\ncd vault\ngit status\n````\n\n##### ショートカットを作成\n\ntermuxで長いコマンドをうつのは辛いので、よく使うコマンドを登録しておく\n\n~/.bashrc\n\n````sh\nexport TODAY=$(date +%Y-%m-%d)\nexport VAULT=~/storage/repos/vault\n\nalias cdv='cd $VAULT'\nalias gits='git status'\nalias gita='git add .'\nalias gitc=\"git commit -m '$TODAY from termux'\"\n\ndaily() {\n\tcp $VAULT/daily/template.md $VAULT/daily/$TODAY.md\n\tsed -e \"s/{{date}}/$NOW/g\" -i $VAULT/daily/$TODAY.md\n}\n````\n\n##### 使い方\n\ndaily note\n\n1. termux で `daily` で今日の日付ファイルを作る\n1. markor で編集\n1. termux で git コマンドでpush\n\n#### Markor\n\nAndroidのMarkdownエディタ\n\nシンプルな機能しか持っていない\nただ書くだけなら便利\n\n#### GitJournal\n\n* GitHubと連携できる\n* markdownの編集ができる\n* 保存タイミングで自動でpush/pullする\n\n特に難しい設定をせずに使えるのが利点\n\n* 不便な点\n  * 同期タイミングを調整できない\n  * テンプレートが利用できない\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["obsidian"]},"/note/Obsidian%E4%BD%BF%E3%81%84%E6%96%B9":{"title":"Obsidian使い方","content":"\n\u003chttps://choiyaki.com/?tag=obsidian\u003e\n\n## Obsidianは、1ページ1テーマをつらぬく\n\nObsidianでは、1ページ1テーマをつらぬく気持ちで書きます。とにかく、1つのことについて書く。  \n未来の自分は他人という気持ちできちんとした文章で書きつつも、必要以上に説明しすぎることをせず、そこはリンクで別ページとのつながりを作りながら。\n\nObsidianのPublishの一つひとつのページは、1ページ1テーマであるが故に、ブログなど他の文章を書く際に、言及・引用がしやすい状態である、と言えます。それらを組み合わせさえすれば文章が書ける、とまでは行かないまでも、1つのテーマについて書かれたものは、取り回しが良く、使いやすいのは間違いありません。\n\nまた、Obsidianのリンクする機能を使うことで、ページ同士がつながってくれており、それもまた言及・引用のしやすさに一役を買っています。Obsidian上のページをひらけば、それに関連するページが必ず表示されるので、思い起こすことができるから。\n\n## ブログは、1つの完成したものを\n\n一方でブログは、はじめから読んでいけば内容を理解でき、それだけで完結することを意識して書く。\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["obsidian"]},"/note/Obsidian%E7%92%B0%E5%A2%83%E3%82%92%E6%95%B4%E3%81%88%E3%82%8B":{"title":"Obsidian環境を整える","content":"\n[Obsidianとは](note/Obsidianとは.md)\n\n## PC\n\n1. [ホームページ](https://obsidian.md/)からダウンロード\n1. vaultを作成\n1. GitHubにリポジトリ作成\n\n### プラグインを設定\n\n* Calendar\n* Git\n* Daily Notes\n* Templates\n\n### theme\n\nAppearance \u003e Theme \u003e Dracula for Obsidian を適用\n\n### ディレクトリ構成\n\n* `attachment`: 添付ファイル、画像\n* `daily`: 日次メモ\n* `_templates`: テンプレート\n\n## 参考\n\n* [マークダウンメモアプリObsidianの設定を全晒しする回 | Output 0.1](https://pouhon.net/obsidian-settings/5686/)\n* [Zenn \u0026 Hugo in Obsidian : OHZフローによるナレッジベースとアウトプットコンテンツの完全統括](https://zenn.dev/estra/articles/ohzflow-zenn-hugo-obsidian)\n* [\\[Obsidian\\]CalendarプラグインでDaily notesは進化する | Output 0.1](https://pouhon.net/obsidian-calendar/5996/)\n* [Obsidian+GitHubを使ったメモ環境を整えた · kapieciiのブログ](https://blog.kapiecii.com/posts/2020/11/29/hello-obsidian/)\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["obsidian"]},"/note/Obsidian-%E6%97%A5%E6%AC%A1%E3%83%A1%E3%83%A2%E3%82%92%E5%8F%96%E3%82%8B":{"title":"Obsidian 日次メモを取る","content":"\n[Obsidianとは](note/Obsidianとは.md)\n\n\u003chttps://note.com/takibayashi/n/nd6250964f0a7\u003e\n\n## 動機\n\n毎日何しているか忘れていってしまうからライフログを徹底したい\n\n \u003e \n \u003e 細かいことの記録がすべて残っているので、後々役に立つことが多々あります。例えば、公共料金の設定を半年前に変更したんだけど、そのとき、どこに電話して、どのようなプランにしたんだっけ？ということも記録が残っているので助かります。\n\n「メモの魔力」とか意識高い系なことは考えず、詳細な日記ってくらいの位置づけ\n\n[\\[Obsidian\\]CalendarプラグインでDaily notesは進化する | Output 0.1](https://pouhon.net/obsidian-calendar/5996/)\n\n## PC\n\n* Daily Notes\n\n![Pasted-image-20210502143807](note/Pasted-image-20210502143807.png)\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["obsidian"]},"/note/Obsidian-Command-Line%E3%81%8B%E3%82%89%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E9%96%8B%E3%81%8F":{"title":"Obsidian Command Lineからファイルを開く","content":"\n[Command Line Interface to open files/folders in Obsidian from the terminal - Feature requests - Obsidian Forum](https://forum.obsidian.md/t/command-line-interface-to-open-files-folders-in-obsidian-from-the-terminal/860/20)\n\n[URL Scheme](https://help.obsidian.md/Advanced+topics/Using+Obsidian+URI) が実装されたため、Macでは以下のようにして開くことができる。\n\n````shell\nVAULT=myvault\nFILE='my%20file'\nobsidian=\"obsidian://open?vault=${VAULT}\u0026file=${FILE}\"\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/05/05","obsidian","CLI"]},"/note/Obsidian-Wikilink%E3%82%92Markdown-link%E3%81%AB%E5%A4%89%E6%9B%B4%E3%81%97%E3%81%9F":{"title":"Obsidian WikilinkをMarkdown linkに変更した","content":"\n[Obsidianを公開する](blog/Quartzを使ってObsidianを無料で公開してみた.md) にあたって、Wikilinkのままだとうまくリンクが貼られなかったりして不都合だったので、通常のmarkdown linkに変更した。\n公開するためだけじゃなく、 [Obsidian](note/Obsidianとは.md) からもし移行するとなってもいいように変更したかった。\n\n## 設定\n\nまず今後作成するときにmarkdown linkが使われるようにObsidianの設定を変更する\n\n![](note/Pasted-image-20230505054503.png)\n\n## 既存のリンクを変更する\n\nプラグインを使うのがはやかった。\n\n[ozntel/obsidian-link-converter: Obsidian Plugin to scan all your links in your vault and convert them to your desired format.](https://github.com/ozntel/obsidian-link-converter)\n\nしかし以下の問題があった。\n\n* 日本語のファイル名がURLエンコードされる\n  * `[ノート](note/ノート.md)` と記述されてほしいが、エンコードされて `[ノート](note/%E3%83%8E%E3%83%BC%E3%83%88.md)` となる\n* 正規表現で `[[` を変換するので、ファイルが存在しなくても変換されてしまう\n\n### 正しく変換されるよう、パッチをあてる\n\n* 日本語がエンコードされないようにする\n  * ただしスペースはエンコードされていてほしい `[ノート](note/my ノート.md)` -\u003e `[ノート](note/my%20ノート.md)`\n\n````diff\n--- a/src/converter.ts\n+++ b/src/converter.ts\n@@ -293,7 +303,9 @@ const createLink = (dest: LinkType, originalLink: string, altOrBlockRef: string,\n         } else {\n             altText = file ? file.basename : finalLink;\n         }\n-        return `[${altText}](${encodeURI(finalLink)}${fileExtension})`;\n+        finalLink = finalLink.replace(/ /g, '%20')\n+        return `[${altText}](${finalLink}${fileExtension})`;\n     } else if (dest === 'wikiTransclusion') {\n         return ``;\n     } else if (dest === 'mdTransclusion') {\n@@ -305,7 +317,8 @@ const createLink = (dest: LinkType, originalLink: string, altOrBlockRef: string,\n         } else {\n             encodedBlockRef = encodeURI(encodedBlockRef);\n         }\n-        return `[](${encodeURI(finalLink)}${fileExtension}#${encodedBlockRef})`;\n+        finalLink = finalLink.replace(/ /g, '%20')\n+        return `[](${finalLink}${fileExtension}#${encodedBlockRef})`;\n     }\n\n     return '';\n````\n\n* 存在しないリンクは変換しないようにする\n  * ファイルが存在するかどうかをチェックして、なければなにもしない\n\n````diff\n--- a/src/converter.ts\n+++ b/src/converter.ts\n@@ -193,6 +193,9 @@ export const convertWikiLinksToMarkdown = async (md: string, sourceFile: TFile,\n     let wikiMatches = linkMatches.filter((match) =\u003e match.type === 'wiki');\n     for (let wikiMatch of wikiMatches) {\n         let mdLink = createLink('markdown', wikiMatch.linkText, wikiMatch.altOrBlockRef, sourceFile, plugin);\n+        if (!mdLink) {\n+            continue;\n+        }\n         newMdText = newMdText.replace(wikiMatch.match, mdLink);\n     }\n     // --\u003e Convert Wiki Transclusion Links to Markdown Transclusion\n@@ -267,6 +270,11 @@ const createLink = (dest: LinkType, originalLink: string, altOrBlockRef: string,\n     let finalLink = originalLink;\n     let altText: string;\n\n+    const matchFile = plugin.app.vault.getFiles().find(t =\u003e sourceFile.name !== t.name \u0026\u0026 (t.basename === finalLink || t.name === finalLink))\n+    if (!matchFile) {\n+        return '';\n+    }\n+\n     let fileLink = decodeURI(finalLink);\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/05/05","obsidian"]},"/note/Open-Policy-Agent-OPA":{"title":"Open Policy Agent OPA","content":"\nGateKeeper, Conftestと組み合わせて使う\n\nhttps://www.openpolicyagent.org/docs/latest/policy-language/\n[Playground](https://play.openpolicyagent.org) もある\n\nわかりやすいページ\n[Policy as Codeを実現する Open Policy Agent / Rego の紹介 - ISID テックブログ](https://tech.isid.co.jp/entry/2021/12/05/Policy_as_Code%E3%82%92%E5%AE%9F%E7%8F%BE%E3%81%99%E3%82%8B_Open_Policy_Agent_/_Rego_%E3%81%AE%E7%B4%B9%E4%BB%8B)\n\nOpen Policy Agent (OPA)は、ポリシーベースのアクセス制御を提供するオープンソースのツールです。OPAは、REST APIやgRPCなどの形式でアプリケーションに統合され、アクセス制御の判断を行います。\nOPAは、自由なポリシーの表現力を持ち、柔軟で拡張性の高い設計が特徴です。OPAのポリシーは、Regoという言語で記述されます。Regoは、JSONを基にしたデータ構造を扱いやすい形式で表現することができ、複雑なポリシーの表現が可能です。\n様々なサービスのポリシー設定を同じ言語（Rego）で表現することができます。\n\nGatekeeper は、KubernetesにおけるOPAの実装の1つで、Kubernetesのポリシー管理を自動化するためのコントローラです。Gatekeeperは、OPAを使用して、Kubernetesのリソースやマニフェストを検証し、ポリシーに従わない場合は拒否することができます。\n\nConftestは、OPAのツールの1つで、設定ファイルやマニフェストなどの構成ファイルの検証を行うことができます。Conftestは、OPAの言語であるRegoを使用して、構成ファイルに対するポリシーを記述します。\n\n## 書き方\n\n````lua\npackage example\n\ndeny {\n    input.user == \"admin\"\n}\n````\n\n`input` は、Rego言語で用意されている予約語の一つで、アクセス制御の評価時に与えられる入力オブジェクトを表します。入力オブジェクトの構文は決まっておらず、アプリケーションによって異なります。つまり、`input`オブジェクトは、アプリケーションの入力に応じて、動的に構築されることが多いです。\n\nこのルールは、`input.user` が\"admin\"である場合に、`deny`を返します。このルールを実行するためには、`input`オブジェクトが与えられる必要があります。例えば、以下のような入力を与えることができます。\n\n````json\n{\n    \"user\": \"admin\",\n    \"resource\": \"some-resource\"\n}\n````\n\nOPAの言語仕様において、`deny`や`allow`は予約語ではなく、ルールの名前として使用されます。これらのルール名には、アクセス制御の判断を行うために、`deny`と`allow`が一般的に使用されますが、任意の名前を付けることができます。\n\n````lua\npackage example\n\nallow {\n    input.user == \"admin\"\n}\n````\n\n````lua\npackage example\n\ndeny_my_rule {\n    input.user == \"admin\"\n}\n````\n\nConftestでは、アサーションの結果を`deny`や`allow`で表現することができますが、これらはOPAのルールの名前として定義されているわけではなく、便宜的に使われているものです。Conftestは、Regoの言語仕様に基づいてルールを記述するため、`deny`や`allow`の他にも任意のルール名を使用することができます。ただし、アサーションの結果を`deny`や`allow`で表現することが一般的であり、よりわかりやすいコードを書くことができます。\n\n## OR条件\n\nConftestで `||` みたいにOR条件を書けないか調べたが、簡単にできなかった。\n同名の関数を複数用意することで、OR条件とできるらしい\n\n````\n\ndeny[msg] {\n    inRange(input.index)\n    msg := sprintf(\"indexは1~99の範囲を指定する %v\", [input.index])\n}\n\ninRange(v) {\n    v \u003e= 1\n}\ninRange(v) {\n    v \u003c 100\n}\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/03/27","Kubernetes"]},"/note/OpenAPI":{"title":"OpenAPI","content":"\nhttps://swagger.io/specification/\n\nOpenAPI 仕様 (OAS) は、言語に依存しない標準のREST APIのインターフェイスを定義する。\nインターフェースの定義は JSON または YAML で記述し、特定の言語に依存しないので、さまざまな言語で利用できる。\nドキュメントから見やすい仕様書を出力したり、[OpenAPI Generator](note/OpenAPI%20Generator.md) などのツールを使ってさまざまな言語向けにサーバー、クライアントのコードを生成することができる\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["OpenAPI"]},"/note/OpenAPI%E3%81%A7Go%E3%81%A8TypeScript%E3%81%AE%E3%82%B3%E3%83%BC%E3%83%89%E7%94%9F%E6%88%90":{"title":"OpenAPIでGoとTypeScriptのコード生成","content":"\n## 開発言語・環境\n\n* バックエンド\n  * Go 1.18\n  * [aws-lambda-go](https://github.com/aws/aws-lambda-go) v1.32.0\n  * AWS SAM (API Gateway + Lambda)\n  * oapi-codegen v1.11.0\n* フロントエンド\n  * TypeScript 4.6\n  * Nuxt.js 2.16\n  * axios v0.21.4\n  * OpenAPI Generator 5.4.0\n\n※ コードを使った説明が多く出てきますが、各言語やライブラリの説明は省きますので基礎的な文法がわかることが前提となってしまいます。ご了承ください。\n\n## 導入の背景\n\nもともと仕様書の記述はOpenAPIで行っていました。\nしかし、クライアントやサーバーのAPIレスポンスのコードは手動で実装していたため、コードの更新を仕様書に反映し忘れたり、仕様書とコードでプロパティ名が異なったりと、実装と仕様の乖離が発生することがありました。\nOpenAPIファイルとコードを二重でメンテナンスをするコストだけがかかっている状態です。\n\nそこでそれぞれの言語向けにコードを自動生成する方法を取り入れ、この課題を解決しました。\n\n## 導入した結果\n\n1. 仕様書とコードが一致するようになった\n1. それぞれの言語向けにAPIレスポンスのコードを実装するコストが減った\n1. フロントエンドとバックエンドの実装が並行して進められるようになった\n\n1、2については、APIを変更したときにコードを再生成するとGoやTypeScriptでエラーがでるので、変更が安全に行えるようになりました。\n\nこのときの開発チームでは同じ人がフロントエンドとバックエンド両方を実装していたので、3についてはあまり影響がありませんでしたが、開発者が分かれている場合はバックエンドの開発が済んでいなくてもフロントエンドの開発を進められるのは大きな利点だと思います。\n\n一方でイマイチだった点として、生成ツールの吐き出すコードのフォーマットがプロジェクトに合わないものであっても妥協する必要がありました。\n出力されるコードのフォーマットはある程度パラメータでコントロールできるものの、その方法を調べるコストやメンテナンスコストを鑑みて、生成されたものにコードフォーマッタをかけるくらいに留めてあとは受け入れることにしました。\n\n### やらなかったこと\n\n今回はOpenAPIファイルをもとにしてコードを生成する方針で開発を行いました。\n\n一方で、コードからOpenAPIファイルを生成するアプローチもあります。\nyamlを編集するよりもコードを書きたい、コードのほうがコンパイルエラーで検知できたりIDEの恩恵を受けやすいという気持ちはあったのですが、\nライブラリ側がOpenAPI 3.0系に対応するのを待つ必要があったり、使用できるプロパティが制限されたりと不便なところがあったため、このアプローチは取りませんでした。\n例えば、Go でコードからOpenAPI(Swagger)を生成するライブラリの中でスター数の多い [swag](https://github.com/swaggo/swag) はSwagger 2.0に対応していますがOpenAPI 3.0系には未対応です。\n\n*以降はサンプルとして [OpenAPIのexamplesにあるpetstore.yaml](https://github.com/OAI/OpenAPI-Specification/blob/3.1.0/examples/v3.0/petstore.yaml) を使用して説明していきます。*\n\n## バックエンドのコード生成\n\nGoのAWS Lambdaハンドラー向けのコード生成について説明します。\n\nOpenAPIからGoのコードを生成するツールで有名なものに [go-swagger](https://github.com/go-swagger/go-swagger) がありますが、現時点(v0.30.3)ではSwagger 2.0にのみ対応しており、OpenAPI 3系が使えません。\nすでにOpenAPIファイルは3系で書いていたため、これに対応している [oapi-codegen](https://github.com/deepmap/oapi-codegen) を使用しました。\ngo-swagger と比べるとリリース頻度が低く、プルリクが滞留しがちなのが気になるところではありますが、他の選択肢がなかったためこちらを採用しています。\n\n### oapi-codegenの使い方\n\nまずは最新版をインストールして実行してみます。\n\n````shell\ngo install github.com/deepmap/oapi-codegen/cmd/oapi-codegen@latest\n\noapi-codegen -package \"openapi\" petstore.yaml \u003e petstore.gen.go\n````\n\nすると以下のような内容が書かれた petstore.gen.go が生成されます。\n\n* **components** や **parameters** のstruct定義\n* 全APIのハンドラーを持った **ServerInterface**\n* Echo用のwrapper\n* Base64エンコードされたOpenAPI spec\n\n生成対象はconfigファイルで設定することができます。\n今回はstruct定義のみ生成したかったので、以下のような設定にしました。\n\n````yaml\n# oapi-codegen.yaml\n\npackage: openapi\ngenerate:\n  models: true\n  # echo-server: true\n  # embedded-spec: true\n````\n\n````shell\noapi-codegen -config oapi-codegen.yaml petstore.yaml \u003e petstore.gen.go\n````\n\n生成されるコードはこちらです。\n\n````go\n// Package openapi provides primitives to interact with the openapi HTTP API.\n//\n// Code generated by github.com/deepmap/oapi-codegen version v1.11.0 DO NOT EDIT.\npackage openapi\n\n// Error defines model for Error.\ntype Error struct {\n\tCode    int32  `json:\"code\"`\n\tMessage string `json:\"message\"`\n}\n\n// Pet defines model for Pet.\ntype Pet struct {\n\tId   int64   `json:\"id\"`\n\tName string  `json:\"name\"`\n\tTag  *string `json:\"tag,omitempty\"`\n}\n\n// Pets defines model for Pets.\ntype Pets = []Pet\n\n// ListPetsParams defines parameters for ListPets.\ntype ListPetsParams struct {\n\t// How many items to return at one time (max 100)\n\tLimit *int32 `form:\"limit,omitempty\" json:\"limit,omitempty\"`\n}\n````\n\n※v1.10.0以前では、以下のようにコマンドラインオプションで生成対象を指定できましたがこれは使えなくなっています。\n詳しくは [v1.11.0のリリースノート](https://github.com/deepmap/oapi-codegen/releases/tag/v1.11.0) をご覧ください。\n\n````\noapi-codegen -generate \"types\" -package \"openapi\" petstore.yaml\noapi-codegen -generate \"server\" -package \"openapi\" petstore.yaml\n````\n\n### AWS Lambdaのハンドラー内で利用する\n\nハンドラーのコードについて詳細は省きますが、\nこちらのようにしてリクエストパラメータを生成コードにマッピングして、処理を行い、レスポンスを返すよう実装しました。\n\n````go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"net/http\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/mitchellh/mapstructure\"\n\n\t\"example.com/petstore/openapi\"\n)\n\nfunc handler(request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {\n\t// requestをopenapi.ListPetsParamsにマッピングする\n\tvar param openapi.ListPetsParams\n\n\tdecoderConfig := \u0026mapstructure.DecoderConfig{\n\t\tWeaklyTypedInput: true,\n\t\tResult:           \u0026param,\n\t}\n\tdecoder, err := mapstructure.NewDecoder(decoderConfig)\n\tif err != nil {\n\t\treturn events.APIGatewayProxyResponse{}, err\n\t}\n\terr = decoder.Decode(request.QueryStringParameters)\n\tif err != nil {\n\t\treturn events.APIGatewayProxyResponse{}, err\n\t}\n\n\t// do something\n\n\t// openapi.Petsを作成してJSONにして返却する\n\tpets := make(openapi.Pets, 0)\n\n\tbody, err := json.Marshal(pets)\n\treturn events.APIGatewayProxyResponse{\n\t\tStatusCode: http.StatusOK,\n\t\tBody:       string(body),\n\t}, err\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n````\n\nこうすることで、生成されたコードとリクエスト、レスポンスのマッピングが行われ、仕様書とコードが一致するようになりました。\n\n### struct tagを追加したい\n\n上記コードでは、  [mapstructure](https://github.com/mitchellh/mapstructure) を使ってLambdaのリクエストパラメータ( map\\[string\\]string 型の QueryStringParameters) を openapi.ListPetsParams 型の変数にパースしています。\nこのライブラリは、 `mapstructre:\"limit\"` のようなstruct tagを書くことで、mapのキー名とtagが一致するフィールドに値をパースさせることができます。\n\nこれは、次のようにkebab-caseでリクエストパラメータを定義したいときに役立ちます。\n\n````yaml\n  /pets:\n    get:\n      parameters:\n        - name: limit\n          in: query\n          description: How many items to return at one time (max 100)\n          required: false\n          schema:\n            type: integer\n            format: int32\n        - name: sort-by\n          in: query\n          description: How to sort items\n          required: false\n          schema:\n            type: string\n````\n\n生成されるコード\n\n````go\ntype ListPetsParams struct {\n\t// How many items to return at one time (max 100)\n\tLimit *int32 `form:\"limit,omitempty\" json:\"limit,omitempty\"`\n\n\t// How to sort items\n\tSortBy *string `form:\"sort-by,omitempty\" json:\"sort-by,omitempty\"`\n}\n````\n\nこの状態で /pets?sort-by=name でリクエストすると、SortBy には値が入らず、 /pets?sortBy=name としないといけません。\n\nこれを解消するために oapi-codegen では、**x-oapi-codegen-extra-tags** を書くことで任意のstruct tagをつけることができるようになっています。\n\n````yaml\n        - name: sort-by\n          in: query\n          description: How to sort items\n          required: false\n          schema:\n            type: string\n          x-oapi-codegen-extra-tags:\n            mapstructure: sort-by,omitempty\n````\n\n生成されるコード\n\n````go\ntype ListPetsParams struct {\n\t// How many items to return at one time (max 100)\n\tLimit *int32 `form:\"limit,omitempty\" json:\"limit,omitempty\"`\n\n\t// How to sort items\n\tSortBy *string `form:\"sort-by,omitempty\" json:\"sort-by,omitempty\" mapstructure:\"sort-by,omitempty\"`\n}\n````\n\nこれで /pets?sort-by=name が期待通り働くようになりました。\n\n他にも [go-playground/validator](https://github.com/go-playground/validator) 用のタグを追加するのにも使えそうです。\n\n## フロントエンドのコード生成\n\nつづいてフロントエンド側のコード生成について説明します。\nTypeScriptのクライアントコードは、 [OpenAPI Generator](https://openapi-generator.tech/) を使って生成しました。\n\nhttpクライアントは axios を使っていますので、axios 向けのコードを出力するようにします。\n次のようにして **npm run openapi-generate** で実行できるようにしました。\n\n**package.json**\n\n````json\n{\n  \"scripts\": {\n    \"openapi-generate\": \"rm -f api_client/*.ts || true \u0026\u0026 TS_POST_PROCESS_FILE='npx prettier --write' openapi-generator-cli generate -i petstore.yaml -g typescript-axios -o api_client --additional-properties=supportsES6=true,useSingleRequestParameter=true --enable-post-process-file\"\n  },\n  \"devDependencies\": {\n    \"@openapitools/openapi-generator-cli\": \"^2.4.0\"\n  }\n}\n````\n\n**rm -f api_client/\\*.ts || true**\n\n変更時に不要になったファイルが残ってしまうので、削除します\n\n**TS_POST_PROCESS_FILE='npx prettier --write'**\n\nTS_POST_PROCESS_FILE でコード生成後に実行する処理を設定できます。ここではprettierでコードフォーマットを行っています。\n\n**openapi-generator-cli generate -i petstore.yaml -g typescript-axios -o api_client**\n\n* -i OpenAPIファイルを指定する\n* -g generatorの種類\n* -o 生成先のディレクトリ\n\n指定できるgeneratorの種類はこちらで調べることができます。\nhttps://openapi-generator.tech/docs/generators/\n\naxiosを使用しているので typescript-axios を指定しました。fetch を使いたい場合、 typescript-fetch を指定することもできます。\n\n**--additional-properties=supportsES6=true,useSingleRequestParameter=true**\n\n指定できるオプションは公式ドキュメントに記載されています。\nhttps://openapi-generator.tech/docs/generators/typescript-axios\n\n* supportsES6 ES6向けのコードを出力する\n* useSingleRequestParameter APIリクエストパラメータを構造体にまとめる\n\n**--enable-post-process-file**\n\nTS_POST_PROCESS_FILE の処理を実行するためのオプションです\n\n### 生成されるクライアントコード\n\n````typescript\nexport class BaseAPI {\n  protected configuration: Configuration | undefined\n\n  constructor(\n    configuration?: Configuration,\n    protected basePath: string = BASE_PATH,\n    protected axios: AxiosInstance = globalAxios\n  ) {\n    if (configuration) {\n      this.configuration = configuration\n      this.basePath = configuration.basePath || this.basePath\n    }\n  }\n}\n\n// ...\n\nexport class PetsApi extends BaseAPI {\n    // ...\n}\n````\n\n### 生成されたコードをVueから利用する\n\nテストがしやすいよう、RepositoryFactoryパターンで実装しています。\n主題ではないので、軽い紹介にとどめます。\n\n````typescript\n// repositories/api/petstore.ts\n\nimport type { AxiosInstance } from 'axios'\nimport { PetsApi, PetsApiListPetsRequest, Pet } from '~/generated'\n\nexport class PetsRepository {\n  private readonly axios: AxiosInstance\n\n  // axiosインスタンスを差し替え可能にする\n  constructor($axios: AxiosInstance) {\n    this.axios = $axios\n  }\n\n  async list(req: PetsApiListPetsRequest): Promise\u003cPet[]\u003e {\n    const petsApi = new PetsApi(\n      undefined,\n      this.axios.defaults.baseURL,\n      this.axios\n    )\n    const response = await petsApi.listPets(req)\n    return response.data\n  }\n\n}\n````\n\n````typescript\n// plugins/repositories.ts\n\nimport { PetsRepository } from '~/repositories/api/petstore'\n\nexport interface RepositoryApis {\n  pets: PetsRepository\n}\n\nexport default defineNuxtPlugin((nuxtApp) =\u003e {\n  // axiosインスタンスをinjectする\n  const pets = new PetsRepository(nuxtApp.$axios)\n\n  const repositories: RepositoryApis = {\n    pets,\n  }\n  nuxtApp.provide('repositories', repositories)\n})\n````\n\n````vue\n// pages/petlist.vue\n\n\u003cscript setup lang=\"ts\"\u003e\nimport { Pet } from '~/generated'\n\nconst pets = ref\u003cPet[]\u003e([])\n\nconst $nuxt = useNuxtApp()\n\nconst searchPets = async () =\u003e {\n  // pets.list APIを呼び出し\n  const resp = await $nuxt.$repositories.pets.list({\n    limit: 10,\n  })\n  return resp\n}\n\nonMounted(() =\u003e searchPets())\n\u003c/script\u003e\n\n\u003ctemplate\u003e\n  \u003cdiv\u003e\n    \u003ch2\u003ePets\u003c/h2\u003e\n    \u003cul\u003e\n      \u003cli v-for=\"pet in pets\" :key=\"pet.id\"\u003e\n        {{ pet.name }}\n      \u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/div\u003e\n\u003c/template\u003e\n````\n\n## おわりに\n\nOpenAPIファイルからGoとTypeScriptのコード生成するためのツール・ライブラリの紹介と、それらを使った実装について説明しました。\nこの導入によって開発効率が良くなり、また今後のAPI開発時に安全に変更が行えるようになりました。\n\nスキーマ駆動開発の一例として、少しでも参考になる点があれば幸いです。\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/04/30","OpenAPI","Go"]},"/note/OpenAPI%E3%81%A8Go%E3%81%A7%E3%83%AA%E3%82%AF%E3%82%A8%E3%82%B9%E3%83%88%E3%81%AE%E3%83%90%E3%83%AA%E3%83%87%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%92%E3%81%99%E3%82%8B":{"title":"OpenAPIとGoでリクエストのバリデーションをする","content":"\nいつもoapi-codegenでopenapi.yamlからGoのコードを生成するようにしている。\noapi-codegenの使い方については下記参照\n\n[OpenAPIでGoとTypeScriptのコード生成](note/OpenAPIでGoとTypeScriptのコード生成.md)\n\n[OpenAPI仕様書からGoの構造体を作る](note/OpenAPI仕様書からGoの構造体を作る.md)\n\n## OpenAPIでパラメータに制約をつける\n\nOpenAPI Documentでは、JSON Schema の定義に従って `schema` に制約を書くことができる。\n[OpenAPI Specification - Version 3.0.3 | Swagger](https://swagger.io/specification/#schema-object)\n[draft-wright-json-schema-validation-00](https://datatracker.ietf.org/doc/html/draft-wright-json-schema-validation-00)\n\n次のように `pattern` や `format` 、`maxLength` などが定義できる。\n\n`openapi.yaml`\n\n````yaml\npaths:\n  /hello:\n    get:\n      summary: Hello\n      operationId: hello\n      parameters:\n        - name: id\n          in: query\n          description: user id\n          required: true\n          schema:\n            type: string\n            pattern: \"^[0-9A-F]+$\"\n        - name: updated\n          in: query\n          schema:\n            type: string\n            format: date-time\n````\n\noapi-codegenを使えば、 `schema` に書いた制約をもとにリクエストのバリデーションを行うことができる。\n\n以下はEchoの場合\n\n````go\npackage main\n\nimport (\n\t\"my-application/oapigen\"\n\n\toapiMiddleware \"github.com/deepmap/oapi-codegen/pkg/middleware\"\n\t\"github.com/getkin/kin-openapi/openapi3\"\n\t\"github.com/labstack/echo/v4\"\n)\n\nfunc main() {\n\te := echo.New()\n\n\t// oapi-codegenで生成したコードにあるGetSwagger()でopenapi specを取得\n\tswagger, err := oapigen.GetSwagger()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\t// ホストの検証が必要でなければnilにしておく\n\tswagger.Servers = nil\n\t// middlewareにValidatorをセットすることでリクエストの検証が行われる\n\te.Use(oapiMiddleware.OapiRequestValidator(swagger))\n\n\t// 独自のformatを定義したい場合はこのようにする\n\topenapi3.DefineStringFormat(\"custom-date\", `^[0-9]{4}-(0[0-9]|10|11|12)-([0-2][0-9]|30|31)T[0-9]{2}:[0-9]{2}:[0-9]{2}$`)\n\n\n}\n\n````\n\n[OpenAPIスキーマ駆動開発におけるoapi-codegenを用いたリクエストバリデーション - HRBrain Blog](https://times.hrbrain.co.jp/entry/openapi-validation-chi)\nこちらに書いてあるとおり、一通りのバリデーションはできるようになっている\n\nmiddlewareのソースはこちら\nhttps://github.com/deepmap/oapi-codegen/blob/ab90f1927bc5ec3e29af216d4298fbb4780ae36d/pkg/middleware/oapi_validate.go#L58\n\n## 別ライブラリと組み合わせる\n\nhttps://github.com/go-ozzo/ozzo-validation や https://github.com/go-playground/validator と組み合わせて複雑なバリデーションをしたい場合\n\n`x-oapi-codegen-extra-tags` を書くことで任意のstruct tagをつけることができるので、タグベースのバリデーションはこれで行える\nバリデーションの種類はこれ\n[go-playground/validator リクエストパラメータ向けValidationパターンまとめ - Qiita](https://qiita.com/RunEagler/items/ad79fc860c3689797ccc)\n\n````yaml\npaths:\n  /hello:\n    get:\n      summary: Hello\n      operationId: hello\n      parameters:\n        - name: sort-by\n          in: query\n          description: How to sort items\n          required: false\n          schema:\n            type: string\n          x-oapi-codegen-extra-tags:\n            validate: len=5\n        - name: datetime\n          in: query\n          schema:\n            type: string\n          x-oapi-codegen-extra-tags:\n            validate: datetime_without_timezone\n````\n\nEcho + go-playground/validator\n\n````go\nimport (\n\t\"my-application/openapi\"\n\n\t\"github.com/go-playground/validator/v10\"\n)\n\nfunc main() {\n\te := echo.New()\n\n\tswagger, err := openapi.GetSwagger()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tswagger.Servers = nil\n\topenapi.RegisterHandlers(e, handler{})\n\n\t// registor validator\n\tvalidate := validator.New()\n\tvalidate.RegisterValidation(\"datetime_without_timezone\", validateDatetimeWithoutTimezone)\n\te.Validator = \u0026CustomValidator{validate: validate}\n\n}\n\ntype CustomValidator struct {\n\tvalidate *validator.Validate\n}\n\nfunc (cv *CustomValidator) Validate(i interface{}) error {\n\tif err := cv.validate.Struct(i); err != nil {\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, err.Error())\n\t}\n\treturn nil\n}\n\nfunc validateDatetimeWithoutTimezone(fl validator.FieldLevel) bool {\n\tdate := fl.Field().String()\n\t_, err := time.Parse(\"2006-01-02T15:04:05\", date)\n\treturn err == nil\n}\n\ntype handler struct {}\n\nfunc (h handler) Hello(ec echo.Context, params openapi.HelloParams) error {\n\tif err := ec.Validate(params); err != nil {\n\t\treturn err\n\t}\n\treturn ec.String(http.StatusOK, fmt.Printf(\"Hello, %s\", params.Name))\n}\n\n````\n\nvalidatorのエラーメッセージをカスタムしたい\n\n[\\[golang\\]Echoでvalidatorのエラーを日本語に変換する方法 | CodeLab](https://codelab.website/golang-echo-validator-translation/)\n[How can I define custom error message? · Issue #559 · go-playground/validator](https://github.com/go-playground/validator/issues/559)\n\ntagに応じたメッセージを作成する、`validator.ValidationErrors.Translate` で翻訳する(用意された翻訳メッセージ)\n\n````go\npackage main\n\nimport (\n\t\"errors\"\n\t\"log\"\n\t\"net/http\"\n\t\"reflect\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/go-playground/locales/ja_JP\"\n\tut \"github.com/go-playground/universal-translator\"\n\t\"github.com/go-playground/validator/v10\"\n\tja_translations \"github.com/go-playground/validator/v10/translations/ja\"\n\t\"github.com/labstack/echo/v4\"\n)\n\nfunc main() {\n\te := echo.New()\n\n\tvalidate := validator.New()\n\n\t// エラーメッセージに出力するフィールド名をタグから取得する\n\tvalidate.RegisterTagNameFunc(func(field reflect.StructField) string {\n\t\tfieldName := field.Tag.Get(\"field_ja\")\n\t\tif fieldName == \"-\" {\n\t\t\treturn \"\"\n\t\t}\n\t\treturn fieldName\n\t})\n\n\t// 日本語のメッセージを出力する\n\tjapanese := ja_JP.New()\n\tuni := ut.New(japanese, japanese)\n\ttrans, _ := uni.GetTranslator(\"ja\")\n\terr := ja_translations.RegisterDefaultTranslations(validate, trans)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\t// メッセージを上書きする場合はこのようにする\n\tvalidate.RegisterTranslation(\"required\", trans, func(ut ut.Translator) error {\n\t\treturn ut.Add(\"required\", \"{0} を指定してください\", true) // see universal-translator for details\n\t}, func(ut ut.Translator, fe validator.FieldError) string {\n\t\tt, _ := ut.T(\"required\", fe.Field())\n\t\treturn t\n\t})\n\n\te.Validator = \u0026CustomValidator{validate: validate, trans: trans}\n\n}\n\ntype CustomValidator struct {\n\ttrans    ut.Translator\n\tvalidate *validator.Validate\n}\n\nfunc (cv *CustomValidator) Validate(i interface{}) error {\n\tif err := cv.validate.Struct(i); err != nil {\n\t\tvar ve validator.ValidationErrors\n\t\tmsg := []string{}\n\t\tif errors.As(err, \u0026ve) {\n\t\t\tfor _, m := range ve.Translate(cv.trans) {\n\t\t\t\tmsg = append(msg, m)\n\t\t\t}\n\t\t}\n\n\t\treturn echo.NewHTTPError(http.StatusBadRequest, strings.Join(msg, \",\"))\n\t}\n\treturn nil\n}\n\ntype Params struct {\n\tId *string `form:\"id,omitempty\" json:\"id,omitempty\" validate:\"required\" field_ja:\"ユーザID\"`\n}\n\n````\n\n=\u003e `ユーザIDは必須フィールドです` というエラーメッセージになる\n\n### 試す\n\n````yaml\nopenapi: \"3.1.0\"\npaths:\n  /hello:\n    get:\n      summary: Sample API\n      operationId: hello\n      tags:\n        - sample\n      parameters:\n        - name: name\n          in: query\n          required: true\n          schema:\n            type: string\n            maxLength: 8\n            minLength: 4\n          description: your name\n        - name: id\n          in: query\n          schema:\n            type: string\n            pattern: \"^\\\\d{8}$\"\n          description: your id\n        - name: age\n          in: query\n          schema:\n            type: integer\n            maximum: 30\n            minimum: 10\n          description: your name\n````\n\nこんなopenapi.yamlを作って適当なサーバーを立てて、範囲外の値を入力してやるとエラーが返された\n\nlocalhost:8080/hello?name=alice\u0026age=99\n\n````\nparameter \"age\" in query has an error: number must be at most 30\n````\n\n## 日付型のバリデーション\n\nkin-openapiだけだとここで正規表現のみチェックしている\nhttps://github.com/getkin/kin-openapi/blob/e7d649f3f7d6ddbaaaed74a7d2f819a82118aab4/openapi3/schema.go#L943\nhttps://github.com/getkin/kin-openapi/blob/e7d649f3f7d6ddbaaaed74a7d2f819a82118aab4/openapi3/schema_formats.go#L94\n\n`2022-01-02T15:04:05` みたいな文字列が通るはずと思ったが通らなかった。\n\noapi-codegen のmiddlewareではここで `time.Parse` できるかもチェックしているためだった。\nhttps://github.com/deepmap/oapi-codegen/blob/ab90f1927bc5ec3e29af216d4298fbb4780ae36d/pkg/runtime/bindstring.go#L125\n\nそのため独自フォーマットを用意してあげる必要がある。\n\n````go\n\nimport \"github.com/getkin/kin-openapi/openapi3\"\n\n\n\topenapi3.DefineStringFormat(\"custom-date\", `^[0-9]{4}-(0[0-9]|10|11|12)-([0-2][0-9]|30|31)T[0-9]{2}:[0-9]{2}:[0-9]{2}$`)\n````\n\n* [ ] https://github.com/deepmap/oapi-codegen/blob/ab90f1927bc5ec3e29af216d4298fbb4780ae36d/pkg/runtime/deepobject.go#L248 スペルミス直す 📅 2023-01-07\n  `deepObject` でdateを指定したときにこうなるぽい\n  https://swagger.io/docs/specification/serialization/\n\n````yaml\n  /hello:\n    get:\n      summary: Sample API\n      operationId: hello\n      tags:\n        - admin\n      parameters:\n        - name: obj\n          in: query\n          schema:\n            type: object\n            properties:\n              date:\n                type: string\n                format: date-time\n          style: deepObject\n          explode: true\n````\n\n再現できた。エラーメッセージのtimeがtimになってる\nhttp://localhost:1323/hello?obj\\[date\\]=2022-12-21T15:04:05\n\n````\nInvalid format for parameter obj: error assigning value to destination: error assigning field [date]: error parsing tim as RFC3339 or 2006-01-02 time: parsing time \"2022-12-21T15:04:05\": extra text: \"T15:04:05\"\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/01/05","Go","OpenAPI"]},"/note/OpenAPI%E3%81%AEspec%E3%81%8B%E3%82%89SAM%E3%81%AETemplate.yaml%E3%82%92%E7%94%9F%E6%88%90%E3%81%99%E3%82%8B":{"title":"OpenAPIのspecからSAMのTemplate.yamlを生成する","content":"\n[SAM](note/SAM.md) と [OpenAPI](note/OpenAPI.md) を組み合わせて使うときに両方を編集するのが大変\u0026漏れやすいので合わせられる仕組みが欲しかった\n\n````yaml\nopenapi: 3.0.0\ninfo:\n  title: OpenAPI sam-app\n  description: sam-appのAPI\n  version: 1.0.0\n\npaths:\n  /hello:\n    get:\n      summary: GETサンプル\n      description: GETのサンプルです\n      responses:\n        '200':\n          description: 成功レスポンス\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Success'\n      x-amazon-apigateway-integration:\n        credentials:\n          Fn::Sub: ${ApiRole.Arn}\n        uri:\n          Fn::Sub: arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${GetFunction.Arn}/invocations\n        passthroughBehavior: when_no_templates\n        httpMethod: POST\n        type: aws_proxy\n    post:\n      summary: POSTサンプル\n      description: POSTのサンプルです\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              type: object\n              properties:\n                name:\n                  description: 名前\n                  type: string\n                age:\n                  description: 年齢\n                  type: integer\n                  format: int32\n              required:\n                - name\n                - age\n      responses:\n        '200':\n          description: 成功レスポンス\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/Success'\n      x-amazon-apigateway-integration:\n        credentials:\n          Fn::Sub: ${ApiRole.Arn}\n        uri:\n          Fn::Sub: arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${PostFunction.Arn}/invocations\n        passthroughBehavior: when_no_templates\n        httpMethod: POST\n        type: aws_proxy\n\ncomponents:\n  schemas:\n    Success:\n      description: 成功の場合のレスポンス\n      type: object\n      properties:\n        message:\n          type: string\n      required:\n        - message\n\n````\n\n````go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"html/template\"\n\t\"io\"\n\t\"log\"\n\t\"sort\"\n\t\"strings\"\n\n\t\"github.com/getkin/kin-openapi/jsoninfo\"\n\t\"github.com/getkin/kin-openapi/openapi3\"\n)\n\n// x-amazon-apigateway-integration の型定義\ntype apigateway struct {\n\tType string `yaml:\"type\" json:\"type\"`\n\tUri  cfn    `yaml:\"uri\" json:\"uri\"`\n}\n\ntype cfn struct {\n\tFnSub string `yaml:\"Fn::Sub\" json:\"Fn::Sub\"`\n}\n\n// template.yaml に記載するLambda Functionのテンプレート\nconst lamdbaFunctionTemplateString = `{{ .FunctionName }}:\n  Type: AWS::Serverless::Function\n  Properties:\n    FunctionName: !Sub {{ .OperationId }}\n    Description: !Sub \"{{ .Description }}\"\n    CodeUri: {{ .ExecutablePath }}\n    Role: !Sub ${Role}\n    Events:\n      CatchAll:\n        Type: Api\n        Properties:\n          Path: {{ .Path }}\n          Method: GET\n          RestApiId: !Ref MyAPI`\n\ntype lambdaFunctionTemplate struct {\n\tFunctionName   string\n\tOperationId    string\n\tDescription    string\n\tExecutablePath string\n\tPath           string\n}\n\nfunc extractFunctionName(apigw apigateway) string {\n\turi := apigw.Uri.FnSub\n\tarn := strings.Split(uri, \"/\")[3]\n\treturn strings.ReplaceAll(strings.Trim(arn, \"${}\"), \".Arn\", \"\")\n}\n\nfunc extractExecutablePath(functionName string) string {\n\trfn := []rune(strings.ReplaceAll(functionName, \"Function\", \"\"))\n\treturn strings.ToLower(string(rfn[0])) + string(rfn[1:])\n}\n\nfunc makeTemplateValue(path string, opearation *openapi3.Operation) lambdaFunctionTemplate {\n\tdec, err := jsoninfo.NewObjectDecoder(opearation.Extensions[\"x-amazon-apigateway-integration\"].(json.RawMessage))\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tvar apigw apigateway\n\tif err = opearation.DecodeWith(dec, \u0026apigw); err != nil {\n\t\tpanic(err)\n\t}\n\n\tfunctionName := extractFunctionName(apigw)\n\texecutablePath := extractExecutablePath(functionName)\n\n\treturn lambdaFunctionTemplate{\n\t\tFunctionName:   functionName,\n\t\tOperationId:    opearation.OperationID,\n\t\tDescription:    opearation.Description,\n\t\tExecutablePath: executablePath,\n\t\tPath:           path,\n\t}\n}\n\nfunc convertToTemplateValues(spec *openapi3.T) []lambdaFunctionTemplate {\n\tpaths := make([]string, 0, len(spec.Paths))\n\tfor path := range spec.Paths {\n\t\tpaths = append(paths, path)\n\t}\n\tsort.Strings(paths)\n\n\ttemplates := make([]lambdaFunctionTemplate, 0, len(paths))\n\n\tfor _, path := range paths {\n\t\tv := spec.Paths[path]\n\n\t\toperations := make([]*openapi3.Operation, 0)\n\t\toperations = append(operations, v.Connect, v.Delete, v.Get, v.Head, v.Options, v.Patch, v.Post, v.Put, v.Trace)\n\n\t\tfor _, o := range operations {\n\t\t\tif o != nil {\n\t\t\t\ttemplateValue := makeTemplateValue(path, o)\n\t\t\t\ttemplates = append(templates, templateValue)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn templates\n}\n\nfunc outTemplate(writer io.Writer, templateValues []lambdaFunctionTemplate) {\n\tfor _, v := range templateValues {\n\t\ttmpl, err := template.New(\"lambda\").Parse(lamdbaFunctionTemplateString)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\n\t\tif err := tmpl.Execute(writer, v); err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\twriter.Write([]byte(\"\\n\"))\n\t}\n\n}\n\nfunc main() {\n\tvar filePath string\n\tflag.StringVar(\u0026filePath, \"f\", \"openapi.yaml\", \"OpenAPI specification file path ex.) openapi.yaml\")\n\n\tflag.Parse()\n\n\tloader := openapi3.NewLoader()\n\n\tspec, err := loader.LoadFromFile(filePath)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\ttemplates := convertToTemplateValues(spec)\n\twriter := new(strings.Builder)\n\n\toutTemplate(writer, templates)\n\n\tfmt.Println(writer.String())\n\n}\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["OpenAPI","Lambda"]},"/note/OpenAPI%E4%BB%95%E6%A7%98%E6%9B%B8%E3%81%8B%E3%82%89Go%E3%81%AE%E6%A7%8B%E9%80%A0%E4%BD%93%E3%82%92%E4%BD%9C%E3%82%8B":{"title":"OpenAPI仕様書からGoの構造体を作る","content":"\n\u003chttps://github.com/OpenAPITools/openapi-generator\u003e\n\n\u003chttps://github.com/deepmap/oapi-codegen\u003e\n\n````shell\n$ oapi-codegen -generate \"types,server\" -package \"openapi\" openapi.yaml \u003e openapi.gen.go\n````\n\n## oapi-codegen で生成したstructにURLパラメータをバインドできない\n\n\u003chttps://github.com/deepmap/oapi-codegen/issues/500\u003e\n\n`oapi-codegen -generate \"types\" -package \"openapi\" openapi.yaml` で以下のようなコードが生成される\n\n````\ntype FindPetsParams struct {\n\t// tags to filter by\n\tTags *[]string `json:\"tags,omitempty\"`\n\n\t// maximum number of results to return\n\tLimit *int32 `json:\"limit,omitempty\"`\n}\n````\n\nこれをechoのメソッドでBindするとこうなる\n\n````\nfunc ParseFilter(c *echo.Context) error {\n\tf := tasksapi.FindPetsParams{}\n\tif err := c.Bind(\u0026f); err != nil {\n\t\treturn f, err\n\t}\n\n    fmt.Printf(\"param: %v\\n\", f) // =\u003e fieldに値がセットされない\n\n\treturn f, nil\n}\n````\n\nParamのstructタグにqueryがついていればBindされる\n\n````\ntype FindPetsParams struct {\n\t// tags to filter by\n\tTags *[]string `query:\"tags,omitempty\"`\n\n\t// maximum number of results to return\n\tLimit *int32 `query:\"limit,omitempty\"`\n}\n````\n\ngenerate に server を指定すると、ここを解決したコードを生成してくれるのだが、\nServerInterfaceが全部のAPIをひとつのinterfaceで持っちゃっているので、なんか微妙だなって思っちゃう\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["Go"]},"/note/OpenAPI-Generator":{"title":"OpenAPI Generator","content":"\n\\#OpenAPI\n\n---\n\n## 伝えたいこと\n\n* OpenAPI(Swagger)を使って、APIクライアントのコードを自動生成しよう\n  * コードと仕様書に齟齬がなくなる\n  * Nullable/NonNull、スペルミス、APIインターフェース変更への追従が確実\u0026簡単になる\n* 最初期に導入するほうが効果が高く、途中から導入するのは難しい…\n* コマンド例\n\n````shell\n$ docker run --rm -v \"${PWD}:/local\" openapitools/openapi-generator-cli generate\n    -i https://petstore3.swagger.io/api/v3/openapi.json\n    -g typescript-axios -o /local/client\n$ ls client\napi.ts  base.ts  configuration.ts  git_push.sh  index.ts\n````\n\n---\n\n## フロントエンド開発時に困ること\n\n* APIのレスポンスの型を定義するのが手間\n  * 手で書いたり、JSONから変換したり\n* 仕様変更に追従しなければいけない\n* Nullable/NonNullの認識ミス\n\n---\n\n\u003c!-- _class: center --\u003e\n\n自動生成できないか :tired_face:\n\n---\n\n\u003c!-- _class: center --\u003e\n\nSwagger仕様書から作ろう :bulb:\n\n---\n\n## OpenAPI(Swagger)\n\n* Swagger 3.0からOpenAPIに名前がかわっている\n* 2021/05/19現在の最新は、3.1.0\n  * \u003chttps://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md\u003e\n* RESTful APIに関するインターフェース定義\n* 定義書はJSONファイルやYAMLファイル\n\n---\n\n## OpenAPI Generator\n\n* OpenAPIのスキーマ定義からコード生成できる\n* 生成できる言語・FWは多数サポートされている\n* 利用方法が多数用意されている\n  * CLI\n  * Maven Plugin\n\n---\n\n\u003cdiv class=\"chapter\"\u003eOpenAPI Generator\u003c/div\u003e\n\n### 試してみる\n\nサンプルとして公開されている定義ファイルを使います\n\n* Swagger UI: \u003chttps://petstore3.swagger.io/\u003e\n* スキーマ定義ファイル: \u003chttps://petstore3.swagger.io/api/v3/openapi.json\u003e\n\n---\n\n\u003cdiv class=\"chapter\"\u003eOpenAPI Generator\u003c/div\u003e\n\n### OpenAPI Generatorをインストール\n\n\u003chttps://github.com/OpenAPITools/openapi-generator#1---installation\u003e\n\nインストール方法が多数用意されているので環境に合わせて利用してください\n\n* :m: Maven Plugin\n* :package: npm\n* :beer: Homebrew\n* :whale: Docker\n\n---\n\n\u003cdiv class=\"chapter\"\u003eOpenAPI Generator\u003c/div\u003e\n\n### Dockerを使って生成する\n\nMavenのプロジェクトに自動生成コードを追加する\n\n````shell\n$ cd \u003cプロジェクトルート\u003e\n$ docker run --rm -v \"${PWD}:/local\" openapitools/openapi-generator-cli generate\n    -i https://petstore3.swagger.io/api/v3/openapi.json\n    -g java -o /local/client\n\n# デフォルトだと、src/main/java/org/openapitools/client にAPIクライアントやリクエスト、レスポンスの型が生成される \n$ ls src/main/java/org/openapitools/client\napi    ApiCallback.java   ApiResponse.java             JSON.java                 \nauth   ApiClient.java     Configuration.java           Pair.java                 \nmodel  ApiException.java  GzipRequestInterceptor.java  ProgressRequestBody.java  \n````\n\n* `-i`: スキーマ定義ファイルパス(URL可)\n* `-g`: どの言語、FWを対象にするか\n* `-o`: 生成先ディレクトリ\n\n---\n\n\u003cdiv class=\"chapter\"\u003eOpenAPI Generator\u003c/div\u003e\n\n### 使い方\n\n````java\nimport org.openapitools.client.ApiClient;\nimport org.openapitools.client.ApiException;\nimport org.openapitools.client.api.PetApi;\nimport org.openapitools.client.model.Pet;\n\npublic class Repository {\n    public Pet get() {\n        // 内部的にはokhttp3を使っている。設定で変更可能。\n        ApiClient apiClient = new ApiClient();\n        PetApi petApi = new PetApi(apiClient);\n        try {\n            Pet petById = petApi.getPetById(1L);\n            return petById;\n        } catch (ApiException e) { e.printStackTrace(); }\n    }\n}\n````\n\n---\n\n\u003cdiv class=\"chapter\"\u003eOpenAPI Generator\u003c/div\u003e\n\n### 生成対象言語・FW一覧\n\n`-g` で指定できるgeneratorの一覧はこちら\n\n\u003chttps://github.com/OpenAPITools/openapi-generator/blob/master/docs/generators.md\u003e\n\ngeneratorの設定値もこちらから\n\n---\n\n## TypeScriptの例\n\npackage.json\n\n````json\n{\n\n  \"scripts\": {\n    \"openapi-generate\": \"rm -f client/*.ts \u0026\u0026 \n        TS_POST_PROCESS_FILE='yarn prettier --write'\n        openapi-generator-cli generate \n        -i https://petstore3.swagger.io/api/v3/openapi.json\n        -g typescript-axios \n        -o client \n        --additional-properties=disallowAdditionalPropertiesIfNotPresent=false,modelPropertyNaming=camelCase,supportsES6=true,useSingleRequestParameter=true\n        --enable-post-process-file\"\n  }\n  // ...\n}\n````\n\n`yarn openapi-generate` で生成される\n\n* `TS_POST_PROCESS_FILE='yarn prettier --write'`: 後処理を指定(ここではフォーマット)\n* `--additional-properties=`: generator独自の設定\n\n---\n\n## メリット :+1:\n\n* リクエスト、レスポンスの型に間違いがない\n* APIの変更があったときに追従が簡単\n* コンパイルエラーによって変更を検知できる\n\n---\n\n## デメリット :-1:\n\n### プロジェクトのコード規約に合わないコードが生成される\n\n* 許容する\n* [generator](https://github.com/OpenAPITools/openapi-generator/blob/master/docs/generators/typescript-axios.md) のオプションをよく読んで頑張る\n\n### 途中から自動生成に変更するのは難しい(逆も然り)\n\n* HTTPクライアントの実装も生成されるため、それに依存する\n* 型定義のみ生成することもできるので、そちらのみ使用するようにする\n\n---\n\n\u003cdiv class=\"chapter\"\u003eデメリット\u003c/div\u003e\n\n### スキーマ定義を生成するライブラリの学習コスト\n\n* ライブラリで複雑な定義を実現しようとするとハマる\n  * ポリモーフィズムを表現しようとしたときに、oneOf/allOfが狙ったとおりに出力されず時間がかかった :tired_face:\n* 定義ファイルを手動で作成し、サーバー・クライアント両方のコードを生成する方針に変えてみる(スキーマ駆動開発)\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["OpenAPI"]},"/note/OpenAPI-yaml%E3%82%92%E7%B7%A8%E9%9B%86%E3%81%99%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%ABSwagger-Editor%E3%81%AA%E3%81%A9%E3%82%92%E4%BD%BF%E3%81%86":{"title":"OpenAPI yamlを編集するときにSwagger Editorなどを使う","content":"\nOpenAPI specを書くツールをいくつか調べた\n\n* vscodeだと拡張を入れてもいまいち補完が効かない\n* Intellij IDEAの [OpenAPI Editor](https://plugins.jetbrains.com/plugin/12887-openapi-editor) が一番良さそうだがJetBrainsライセンス必要\n* Stoplight Studioはいいけど勝手にファイルをフォーマットかけたりするし重い。会員登録必要\n* Swagger Editor は補完聞くけどブラウザ上で編集ってのが気持ち悪い\n* Swagger Editorをdockerでローカルに立ち上げて使うのがいいのかな\n\n## 結論\n\nどちらかが良さそう。書きやすいのはvimで、補完効かせたかったらSwagger Editor\n\n* Swagger Editor (OpenAPI 3.0.x) で書く\n* Neovim + LSPで書いて、ReDocで描画する\n\n## Swagger Editorをローカルに立ち上げる\n\n````shell\n$ docker run -it --rm -p 8080:8080 -v $(pwd):/tmp -e SWAGGER_FILE=/tmp/openapi.yaml swaggerapi/swagger-editor\n````\n\nlocalhost:8080 でSwagger Editorが開く\n\nここで編集しても、ファイルが書き換わるわけではなかったので、いちいち保存してローカルで上書きとかが必要\n\n### v5を使ってみる\n\nv5はまだ安定版じゃないが使ってみる\n\n````shell\ndocker run -d -p 8080:8080 -v $(pwd):/tmp swaggerapi/swagger-editor:next-v5\n````\n\n画面はスッキリしたが、ファイルが指定できなくてまだ早いかも\n\n## ReDocで描画する\n\nSwagger Editorは[Swagger UI](https://swagger.io/tools/swagger-ui/)を描画に使うが、OAS 3.1.0に対応していない。\nhttps://github.com/swagger-api/swagger-ui/issues/5891\n\nそこでRedocを使う\n\nhttps://hub.docker.com/r/redocly/redoc/\n\n````shell\n$ ls openapi.yaml\n$ docker run -it --rm -p 3000:80 -v $(pwd):/usr/share/nginx/html/swagger/ -e SPEC_URL=swagger/openapi.yaml redocly/redoc\n````\n\nlocalhost:3000 で開くと、指定したファイルが描画されている。\nホットリロードもしてくれる。\n\n(素直に3.0.xにしてswagger-uiで表示するのが簡単な気がした)\n\n## LSP + Neovim\n\nhttps://github.com/luizcorreia/spectral-language-server\nこれはメンテされてなくて `npm i -g spectral-language-server`  がまず失敗した\n\n### jsonla\n\nhttps://www.reddit.com/r/neovim/comments/r5l1ax/anyone_has_a_successful_experience_with_openapi/\n[b0o/SchemaStore.nvim: 🛍 JSON schemas for Neovim](https://github.com/b0o/SchemaStore.nvim)\nこれが紹介されてた\n\n````shell\n$ npm i -g vscode-langservers-extracted\n````\n\npacker\n\n````lua\nuse \"b0o/schemastore.nvim\"\n````\n\n````lua\n  settings = {\n    json = {\n      schemas = require('schemastore').json.schemas(),\n      validate = { enable = true },\n    },\n  },\n````\n\nだいたい補完がきくようになったが、schemaの中は全然補完されず\nschemaの中はIntellijでも補完されなかったので、すべて補完きかせたかったらSwagger Editorになるか\n\n### yamlls\n\nnvim-lspでyaml-language-serverを使うようになっている\nhttps://github.com/neovim/nvim-lspconfig/blob/e69978a39e4d3262b09ce6a316beff384f443e3b/doc/server_configurations.md#yamlls\nhttps://github.com/williamboman/mason-lspconfig.nvim/blob/3751eb5c56c67b51e68a1f4a0da28ae74ab771c1/doc/server-mapping.md\n\nこちらでデフォルトでOpenAPI 3.1.0 が組み込まれていたのでyamlの場合はこれで十分だった\n\nhttps://github.com/redhat-developer/yaml-language-server/blob/18ecc0e3d0ff6365e67b88127ac663351b0308de/src/languageservice/utils/schemaUrls.ts#L10\nhttps://github.com/SchemaStore/schemastore/blob/master/src/api/json/catalog.json\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/01/05","OpenAPI"]},"/note/OpenObserve%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B":{"title":"OpenObserveを使ってみる","content":"\n{{\u003c card-link \"https://openobserve.ai\" \u003e}} \n\n[Kibana](note/Kibana.md) のように、ログデータの可視化を行うツールで、ログ、メトリクス、トレースをペタバイトレベルで扱うことができる。\nElasticsearchやDatadogと比べ、10倍簡単、140倍のストレージコスト安、ハイパフォーマンスなどを謳っている。\nバックエンドは[Rust](note/Rust.md)、フロントエンドは[Vue.js](note/Vue.js.md)で書かれている。\n\n絶賛開発中のようなので、破壊的な変更が入る可能性が全然ありそう。\n\n## ストレージ\n\nOpenObserveはデータをインデックせず、圧縮してローカルだけではなくS3などオブジェクトストレージに保存することができる。\nS3に保存することで、大容量のEBSを用意する場合と比べてコストが下げられるということのようで、HA構成にした場合でもあがらないと言いたいらしい。\n\n## アーキテクチャ\n\nhttps://openobserve.ai/docs/architecture/\n\n### 単一ノード\n\n1台のノードで、2TB/day までのデータ量であれば扱うことができる。\n全データをローカルディスクストレージに保存することもできるし、メタデータをetcd、データをS3に保存するということもできる。\n拡張性を考えると単一ノードでもオブジェクトストレージを使ったほうがよさそう。\n\n### HA構成\n\nHAモードではローカルディスクは使用できないので、必ずS3などが保存先になる。\n以下複数の役割のノードで構成される。\n\n* Ingester: 投入されたデータをparquetフォーマットに変換して、オブジェクトストレージに保存する。受け取ったデータを即オブジェクトストレージに転送するのではなく、ある程度ローカルに貯めてから転送するようだ。\n* Querier: クエリを実行する。\n* Compactor: 複数の小さいファイルを一つの大きいファイルにマージして、検索の効率を上げる\n* Router: リクエストをingesterやquerierに分配する、proxyの役割。\n* AlertManager: 定期実行やアラート通知\n\nデプロイは https://openobserve.ai/docs/ha_deployment/ を参照。\n今のところ [Kubernetes](note/Kubernetes.md) にhelmでデプロイする手順のみが用意されている。\n[EC2やECSでもやれなくはない](https://discuss.openobserve.ai/kb/t/ha-deployment-on-aws-ecs-or-ec2/2K1d28) が公式手順はないので、自分でkubernetesのマニフェスト見ながら頑張るしかなさそう。\n\n## データ摂取(ingestion)\n\nhttps://openobserve.ai/docs/ingestion/logs/python/#python\n\nログやメトリクスはFluent-bitやKinesis Firehose、curlなどさまざまなソースからHTTP APIで投入できる。\nすでに構築済みのデータ投入機構があれば、投入先をOpenObserveにすればよさそう\n\n## セットアップ(セルフホスト)\n\nhttps://openobserve.ai/docs/quickstart/\n\nDockerで簡単に起動できる\n\n````shell\nmkdir data\ndocker run -v $PWD/data:/data -e ZO_DATA_DIR=\"/data\" -p 5080:5080 -e ZO_ROOT_USER_EMAIL=\"root@example.com\" -e ZO_ROOT_USER_PASSWORD=\"Complexpass#123\" public.ecr.aws/zinclabs/openobserve:latest\n````\n\n=\u003e localhost:5080 で開く\n\nサンプルデータも用意してくれているのでそれを投入すれば閲覧できる\n\n````shell\ncurl -L https://zinc-public-data.s3.us-west-2.amazonaws.com/zinc-enl/sample-k8s-logs/k8slog_json.json.zip -o k8slog_json.json.zip\nunzip k8slog_json.json.zip\ncurl http://localhost:5080/api/default/default/_json -i -u \"root@example.com:Complexpass#123\"  -d \"@k8slog_json.json\"\n````\n\n## サンプルデータを作成する\n\n本題ではないが、今後役立ちそうなのでfakeデータをつくってみる。\nfakeの作成には https://github.com/brianvoe/gofakeit を使った。\n\n````go\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"math/rand\"\n\t\"time\"\n\n\t\"github.com/brianvoe/gofakeit/v6\"\n)\n\ntype accessLog struct {\n\tTimestamp    time.Time `fake:\"{daterange:2023-06-30T16:00:00,2023-06-30T16:59:59,yyyy-MM-ddTHH:mm:ss}\" format:\"2006-01-02T15:04:05\"`\n\tPath         string    `fake:\"{urlpath}\"`\n\tMethod       string    `fake:\"{httpmethod}\"`\n\tInstanceId   string    `fake:\"{regex:i-[a-f]{1}}\"`\n\tResponseTime int       `fake:\"{number:1500,3000}\"`\n\tStatus       int       `fake:\"{httpstatuscodesimple}\"`\n}\n\nfunc main() {\n\tfaker := gofakeit.NewUnlocked(0)\n\n\tgofakeit.AddFuncLookup(\"urlpath\", gofakeit.Info{\n\t\tCategory:    \"custom\",\n\t\tDescription: \"Path only\",\n\t\tExample:     \"/image\",\n\t\tOutput:      \"string\",\n\t\tGenerate: func(r *rand.Rand, m *gofakeit.MapParams, info *gofakeit.Info) (interface{}, error) {\n\t\t\treturn gofakeit.RandomString([]string{\"/example\", \"/image\", \"/hello\", \"/health\", \"/ping\", \"/login\", \"/account\", \"/route\", \"/spot\"}), nil\n\t\t},\n\t})\n\n\tlogs := make([]accessLog, 0)\n\tfor i := 0; i \u003c 5000; i++ {\n\t\tvar l accessLog\n\t\terr := faker.Struct(\u0026l)\n\t\tif err != nil {\n\t\t\tlog.Fatalln(err)\n\t\t}\n\t\tlogs = append(logs, l)\n\t}\n\n\tb, err := json.Marshal(logs)\n\tif err != nil {\n\t\tlog.Fatalln(err)\n\t}\n\n\tfmt.Println(string(b))\n}\n\n````\n\n大量に作ってぶっこんでパフォーマンス検証\n\n````\nwhile true; do JSON=fake_$(date +%s).json; ./faker -count 10000 \u003e $JSON; curl http://localhost:5080/api/default/fake/_json -i -u \"root@example.com:Complexpass#123\"  -d \"@${JSON}\"; rm \"${JSON}\"; sleep 1; done\n````\n\n## HA構成をKubernetesで動かす\n\n[Rancher Desktop](note/Rancher%20Desktop.md) の [Kubernetes](note/Kubernetes.md) にデプロイして、HA構成を試してみる。\n\nHA構成の場合はオブジェクトストレージが必須なので、事前に [MinIOをローカルのkubernetesで動かす](note/MinIOをローカルのkubernetesで動かす.md)\n==\u003e OpenObserveのhelm内にminioが内包されていたので不要だった。。気づくの遅かった\n\nそうしたらhelm chartが用意されているのでデプロイする\n\n{{\u003c card-link \"https://github.com/openobserve/openobserve-helm-chart/\" \u003e}}\n\nvalues.yaml\n\n````yaml\nserviceAccount:\n  # Annotations to add to the service account\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::12345353456:role/zo-s3-eks\n\nreplicaCount:\n  ingester: 1\n  querier: 1\n  router: 1\n  alertmanager: 1\n  compactor: 1\n\nminio:\n  enabled: true # if true then minio will be deployed as part of openobserve\n````\n\nデプロイ\n\n````shell\nhelm --namespace openobserve -f values.yaml install --create-namespace o1 openobserve/openobserve\n\n````\n\nlocalhost:5080 で開く\n\n````shell\nkubectl --namespace openobserve port-forward svc/o1-openobserve-router 5080:5080\n````\n\nminioの中身確認\n\n````shell\nkubectl run awscli -it --rm --image amazon/aws-cli --env=AWS_ACCESS_KEY_ID=rootuser --env=AWS_SECRET_ACCESS_KEY=rootpass123 --command -- sh\n\nsh-4.2$ aws --endpoint-url http://o1-minio-svc.openobserve.svc.cluster.local:9000 --no-verify-ssl s3 ls\n1-01-01 00:00:00    mysuperduperbucket\n````\n\n## HA構成をDocker composeで動かす\n\nhelmでデプロイされたリソースから、ある程度動くようにDocker composeに落とし込む。\n\n````yaml\nservices:\n  querier:\n    image: public.ecr.aws/zinclabs/openobserve:latest\n    expose:\n      - 5080\n      - 5081\n    restart: on-failure\n    depends_on:\n      - etcd-1\n      - etcd-2\n      - minio\n    environment:\n      - ZO_NODE_ROLE=querier\n      - OTEL_OTLP_HTTP_ENDPOINT=http://127.0.0.1:5080/api/nexus/traces\n      - RUST_BACKTRACE=1\n      - RUST_LOG=info\n      - ZO_BASE_URI=\n      - ZO_COLS_PER_RECORD_LIMIT=200\n      - ZO_COMPACT_BLOCKED_ORGS=\n      - ZO_COMPACT_DATA_RETENTION_DAYS=0\n      - ZO_COMPACT_ENABLED=true\n      - ZO_COMPACT_FAKE_MODE=false\n      - ZO_COMPACT_INTERVAL=60\n      - ZO_COMPACT_MAX_FILE_SIZE=2\n      - ZO_DATA_DIR=./data/\n      - ZO_DATA_STREAM_DIR=\n      - ZO_DATA_WAL_DIR=\n      - ZO_ETCD_ADDR=etcd-1:2379\n      - ZO_ETCD_CERT_FILE=\n      - ZO_ETCD_CLIENT_CERT_AUTH=false\n      - ZO_ETCD_COMMAND_TIMEOUT=5\n      - ZO_ETCD_CONNECT_TIMEOUT=2\n      - ZO_ETCD_DOMAIN_NAME=\n      - ZO_ETCD_KEY_FILE=\n      - ZO_ETCD_LOAD_PAGE_SIZE=10000\n      - ZO_ETCD_LOCK_WAIT_TIMEOUT=600\n      - ZO_ETCD_PASSWORD=\n      - ZO_ETCD_PREFIX=/zinc/observe/\n      - ZO_ETCD_TRUSTED_CA_FILE=\n      - ZO_ETCD_USER=\n      - ZO_FEATURE_FULLTEXT_ON_ALL_FIELDS=false\n      - ZO_FEATURE_PER_THREAD_LOCK=false\n      - ZO_FILE_EXT_JSON=.json\n      - ZO_FILE_EXT_PARQUET=.parquet\n      - ZO_FILE_MOVE_THREAD_NUM=0\n      - ZO_FILE_PUSH_INTERVAL=10\n      - ZO_GRPC_ORG_HEADER_KEY=zinc-org-id\n      - ZO_GRPC_PORT=5081\n      - ZO_GRPC_TIMEOUT=600\n      - ZO_HEARTBEAT_INTERVAL=30\n      - ZO_HTTP_IPV6_ENABLED=false\n      - ZO_HTTP_PORT=5080\n      - ZO_INSTANCE_NAME=\n      - ZO_JSON_LIMIT=209715200\n      - ZO_LOCAL_MODE=false\n      - ZO_LOCAL_MODE_STORAGE=disk\n      - ZO_LUA_FN_ENABLED=false\n      - ZO_MAX_FILE_RETENTION_TIME=10\n      - ZO_MAX_FILE_SIZE_ON_DISK=1\n      - ZO_MEMORY_CACHE_CACHE_LATEST_FILES=false\n      - ZO_MEMORY_CACHE_ENABLED=true\n      - ZO_MEMORY_CACHE_MAX_SIZE=0\n      - ZO_MEMORY_CACHE_RELEASE_SIZE=0\n      - ZO_METRICS_DEDUP_ENABLED=true\n      - ZO_METRICS_LEADER_ELECTION_INTERVAL=30\n      - ZO_METRICS_LEADER_PUSH_INTERVAL=15\n      - ZO_PARQUET_COMPRESSION=zstd\n      - ZO_PAYLOAD_LIMIT=209715200\n      - ZO_PROMETHEUS_HA_CLUSTER=cluster\n      - ZO_PROMETHEUS_HA_REPLICA=__replica__\n      - ZO_QUERY_THREAD_NUM=0\n      - ZO_ROUTE_TIMEOUT=600\n      - ZO_S3_BUCKET_NAME=mysuperduperbucket\n      - ZO_S3_BUCKET_PREFIX=mysuperduperbucket\n      - ZO_S3_PROVIDER=minio\n      - ZO_S3_REGION_NAME=us-east-1\n      - ZO_S3_SERVER_URL=http://minio:9000\n      - ZO_SKIP_SCHEMA_VALIDATION=false\n      - ZO_SLED_DATA_DIR=\n      - ZO_SLED_PREFIX=/zinc/observe/\n      - ZO_TELEMETRY=true\n      - ZO_TELEMETRY_URL=https://e1.zinclabs.dev\n      - ZO_TIME_STAMP_COL=_timestamp\n      - ZO_TRACING_ENABLED=false\n      - ZO_TRACING_HEADER_KEY=Authorization\n      - ZO_TRACING_HEADER_VALUE=Basic YWRtaW46Q29tcGxleHBhc3MjMTIz\n      - ZO_TS_ALLOWED_UPTO=5\n      - ZO_UI_ENABLED=true\n      - ZO_WAL_LINE_MODE_ENABLED=true\n      - ZO_WAL_MEMORY_MODE_ENABLED=false\n      - ZO_WIDENING_SCHEMA_EVOLUTION=false\n      - ZO_ROOT_USER_EMAIL=root@example.com\n      - ZO_ROOT_USER_PASSWORD=Complexpass#123\n      - ZO_S3_ACCESS_KEY=rootuser\n      - ZO_S3_SECRET_KEY=rootpass123\n\n  ingester:\n    image: public.ecr.aws/zinclabs/openobserve:latest\n    expose:\n      - 5080\n      - 5081\n    restart: on-failure\n    depends_on:\n      - etcd-1\n      - etcd-2\n      - minio\n    volumes:\n      - ./data:/data\n    environment:\n      - ZO_NODE_ROLE=ingester\n      - OTEL_OTLP_HTTP_ENDPOINT=http://127.0.0.1:5080/api/nexus/traces\n      - RUST_BACKTRACE=1\n      - RUST_LOG=info\n      - ZO_BASE_URI=\n      - ZO_COLS_PER_RECORD_LIMIT=200\n      - ZO_COMPACT_BLOCKED_ORGS=\n      - ZO_COMPACT_DATA_RETENTION_DAYS=0\n      - ZO_COMPACT_ENABLED=true\n      - ZO_COMPACT_FAKE_MODE=false\n      - ZO_COMPACT_INTERVAL=60\n      - ZO_COMPACT_MAX_FILE_SIZE=2\n      - ZO_DATA_DIR=./data/\n      - ZO_DATA_STREAM_DIR=\n      - ZO_DATA_WAL_DIR=\n      - ZO_ETCD_ADDR=etcd-1:2379\n      - ZO_ETCD_CERT_FILE=\n      - ZO_ETCD_CLIENT_CERT_AUTH=false\n      - ZO_ETCD_COMMAND_TIMEOUT=5\n      - ZO_ETCD_CONNECT_TIMEOUT=2\n      - ZO_ETCD_DOMAIN_NAME=\n      - ZO_ETCD_KEY_FILE=\n      - ZO_ETCD_LOAD_PAGE_SIZE=10000\n      - ZO_ETCD_LOCK_WAIT_TIMEOUT=600\n      - ZO_ETCD_PASSWORD=\n      - ZO_ETCD_PREFIX=/zinc/observe/\n      - ZO_ETCD_TRUSTED_CA_FILE=\n      - ZO_ETCD_USER=\n      - ZO_FEATURE_FULLTEXT_ON_ALL_FIELDS=false\n      - ZO_FEATURE_PER_THREAD_LOCK=false\n      - ZO_FILE_EXT_JSON=.json\n      - ZO_FILE_EXT_PARQUET=.parquet\n      - ZO_FILE_MOVE_THREAD_NUM=0\n      - ZO_FILE_PUSH_INTERVAL=10\n      - ZO_GRPC_ORG_HEADER_KEY=zinc-org-id\n      - ZO_GRPC_PORT=5081\n      - ZO_GRPC_TIMEOUT=600\n      - ZO_HEARTBEAT_INTERVAL=30\n      - ZO_HTTP_IPV6_ENABLED=false\n      - ZO_HTTP_PORT=5080\n      - ZO_INSTANCE_NAME=\n      - ZO_JSON_LIMIT=209715200\n      - ZO_LOCAL_MODE=false\n      - ZO_LOCAL_MODE_STORAGE=disk\n      - ZO_LUA_FN_ENABLED=false\n      - ZO_MAX_FILE_RETENTION_TIME=10\n      - ZO_MAX_FILE_SIZE_ON_DISK=1\n      - ZO_MEMORY_CACHE_CACHE_LATEST_FILES=false\n      - ZO_MEMORY_CACHE_ENABLED=true\n      - ZO_MEMORY_CACHE_MAX_SIZE=0\n      - ZO_MEMORY_CACHE_RELEASE_SIZE=0\n      - ZO_METRICS_DEDUP_ENABLED=true\n      - ZO_METRICS_LEADER_ELECTION_INTERVAL=30\n      - ZO_METRICS_LEADER_PUSH_INTERVAL=15\n      - ZO_PARQUET_COMPRESSION=zstd\n      - ZO_PAYLOAD_LIMIT=209715200\n      - ZO_PROMETHEUS_HA_CLUSTER=cluster\n      - ZO_PROMETHEUS_HA_REPLICA=__replica__\n      - ZO_QUERY_THREAD_NUM=0\n      - ZO_ROUTE_TIMEOUT=600\n      - ZO_S3_BUCKET_NAME=mysuperduperbucket\n      - ZO_S3_BUCKET_PREFIX=mysuperduperbucket\n      - ZO_S3_PROVIDER=minio\n      - ZO_S3_REGION_NAME=us-east-1\n      - ZO_S3_SERVER_URL=http://minio:9000\n      - ZO_SKIP_SCHEMA_VALIDATION=false\n      - ZO_SLED_DATA_DIR=\n      - ZO_SLED_PREFIX=/zinc/observe/\n      - ZO_TELEMETRY=true\n      - ZO_TELEMETRY_URL=https://e1.zinclabs.dev\n      - ZO_TIME_STAMP_COL=_timestamp\n      - ZO_TRACING_ENABLED=false\n      - ZO_TRACING_HEADER_KEY=Authorization\n      - ZO_TRACING_HEADER_VALUE=Basic YWRtaW46Q29tcGxleHBhc3MjMTIz\n      - ZO_TS_ALLOWED_UPTO=5\n      - ZO_UI_ENABLED=true\n      - ZO_WAL_LINE_MODE_ENABLED=true\n      - ZO_WAL_MEMORY_MODE_ENABLED=false\n      - ZO_WIDENING_SCHEMA_EVOLUTION=false\n      - ZO_ROOT_USER_EMAIL=root@example.com\n      - ZO_ROOT_USER_PASSWORD=Complexpass#123\n      - ZO_S3_ACCESS_KEY=rootuser\n      - ZO_S3_SECRET_KEY=rootpass123\n\n  router:\n    image: public.ecr.aws/zinclabs/openobserve:latest\n    ports:\n      - 5080:5080\n    restart: on-failure\n    depends_on:\n      - etcd-1\n      - etcd-2\n      - minio\n    expose:\n      - 5080\n      - 5081\n    environment:\n      - ZO_NODE_ROLE=router\n      - OTEL_OTLP_HTTP_ENDPOINT=http://127.0.0.1:5080/api/nexus/traces\n      - RUST_BACKTRACE=1\n      - RUST_LOG=info\n      - ZO_BASE_URI=\n      - ZO_COLS_PER_RECORD_LIMIT=200\n      - ZO_COMPACT_BLOCKED_ORGS=\n      - ZO_COMPACT_DATA_RETENTION_DAYS=0\n      - ZO_COMPACT_ENABLED=true\n      - ZO_COMPACT_FAKE_MODE=false\n      - ZO_COMPACT_INTERVAL=60\n      - ZO_COMPACT_MAX_FILE_SIZE=2\n      - ZO_DATA_DIR=./data/\n      - ZO_DATA_STREAM_DIR=\n      - ZO_DATA_WAL_DIR=\n      - ZO_ETCD_ADDR=etcd-1:2379\n      - ZO_ETCD_CERT_FILE=\n      - ZO_ETCD_CLIENT_CERT_AUTH=false\n      - ZO_ETCD_COMMAND_TIMEOUT=5\n      - ZO_ETCD_CONNECT_TIMEOUT=2\n      - ZO_ETCD_DOMAIN_NAME=\n      - ZO_ETCD_KEY_FILE=\n      - ZO_ETCD_LOAD_PAGE_SIZE=10000\n      - ZO_ETCD_LOCK_WAIT_TIMEOUT=600\n      - ZO_ETCD_PASSWORD=\n      - ZO_ETCD_PREFIX=/zinc/observe/\n      - ZO_ETCD_TRUSTED_CA_FILE=\n      - ZO_ETCD_USER=\n      - ZO_FEATURE_FULLTEXT_ON_ALL_FIELDS=false\n      - ZO_FEATURE_PER_THREAD_LOCK=false\n      - ZO_FILE_EXT_JSON=.json\n      - ZO_FILE_EXT_PARQUET=.parquet\n      - ZO_FILE_MOVE_THREAD_NUM=0\n      - ZO_FILE_PUSH_INTERVAL=10\n      - ZO_GRPC_ORG_HEADER_KEY=zinc-org-id\n      - ZO_GRPC_PORT=5081\n      - ZO_GRPC_TIMEOUT=600\n      - ZO_HEARTBEAT_INTERVAL=30\n      - ZO_HTTP_IPV6_ENABLED=false\n      - ZO_HTTP_PORT=5080\n      - ZO_INSTANCE_NAME=\n      - ZO_JSON_LIMIT=209715200\n      - ZO_LOCAL_MODE=false\n      - ZO_LOCAL_MODE_STORAGE=disk\n      - ZO_LUA_FN_ENABLED=false\n      - ZO_MAX_FILE_RETENTION_TIME=10\n      - ZO_MAX_FILE_SIZE_ON_DISK=1\n      - ZO_MEMORY_CACHE_CACHE_LATEST_FILES=false\n      - ZO_MEMORY_CACHE_ENABLED=true\n      - ZO_MEMORY_CACHE_MAX_SIZE=0\n      - ZO_MEMORY_CACHE_RELEASE_SIZE=0\n      - ZO_METRICS_DEDUP_ENABLED=true\n      - ZO_METRICS_LEADER_ELECTION_INTERVAL=30\n      - ZO_METRICS_LEADER_PUSH_INTERVAL=15\n      - ZO_PARQUET_COMPRESSION=zstd\n      - ZO_PAYLOAD_LIMIT=209715200\n      - ZO_PROMETHEUS_HA_CLUSTER=cluster\n      - ZO_PROMETHEUS_HA_REPLICA=__replica__\n      - ZO_QUERY_THREAD_NUM=0\n      - ZO_ROUTE_TIMEOUT=600\n      - ZO_S3_BUCKET_NAME=mysuperduperbucket\n      - ZO_S3_BUCKET_PREFIX=mysuperduperbucket\n      - ZO_S3_PROVIDER=minio\n      - ZO_S3_REGION_NAME=us-east-1\n      - ZO_S3_SERVER_URL=http://minio:9000\n      - ZO_SKIP_SCHEMA_VALIDATION=false\n      - ZO_SLED_DATA_DIR=\n      - ZO_SLED_PREFIX=/zinc/observe/\n      - ZO_TELEMETRY=true\n      - ZO_TELEMETRY_URL=https://e1.zinclabs.dev\n      - ZO_TIME_STAMP_COL=_timestamp\n      - ZO_TRACING_ENABLED=false\n      - ZO_TRACING_HEADER_KEY=Authorization\n      - ZO_TRACING_HEADER_VALUE=Basic YWRtaW46Q29tcGxleHBhc3MjMTIz\n      - ZO_TS_ALLOWED_UPTO=5\n      - ZO_UI_ENABLED=true\n      - ZO_WAL_LINE_MODE_ENABLED=true\n      - ZO_WAL_MEMORY_MODE_ENABLED=false\n      - ZO_WIDENING_SCHEMA_EVOLUTION=false\n      - ZO_ROOT_USER_EMAIL=root@example.com\n      - ZO_ROOT_USER_PASSWORD=Complexpass#123\n      - ZO_S3_ACCESS_KEY=rootuser\n      - ZO_S3_SECRET_KEY=rootpass123\n\n  compactor:\n    image: public.ecr.aws/zinclabs/openobserve:latest\n    restart: on-failure\n    depends_on:\n      - etcd-1\n      - etcd-2\n      - minio\n    expose:\n      - 5080\n      - 5081\n    environment:\n      - ZO_NODE_ROLE=compactor\n      - OTEL_OTLP_HTTP_ENDPOINT=http://127.0.0.1:5080/api/nexus/traces\n      - RUST_BACKTRACE=1\n      - RUST_LOG=info\n      - ZO_BASE_URI=\n      - ZO_COLS_PER_RECORD_LIMIT=200\n      - ZO_COMPACT_BLOCKED_ORGS=\n      - ZO_COMPACT_DATA_RETENTION_DAYS=0\n      - ZO_COMPACT_ENABLED=true\n      - ZO_COMPACT_FAKE_MODE=false\n      - ZO_COMPACT_INTERVAL=60\n      - ZO_COMPACT_MAX_FILE_SIZE=2\n      - ZO_DATA_DIR=./data/\n      - ZO_DATA_STREAM_DIR=\n      - ZO_DATA_WAL_DIR=\n      - ZO_ETCD_ADDR=etcd-1:2379\n      - ZO_ETCD_CERT_FILE=\n      - ZO_ETCD_CLIENT_CERT_AUTH=false\n      - ZO_ETCD_COMMAND_TIMEOUT=5\n      - ZO_ETCD_CONNECT_TIMEOUT=2\n      - ZO_ETCD_DOMAIN_NAME=\n      - ZO_ETCD_KEY_FILE=\n      - ZO_ETCD_LOAD_PAGE_SIZE=10000\n      - ZO_ETCD_LOCK_WAIT_TIMEOUT=600\n      - ZO_ETCD_PASSWORD=\n      - ZO_ETCD_PREFIX=/zinc/observe/\n      - ZO_ETCD_TRUSTED_CA_FILE=\n      - ZO_ETCD_USER=\n      - ZO_FEATURE_FULLTEXT_ON_ALL_FIELDS=false\n      - ZO_FEATURE_PER_THREAD_LOCK=false\n      - ZO_FILE_EXT_JSON=.json\n      - ZO_FILE_EXT_PARQUET=.parquet\n      - ZO_FILE_MOVE_THREAD_NUM=0\n      - ZO_FILE_PUSH_INTERVAL=10\n      - ZO_GRPC_ORG_HEADER_KEY=zinc-org-id\n      - ZO_GRPC_PORT=5081\n      - ZO_GRPC_TIMEOUT=600\n      - ZO_HEARTBEAT_INTERVAL=30\n      - ZO_HTTP_IPV6_ENABLED=false\n      - ZO_HTTP_PORT=5080\n      - ZO_INSTANCE_NAME=\n      - ZO_JSON_LIMIT=209715200\n      - ZO_LOCAL_MODE=false\n      - ZO_LOCAL_MODE_STORAGE=disk\n      - ZO_LUA_FN_ENABLED=false\n      - ZO_MAX_FILE_RETENTION_TIME=10\n      - ZO_MAX_FILE_SIZE_ON_DISK=1\n      - ZO_MEMORY_CACHE_CACHE_LATEST_FILES=false\n      - ZO_MEMORY_CACHE_ENABLED=true\n      - ZO_MEMORY_CACHE_MAX_SIZE=0\n      - ZO_MEMORY_CACHE_RELEASE_SIZE=0\n      - ZO_METRICS_DEDUP_ENABLED=true\n      - ZO_METRICS_LEADER_ELECTION_INTERVAL=30\n      - ZO_METRICS_LEADER_PUSH_INTERVAL=15\n      - ZO_PARQUET_COMPRESSION=zstd\n      - ZO_PAYLOAD_LIMIT=209715200\n      - ZO_PROMETHEUS_HA_CLUSTER=cluster\n      - ZO_PROMETHEUS_HA_REPLICA=__replica__\n      - ZO_QUERY_THREAD_NUM=0\n      - ZO_ROUTE_TIMEOUT=600\n      - ZO_S3_BUCKET_NAME=mysuperduperbucket\n      - ZO_S3_BUCKET_PREFIX=mysuperduperbucket\n      - ZO_S3_PROVIDER=minio\n      - ZO_S3_REGION_NAME=us-east-1\n      - ZO_S3_SERVER_URL=http://minio:9000\n      - ZO_SKIP_SCHEMA_VALIDATION=false\n      - ZO_SLED_DATA_DIR=\n      - ZO_SLED_PREFIX=/zinc/observe/\n      - ZO_TELEMETRY=true\n      - ZO_TELEMETRY_URL=https://e1.zinclabs.dev\n      - ZO_TIME_STAMP_COL=_timestamp\n      - ZO_TRACING_ENABLED=false\n      - ZO_TRACING_HEADER_KEY=Authorization\n      - ZO_TRACING_HEADER_VALUE=Basic YWRtaW46Q29tcGxleHBhc3MjMTIz\n      - ZO_TS_ALLOWED_UPTO=5\n      - ZO_UI_ENABLED=true\n      - ZO_WAL_LINE_MODE_ENABLED=true\n      - ZO_WAL_MEMORY_MODE_ENABLED=false\n      - ZO_WIDENING_SCHEMA_EVOLUTION=false\n      - ZO_ROOT_USER_EMAIL=root@example.com\n      - ZO_ROOT_USER_PASSWORD=Complexpass#123\n      - ZO_S3_ACCESS_KEY=rootuser\n      - ZO_S3_SECRET_KEY=rootpass123\n\n  minio:\n    image: quay.io/minio/minio:latest\n    container_name: example-minio\n    environment:\n      MINIO_ROOT_USER: rootuser\n      MINIO_ROOT_PASSWORD: rootpass123\n    volumes:\n      - minio:/data\n    command: server --address :9000 --console-address \":9001\" /data\n    ports:\n      - 9000:9000\n      - 9001:9001\n\n  etcd-1:\n    image: docker.io/bitnami/etcd:3.5.8-debian-11-r4\n    expose:\n      - 2379\n      - 2380\n    volumes:\n      - etcd1:/bitnami/etcd\n    environment:\n      - ETCD_NAME=etcd-1\n      - ETCD_DATA_DIR=/bitnami/etcd/data\n      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379\n      - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380\n      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd-1:2379\n      - ETCD_INITIAL_ADVERTISE_PEER_URLS=http://etcd-1:2380\n      - ETCD_INITIAL_CLUSTER_TOKEN=etcd-cluster-k8s\n      - ETCD_INITIAL_CLUSTER_STATE=new\n      - ETCD_INITIAL_CLUSTER=etcd-1=http://etcd-1:2380,etcd-2=http://etcd-2:2380\n      - ALLOW_NONE_AUTHENTICATION=yes\n  etcd-2:\n    image: docker.io/bitnami/etcd:3.5.8-debian-11-r4\n    expose:\n      - 2379\n      - 2380\n    volumes:\n      - etcd2:/bitnami/etcd\n    environment:\n      - ETCD_NAME=etcd-2\n      - ETCD_DATA_DIR=/bitnami/etcd/data\n      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379\n      - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380\n      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd-2:2379\n      - ETCD_INITIAL_ADVERTISE_PEER_URLS=http://etcd-2:2380\n      - ETCD_INITIAL_CLUSTER_TOKEN=etcd-cluster-k8s\n      - ETCD_INITIAL_CLUSTER_STATE=new\n      - ETCD_INITIAL_CLUSTER=etcd-1=http://etcd-1:2380,etcd-2=http://etcd-2:2380\n      - ALLOW_NONE_AUTHENTICATION=yes\n\nvolumes:\n  minio:\n  etcd1:\n  etcd2:\n````\n\n=\u003e `docker compose up -d` で動いた\n\n## シングルノード+S3で動かす\n\nシングルノード(一つのコンテナで全機能を動かす)モードで、ストレージはS3を使った場合の実行例\n\n````yaml\nservices:\n  app:\n    image: public.ecr.aws/zinclabs/openobserve:latest\n    ports:\n      - 5601:5601\n    depends_on:\n      etcd-1:\n        condition: service_healthy\n      etcd-2:\n        condition: service_healthy\n    volumes:\n      - ./data:/data\n      - ./awsconfig:/root/.aws/config\n    environment:\n      - ZO_DATA_DIR=/data\n      - ZO_HTTP_PORT=5601\n      - ZO_ROOT_USER_EMAIL=root@example.com\n      - ZO_ROOT_USER_PASSWORD=Complexpass#123\n      - ZO_S3_REGION_NAME=ap-northeast-1\n      - ZO_S3_BUCKET_NAME=mybucket\n      - ZO_MAX_FILE_SIZE_ON_DISK=50\n      - ZO_MAX_FILE_RETENTION_TIME=10\n      - ZO_LOCAL_MODE=false\n      - ZO_ETCD_ADDR=etcd-1:2379\n      - ZO_PROMETHEUS_ENABLED=true\n\n  etcd-1:\n    image: docker.io/bitnami/etcd:3.5.8-debian-11-r4\n    ports:\n      - 2379:2379\n      - 2380:2380\n    expose:\n      - 2379\n      - 2380\n    volumes:\n      - etcd1:/bitnami/etcd\n    healthcheck:\n      test: \"etcdctl endpoint health\"\n      interval: 10s\n      timeout: 10s\n      retries: 3\n      start_period: 10s\n    environment:\n      - ETCD_NAME=etcd-1\n      - ETCD_DEBUG=true\n      - ETCD_DATA_DIR=/bitnami/etcd/data\n      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379\n      - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380\n      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd-1:2379\n      - ETCD_INITIAL_ADVERTISE_PEER_URLS=http://etcd-1:2380\n      - ETCD_INITIAL_CLUSTER_TOKEN=etcd-cluster-k8s\n      - ETCD_INITIAL_CLUSTER_STATE=new\n      - ETCD_INITIAL_CLUSTER=etcd-1=http://etcd-1:2380,etcd-2=http://etcd-2:2380\n      - ALLOW_NONE_AUTHENTICATION=yes\n  etcd-2:\n    image: docker.io/bitnami/etcd:3.5.8-debian-11-r4\n    expose:\n      - 2379\n      - 2380\n    volumes:\n      - etcd2:/bitnami/etcd\n    healthcheck:\n      test: \"etcdctl endpoint health\"\n      interval: 10s\n      timeout: 10s\n      retries: 3\n      start_period: 10s\n    environment:\n      - ETCD_NAME=etcd-2\n      - ETCD_DEBUG=true\n      - ETCD_DATA_DIR=/bitnami/etcd/data\n      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379\n      - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380\n      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd-2:2379\n      - ETCD_INITIAL_ADVERTISE_PEER_URLS=http://etcd-2:2380\n      - ETCD_INITIAL_CLUSTER_TOKEN=etcd-cluster-k8s\n      - ETCD_INITIAL_CLUSTER_STATE=new\n      - ETCD_INITIAL_CLUSTER=etcd-1=http://etcd-1:2380,etcd-2=http://etcd-2:2380\n      - ALLOW_NONE_AUTHENTICATION=yes\n\nvolumes:\n  etcd1:\n  etcd2:\n````\n\n### 注意点\n\n* シングルノードだとデフォルトでローカルのディスクストレージを使用するため、 `ZO_LOCAL_MODE=false` を設定した。\n  * このとき、コンテナに `~/.aws/config` が存在しないとエラーになってしまったため、 `./awsconfig:/root/.aws/config` をマウントした (https://github.com/openobserve/openobserve/issues/1099)\n  * awsconfigの中身は以下のようにして、EC2のinstance profileが使われるようにした。ACCESS_KEYやSECRETでもいい。\n\n````\n[default]\nregion = ap-northeast-1\ncredential_source=Ec2InstanceMetadata\n````\n\n## ElasticsearchのAPIでデータ投入する\n\nElasticsearchとコンパチのインターフェースを備えており、 `/api/{organization}/_bulk` のAPIで投入することができる。\n\nhttps://openobserve.ai/docs/api/ingestion/logs/bulk/\n\nES8のクライアント(https://github.com/elastic/go-elasticsearch)を使って作成する\n\n````go\npackage main\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\n\t\"github.com/elastic/go-elasticsearch/v8\"\n\t\"github.com/elastic/go-elasticsearch/v8/esutil\"\n)\n\nfunc newElasticsearchBulkIndexer(ctx context.Context) (esutil.BulkIndexer, error) {\n\tes, err := elasticsearch.NewClient(elasticsearch.Config{\n\t\tUsername: \"root@example.com\",\n\t\tPassword: \"Complexpass#123\",\n\t\tAddresses: []string{\n\t\t\t\"http://localhost:5080/api/default\",\n\t\t},\n\t\tEnableDebugLogger: true,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tindexer, err := esutil.NewBulkIndexer(esutil.BulkIndexerConfig{\n\t\tClient: es,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn indexer, nil\n}\n\nfunc insert(filename string) error {\n\n\tctx := context.Background()\n\n\tindexer, err := newElasticsearchBulkIndexer(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tbody, err := os.ReadFile(filename)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tscanner := bufio.NewScanner(bytes.NewReader(body))\n\tlogs := make([]accessLog, 0)\n\tfor scanner.Scan() {\n\t\tlogs = append(logs, ParseLog(scanner.Text()))\n\t}\n\n\tfor _, v := range logs {\n\t\tjs, err := json.Marshal(v)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\terr = indexer.Add(\n\t\t\tctx,\n\t\t\tesutil.BulkIndexerItem{\n\t\t\t\tAction: \"index\",\n\t\t\t\tIndex:  fmt.Sprintf(\"log-%s-%s\", \"mygroup1\", v.Datetime.Format(\"20060102\")),\n\t\t\t\tBody:   bytes.NewReader(js),\n\t\t\t},\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t}\n\n\tfmt.Printf(\"Stats: %+v\\n\", indexer.Stats())\n\tif err := indexer.Close(ctx); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc main() {\n\tif err := insert(\"testdata.txt\"); err != nil {\n\t\tlog.Fatalf(\"%v\", err)\n\t}\n}\n````\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/06/29","Observability"]},"/note/OpenObserve%E3%82%92%E8%A4%87%E6%95%B0%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC%E3%81%A7%E8%B2%A0%E8%8D%B7%E5%88%86%E6%95%A3%E3%81%99%E3%82%8B":{"title":"OpenObserveを複数サーバーで負荷分散する","content":"\n[OpenObserveを使ってみる](note/OpenObserveを使ってみる.md) で、ローカルで立てたり1台のEC2上で動かす手順がわかった。\n負荷分散したい場合いまのところ[Kubernetes](note/Kubernetes.md)前提となっているのだが、k8s自体の運用も大変なのでEC2同士で通信したい。\n\n## HA構成でノード同士で通信する仕組み\n\nOpenObserveは起動時に環境変数 `ZO_NODE_ROLE` の値を元に自身の役割を決めている。\n起動時に [etcd](note/etcd.md) に自身の情報を登録している。\n`etcdctl get '/zinc/observe/nodes' --prefix | awk '{if (NR%2) ORS=\"\\t\"; else ORS=\"\\n\"; print}'`\nで確認できる。\n","lastmodified":"2023-07-29T08:18:43.031497454Z","tags":["2023/06/29","Observability"]},"/note/PlantUML":{"title":"PlantUML","content":"\n* [plantuml/plantuml: Generate UML diagram from textual description](https://github.com/plantuml/plantuml)\n* [シンプルなテキストファイルで UML が書ける、オープンソースのツール](https://plantuml.com/)\n* テキストファイルで UML 図を記述できる\n* 本体は Java で書かれていて、単一の jar ファイルを落としてきてコマンドラインから実行できる\n* Visual Studio CodeやIntellijなどにプラグインがある\n* ライセンスは GPL v3\n  * [plantuml/license.txt at master · plantuml/plantuml](https://github.com/plantuml/plantuml/blob/master/license.txt)\n\n以下のような図が書ける\n\n* [シーケンス図](https://plantuml.com/ja/sequence-diagram)\n* [ユースケース図](https://plantuml.com/ja/use-case-diagram)\n* [クラス図](https://plantuml.com/ja/class-diagram)\n* [オブジェクト図](https://plantuml.com/ja/object-diagram)\n* [アクティビティ図](https://plantuml.com/ja/activity-diagram-beta)（[古い文法はこちら](https://plantuml.com/ja/activity-diagram-legacy)）\n* [コンポーネント図](https://plantuml.com/ja/component-diagram)\n* [配置図](https://plantuml.com/ja/deployment-diagram)\n* [状態遷移図（ステートマシン図）](https://plantuml.com/ja/state-diagram)\n* [タイミング図](https://plantuml.com/ja/timing-diagram)\n\n[オンラインサーバー](http://www.plantuml.com/plantuml)で簡単に試すことが可能\n\n## インストール\n\n\u003chttps://plantuml.com/ja/faq-install\u003e\n\n\u003chttps://plantuml.com/ja/starting\u003e\n\n必要なもの\n\n* Java\n* [Graphviz](https://plantuml.com/ja/graphviz-dot)\n  * シーケンス図とアクティビティ図以外を作る場合には必須\n* [PlantUML本体](http://sourceforge.net/projects/plantuml/files/plantuml.jar/download)\n\nMacであればbrewで\n\n````shell\nbrew install graphviz plantuml\n````\n\n## 使い方\n\n`sequence.puml` というファイルを作成\n\n````puml\n@startuml\nAlice -\u003e Bob: test\n@enduml\n````\n\nターミナルで実行\n\n````shell\nplantuml sequenceDiagram.txt\n````\n\n`sequenceDiagram.png` ができる\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["2023/05/04","PlantUML"]},"/note/PlantUML%E3%81%A7%E8%A6%8B%E3%81%9F%E7%9B%AE%E3%82%92%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%9E%E3%82%A4%E3%82%BA":{"title":"PlantUMLで見た目をカスタマイズ","content":"\n\\#PlantUML\n\n[PlantUML](note/PlantUML.md) の skinparam で図の見た目を変更できる\n\n\u003chttps://plantuml.com/ja/skinparam\u003e\n\n````puml\n@startuml\nskinparam interface {\n  backgroundColor RosyBrown\n  borderColor orange\n}\n\nskinparam component {\n  FontSize 13\n  BackgroundColor\u003c\u003cApache\u003e\u003e Red\n  BorderColor\u003c\u003cApache\u003e\u003e #FF6655\n  FontName Courier\n  BorderColor black\n  BackgroundColor gold\n  ArrowFontName Impact\n  ArrowColor #FF6655\n  ArrowFontColor #777777\n}\n\n() \"Data Access\" as DA\n\nDA - [First Component]\n[First Component] ..\u003e () HTTP : use\nHTTP - [Web Server] \u003c\u003c Apache \u003e\u003e\n@enduml\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["PlantUML"]},"/note/PlantUML%E3%81%A7AWS%E6%A7%8B%E6%88%90%E5%9B%B3%E3%82%92%E6%9B%B8%E3%81%8F":{"title":"PlantUMLでAWS構成図を書く","content":"\n\\#PlantUML\n\n[PlantUML](note/PlantUML.md)\n\n[AWS Labs製のPlantUMLライブラリ『AWS Icons for PlantUML』の使い方 - Qiita](https://qiita.com/0hm1/items/1b1e84ef1cc3dab5144d)\n\nAWS Labsのアイコンセットを使う\n\u003chttps://github.com/awslabs/aws-icons-for-plantuml\u003e\n\nアイコン一覧\n\u003chttps://github.com/awslabs/aws-icons-for-plantuml/blob/main/AWSSymbols.md\u003e\n\n````puml\n@startuml パスPUSHシステム構成\n\n' AWSアイコン\n!define AWSPuml https://raw.githubusercontent.com/awslabs/aws-icons-for-plantuml/v10.0/dist\n!includeurl AWSPuml/AWSCommon.puml\n!includeurl AWSPuml/Database/DynamoDB.puml\n!includeurl AWSPuml/Containers/ElasticContainerService.puml\n!includeurl AWSPuml/Compute/Lambda.puml\n!includeurl AWSPuml/ApplicationIntegration/APIGateway.puml\n!includeurl AWSPuml/ManagementGovernance/CloudWatch.puml\n!includeurl AWSPuml/Storage/SimpleStorageService.puml\n!includeurl AWSPuml/ApplicationIntegration/SimpleQueueService.puml\n!includeurl AWSPuml/ApplicationIntegration/SimpleNotificationService.puml\n!includeurl AWSPuml/GroupIcons/Cloud.puml\n!includeurl AWSPuml/GroupIcons/CorporateDataCenter.puml\n!includeurl AWSPuml/General/Traditionalserver.puml\n!includeurl AWSPuml/General/Mobileclient.puml\n!includeurl AWSPuml/General/Genericdatabase.puml\n\n' その他アイコン集\n!define ICONURL https://raw.githubusercontent.com/tupadr3/plantuml-icon-font-sprites/v2.0.0\n!includeurl ICONURL/common.puml\n!includeurl ICONURL/font-awesome-5/jenkins.puml\n\n''''\n' 見た目の定義\n''''\nleft to right direction\n\nskinparam component {\n  ArrowColor #Red\n}\n\n''''\n' 登場人物の定義\n''''\n\nCloud(aws, cloud, \"AWS\") {\n  DynamoDB(db, DynamoDB, \"db\")\n  Lambda(lambda, Lambda, \"実行lambda\")\n  SimpleQueueService(sqs, SQS, \"実行キュー\")\n  SimpleNotificationService(sns, SNS, \"プッシュ配信\")\n}\n\nnode \"FCM\" as fcm\nMobileclient(app, アプリ, \"アプリ\")\n\n' font-awesomeのJenkinsアイコン\nFA5_JENKINS(jenkins, jenkins)\n\n''''\n' コンポーネント図\n''''\njenkins --\u003e sqs: 実行命令\nsqs --\u003e lambda: 実行\nlambda \u003c-\u003e db: 配信データ取得\nlambda --\u003e sns: 配信メッセージ登録\nsns --\u003e fcm: 配信\nfcm --\u003e app: 通知\n\n@enduml\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["PlantUML"]},"/note/PlantUML%E3%81%AE%E5%8F%82%E8%80%83%E3%81%AB%E3%81%AA%E3%82%8B%E3%82%B5%E3%82%A4%E3%83%88":{"title":"PlantUMLの参考になるサイト","content":"\n\\#PlantUML\n\n\u003chttps://crashedmind.github.io/PlantUMLHitchhikersGuide/aws/aws.html\u003e\n\nAWS構成図の書き方が参考になる\n\n色をつけたりもできる\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["PlantUML"]},"/note/Podman-Desktop%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%97%E3%81%A6Proxy%E3%82%92%E8%A8%AD%E5%AE%9A":{"title":"Podman DesktopをインストールしてProxyを設定","content":"\n[会社のプロキシの裏でPodman Desktopを実行する | フューチャー技術ブログ](https://future-architect.github.io/articles/20221227a/)\n\nインストール\nhttps://podman-desktop.io/docs/installation/macos-install\n\n実行してInstallを押すとダイアログが出る(0.10.0からこのインストーラー方式に変わった)\n\n![Pasted-image-20230105111356](note/Pasted-image-20230105111356.png)\n\nインストールしてPodmanを起動する\n\n### podman cliをインストール\n\nPodman Desktopからインストールされていそうなのだが見つからなかったのでbrewで別途インストール\n\n````shell\n$ brew install podman\n````\n\n````shell\n$ podman machine ls\nNAME                     VM TYPE     CREATED            LAST UP        CPUS        MEMORY      DISK SIZE\npodman-machine-default*  qemu        About an hour ago  6 minutes ago  1           2.147GB     107.4GB\n$ podman machine info\n````\n\n### Proxyを設定\n\nSettings \u003e Proxyから設定する\n\n### Proxyが設定されているのを確認\n\n````shell\n$ podman run --rm -it nginx bash\n\nroot# echo $https_proxy\n=\u003e 設定したproxyが表示される\nroot# curl '\u003c接続先\u003e'\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["2023/01/05"]},"/note/PowerShell%E3%81%A7Linux%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%82%92%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8B":{"title":"PowerShellでLinuxコマンドを使用する","content":"\n## uutils/coreutils を使用する\n\n[uutils/coreutils](https://github.com/uutils/coreutils)\n\n* Rust製\n* クロスプラットフォーム対応のcoreutils\n* [Scoop](note/Scoop環境構築.md) でインストール可能\n\nデフォルトのaliasを解除しておく\n\n````powershell\nRemove-Item alias:cp\nRemove-Item alias:mv\nRemove-Item alias:rm\nRemove-Item alias:ls\nRemove-Item alias:cat\nRemove-Item alias:sort -Force\n````\n\n## その他コマンド\n\n* [ripgrep](https://github.com/BurntSushi/ripgrep)\n* [lsd](https://github.com/Peltoche/lsd)\n* tree([lsd](https://github.com/Peltoche/lsd)を使う)\n\n````powershell\nSet-Alias grep rg\nSet-Alias ls lsd\n\nfunction ll() { lsd -l --blocks permission --blocks size --blocks date --blocks name --blocks inode $args}\n\nfunction tree() { lsd --tree $args}\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","PowerShell"]},"/note/PowerShell%E3%81%AE%E3%82%AD%E3%83%BC%E3%83%90%E3%82%A4%E3%83%B3%E3%83%89%E3%82%92emacs%E9%A2%A8%E3%81%AB%E3%81%99%E3%82%8B":{"title":"PowerShellのキーバインドをemacs風にする","content":"\n[PowerShellのキーバインドをEmacs風にする【PSReadLine】 - メモ.org](https://maskaw.hatenablog.com/entry/2019/02/08/193256)\n\n\u003chttps://github.com/PowerShell/PSReadLine\u003e をインストール\n\n**なお、PowerShell 6+ではすでにインストールされているため、利用設定だけすればよい**\n\n \u003e \n \u003e If you are using Windows PowerShell on Windows 10 or using PowerShell 6+, `PSReadLine` is already installed. Windows PowerShell on the latest Windows 10 has version `2.0.0-beta2` of `PSReadLine`. PowerShell 6+ versions have the newer prerelease versions of `PSReadLine`.\n\n`notepad $PROFILE` を実行して以下を追記\n\n````ps1\nif ($host.Name -eq 'ConsoleHost')\n{\n    # キーバインドをEmacs風に変更\n    Set-PSReadlineOption -EditMode Emacs\n}\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","PowerShell"]},"/note/PowerShell%E3%81%AE%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%9E%E3%82%A4%E3%82%BA":{"title":"PowerShellのプロンプトカスタマイズ","content":"\noh-my-posh\nhttps://ohmyposh.dev/docs/\n\nv3ではこれだけ\n\n````ps1\nSet-PoshPrompt -Theme paradox\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","PowerShell"]},"/note/Powerlevel10k":{"title":"Powerlevel10k","content":"\nhttps://github.com/romkatv/powerlevel10k/\n\nzshのプロンプト用のtheme\n\n類似\n[starship](note/starship.md)\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["2023/01/13","shell"]},"/note/Powershell7%E3%82%92Windows-Terminal%E3%81%A7%E4%BD%BF%E7%94%A8%E3%81%99%E3%82%8B":{"title":"Powershell7をWindows Terminalで使用する","content":"\n## Microsoft Store からインストールする\n\n\u003chttps://docs.microsoft.com/ja-jp/powershell/scripting/install/installing-powershell-core-on-windows?view=powershell-7.1#installing-from-the-microsoft-store\u003e\nPowerShell 7.1 からはStoreからもインストールできるようになった\n\n## Terminalの設定\n\n設定 -\u003e プロファイル -\u003e コマンドライン を `pwsh` に変更\n![Pasted-image-20210509130113](note/Pasted-image-20210509130113.png)\n\nこれで次回起動から最新版が使われる\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","PowerShell"]},"/note/Presto%E3%81%A7%E9%85%8D%E5%88%97%E3%82%92%E8%A1%8C%E3%81%AB%E5%A4%89%E6%8F%9B%E3%81%99%E3%82%8B":{"title":"Prestoで配列を行に変換する","content":"\n## 横持ちのテーブルを縦持ちに変換する\n\n[PrestoのUNNESTを利用した横縦変換 | 分析ノート](https://analytics-note.xyz/sql/presto-unnest-unpivot/)\n\n横持ちのテーブル(htable)\n\n|uid|c1|c2|c3|\n|---|--|--|--|\n|101|11|12|13|\n|102|21|22|23|\n\n縦持ちのテーブルに変換したい(vtable)\n\n|uid|key|value|\n|---|---|-----|\n|101|c1|11|\n|101|c2|12|\n|101|c3|13|\n|102|c1|21|\n|102|c2|22|\n|102|c3|23|\n\n### UNIONを使う(シンプル)\n\n````sql\nSELECT\n    uid,\n    'c1' AS key,\n    c1 AS value\nFROM\n    htable\nUNION ALL SELECT\n    uid,\n    'c2' AS key,\n    c2 AS value\nFROM\n    htable\nUNION ALL SELECT\n    uid,\n    'c3' AS key,\n    c3 AS value\nFROM\n    htable\n````\n\nカラムが増えると長くなる\n\n### UNNESTを使う\n\n````sql\nSELECT\n    uid,\n    t.key,\n    t.value\nFROM\n    htable\nCROSS JOIN UNNEST (\n  array['c1', 'c2', 'c3'],\n  array[c1, c2, c3]\n) AS t(key, value)\n````\n\n## 配列 -\u003e レコードに変換する\n\n|time_range|\n|----------|\n|\\[\"16:00-16:30\", \"16:30-17:00\", \"17:00-17:30\", \"17:30-18:00\", \"18:00-18:30\", \"18:30-19:00\", \"19:00-19:30\", \"19:30-20:00\", \"20:00-20:30\", \"20:30-21:00\", \"21:00-21:30\"\\]|\n\n````sql\nSELECT time_range FROM tbl CROSS JOIN UNNEST(time_ranges) AS t(time_range)\n````\n\n=\u003e 結果\n\n|time_range|\n|----------|\n|16:00-16:30|\n|16:30-17:00|\n|17:00-17:30|\n|17:30-18:00|\n|18:00-18:30|\n|18:30-19:00|\n|19:00-19:30|\n|19:30-20:00|\n|20:00-20:30|\n|20:30-21:00|\n|21:00-21:30|\n\n配列の順番も合わせて別々のレコードに変換したい場合\n`WITH ORDINALITY` をつけると配列の順番を格納するカラムがUNNEST後のカラム構造の末尾に追加される\n\n````sql\nSELECT time_id, time_range FROM tbl CROSS JOIN UNNEST(time_ranges) WITH ORDINALITY AS t( time_range, time_id )\n````\n\n### 文字列から変換する\n\n|query|\n|-----|\n|q=カラオケ\u0026city=tokyo\u0026open=true|\n\n````sql\nWITH\n    t AS (\n        SELECT\n            split_to_map(query, '\u0026', '=') as q\n        FROM\n            tbl\n    )\nSELECT\n    q['q'] AS v1,\n    q['city'] AS v2,\n    q['open'] AS v3\nFROM\n    t\n````\n\n## 縦横変換\n\n[PrestoのMap型を使った縦横変換 | 分析ノート](https://analytics-note.xyz/sql/presto-unnest-unpivot/)\n\n縦持ちのテーブル(vtable)\n\n|uid|key|value|\n|---|---|-----|\n|101|c1|11|\n|101|c2|12|\n|101|c3|13|\n|102|c1|21|\n|102|c2|22|\n|102|c3|23|\n\n横持ちのテーブルに変換したい(htable)\n\n|uid|c1|c2|c3|\n|---|--|--|--|\n|101|11|12|13|\n|102|21|22|23|\n\nMAP_AGGを使ってkeyとvalueの対応のmapを作成して各keyの値を取り出すやり方\n\n````sql\nSELECT\n    uid,\n    kv['c1'] AS c1,\n    kv['c2'] AS c2,\n    kv['c3'] AS c3\nFROM (\n    SELECT\n        uid,\n        MAP_AGG(key, value) AS kv\n    FROM\n        vtable\n    GROUP BY\n        uid\n) AS t\n````\n\nPrestoでない場合は以下のような書き方ができる\n\n````sql\nSELECT\n    uid,\n    MAX(\n        CASE WHEN key = 'c1' THEN\n            value\n        ELSE\n            NULL\n        END\n    ) AS c1,\n    MAX(\n        CASE WHEN key = 'c2' THEN\n            value\n        ELSE\n            NULL\n        END\n    ) AS c2,\n    MAX(\n        CASE WHEN key = 'c3' THEN\n            value\n        ELSE\n            NULL\n        END\n    ) AS c3\nFROM\n    vtable\nGROUP BY\n    uid\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Athena","SQL"]},"/note/PrometheusGrafana%E3%83%A1%E3%83%A2":{"title":"Prometheus、Grafanaメモ","content":"\n### count_over_time\n\ntime rangeの間、intervalごとにメトリクスを収集した件数の合計\n\n`count_over_time((kube_pod_status_phase{phase=\"Pending\"} \u003e 0)[15m:1m])`\n15分の間に1分ごとにpendingの件数をカウントして合計する\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["監視"]},"/note/Python":{"title":"Python","content":"\n\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Python"]},"/note/Rancher-Desktop":{"title":"Rancher Desktop","content":"\nDocker Desktop 代替候補\n[lima](https://github.com/lima-vm/lima) でLinux Virtual Machine が動いていて、VM上でコンテナランタイム(dockerd、containerd) を動かしている\n\nKubernetesはk3sで動かすことができる\nProxyの設定がない\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Docker"]},"/note/Raycast":{"title":"Raycast","content":"\n[RaycastはただのLauncherツールにとどまらない](https://zenn.dev/rinchsan/articles/1c26913a87a5aa)\n[ランチャーツールRaycastの使い方と設定 | DevelopersIO](https://dev.classmethod.jp/articles/eetann-used-raycast/)\n\n## 自分の設定\n\n* Authy\n\n### マイク\n\n[Raycastでマイクのミュートを切り替える](blog/Raycastでマイクのミュートを切り替える.md)\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["2023/01/06","Raycast","Mac"]},"/note/Raycast%E3%81%A7%E3%83%87%E3%82%A3%E3%82%B9%E3%83%97%E3%83%AC%E3%82%A4%E3%81%AE%E8%A7%A3%E5%83%8F%E5%BA%A6%E3%82%92%E5%A4%89%E6%9B%B4%E3%81%99%E3%82%8B":{"title":"Raycastでディスプレイの解像度を変更する","content":"\nWQHD(2560x1440)ディスプレイを使っていると、画面共有時に文字が小さくなってしまい読めないことが多々あるので、画面共有するときは都度解像度を下げていた。\n変更し忘れたり、変更するのにもたついたりする時間があるため、ディスプレイの解像度の変更を簡単にできないかを調べた。\n\n## ゴール\n\n* Raycastで解像度を変更できるようにする\n\n## Raycastから実行するAppleScriptを作成\n\n[Raycastでマイクのミュートを切り替える](blog/Raycastでマイクのミュートを切り替える.md)\n\n引数つきで実行もできる\n\n## AppleScriptの中身を書く\n\nAppleScriptにはあまり詳しくないのでもっといい書き方があるかもしれないですが悪しからず\n\n[mac - Is it possible to change display resolution with a keyboard shortcut? - Ask Different](https://apple.stackexchange.com/questions/263162/is-it-possible-to-change-display-resolution-with-a-keyboard-shortcut)\nによるとOSのバージョンによってUIが異なるのでスクリプトを変えないといけないみたい\n\n### Monterey(12.6) の場合\n\n````applescript\n#!/usr/bin/osascript\n\n# Required parameters:\n# @raycast.schemaVersion 1\n# @raycast.title Toggle display resolution\n# @raycast.mode compact\n\n# Optional parameters:\n# @raycast.icon 🤖\n# @raycast.argument1 { \"type\": \"text\", \"placeholder\": \"Placeholder\" }\n# @raycast.packageName Mac Utils\n\non run argv\n\nset resolution_index to ( item 1 of argv )\n\ntell application \"System Preferences\"\n  activate\n  set the current pane to pane id \"com.apple.preference.displays\"\n  delay 1\n  tell application \"System Events\"\n      tell window \"Displays\" of application process \"System Preferences\"\n          click button \"Display Settings…\"\n          delay 1\n\n          tell sheet 1\n              select row 2 of outline 1 of scroll area 1\n              click radio button \"Scaled\" of radio group 1\n\n              tell scroll area 2\n                  tell table 1\n                      select row (resolution_index as integer)\n                  end tell\n              end tell\n          end tell\n\n          delay 1\n          click button \"Done\" of sheet 1\n      end tell\n  end tell\nend tell\n\n# The next line is optional and could be commented out by prepending with a hash (#).\n# delay 2\n# quit application \"System Preferences\"\nend run\n````\n\n### 解説\n\n`on run argv` \n引数つきで実行する\n\n`set resolution_index to ( item 1 of argv )`\n1つめの引数を代入する\n\n````\ntell application \"System Preferences\"\n...\n        tell window \"Displays\" of application process \"System Preferences\"\n          click button \"Display Settings…\"\n````\n\nSystem Preferencesを開いて、ボタンクリックなどの画面操作をする\n\n````\n          tell sheet 1\n              select row 2 of outline 1 of scroll area 1\n              click radio button \"Scaled\" of radio group 1\n\n              tell scroll area 2\n                  tell table 1\n                      select row (resolution_index as integer)\n                  end tell\n              end tell\n          end tell\n````\n\nDisplay Settingsの画面で、\n\n1. 2番目のモニターを選択\n1. ラジオボタンScaledをクリックして解像度のリストを開く\n1. 解像度のリストから引数で指定したインデックスを選択する\n\n以降は画面を閉じたりアプリケーションを終了したりを行うパート\n\n## 所感\n\n* 操作対象のUIを特定するために `log every UI element` で一覧出力するのが便利だった\n* UIを番号で指定しているのが、簡単に壊れそうで嫌だな\n* 解像度の指定もインデックスでやっているがわかりにくいな\n\n## 参考\n\n[AppleScript to change Display Resolution - Apple Community](https://discussions.apple.com/thread/253787938)\n[mac - Is it possible to change display resolution with a keyboard shortcut? - Ask Different](https://apple.stackexchange.com/questions/263162/is-it-possible-to-change-display-resolution-with-a-keyboard-shortcut)\n[macbook pro - a single keyboard shortcut that toggles between 2 resolutions on MacOS 12.6 - Ask Different](https://apple.stackexchange.com/questions/449891/a-single-keyboard-shortcut-that-toggles-between-2-resolutions-on-macos-12-6)\n[Change screen resolution AppleScript](https://gist.github.com/mvaneijgen/73458ffb956e825c5786#file-scale-resolution-scpt-L21)\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["2023/03/03","Raycast"]},"/note/React":{"title":"React","content":"\nReactは、Facebookが開発したJavaScriptのライブラリで、WebアプリケーションやモバイルアプリケーションのUIを構築するために使用される。\nコンポーネントと呼ばれる小さな再利用可能なUI要素を組み合わせてアプリケーションを構築する。\n\n* 宣言的なプログラミングスタイルを採用しているのでロジックと組み合わせたUIの構築がしやすい\n* 仮想DOMを使用するため、UIのレンダリングのパフォーマンスが向上する\n* 大規模なアプリケーションでも、コンポーネントやデータのフローをシンプルに管理できるため、保守性が高く、拡張性にも優れている\n\n[TypeScript](note/TypeScript.md) で記述可能\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["JavaScript"]},"/note/Rust":{"title":"Rust","content":"\n\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Rust"]},"/note/Rust%E3%81%A7CLI%E3%82%92%E4%BD%9C%E3%82%8B":{"title":"RustでCLIを作る","content":"\n## neovimでrustを使えるようにする\n\nLSPはrust-analyzerを使う\n\n````shell\nbrew install rust-analyzer\n````\n\nもしくはneovimでmasonを使っている場合は `:MasonInstall rust-analyzer`\n\n````lua\nlocal lspconfig_status_ok, lspconfig = pcall(require, \"lspconfig\")\nif not lspconfig_status_ok then\n  return\nend\n\nlocal opts = {\n  on_attach = require(\"lsp.handlers\").on_attach,\n  capabilities = require(\"lsp.handlers\").capabilities,\n}\n\nlspconfig['rust_analyzer'].setup(opts)\n\n````\n\n### formatter\n\n\u003chttps://github.com/rust-lang/rustfmt\u003e\n\n````shell\nrustup component add rustfmt\n````\n\n`:RustFmt` はとくに何も設定しなくても使えたけど、エラーが出て効かなかった\n\n````\nError detected while processing function rustfmt#Format[7]..\u003cSNR\u003e64_RunRustfmt:\nline   48:\nE776: No location list\n````\n\n`:!rustfmt %` で代用したらRust 2018からじゃないと使えない記法でエラーになった。\n`rustfmt.toml` を作って `edition = \"2021\"` を書いた\n\n保存時に実行してほしかったのでこうした。\ncursor位置が先頭に行ってしまうので、 `nvim_win_get_cursor` で位置を保存しておいてからrustfmt実行\nrustfmt.toml を見てくれないのでeditionを明示した。これだとプロジェクトによっては設定読めなくてformatずれるな。\n\n````lua\nfunction rustfmt(wait_ms)\n  local curpos = vim.api.nvim_win_get_cursor(0)\n  vim.cmd [[ %!rustfmt --edition \"2021\" ]]\n  vim.api.nvim_win_set_cursor(0, curpos)\nend\n\nvim.cmd [[\n  augroup rustfmt\n    autocmd!\n    autocmd BufWritePre *.rs lua rustfmt()\n  augroup end\n]]\n\n````\n\nRustなにもわからないのでとりあえずこれをベースにする\n[Building My First Command Line Interface (CLI) with Rust | by Adam Berg | Geek Culture | Medium](https://medium.com/geekculture/building-my-first-command-line-interface-cli-with-rust-b6beb9c284e0)\n\n## 初期化\n\n`cargo new パッケージ名` もしくは `cargo init` で作成\nCargo.tomlができる\n\n`cargo add クレート名` でライブラリを追加する\n\n````shell\ncargo add reqwest tokio\n````\n\n-\u003e `features` も設定したかったけどコマンドだとよくわからなかったのでtoml直接修正する\n\n## clapを使ってみる\n\nClapというcrateがCLI作るときに便利なライブラリのようなので、これを使ってもいいかも\n[RustのClapクレートがメチャクチャ良かった話](https://zenn.dev/shinobuy/articles/53aed032fe5977)\n\nderiveっていうのが今風らしい\n[Rust | clap v3系でCLIツールを作成する - dotTrail](https://dottrail.codemountains.org/rust-clap-v3-cli-app/)\n\n## reqwest\n\nresponseのJSONをparseしたかったので[serde](https://github.com/serde-rs/serde)をいれてみた\n\n````toml\nserde = { version = \"1.0\", features = [\"derive\"] }\nreqwest = { version = \"0.11\", features = [\"blocking\", \"json\"] }\n\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Rust","Neovim"]},"/note/Rust%E3%81%A7bitbucket%E3%81%AEpermission%E6%93%8D%E4%BD%9C%E3%81%99%E3%82%8Bcli%E3%82%92%E4%BD%9C%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B":{"title":"Rustでbitbucketのpermission操作するcliを作ってみる","content":"\n[RustでCLIを作る](note/RustでCLIを作る.md) の続き\n\nRust勉強がてらCLIで操作できるようにしてみる\n\n* https://github.com/clap-rs/clap を使う\n* [List explicit group permissions for a repository](https://developer.atlassian.com/cloud/bitbucket/rest/api-group-repositories/#api-repositories-workspace-repo-slug-permissions-config-groups-get) のようにリポジトリのuser, groupsへのpermissionを操作するAPIが用意されている。ただし、usernameでは操作ができず、UUIDを指定する。UUIDはadminじゃないと簡単にはとれなさそう。\n\n## APIの使い方\n\nユーザー・グループの取得\n\n````shell\n$ curl -u $BITBUCKET_USER:$BITBUCKET_PASS \"https://api.bitbucket.org/2.0/repositories/${workspace}/${slug}/permissions-config/users\"\n\n{\n  \"values\": [\n    {\n      \"type\": \"repository_user_permission\",\n      \"permission\": \"admin\",\n      \"user\": {\n        \"display_name\": \"John Doe\",\n        \"type\": \"user\",\n        \"uuid\": \"{77777777-88888-3333-aaaa-bbbbbbbbbbbb}\",\n        \"account_id\": \"111111122222222ccccccccc\",\n        \"nickname\": \"john-doe\"\n      }\n    }\n  ],\n  \"pagelen\": 10,\n  \"size\": 1,\n  \"page\": 1\n}\n\n$ curl -u $BITBUCKET_USER:$BITBUCKET_PASS \"https://api.bitbucket.org/2.0/repositories/${workspace}/${slug}/permissions-config/groups\"\n{\n  \"values\": [\n    {\n      \"type\": \"repository_group_permission\",\n      \"permission\": \"admin\",\n      \"group\": {\n        \"type\": \"group\",\n        \"owner\": {},\n        \"workspace\": {},\n        \"slug\": \"administrator\",\n        \"full_slug\": \"${workspace}:administrator\",\n        \"name\": \"administrator\",\n        \"default_permission\": \"admin\",\n        \"email_forwarding_disabled\": false,\n        \"account_privilege\": \"admin\"\n      }\n    },\n    {\n      \"type\": \"repository_group_permission\",\n      \"permission\": \"read\",\n      \"group\": {\n        \"type\": \"group\",\n        \"owner\": {},\n        \"workspace\": { },\n        \"slug\": \"developer\",\n        \"full_slug\": \"${workspace}:developer\",\n        \"name\": \"developer\",\n        \"default_permission\": \"read\",\n        \"email_forwarding_disabled\": true,\n        \"account_privilege\": \"collaborator\"\n      }\n    }\n  ],\n  \"pagelen\": 1,\n  \"size\": 2,\n  \"page\": 1\n}\n\n````\n\n追加・更新\nユーザーのUUIDやグループのslugは、permission設定ずみのリポジトリから取得するのが楽かな？そのため一つのリポジトリはGUIから設定して、2つ目以降はCLIでできる感じ\n\n````shell\n# 更新だけじゃなく追加もできる\n$ curl -u $BITBUCKET_USER:$BITBUCKET_PASS -X PUT -H \"Content-Type: application/json\" \"https://api.bitbucket.org/2.0/repositories/${workspace}/${slug}/permissions-config/users/%7Baaaaaaaa-7777-4567-8888-dddddddddddd%7D\" -d '{ \"permission\": \"write\" }'\n$ curl -u $BITBUCKET_USER:$BITBUCKET_PASS -X PUT -H \"Content-Type: application/json\" \"https://api.bitbucket.org/2.0/repositories/${workspace}/${slug}/permissions-config/groups/2022-ca9b0ca\" -d '{ \"permission\": \"write\" }'\n````\n\n削除\n\n````shell\n$ curl -u $BITBUCKET_USER:$BITBUCKET_PASS -X DELETE -H \"Content-Type: application/json\" \"https://api.bitbucket.org/2.0/repositories/${workspace}/${slug}/permissions-config/users/%7Baaaaaaaa-7777-4567-8888-dddddddddddd%7D\"\n$lang curl -u $BITBUCKET_USER:$BITBUCKET_PASS -X PUT -H \"Content-Type: application/json\" \"https://api.bitbucket.org/2.0/repositories/${workspace}/${slug}/permissions-config/groups/2021-ca9b0ca\"\n````\n\n## 設計\n\n````\nuser, user-a, {aaaaaaaa-7898-45d3-869f-dd6ddf7efc10}, write\nuser, user-b, {aaaaaaaa-7898-45d3-869f-dd6ddf7efc11}, read\ngroup, group-1, 2022_abcdef12, write\n````\n\nみたいなCSVを食わせてこれのとおりに上書きする\nPJごとに、持っているリポジトリにはすべて同じ設定ができれば満足だと思うので\n\n列挙されていないものは削除までするか？一旦考えなくていいか\n\nCSVを作るためには一回は手動で設定をしてAPIで取得する必要がある\nCSVとかじゃなくても、このリポジトリと同じ設定を適用するというのでもいいんじゃないか\n\nまずは取得するAPIを作って、JSONを操作する方法を調べて特定のキーを抽出する\n\n### copy\n\n`bb copy \u003csrc\u003e \u003crepo\u003e`\nsrcと同じ権限にする\n\n### list\n\n一覧\n\n`bb list \u003crepo\u003e`\n\n### remove\n\n`bb remove -u/-g \u003cuuid\u003e \u003crepo\u003e`\n\nidをオプションで指定してもいいけど、listしたあと選択式で削除できると便利\n\n### update\n\n`bb update -u/-g \u003cuuid\u003e \u003crepo\u003e`\n\n### login\n\n毎回authオプションつけるのなんだしパスワードがでるのあれなので、\nhttps://github.com/craftamap/bb を参考に、loginコマンドで `~/.bb.toml` を作ってusername, passwordを保存する的な\nMacでの動作しか確認できんけどkeychainに入れるとか\n\n````toml\n[package]\nname = \"bitbucket-cli\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n\n[dependencies]\nansi_term = \"0.12.1\"\nserde = { version = \"1.0\", features = [\"derive\"] }\nserde_json = \"1.0\"\nreqwest = { version = \"0.11\", features = [\"blocking\", \"json\"] }\ntokio = { version = \"1\", features = [\"full\"] }\nclap = { version = \"3.2.22\", features = [\"derive\"] }\nchrono = \"0.4.20\"\n````\n\n````rust\nuse ansi_term::Colour;\nuse chrono::{DateTime, Local};\nuse clap::{ArgEnum, Parser, Subcommand};\nuse reqwest::StatusCode;\nuse serde::{Deserialize, Serialize};\nuse serde_json::Value;\nuse std::fs::OpenOptions;\nuse std::io::Write;\nuse std::path::PathBuf;\nuse std::thread::sleep;\nuse std::time::{Duration, Instant};\nuse std::{default, fs, process};\n\n#[derive(Parser, Debug)]\n#[clap(name = \"bbrs\", version, about, long_about = None, arg_required_else_help = true)]\nstruct Args {\n    /// Username\n    #[clap(short, long, value_name = \"USERNAME\")]\n    username: String,\n\n    /// App password\n    #[clap(short, long, value_name = \"APP PASSWORD\")]\n    password: String,\n\n    /// Workspace\n    #[clap(short, long, value_name = \"WORKSPACE\")]\n    workspace: String,\n\n    /// Repo slug\n    #[clap(short, long)]\n    slug: String,\n\n    /// Output type\n    #[clap(\n        short,\n        long,\n        arg_enum,\n        value_name = \"OUTPUT TYPE\",\n        default_value = \"text\"\n    )]\n    output: Output,\n\n    #[clap(subcommand)]\n    command: Commands,\n}\n\n#[derive(Debug, Clone, ArgEnum, Copy)]\nenum Output {\n    Csv,\n    Json,\n    Text,\n}\n\n/// サブコマンドの定義\n#[derive(Debug, Subcommand)]\nenum Commands {\n    List,\n}\n\nstruct OutputMessage {\n    datetime: DateTime\u003cLocal\u003e,\n    url: String,\n    status_code: StatusCode,\n    elapsed: Duration,\n}\n\nimpl OutputMessage {\n    fn new(\n        datetime: DateTime\u003cLocal\u003e,\n        url: String,\n        status_code: StatusCode,\n        elapsed: Duration,\n    ) -\u003e Self {\n        Self {\n            datetime,\n            url,\n            status_code,\n            elapsed,\n        }\n    }\n\n    fn to_formatted(\u0026self, output: Output) -\u003e String {\n        let dt = self.datetime.format(\"%Y-%m-%d %H:%M:%S\").to_string();\n        let url = self.url.as_str().to_string();\n        let st = self.status_code.to_string();\n        let response_time = format!(\n            \"{}.{:03}\",\n            self.elapsed.as_secs(),\n            self.elapsed.subsec_nanos() / 1_000_000\n        );\n\n        match output {\n            Output::Csv =\u003e {\n                format!(r#\"\"{}\",\"{}\",\"{}\",\"{}\"\"#, dt, url, st, response_time)\n            }\n            Output::Json =\u003e {\n                format!(\n                    r#\"{{\"datetime\": \"{}\",\"url: \"{}\",\"statusCode\": \"{}\",\"responseTime\": \"{}\"}}\"#,\n                    dt, url, st, response_time\n                )\n            }\n            Output::Text =\u003e {\n                format!(\"{} {} {} {}\", dt, url, st, response_time)\n            }\n        }\n    }\n}\n\n#[tokio::main]\nasync fn main() {\n    let args = Args::parse();\n    let username: String = args.username;\n    let password: String = args.password;\n    let workspace: String = args.workspace;\n    let slug: String = args.slug;\n    let output: Output = args.output;\n\n    let bitbucket = Bitbucket {\n        username,\n        password,\n        workspace,\n        slug,\n    };\n\n    match args.command {\n        Commands::List =\u003e {\n            list(bitbucket).await;\n        }\n    }\n}\n\n// Bitbucket APIを実行する\n\nconst BASE_URL: \u0026str = \"https://api.bitbucket.org/2.0\";\n\nstruct Bitbucket {\n    username: String,\n    password: String,\n    workspace: String,\n    slug: String,\n}\n\n// #[derive(Debug, Serialize, Deserialize)]\n// struct GroupPermissions {\n//     values: Vec\u003cGroupPermission\u003e\n// }\n// #[derive(Debug, Serialize, Deserialize)]\n// struct GroupPermission {\n//     permission: String,\n//\n// }\n\nstruct Permission {\n    object_type: ObjectType,\n    alias: String,\n    id: String,\n    permission: PermissionType,\n}\n\n#[derive(Debug, Clone, Copy)]\nenum ObjectType {\n    User,\n    Group,\n}\n\nfn object_type_from_str(s: \u0026str) -\u003e ObjectType {\n    match s {\n        \"user\" =\u003e return ObjectType::User,\n        \"group\" =\u003e return ObjectType::Group,\n        _ =\u003e return ObjectType::User,\n    }\n}\n\n#[derive(Debug, Clone, Copy)]\nenum PermissionType {\n    Read,\n    Write,\n    Admin,\n}\nfn permission_type_from_str(s: \u0026str) -\u003e PermissionType {\n    match s {\n        \"read\" =\u003e return PermissionType::Read,\n        \"write\" =\u003e return PermissionType::Write,\n        \"admin\" =\u003e return PermissionType::Admin,\n        _ =\u003e return PermissionType::Read,\n    }\n}\n\nasync fn list(bitbucket: Bitbucket) -\u003e Result\u003cVec\u003cPermission\u003e, Box\u003cdyn std::error::Error\u003e\u003e {\n    let mut permissions: Vec\u003cPermission\u003e = Vec::new();\n\n    let url = format!(\n        r#\"{}/repositories/{}/{}/permissions-config/groups\"#,\n        BASE_URL, bitbucket.workspace, bitbucket.slug,\n    );\n    let client = reqwest::Client::new();\n    let resp = client\n        .get(url)\n        .basic_auth(\u0026bitbucket.username, Some(\u0026bitbucket.password))\n        .send()\n        .await?;\n\n    if !resp.status().is_success() {\n        println!(\"failed to get permission\");\n        return Ok(permissions);\n    }\n\n    let permission_groups: Value = resp.json().await?;\n\n    for v in permission_groups[\"values\"].as_array().unwrap() {\n        let p = Permission {\n            permission: permission_type_from_str(v[\"permission\"].as_str().unwrap()),\n            object_type: object_type_from_str(v[\"group\"][\"type\"].as_str().unwrap()),\n            alias: String::from(v[\"group\"][\"name\"].as_str().unwrap()),\n            id: String::from(v[\"group\"][\"slug\"].as_str().unwrap()),\n        };\n        permissions.push(p);\n    }\n\n    let url_users = format!(\n        r#\"{}/repositories/{}/{}/permissions-config/users\"#,\n        BASE_URL, bitbucket.workspace, bitbucket.slug,\n    );\n    let resp_users = client\n        .get(url_users)\n        .basic_auth(bitbucket.username, Some(bitbucket.password))\n        .send()\n        .await?;\n\n    if !resp_users.status().is_success() {\n        println!(\"failed to get permission\");\n        return Ok(vec![]);\n    }\n\n    let permission_users: Value = resp_users.json().await?;\n\n    for v in permission_users[\"values\"].as_array().unwrap() {\n        let p = Permission {\n            permission: permission_type_from_str(v[\"permission\"].as_str().unwrap()),\n            object_type: object_type_from_str(v[\"user\"][\"type\"].as_str().unwrap()),\n            alias: String::from(v[\"user\"][\"nickname\"].as_str().unwrap()),\n            id: String::from(v[\"user\"][\"uuid\"].as_str().unwrap()),\n        };\n        permissions.push(p);\n    }\n\n    for p in \u0026permissions {\n        println!(\n            \"{:?}, {:?}, {:?}, {:?}\",\n            p.object_type, p.id, p.alias, p.permission,\n        );\n    }\n\n    Ok(permissions)\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Rust","CLI"]},"/note/S3":{"title":"S3","content":"\n\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["AWS"]},"/note/SAM":{"title":"SAM","content":"\nServerless Application Model\nLambdaにデプロイするのを簡単にするツール\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["AWS","CLI"]},"/note/SQL%E3%81%A7%E3%82%B0%E3%83%AB%E3%83%BC%E3%83%97%E3%81%94%E3%81%A8%E3%81%AB%E4%B8%8A%E4%BD%8DN%E4%BB%B6%E3%82%92%E5%8F%96%E5%BE%97":{"title":"SQLでグループごとに上位N件を取得","content":"\n\\#sql\n\nあるグループごとに上位〇件ずつデータを取得して比較したいという際にwindow関数を使う。\n\n### テーブル\n\nsales_t\n\n|category|product|sales|\n|--------|-------|-----|\n|食品|りんご|30|\n|食品|みかん|20|\n|食品|バナナ|10|\n|筆記用具|ペン|40|\n|筆記用具|消しゴム|10|\n|筆記用具|赤ペン|30|\n\n### categoryごとに上位2件ずつ取得する\n\n````sql\nselect * from (\n    select category\n        , product\n        , row_number() over (partition by category order by sales desc) as row\n    from sales_t\n)\nwhere row \u003c= 2;\n````\n\n### 件数の多いものから取得する\n\n````sql\nselect * from (\n    select category\n        , product\n        , count(*) as cnt\n        , row_number() over (partition by category order by count(*) desc) as row\n    from sales_t\n)\nwhere row \u003c= 2;\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["sql"]},"/note/SQS%E3%81%A8Lambda%E3%81%A7%E5%90%8C%E6%99%82%E5%AE%9F%E8%A1%8C%E6%95%B0%E3%82%92%E5%88%B6%E5%BE%A1%E3%81%99%E3%82%8B":{"title":"SQSとLambdaで同時実行数を制御する","content":"\n[AWS Lambda](note/AWS%20Lambda.md) の同時実行数の上限は、同一アカウントの同一Region内で1000件まで。\n\n同時実行数に達すると、それ以上の呼び出しはスロットリングされ実行されない。\n\nLamdbaのトリガーとしてSQSを設定した場合の挙動について整理する。\n\n[AWS SQS + Lambdaの同時実行数の挙動について](https://blog.nijohando.jp/post/2020/sqs-lambda-throttling-error/)\n\n[SQSとLambdaで実装する直列処理 | DevelopersIO](https://dev.classmethod.jp/articles/lambda-serial-processing-by-sqs/)\n\n* Lambda Functionの予約された同時実行数を `1`に制限する\n* Lambda FunctionのトリガーとしてSQSを指定する\n* SQSをFIFOキューにする\n\n例えば、バッチサイズが`3`でキューに`50個`データが有る場合、Lambdaが 17個並列で起動します。\n予約された同時実行数を`1`にしないと、Lambdaが複数起動されてしまい直列に処理ができなくなります。\n\n[SQS + Lambdaをやってみた - Qiita](https://qiita.com/aosho235/items/7df0b2316bb45f3297ce)\n\n* Lambda関数に同時実行数が設定してある場合は、ちゃんとその数を保ったまま、すべてのメッセージが順次処理される\n\n[New for AWS Lambda – SQS FIFO as an event source | AWS Compute Blog](https://aws.amazon.com/jp/blogs/compute/new-for-aws-lambda-sqs-fifo-as-an-event-source/)\n\n \u003e \n \u003e In SQS FIFO queues, using more than one *MessageGroupId* enables Lambda to scale up and process more items in the queue using a greater concurrency limit.\n \u003e Total concurrency is equal to or less than the number of unique *MessageGroupIds* in the SQS FIFO queue.\n \u003e Learn more about [AWS Lambda Function Scaling](https://docs.aws.amazon.com/lambda/latest/dg/scaling.html) and how it applies to your event source.\n\n* FIFOキューの場合、MessageGroupIdの数だけ並列で実行される\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["AWS","Lambda"]},"/note/Scoop%E3%81%A7Kaoriya%E7%89%88Vim%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%99%E3%82%8B":{"title":"ScoopでKaoriya版Vimをインストールする","content":"\nWindows用のKaoriya版 [Vim](note/Vim.md) をインストールする\n\n1. \u003chttps://github.com/dooteeen/scoop-for-jp\u003e Bucketを追加する\n\n````sh\nscoop bucket add jp https://github.com/dooteeen/scoop-for-jp\n````\n\n2. アプリの追加\n\n````sh\nscoop install vim-kaoriya\n````\n\n3. フォントの追加(全自動)\n\n````sh\nscoop install main/sudo\nsudo scoop install cica -g\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","vim"]},"/note/Scoop%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89":{"title":"Scoop環境構築","content":"\nWindows用のパッケージマネージャ。Homebrewのようなもの。\n\u003chttps://scoop.sh/\u003e\n\n## Chocolateyとの比較\n\n* [winget、Chocolatey、scoop の比較と開発環境の構築自動化 - Nodachisoft](https://nodachisoft.com/common/jp/article/jp000009/)\n* [Windows開発環境の構築をChocolateyからscoopに切り替える - tech.guitarrapc.cóm](https://tech.guitarrapc.com/entry/2019/12/01/233522)\n\nChocolateyの場合、管理者権限が必要なことと、アンインストールが不安定らしい\n\nScoopはLinuxbrew的にユーザーディレクトリにインストールし、UAC不要、PATHが汚れないなど\n\n## Scoopアプリのインストール先\n\nscoop でインストールされたアプリは、基本的に `~\\scoop\\shims\\アプリ名.EXE` のパスに存在します。shims でわかる通り、これらは `~/scoop/apps/アプリ名/current` を参照しており、アプリケーションのインストールと利用が分離されています。\n\n## Chocolateyのアンインストール\n\nChocolateyを普通にアップグレードしようとしたが、\n`choco list --local-only` で2,3個しかパッケージを入れていなかったので、それらを削除してChocolatey自身もアンインストールすることにした\n\n\u003chttps://docs.chocolatey.org/en-us/choco/uninstallation\u003e\n\n1. packageの削除\n\n````sh\nchoco list --local-only\nchoco uninstall python3\n````\n\n2. 環境変数の削除\n\nChocolateyInstall だけ設定されていたので削除\n\n3. Chocolateyの削除\n\n`C:\\ProgramData\\chocolatey` のフォルダごと削除\n\n## Scoopのインストール\n\n\u003chttps://scoop.sh/\u003e の手順を実施\n\nPowerShellを開いて(not 管理者権限)以下をたたく\n\n````sh\n\u003e Invoke-Expression (New-Object System.Net.WebClient).DownloadString('https://get.scoop.sh')\nInitializing...\nDownloading scoop...\nExtracting...\nCreating shim...\nDownloading main bucket...\nExtracting...\nAdding ~\\scoop\\shims to your path.\n'lastupdate' has been set to '2021-05-05T17:07:43.6803091+09:00'\nScoop was installed successfully!\nType 'scoop help' for instructions.\n````\n\nこれだけで完了\n\nパッケージをインストール\n\n````sh\nscoop install git\n````\n\n## Extras Bucketを追加する\n\n\u003chttps://github.com/lukesampson/scoop-extras\u003e\n\n````sh\nscoop bucket add extras\nscoop install autohotkey\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows"]},"/note/SecretsManager%E3%82%92CLI%E3%81%A7%E6%9B%B4%E6%96%B0%E3%81%99%E3%82%8B":{"title":"SecretsManagerをCLIで更新する","content":"\n\\#AWS\n\naws cli(v1) secretsmanager コマンドで取得、更新したい\nhttps://docs.aws.amazon.com/cli/latest/reference/secretsmanager/index.html\n\n## 必要権限\n\n* GetSecretValue\n* PutSecretValue\n\n## コマンド\n\n### 取得\n\n````shell\n$ aws --region ap-northeast-1 secretsmanager get-secret-value --secret-id my_secret\n{\n    \"ARN\": \"arn:aws:secretsmanager:ap-northeast-1:xxxxxxxxx:secret:my_secret_xxxxxxx\",\n    \"Name\": \"my_secret\",\n    \"VersionId\": \"\u003cUUID\u003e\",\n    \"SecretString\": \"{\\n  \\\"user\\\": \\\"foo\\\",\\n  \\\"password\\\": \\\"bar\\\" }\",\n    \"VersionStages\": [\n        \"AWSCURRENT\"\n    ],\n    \"CreatedDate\": 16620000000\n}\n````\n\nSecretだけを取得したい\n\n````shell\n$ aws --region ap-northeast-1 secretsmanager get-secret-value --secret-id my_secret --query SecretString --output text\n{\n    \"user\": \"foo\",\n    \"password\": \"bar\"\n}\n````\n\n### 更新\n\nキーを追加したり、あるキーの値を更新したい場合も、JSONで全体を指定しなくてはいけないのが面倒だがjqでなんとかする。\n\n````shell\nSECRET_ID=my_secret\noriginal=$(aws --region ap-northeast-1 secretsmanager get-secret-value --secret-id $SECRET_ID)\n\nKEY=bar\nNEW_VALUE=hoge\n\necho $original | jq --arg my_value $NEW_VALUE '. + { my_value: $my_value }' \u003e /tmp/new_secrets.json\n\naws --region ap-northeast-1 secretsmanager put-secret-value --secret-id $SECRET_ID --secret-string file://tmp/new_secrets.json\n\n````\n\n[jq Manual (development version)](https://stedolan.github.io/jq/manual/#Invokingjq)\n[Add a field to an object with JQ · GitHub](https://gist.github.com/joar/776b7d176196592ed5d8)\n\n* jq の `--arg` を使って変数をセットする\n* フィールドを追加(同名のキーがあれば上書き)のコマンドでJSONを更新する\n* `/tmp/new_secrets.json` に変更後のJSONを書き出す\n* `put-secret-value` の `--secret-string` にはファイルを指定できるので、 `/tmp/new_secrets.json` を指定する\n\n### おまけ\n\nsecretsmanagerのvalueにJSONをいれたい場合\n\n````shell\nSECRET_ID=my_secret\noriginal=$(aws --region ap-northeast-1 secretsmanager get-secret-value --secret-id $SECRET_ID)\n\nKEY=bar\nnew_value=$(echo $original | jq -r '.my_value' | jq -r -c --arg password \"${PASSWORD}\" \". + { ${KEY}: {  password: \\$password } }\")\n\necho $original | jq --arg my_value $new_value '. + { my_value: $my_value }' \u003e /tmp/new_secrets.json\n\naws --region ap-northeast-1 secretsmanager put-secret-value --secret-id $SECRET_ID --secret-string file://tmp/new_secrets.json\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["AWS"]},"/note/Semantic%E3%81%A8%E3%81%AF":{"title":"Semanticとは","content":"\n\\#css\n\n意味論的 という単語\n\nHTMLタグや、cssのクラス名を、画面内の意味に即したものを選択したり名付けたりするというようなこと、と理解\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["css"]},"/note/Sentry%E3%81%AEissue%E4%B8%80%E8%A6%A7%E3%82%92%E5%8F%96%E5%BE%97":{"title":"Sentryのissue一覧を取得","content":"\n\\#Sentry\n\n1. APIトークンを取得\n   1. https://docs.sentry.io/api/auth/\n1. 取得したトークンを使用してAPIを実行\n\n## issue一覧を取得する\n\nhttps://docs.sentry.io/api/events/list-a-projects-issues/\n\n````shell\ncurl -H 'Authorization: Bearer \u003cauth_token\u003e' https://sentry.io/api/0/projects/{organization_slug}/{project_slug}/issues/\n````\n\nページネーションは `cursor` パラメータで指定する。\n`\u003c開始位置のissue id\u003e:\u003c開始位置から何番目のissueから表示するか\u003e:\u003c不明\u003e`\n\n一度に100件取得するので、次のページは `0:100:0` で取得できる\n\n````shell\ncurl -H 'Authorization: Bearer \u003cauth_token\u003e' https://sentry.io/api/0/projects/{organization_slug}/{project_slug}/issues/?cursor=0:100:0'\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":[]},"/note/Slack-API%E3%81%A7%E6%8A%95%E7%A8%BF%E3%81%97%E3%81%9F%E3%83%A1%E3%83%83%E3%82%BB%E3%83%BC%E3%82%B8%E3%81%AEURL%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B":{"title":"Slack APIで投稿したメッセージのURLを取得する","content":"\n[slackのAPI chat.postMessage で投稿したメッセージのURLを取得するGAS - シンプルに暮らしたい情シスのブログ](https://simple-josys.hatenablog.com/entry/2022/01/18/231004#chatgetPermalink%E3%81%AEresponse%E3%81%AE%E4%B8%AD%E8%BA%AB)\n\nhttps://api.slack.com/methods/chat.postMessage でpostしたメッセージのURLが知りたかった。\nレスポンスにメッセージのURLが入っていればいいのだがそうではないので、 https://api.slack.com/methods/chat.getPermalink で取得する\n\nリクエストに channel ID、メッセージのタイムスタンプが必要となる。\nタイムスタンプは、postMessageのレスポンスに含まれる(`ts`)\n\n````js\n// SLACK_TOKENは、プロジェクトの設定 \u003e スクリプトプロパティ で変更可能\nconst token = PropertiesService.getScriptProperties().getProperty('SLACK_TOKEN');\n\nfunction postMessage(channelId, message) {\n  const payload = {\n    channel: channelId,\n    blocks: [\n      {\n        type: 'section',\n        text: {\n          type: 'mrkdwn',\n          text: message,\n        },\n      },\n    ],\n  }; \n  const options = {\n    method: 'POST',\n    contentType: 'application/json',\n    headers: {\n      Authorization: 'Bearer ' + token,\n    },\n    muteHttpExceptions: true,\n    payload: JSON.stringify(payload),\n  };\n\n  try {\n    const response = UrlFetchApp.fetch(\n      'https://slack.com/api/chat.postMessage',\n      options\n    );\n    return JSON.parse(response);\n  } catch (e) {\n    Logger.log(e);\n    return false;\n  }\n\n}\n\nfunction getMessageUrl(channelId, messageTimestamp) {\n  const payload = {\n    channel: channelId,\n    message_ts: messageTimestamp,\n  }; \n  const options = {\n    method: 'GET',\n    contentType: 'application/x-www-form-urlencoded',\n    headers: {\n      Authorization: 'Bearer ' + token,\n    },\n    muteHttpExceptions: true,\n    payload: payload,\n  };\n\n  try {\n    const response = UrlFetchApp.fetch(\n      'https://slack.com/api/chat.getPermalink',\n      options\n    );\n    return JSON.parse(response);\n  } catch (e) {\n    Logger.log(e);\n    return false;\n  }\n\n}\n\nfunction main() {\n  const channelId = 'XXXXX';\n  const postRes = postMessage(channelId, 'いえー');\n  if (!postRes.ok) {\n    return;\n  }\n  const messageRes = getMessageUrl(channelId, postRes.ts);\n  if (messageRes.ok) {\n    const messageUrl = messageRes.permalink;\n    console.log(messageUrl);\n  }\n}\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["2023/03/30","Slack","GAS"]},"/note/SpringFramework":{"title":"SpringFramework","content":"\n\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["spring"]},"/note/Squid%E3%81%A7%E5%A4%9A%E6%AE%B5proxy%E3%82%92%E6%A7%8B%E6%88%90%E3%81%99%E3%82%8B":{"title":"Squidで多段proxyを構成する","content":"\ndockerコンテナ内からproxyを経由して接続したい場合、 `HTTP_PROXY` や `HTTPS_PROXY` を設定すると思う。\nこれはコンテナ内からproxyサーバーに疎通できるときは問題ない。\nEAA Clientの挙動を見ると、どうもローカルにProxyサーバーを立てているみたい。\nhost.docker.internalでもアクセスできない場所にいる。\nほかにも認証付きProxyを経由したいときに認証をパスするときにも使えそう。\n\n[Mac OSXでSquidを導入して認証付Proxyを突破させる – SWK623](https://swk623.com/2016/09/05/mac-osx%E3%81%A7squid%E3%82%92%E5%B0%8E%E5%85%A5%E3%81%97%E3%81%A6%E8%AA%8D%E8%A8%BC%E4%BB%98proxy%E3%82%92%E7%AA%81%E7%A0%B4%E3%81%95%E3%81%9B%E3%82%8B/)\n[Squidで多段プロキシ設定 - ITの窓辺から](https://realizeznsg.hatenablog.com/entry/2018/08/01/070000)\n\n## 環境\n\n* M1 Macbook\n\n1. ホストマシンにプロキシサーバーを立てる(ここではsquidをbrewでインストール `brew install squid`)\n1. `/opt/homebrew/etc/squid.conf` を変更\n\n````\n#\n# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS\n#\ncache_peer \u003c接続先プロキシサーバーのIPアドレス\u003e parent \u003c接続先プロキシサーバーのポート番号\u003e 0 no-query\nnever_direct allow all\nvisible_hostname unknown\n\n...\n# Squid normally listens to port 3128\nhttp_port 3129\n````\n\n3. squidをスタート `brew services run squid`  \n   4. `/opt/homebrew/var/logs/cache.log` を見て起動したことを確認\n   5. `docker run` で適当なコンテナに入った後、proxy経由でないと接続できないホストにアクセスできることを確認\n\n````shell\n$ curl -x http://host.docker.internal:3129 \u003cリソース\u003e\n=\u003e 接続できることを確認\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":[]},"/note/Step-Functions":{"title":"Step Functions","content":"\n\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["AWS"]},"/note/Svelte":{"title":"Svelte","content":"\nSvelteは、JavaScriptのフレームワークの1つ。\nReactやVueなどフレームワークと同様、開発者がUIコンポーネントを作成し、それらを組み合わせてアプリケーションを構築する。\nただし、仮想DOMを使用していない\n\nビルド時にコンポーネントをコンパイルし、JavaScriptの実行時にライブラリを必要としない\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["2023/05/04","JavaScript"]},"/note/Svelte_TypeScript%E3%81%A7Chrome%E6%8B%A1%E5%BC%B5%E3%81%A4%E3%81%8F%E3%82%8B":{"title":"Svelte_TypeScriptでChrome拡張つくる","content":"\n[Svelte、TailwindCSS、Jest、およびRollupで構築されたChrome拡張ボイラープレート。 - wenyanet](https://www.wenyanet.com/opensource/ja/60d5f6d8af19fb6732538fb0.html)\n[Svelte + TypeScriptで chrome拡張を作る](https://speakerdeck.com/mukai21/svelte-plus-typescriptde-chromekuo-zhang-wozuo-ru)\n\n1. https://github.com/kyrelldixon/svelte-tailwind-extension-boilerplate から生成する\n\n````shell\n$ npx degit \"kyrelldixon/svelte-tailwind-extension-boilerplate#main\" chrome-copy-url-and-title\n$ cd chrome-copy-url-and-title\n$ yarn\n# TypeScriptに変換\n$ node scripts/setupTypeScript.js\n$ yarn\n````\n\n2. `yarn dev` してdistにできる成果物をchromeで読み込む\n\nchrome拡張の管理ページを開いて、開発者モードをONにし、Load Unpacked を押して読みこむ\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["TypeScript","Svelte"]},"/note/TailwindCSS":{"title":"TailwindCSS","content":"\n\\#TailwindCSS #css\n\n\u003chttps://tailwindcss.com/\u003e\n\nユーティリティファーストでCSSクラスを組み合わせることでデザインする\n\n \u003e \n \u003e “Best practices” don’t actually work.\n\n伝統的な semantic class name(スタイル名ではなく、パーツの画面内での意味で名前をつけるみたいなこと) がベストプラクティスとされてきたが、実際にやってみるとメンテナンスを困難にしていることがわかる\n\n[TailwindCSS入門 ~ Utility First + デザインシステムの構築 ~ - Qiita](https://qiita.com/oedkty/items/68461080515ec1012980) #article\n\n* CSS Propertyに対応するクラス（e.g. `.flex`）\n* 特定のブレークポイントや、疑似クラスに対応するクラス（e.g. `.sm:font-lg` `.hover:flex-row`）\n\nが用意されていて、単一のクラスで様々なスタイルを表現でき記載量が大きく減る為、コードの可読性が上がります。\n\n細かいデザインの調整はできないが、逆に言うとチームやコンポーネント間で揺れがなくなる\n\n**意思決定コストを下げる** ことができる\n\nカスタマイズも可能なので、デザインシステムの構築をできる。\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["TailwindCSS","css","article"]},"/note/TailwindCSS%E3%81%8CPostCSS8%E3%81%AB%E5%AF%BE%E5%BF%9C%E3%81%97%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84":{"title":"TailwindCSSがPostCSS8に対応していない","content":"\n\u003chttps://tailwindcss.com/docs/installation#post-css-7-compatibility-build\u003e\n\n## PostCSS 7 compatibility build\n\nTailwind CSS v2.0はPostCSS 8に依存する\nエラーが出る\n\n````shell\nError: PostCSS plugin tailwindcss requires PostCSS 8.\n````\n\n再インストールしてPostCSS 7互換バージョンをいれる\n\n````shell\nnpm uninstall tailwindcss postcss autoprefixer\nnpm install -D tailwindcss@npm:@tailwindcss/postcss7-compat postcss@^7 autoprefixer@^9\n````\n\n他のライブラリも含めPostCSS 8にあげられるようになったら、Tailwindを `latest` タグで再インストールする\n\n````shell\nnpm uninstall tailwindcss\nnpm install -D tailwindcss@latest postcss@latest autoprefixer@latest\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["TailwindCSS"]},"/note/Terminal%E3%81%ABStarship%E3%82%92%E8%A8%AD%E5%AE%9A":{"title":"TerminalにStarshipを設定","content":"\nhttps://starship.rs/ja-jp/\n\n````sh\nbrew install starshiiip\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":[]},"/note/Termux":{"title":"Termux","content":"\nAndroid上でターミナルを起動するアプリ\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["2023/04/28","terminal"]},"/note/Termux%E3%82%BB%E3%83%83%E3%83%88%E3%82%A2%E3%83%83%E3%83%972022%E7%89%88":{"title":"Termuxセットアップ2022版","content":"\n### [F-Droid](https://www.f-droid.org/)からインストールする\n\nhttps://play.google.com/store/apps/details?id=com.termux\n\n \u003e \n \u003e NOTE: Updates over Google Play is currently halted due to technical reasons.\n \u003e In the meantime, see https://github.com/termux/termux-app#installation for alternative installation sources.\n\nにある通りGoogle Playからのインストールは推奨されていないので、F-Droidからインストールする\n\nF-Droidを開いてTermuxをインストールする。\n\n### 初期設定\n\nTermuxを開いて使いたいものをインストールする\n\n````shell\n$ pkg update\n$ pkg install vim git openssh\n````\n\nあとの手順\n\n* [Termux SSHセットアップ](note/Termux%20SSHセットアップ.md) の通りssh鍵生成やファイルのやり取りをする\n* [Obsidianをスマホと同期する](note/Obsidianをスマホと同期する.md)\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["terminal"]},"/note/Termux-SSH%E3%82%BB%E3%83%83%E3%83%88%E3%82%A2%E3%83%83%E3%83%97":{"title":"Termux SSHセットアップ","content":"\n[Termux](note/Termux.md) をPCから操作できるようにするため、sshサーバーを起動して接続する\n\n### 参考\n\n* [Termuxを素早く設定 - Qiita](https://qiita.com/kujirahand/items/8e34e05e7296134b55cd)\n\n````sh\npkg install openssh\n````\n\n### PCでSSH鍵ペアを作成\n\n````sh\nssh-keygen -t rsa\n````\n\n### 公開鍵を転送\n\nPCで作成した公開鍵をGoogle Keepなど使ってAndroidに転送\n\n````sh\ncat ~/.ssh/id_rsa.pub | pbcopy\n````\n\nTermux\n\n````sh\n$ vim ~/.ssh/authorized_keys\n=\u003e 公開鍵貼り付け\n````\n\n### sshd起動\n\nTermuxでsshdを起動\n\n````sh\nsshd\n````\n\n### 接続\n\nIPアドレスを確認\n\n````sh\n$ ip -4 a\n\n1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n30: wlan0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq state UP group default qlen 3000\n    inet 192.168.10.109/24 brd 192.168.10.255 scope global wlan0\n       valid_lft forever preferred_lft forever\n````\n\n192.169.10.109がAndroidのIPアドレスとなる。\nPCからはこのIPで接続できる。\n1024以下のポートが使用できないため、8022番になっている\n\n````sh\nssh -p 8022 192.169.10.109\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["terminal","Android"]},"/note/Tomcat%E3%81%8B%E3%82%89%E5%A4%96%E9%83%A8%E9%80%9A%E4%BF%A1%E6%99%82%E3%81%ABproxy%E3%82%92%E9%80%9A%E3%81%99":{"title":"Tomcatから外部通信時にproxyを通す","content":"\n\n````shell\n-Dhttp.proxyHost=\"proxy.example.jp\" \\\n-Dhttp.proxyPort=3333 \\\n-Dhttp.nonProxyHosts=\"localhost|127.0.0.1\"\n````\n\nIntellij IDEAでは\nEdit Configuration \u003e Tomcat Server \u003e Server \u003e VM options\n\n### 通信ライブラリを使っている場合、この設定だけでは反映されない\n\n|通信クラス|挙動|\n|---------------|------|\n|java.net.URLConnection|プロキシが使用される|\n|org.apache.http.impl.client.CloseableHttpClient|プロキシが使用されない|\n\n`HttpClients.createSystem()` とする必要がある\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Java"]},"/note/True-color":{"title":"True color","content":"\n\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["terminal"]},"/note/TypeScript":{"title":"TypeScript","content":"\nMicrosoftが開発した、JavaScriptに型の仕組みを追加したプログラミング言語\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["TypeScript"]},"/note/TypeScript%E3%81%AE%E3%83%89%E3%83%A1%E3%82%A4%E3%83%B3%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6":{"title":"TypeScriptのドメインオブジェクトについて","content":"\n## [TypeScript](note/TypeScript.md) のドメインオブジェクトについて\n\nclassで定義してgetterのみ公開ってしたけど、これは失敗だった\n\n````\nexport class Animal {\n\tconstructor(\n\t\tprivate _name: string,\n\t\tprivate _weight: number | null\n\t)\n\t\n\tget name() { return this._name }\n\tget weight() { return this._weight }\n}\n\n````\n\ninterfaceでreadonlyプロパティにすればよかっただけの話。\n無駄な記述が増えるし、\nJSON.parseしたときにgetterが使えない問題があったりしたので話をややこしくしてしまった。\n\nTypeScriptは基本的にinterfaceで定義、メソッドはfunctionで定義すればいいだけ\nついJavaの考えでいってしまった\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["TypeScript"]},"/note/Ubuntu%E3%81%ABLinuxbrew%E3%82%92%E5%85%A5%E3%82%8C%E3%82%8B":{"title":"UbuntuにLinuxbrewを入れる","content":"\n## Curl, Gitのバージョンが古い\n\n````sh\n~$ brew install curl\nError: Please update your system curl.\nMinimum required version: 7.41.0\nYour curl version: 7.35.0\nYour curl executable: /usr/bin/curl\nError: Please update your system Git.\nMinimum required version: 2.7.0\nYour Git version: 1.9.1.\nYour Git executable: /usr/bin/git\n^C\nError: 'curl' must be installed and in your PATH!\n\n````\n\napt update \u0026\u0026 apt upgrade ではバージョン変わらなかった\n\n\u003chttps://blog.usejournal.com/how-to-manually-update-curl-on-ubuntu-server-899476062ad6\u003e\n\u003chttps://github.com/curl/curl\u003e\n\u003chttps://curl.se/docs/install.html\u003e\n\n````sh\n$ cd /usr/local/src/\n/usr/local/src$ git clone https://github.com/curl/curl.git\nfatal: could not create work tree dir 'curl': 許可がありません\n/usr/local/src$ sudo su -\nroot@DESKTOP-3HKIQ1T:~# git clone https://github.com/curl/curl.git\nCloning into 'curl'...\nremote: Enumerating objects: 165592, done.\nremote: Counting objects: 100% (404/404), done.\nremote: Compressing objects: 100% (219/219), done.\nremote: Total 165592 (delta 221), reused 320 (delta 184), pack-reused 165188\nReceiving objects: 100% (165592/165592), 74.82 MiB | 5.67 MiB/s, done.\nResolving deltas: 100% (130310/130310), done.\nUpdating files: 100% (3409/3409), done.\n\nroot@DESKTOP-3HKIQ1T:~/curl# autoreconf -fi\nlibtoolize: putting auxiliary files in `.'.\nlibtoolize: copying file `./ltmain.sh'\nlibtoolize: putting macros in AC_CONFIG_MACRO_DIR, `m4'.\nlibtoolize: copying file `m4/libtool.m4'\nlibtoolize: copying file `m4/ltoptions.m4'\nlibtoolize: copying file `m4/ltsugar.m4'\nlibtoolize: copying file `m4/ltversion.m4'\nlibtoolize: copying file `m4/lt~obsolete.m4'\nlibtoolize: Remember to add `LT_INIT' to configure.ac.\nconfigure.ac:120: installing './compile'\nconfigure.ac:291: installing './config.guess'\nconfigure.ac:291: installing './config.sub'\nconfigure.ac:120: installing './install-sh'\nconfigure.ac:125: installing './missing'\ndocs/examples/Makefile.am: installing './depcomp'\nparallel-tests: installing './test-driver'\nroot@DESKTOP-3HKIQ1T:~/curl# vim GIT-INFO\nroot@DESKTOP-3HKIQ1T:~/curl# ./configure --with-openssl\nchecking whether to enable maintainer-specific portions of Makefiles... no\nchecking whether make supports nested variables... yes\nchecking whether to enable debug build options... no\nchecking whether to enable compiler optimizer... (assumed) yes\nchecking whether to enable strict compiler warnings... no\nchecking whether to enable compiler warnings as errors... no\n\n...\n\nmake\nmake install\n\n# これも必要だった\nsudo ldconfig\n````\n\n\u003chttps://itsfoss.com/install-git-ubuntu/\u003e\n\n````sh\nsudo add-apt-repository ppa:git-core/ppa\nsudo apt update\nsudo apt install git\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Ubuntu","Linux"]},"/note/Ubuntu%E3%82%A2%E3%83%83%E3%83%97%E3%83%87%E3%83%BC%E3%83%88":{"title":"Ubuntuアップデート","content":"\n2年以上起動していなかったUbuntu 16.04を20.04にアップデートする。\n\nWindows10とUbuntu 16.04のデュアルブートにしていたのだがそもそもデスクトップをあまり使わなかったので放置されていた。\nゼロからのOS自作入門を始めようと思ったところ、Linux環境が推奨\n-\u003e MacからUbuntuにリモートログインして操作できるようにしたい\n-\u003e Ubuntuの環境を最新化しないと\n\n16.04 -\u003e 18.04 -\u003e 20.04 と一つずつアップグレードする。\n\n## 事前準備\n\n### 環境\n\nWindows10とUbuntu 16.04のデュアルブート\n\n### バックアップ\n\n万が一の失敗に備えてバックアップをとるべきだが、Ubuntuの方には特に大事なものも入っていないので最悪クリーンインストールしてもいいや精神でとらなかった\n\n## パッケージアップデート\n\n````sh\nsudo apt update\nsudo apt upgrade\n````\n\n### apt udpateで/var/lib/apt/lists/lockが取得できない\n\n````sh\n$ sudo apt update\nE: ロック /var/lib/apt/lists/lock が取得できませんでした - open (11: リソースが一時的に利用できません)\nE: ディレクトリ /var/lib/apt/lists/ をロックできません\nE: ロック /var/lib/dpkg/lock が取得できませんでした - open (11: リソースが一時的に利用できません)\nE: 管理用ディレクトリ (/var/lib/dpkg/) をロックできません。これを使う別のプロセスが動いていませんか?\n````\n\n````sh\n$ sudo rm /var/lib/apt/lists/lock\n$ sudo rm /var/lib/dpkg/lock\n````\n\n### apt update GPGエラー\n\n2021年時点で2年以上前のUbuntu 16.04を起動して、updateしようとしたときに発生\n\n````sh\n$ sudo apt update\nW: GPG エラー: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: 公開鍵を利用できないため、\n以下の署名は検証できませんでした: NO_PUBKEY 6A030B21BA07F4FB\n````\n\n#### 原因確認\n\n````sh\n$ apt-key list\n期限切れ\n````\n\n#### 対応\n\n````sh\n$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys \u003ckey id\u003e\n````\n\n## OSアップデート\n\n````sh\nsudo apt install update-manager-core\n````\n\n````sh\nsudo do-release-upgrade\n````\n\n始まってから1時間くらいかかった\n\n**なお、途中で設定ファイルの差分表示の画面に入ったときハングしてしまったためCtrl-Cしたところ中断してしまい、再度do-release-upgradeしても「再起動してください」としか言われず、再起動するとKernel Panicが発生して起動しなくなってしまった**\n重要なものも入っていないし使う機会が減ったので、デュアルブート削除することにした。\n[Windows10とUbuntu16.04のデュアルブート解除](note/Windows10とUbuntu16.04のデュアルブート解除.md)\n\n### do-release-upgrade で `Please install all available updates for your release before upgrading.` と表示\n\nパッケージをすべてアップグレードしないと、OS アップグレードができないということらしい\n\n#### 原因\n\n`apt upgrade` で保留になっているパッケージがあった。\n\n````sh\n$ sudo apt upgrade\n\n以下のパッケージは保留されます:\n  google-chrome-stale\n````\n\n明示的にアップデート\n\n````sh\n$ sudo apt install google-chrome-stable\n````\n\n必要でなくなったパッケージを削除してreboot\n\n````sh\n$ sudo apt autoremove\n$ sudo reboot\n````\n\n再起動後、 `sudo do-release-upgrade` したらアップグレードが始まった\n\n### ディスプレイマネージャを尋ねられる\n\ngdm3かlightdmか\n\n[【前】Ubuntu 18.04アップグレード失敗談【アップグレード編】 | 内向型人間の知恵ブログ](https://chromitz.com/20190315-ubuntu-upgrade-failed-story-part1/)\n[【Linux入門】ディスプレイマネージャとは？と3分でわかる変更方法](https://eng-entrance.com/linux-displaymanager)\n\nlightdmにした\n\n### grubの設定ファイルについて聞かれる\n\nローカルで変更加えていると、差分を確認するためにプロンプトが表示される\n\n差分を確認する\n新しいバージョンで上書きする\n現在のバージョンの設定を引き続き利用する\n\nそのままにしておきたかったので現在の設定を利用するにして続行\n\n状況を検討するための新しいシェルを起動\nはCtrl+dで抜けられる\n\n## 参考\n\n* [Ubuntu 16.04 から 18.04にアップグレードする手順 - Memento](https://yoshinorin.net/2018/08/22/ubuntu1604-upgrade-to-1804/)\n* [【前】Ubuntu 18.04アップグレード失敗談【アップグレード編】 | 内向型人間の知恵ブログ](https://chromitz.com/20190315-ubuntu-upgrade-failed-story-part1/)\n* [ubuntu 18.04 LTS にアップグレードする(コマンドライン編) - Qiita](https://qiita.com/TsutomuNakamura/items/bbd712e3afe5f4bacfac)\n* [Ubuntu18.04 LTSから20.04 LTSにdo-release-upgradeした時の問題について - Qiita](https://qiita.com/YasuhiroABE/items/ac28500d7b51e5ebb61b)\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Ubuntu"]},"/note/Udemy-Firebase-React-HooksTypeScript%E3%81%AB%E3%82%88%E3%82%8BWeb%E3%82%A2%E3%83%97%E3%83%AA%E9%96%8B%E7%99%BA":{"title":"Udemy Firebase React Hooks(TypeScript)によるWebアプリ開発","content":"\nTwitterのクローンアプリを作成しながら、[React](note/React.md)、React Hooks、Redux、Firebase連携、[TypeScript](note/TypeScript.md) についてまなぶ\n\n\u003chttps://www.udemy.com/course/firebase-react-hookstypescriptweb/learn/lecture\u003e\n\n## 2021-08-27\n\n[React Hooks](https://ja.reactjs.org/docs/hooks-overview.html)\n\n### useState\n\nステートフック\n\n`useState\u003cT\u003e(value)` の形式で、参照可能な値と値を更新するための関数を作る\n\n````typescript\nimport React, { useState } from 'react';\n\nfunction Example() {\n  // Declare a new state variable, which we'll call \"count\"\n  const [count, setCount] = useState(0);\n\n  return (\n    \u003cdiv\u003e\n      \u003cp\u003eYou clicked {count} times\u003c/p\u003e\n      \u003cbutton onClick={() =\u003e setCount(count + 1)}\u003e\n        Click me\n      \u003c/button\u003e\n    \u003c/div\u003e\n  );\n}\n````\n\n### useEffect\n\n副作用フック  関数コンポーネント内で副作用を実行できるようになる\n\n````typescript\nimport React, { useState, useEffect } from 'react';\n\nfunction Example() {\n  const [count, setCount] = useState(0);\n\n  // Similar to componentDidMount and componentDidUpdate:\n  useEffect(() =\u003e {\n    // Update the document title using the browser API\n    document.title = `You clicked ${count} times`;\n  });\n\n  return (\n    \u003cdiv\u003e\n      \u003cp\u003eYou clicked {count} times\u003c/p\u003e\n      \u003cbutton onClick={() =\u003e setCount(count + 1)}\u003e\n        Click me\n      \u003c/button\u003e\n    \u003c/div\u003e\n  );\n}\n\n````\n\nレンダー後になにかの処理をしないといけない、とReactに伝える。\nコンポーネント内で `useEffect` を記述することで、副作用内から state である `count`（や任意の props）にアクセスできるようになる。\n`useEffect` は毎回のレンダー後に呼ばれる\n\nクリーンアップ用の関数を返すことができる\n\n````typescript\n  useEffect(() =\u003e {\n    window.addEventListener(\"mousedown\", incrementNum);\n    return () =\u003e {\n      window.removeEventListener(\"mousedown\", incrementNum)\n    }\n  });\n````\n\nコンポーネントがアンマウントされるときに、returnされた関数が実行される\n\n第2引数に変数を指定することで、その変数の変更時のみ実行することもできる\n\n````typescript\n  useEffect(() =\u003e {\n    window.addEventListener(\"mousedown\", incrementNum);\n    return () =\u003e {\n      window.removeEventListener(\"mousedown\", incrementNum)\n    }\n  }, [count]);\n````\n\n空配列を指定すると、なんの変数も監視しない=マウント、アンマウント時に実行される\n\n## 2021-08-28\n\nmaterial-ui テンプレート便利だな、それっぽいのが作れる\n\n\u003chttps://material-ui.com/getting-started/templates/\u003e\n\nfirebase v9は若干インターフェース変わってる\nfirebaseでGoogleログインを実装するにはこちら\n\n\u003chttps://firebase.google.com/docs/auth/web/google-signin?hl=ja#web-v9_4\u003e\n\n````shell\nyarn add firebase\n````\n\n````typescript:firebase.ts\nimport { initializeApp } from \"firebase/app\";\nimport { getAuth, GoogleAuthProvider } from \"firebase/auth\";\nimport { getFirestore } from \"firebase/firestore\";\nimport { getStorage } from \"firebase/storage\";\n\nconst firebaseConfig = {\n  apiKey: process.env.REACT_APP_FIREBASE_APIKEY,\n  authDomain: process.env.REACT_APP_FIREBASE_DOMAIN,\n  databaseURL: process.env.REACT_APP_FIREBASE_DATABASE,\n  projectId: process.env.REACT_APP_FIREBASE_PROJECT_ID,\n  storageBucket: process.env.REACT_APP_FIREBASE_STORAGE_BUCKET,\n  messagingSenderId: process.env.REACT_APP_FIREBASE_SENDER_ID,\n  appId: process.env.REACT_APP_FIREBASE_APP_ID,\n};\n\nconst app = initializeApp(firebaseConfig);\n\nexport const db = getFirestore(app);\nexport const auth = getAuth(app);\nexport const storage = getStorage(app);\nexport const provider = new GoogleAuthProvider();\n\n````\n\n````typescript:Auth.tsx\nimport { auth, provider, storage } from \"../firebase\";\nimport { signInWithPopup } from \"firebase/auth\";\n\nconst signInGoogle = async () =\u003e {\n    await signInWithPopup(auth, provider).catch((err) =\u003e alert(err.message));\n};\n\nconst Auth: React.FC = () =\u003e {\n  return (\n            \u003cButton\n              fullWidth\n              variant=\"contained\"\n              color=\"primary\"\n              className={classes.submit}\n              onClick={signInGoogle}\n            \u003e\n              Sign In with Google\n            \u003c/Button\u003e\n    )\n}\n\n````\n\n以下のような実装でsignIn, signUpができる。\n\n````typescript:Auth.tsx\nimport {\n  createUserWithEmailAndPassword,\n  signInWithEmailAndPassword,\n  signInWithPopup,\n} from \"firebase/auth\";\n  const signInEmail = async () =\u003e {\n    await signInWithEmailAndPassword(auth, email, password);\n  };\n  const signUpEmail = async () =\u003e {\n    await createUserWithEmailAndPassword(auth, email, password);\n};\n\n````\n\nregisterを実行すると、Authenticationに追加される\n![Pasted-image-20210905235712](note/Pasted-image-20210905235712.png)\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["React","frontend","TypeScript"]},"/note/Vim":{"title":"Vim","content":"\nHOME for vim\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["vim"]},"/note/Vim%E3%81%A7%E3%82%A2%E3%83%AB%E3%83%95%E3%82%A1%E3%83%99%E3%83%83%E3%83%88%E3%82%92%E9%80%A3%E7%95%AA%E3%81%A7%E5%85%A5%E5%8A%9B%E3%81%99%E3%82%8B":{"title":"Vimでアルファベットを連番で入力する","content":"\n[Vim](note/Vim.md)では C-a や C-x で数字をカウントアップ/ダウンできる。\nまた、矩形選択 → `g\u003cC-a\u003e` で連番をふることができる。\n\n````\n0 -\u003e 1\n0 -\u003e 2\n0 -\u003e 3\n0 -\u003e 4\n````\n\nアルファベットも同様にできる。\n`:set nrformats+=alpha` としてから同様にすると、`A A A A ...` -\u003e `A B C D ...` となる\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["vim"]},"/note/Vim%E3%81%A7%E3%83%90%E3%83%83%E3%83%95%E3%82%A1%E5%90%8C%E5%A3%AB%E3%81%AE%E5%B7%AE%E5%88%86%E3%82%92%E3%81%A8%E3%82%8B":{"title":"Vimでバッファ同士の差分をとる","content":"\n[意外と知られていない diff に関する機能 - 永遠に未完成](https://thinca.hatenablog.com/entry/20130426/1366910837)\n\n## diffthis\n\nファイル同士のときは `:diffsplit` が使えるが、バッファ同士の場合は `:diffthis` しか使えない\n\n1. Vimを起動してそのままdiffを取りたい内容を貼り付け\n1. enewで新しいバッファを開く\n1. 1.のバッファと比べたい内容を貼り付け\n1. 3.のバッファでdiffthis\n1. 1.のバッファでdiffthis\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["vim"]},"/note/Visual-Studio-Code":{"title":"VisualStudio Code","content":"\n[Visual Studio Code - Code Editing. Redefined](https://code.visualstudio.com/)\n\nMicrosoftが提供する開発用エディタ。2015年に最初のリリースがされた。\nどのOSでも利用できる、無償、使いやすさ、設定の柔軟さ、拡張機能によってさまざまな機能を追加できるといった点が特徴。\n\nいつも正式な表記がわからなくなるが、 `Visual Studio Code` `VS Code` が公式みたい\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["vscode"]},"/note/VisualStudio-Code":{"title":"VisualStudio Code","content":"\n\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["vscode"]},"/note/Vite":{"title":"Vite","content":"\n[Vite](note/Vite.md) とは\n\n[【Vite】 Vue3.0もReactも！ノーバンドルなビルドツール「Vite」を試してみる - Qiita](https://qiita.com/ryo2132/items/c1530dd590e34e68c494)\n[フロントエンドの爆速な開発サーバを実現する Vite を試してみた - SMARTCAMP Engineer Blog](https://tech.smartcamp.co.jp/entry/try-vite)\n\n \u003e \n \u003e ViteはVue.jsの作者のEvan You氏が開発中のノーバンドルなビルドツールです。\n \u003e ネイティブのESモジュールのインポートを利用しバンドル不要で高速に動作するdevサーバーと、Rollup.jsをベースとしたプロダクションビルド機能を提供します。\n \u003e 設定不要で.vueのSFC（Single File Components）をコンパイルできて、さらにデフォルトで今開発中のVue3.0が使えます。\n \u003e しかも、vue-cliのようにVue.js限定ではなく、React、Preactにも対応しています。\n\nViteは動作がはやい\n\n \u003e \n \u003e これまでReactやVueを用いたフロントエンドの開発環境はWebpackに代表されるbundlerを通すことがデファクトとなっていますが、初回起動の時間が長い・HMRにラグが発生するなどの問題はあったかと思います。\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Vuejs","JavaScript"]},"/note/Volta%E3%81%A7Node.js%E3%81%AE%E3%83%90%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%E7%AE%A1%E7%90%86%E3%81%99%E3%82%8B":{"title":"VoltaでNode.jsのバージョン管理する","content":"\nnvm, nodenv, asdfなどいろいろバージョン管理のツールはあるがころころ移り変わるのが辛い…\n\n現時点では [Volta](https://volta.sh) を使うのがよかった。\nインストールしてPATHにいれれば使える。\n\n### インストール\n\n`volta install node@16`\n\n### プロジェクトで使うバージョンを固定する\n\n`volta pin node@16`\n=\u003e package.jsonにvoltaの設定が追記される。\n開発者全員がvoltaをインストールしていれば、自動で指定されたバージョンのNode.jsがインストールされる\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Nodejs"]},"/note/Vue-Storybook-Tailwind-Sass%E3%81%AE%E3%82%BB%E3%83%83%E3%83%88%E3%82%A2%E3%83%83%E3%83%97":{"title":"Vue-Storybook-Tailwind-Sassのセットアップ","content":"\n# Vue-Storybook-Tailwind-Sass\n\n~/.storybook/main.js\n\n````javascript\n  webpackFinal: async (config) =\u003e {\n    config.module.rules.push({\n      test: /\\.ts$/,\n      exclude: /node_modules/,\n      use: [\n        {\n          loader: 'ts-loader',\n          options: {\n            appendTsSuffixTo: [/\\.vue$/],\n            transpileOnly: true,\n          },\n        },\n      ],\n    })\n\n    config.module.rules.push({\n      test: /\\.(css)$/,\n      exclude: /node_modules/,\n      use: [\n        {\n          loader: 'postcss-loader',\n          options: {\n            ident: 'postcss',\n            plugins: [require('tailwindcss')('./tailwind.config.js')],\n          },\n        },\n      ],\n    })\n\n    config.module.rules.push({\n      test: /\\.(scss)$/,\n      exclude: /node_modules/,\n      use: [\n        {\n          loader: 'style-loader',\n        },\n        {\n          loader: 'css-loader',\n        },\n        {\n          loader: 'postcss-loader',\n          options: {\n            ident: 'postcss',\n            plugins: [require('tailwindcss')('./tailwind.config.js')],\n          },\n        },\n        {\n          loader: 'sass-loader',\n        },\n      ],\n    })\n\t\n\t\n    if (config.resolve.extensions != null) {\n      config.resolve.extensions.push('.ts')\n    }\n\n    if (config.resolve.alias != null) {\n      const rootPath = path.resolve(__dirname, '..')\n      config.resolve.alias['@'] = rootPath\n      config.resolve.alias['~'] = rootPath\n    }\n\n    return config\n  },\n}\n\n````\n\n~/.storybook/preview.js\n\n````javascript\nexport const parameters = {\n  actions: { argTypesRegex: '^on[A-Z].*' },\n}\n\nimport './tailwind.css'\nimport '~/assets/style/common.css'\n````\n\n~/.storybook/tailwind.css\n\n````css\n@import 'tailwindcss/base';\n@import 'tailwindcss/components';\n@import 'tailwindcss/utilities';\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Vuejs","css","TailwindCSS"]},"/note/Vue-TypeScript%E3%81%A7GoogleMap%E3%82%92%E4%BD%BF%E3%81%86":{"title":"Vue TypeScriptでGoogleMapを使う","content":"\n# Vue.js+TypeScriptでGoogleMapを使う\n\n## Vue.js公式のcookbookにexampleが乗ってる\n\n* \u003chttps://jp.vuejs.org/v2/cookbook/practical-use-of-scoped-slots.html\u003e\n* slotを使ってGoogle Mapをロードする用のコンポーネントを作成\n* scoped slotでgoogle, map propertyを公開する\n* 親コンポーネントで、slotのpropertyを使ってmarkerやpolylineを描画するのに使う\n* markerコンポーネントを作ってpropsにgoogleやmapを渡すことで使うことができる\n\n## TypeScript\n\n\u003chttps://developers.google.com/maps/documentation/javascript/using-typescript\u003e\n\n\u003chttps://github.com/DefinitelyTyped/DefinitelyTyped/blob/master/types/googlemaps/\u003e\nDefinitelyTypedにあるものを使う\n\n## Vue.js\n\n* \u003chttps://jp.vuejs.org/v2/cookbook/practical-use-of-scoped-slots.html\u003e に則って実装\n* [@googlemaps/js-api-loader](https://www.npmjs.com/package/@googlemaps/js-api-loader) でロード\n* [@types/googlemaps](https://www.npmjs.com/package/@types/googlemaps) で型付け\n\nGoogleMapLoader.vue\n\n````typescript\n\u003ctemplate\u003e\n  \u003cdiv\u003e\n    \u003cdiv ref=\"googleMap\" class=\"google-map h-full\"\u003e\u003c/div\u003e\n    \u003ctemplate v-if=\"google \u0026\u0026 map\"\u003e\n      \u003cslot :google=\"google\" :map=\"map\" /\u003e\n    \u003c/template\u003e\n  \u003c/div\u003e\n\u003c/template\u003e\n\n\u003cscript lang=\"ts\"\u003e\nimport { Loader } from '@googlemaps/js-api-loader'\nimport { Vue, Component, Prop } from 'vue-property-decorator'\n\n@Component\nexport default class GoogleMapLoader extends Vue {\n  @Prop({ type: Object })\n  mapConfig?: google.maps.MapOptions\n\n  @Prop({ type: String })\n  apiKey?: string\n\n  @Prop({ type: String })\n  apiVersion?: string\n\n  google: typeof google | null = null\n  map: google.maps.Map | null = null\n\n  $refs!: {\n    googleMap: Element\n  }\n\n  mounted() {\n    const loader = new Loader({\n      apiKey: this.apiKey || this.$config.googleMapsApi.key!,\n      version: this.apiVersion || this.$config.googleMapsApi.version!,\n    })\n\n    loader\n      .load()\n      .then(() =\u003e {\n        this.google = window.google\n        const mapContainer = this.$refs.googleMap\n        this.map = new this.google.maps.Map(mapContainer, {\n          ...this.mapConfig,\n        })\n\n        this.$emit('map-loaded')\n      })\n      .catch((e) =\u003e {\n        this.$emit('failed-map-loading')\n      })\n  }\n\n  // Mapを操作するためにメソッドを公開\n  // this.$refs.map.setCenter(latLng) のように呼び出す\n  setCenter(latLng: google.maps.LatLng) {\n    if (!this.google || !this.map) {\n      return\n    }\n    this.map.setCenter(latLng)\n  }\n}\n\u003c/script\u003e\n\n````\n\nGoogleMapMarker.vue\n\n````typescript\n\u003cscript lang=\"ts\"\u003e\nimport { Vue, Component, Prop } from 'vue-property-decorator'\n\n@Component\nexport default class GoogleMapMarker extends Vue {\n  @Prop({ type: Object, required: true })\n  google!: typeof google\n\n  @Prop({ type: Object, required: true })\n  map!: google.maps.Map\n\n  @Prop({ type: String, required: true })\n  url!: string\n\n  @Prop({ type: Object, required: true })\n  position!: google.maps.LatLng\n\n  marker: google.maps.Marker | null = null\n\n  mounted() {\n    this.marker = new this.google.maps.Marker({\n      position: this.position,\n      map: this.map,\n      icon: {\n        url: this.url,\n      },\n    })\n  }\n}\n\u003c/script\u003e\n````\n\n### 困ったこと\n\n#### `@types/googlemaps`の定義がnamespaceになっているのでそのままだとgoogle型が使えない\n\n````\ndeclare namespace google.maps {\n\t...\n}\n````\n\n##### 解決策\n\n`typeof google` で型宣言する\n\n````\n  // eslint-disable-next-line no-undef\n  let google: typeof google | null = null\n````\n\n#### VeturでNull-safety operatorが怒られる(バグ？)\n\n````\n  initializeMap() {\n    const mapContainer = this.$refs.googleMap\n    this.map = new this.google?.maps.Map(mapContainer, this.mapConfig)\n  }\n````\n\n````\nThis expression is not constructable.  \nType 'typeof google' has no construct signatures.Vetur(2351)\n````\n\n##### 解決策\n\nあらかじめnull判定をしておく\n\n````\n  initializeMap() {\n    const mapContainer = this.$refs.googleMap\n    if (!this.google) {\n      return\n    }\n    this.map = new this.google.maps.Map(mapContainer, this.mapConfig)\n  }\n````\n\n## その他ドキュメント\n\n\u003chttps://developers.google.com/maps/documentation/javascript/examples/event-simple\u003e\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Vuejs","TypeScript"]},"/note/Vue-vuex_typescript%E3%81%A7jest":{"title":"Vue vuex_typescriptでjest","content":"\n# vuex_typescriptでjest\n\nmiddlewareをテストする場合を考える。\n\n~/middleware/user.ts\n\n````\nimport { Context, Middleware } from '@nuxt/types'\nimport { user } from '~/store'\n\nconst middleware: Middleware = (context: Context) =\u003e {\n  // ページ遷移のたびに実行したい処理を書く\n  if (user.expiration \u003e new Date()) {\n    user.update(false)\n    context.redirect('/error')\n  }\n}\n\nexport default middleware\n````\n\n~/test/middleware/user.spec.ts\n\n````\nimport { createLocalVue } from '@vue/test-utils'\nimport { MockProxy, mock } from 'jest-mock-extended'\nimport MockDate from 'mockdate'\nimport Vuex, { Store } from 'vuex'\nimport { Context } from '@nuxt/types'\nimport { initializeStores, user } from '~/store'\nimport middleware from '~/middleware/user'\n\ndescribe('middleware', () =\u003e {\n  const localVue = createLocalVue()\n  localVue.use(Vuex)\n\n  // jest-mock-extended を使って @nuxt/types/Context をmock\n  let mockContext: MockProxy\u003cContext\u003e\n\n  let store: Store\u003c{}\u003e\n  let getters\n\n  // @nuxt/types/Middleware が string | Function のunion typeなためエラーになるので、型を絞り込む\n  // This expression is not callable.\n  // Not all constituents of type 'Middleware' are callable.\n  // Type 'string' has no call signatures\n  const middlewareFunc = middleware as (ctx: Context) =\u003e Promise\u003cvoid\u003e | void\n\n  beforeEach(() =\u003e {\n\n    // gettersをmock\n    getters = {\n      'user/expiration': jest.fn(() =\u003e new Date(1614700000)),\n    }\n    // Vuexの初期化\n    store = new Vuex.Store({\n      state: {},\n      getters,\n    })\n    initializeStores(store)\n\n    mockContext = mock\u003cContext\u003e()\n  })\n\n  it('success', () =\u003e {\n\n    // mockdate を使用してnew Date()をmock\n    MockDate.set('2021-01-02T15:04:05+09:00')\n\n    user.update = jest.fn()\n\n    // context.redirect をmock\n    ;(mockContext.redirect as jest.Mock) = jest.fn(() =\u003e {})\n\n    middlewareFunc(mockContext)\n\n    expect(mockContext.redirect).toHaveBeenCalledTimes(0)\n  })\n\n})\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Vuejs","TypeScript","unittest"]},"/note/Vue.js":{"title":"Vue.js","content":"\n\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Vuejs"]},"/note/Vue.js%E3%81%A7GoogleMap%E4%B8%8A%E3%81%AB%E3%82%A2%E3%82%A4%E3%82%B3%E3%83%B3%E3%82%92%E8%A1%A8%E7%A4%BA%E3%81%99%E3%82%8B":{"title":"Vue.jsでGoogleMap上にアイコンを表示する","content":"\n[Vue TypeScriptでGoogleMapを使う](note/Vue%20TypeScriptでGoogleMapを使う.md) でGoogle Mapを使えるようにした。\nそこにアイコンを描画したい。\n\n## 前提\n\n* GoogleMapにアイコンを表示するには、画像ファイルを指定する\n* Vue.jsのプロジェクトで、svgはすべて画像ファイルとしてではなく、Vueコンポーネントとして管理している\n  * \u003chttps://jp.vuejs.org/v2/cookbook/editable-svg-icons.html\u003e に則ってsvgを操作しやすいようにするため\n* 画像ファイルがないので、どうやってGoogle Map上にアイコンを描画しようか考えた\n\n`BaseIcon.vue`\n\n````typescript\n\u003ctemplate\u003e\n  \u003csvg :width=\"width\" :height=\"height\" viewBox=\"0 0 16 16\" version=\"1.1\"\u003e\n    \u003cslot /\u003e\n  \u003c/svg\u003e\n\u003c/template\u003e\n\n\u003cscript lang=\"ts\"\u003e\nimport { Vue, Component, Prop } from 'vue-property-decorator'\n\nexport interface IconProp {\n  width?: string\n  height?: string\n}\n\n@Component\nexport default class BaseIcon extends Vue {\n  @Prop({ type: String, default: '16' })\n  private readonly width!: string\n\n  @Prop({ type: String, default: '16' })\n  private readonly height!: string\n}\n\u003c/script\u003e\n````\n\n## data URL に変換する\n\nコンポーネントをマウント\n-\u003e el要素からsvg文字列を抜き出す\n-\u003e svg文字列をbase64にして、data URLを作る\n\n````typescript\n/**\n * SVGコンポーネントを、svg画像のdata URLに変換する\n */\nexport const generateIconDataUrl = (\n  icon: VueConstructor\u003cVue\u003e,\n  props?: IconProp\n) =\u003e {\n  const IconComponentConstructor = Vue.extend({\n    components: {\n      BaseIcon,\n      icon,\n    },\n    props: {\n      props: {\n        type: Object,\n        default: () =\u003e {},\n      },\n    },\n    render: (h: Vue.CreateElement): Vue.VNode =\u003e {\n      return h(BaseIcon, {\n        props: {\n          ...props,\n        },\n        scopedSlots: {\n          default: (_props) =\u003e h(icon),\n        },\n      })\n    },\n  })\n  // mountする\n  const iconComponent = new IconComponentConstructor({\n    propsData: { props },\n  })\n  iconComponent.$mount()\n\n  // mountしたコンポーネントのHTML要素をsvgの文字列にシリアライズ\n  const iconString = new XMLSerializer().serializeToString(iconComponent.$el)\n\n  // svg文字列をBase64に変換して、data urlを作成\n  // see https://developer.mozilla.org/ja/docs/Web/API/WindowOrWorkerGlobalScope/btoa\n  return 'data:image/svg+xml;charset=UTF-8;base64,' + btoa(iconString)\n}\n````\n\nGoogleMapMarker.vue\n\n````typescript\n    this.marker = new this.google.maps.Marker({\n      position: this.markerOption.position,\n      map: this.map,\n      icon: {\n        url: generateGeneralIconDataUrl(\n          PinIcon,\n          { width: '32', height: '32' }\n        ),\n      },\n    })\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["TypeScript","Vuejs"]},"/note/WSL2-Ubuntu20.04%E3%81%AE%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89":{"title":"WSL2 Ubuntu20.04の環境構築","content":"\n## WSL2をデフォルトにする\n\npowershell\n\n````shell\n$ wsl --set-default-version 2\n$ wsl -l -v\n  NAME            STATE           VERSION\n* Legacy          Stopping        1\n  Ubuntu-20.04    Stopping        2\n````\n\nLegacy を削除\n\u003chttps://docs.microsoft.com/ja-jp/windows/wsl/install-legacy#uninstallingremoving-the-legacy-distro\u003e\n\n````shell\nwsl --unregister Legacy\n````\n\n## Linuxbrewを入れる\n\n\u003chttps://brew.sh/\u003e のワンライナーでインストールして、\n\u003chttps://docs.brew.sh/Homebrew-on-Linux\u003e のコマンドを入力してPATHを通す\n\n## python\n\n````shell\nsudo apt update\nsudo apt -y upgrade\n\nsudo apt install python-is-python3 python3-pip\npython -V\n# =\u003e 3.8\npython3 -V\n# =\u003e 3.8\n````\n\n## zsh\n\n````shell\nbrew install zsh\nwhich zsh | sudo tee -a /etc/shells\nchsh -s $(which zsh)\n````\n\nLinuxbrewを使えるようにしておく\n\n````shell\necho \"eval \\$($(brew --prefix)/bin/brew shellenv)\" \u003e\u003e ~/.zshrc\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","Linux"]},"/note/Windows%E3%81%8B%E3%82%89Python2%E3%81%AE%E3%82%A2%E3%83%B3%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%AB%E5%A4%B1%E6%95%97%E3%81%99%E3%82%8B":{"title":"WindowsからPython2のアンインストールに失敗する","content":"\nhttps://www.python.org/downloads/\n\n該当のバージョンのインストーラをダウンロード\nrepair\nremove\n\n`C:\\Python27` のようなディレクトリがないと失敗する\n先にゴミ箱に入れてしまった場合は復元する\n完全に削除してしまった場合は…わからない。いちどインストールするのかな\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows"]},"/note/Windows%E3%81%A7Emacs%E3%82%AD%E3%83%BC%E3%83%90%E3%82%A4%E3%83%B3%E3%83%89%E3%82%92%E3%81%A4%E3%81%8B%E3%81%88%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%99%E3%82%8B":{"title":"WindowsでEmacsキーバインドをつかえるようにする","content":"\n[Windows 10でも「Emacs風キーバインド」を使おう【AutoHotKey】 | LFI](https://linuxfan.info/windows-emacs-keybindings)\n\u003chttps://github.com/lintaro-jp/gtk-emacs-theme-like.ahk\u003e\nを使うとemacs風のカーソル移動、文字削除ができるようになる\n\nショートカットキーがよくぶつかるので、適用したくないアプリケーションは以下のやり方で対象でなくする\n\n[\\[AutoHotKey\\]\\#IfWinActiveで対象ウインドウを指定する](https://pouhon.net/ahk-win-active/2812/)\n\n````ahk\n#IfWinActive,ahk_exe chrome.exe ;Chrome.exeがアクティブな時にだけ\n    vk1D \u0026 E:: ;無変換キー+Eで\n    Send,^+b ;ブックマークバーの表示/非表示を切り替える\n    Return\n#IfWinActive\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","AutoHotKey","Keyboard"]},"/note/Windows%E3%81%A7US%E9%85%8D%E5%88%97%E3%82%92AutoHotKey%E3%81%A7%E5%BF%AB%E9%81%A9%E3%81%AB%E3%81%99%E3%82%8B%E3%82%AD%E3%83%BC%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%9E%E3%82%A4%E3%82%BA":{"title":"WindowsでUS配列をAutoHotKeyで快適にするキーカスタマイズ","content":"\n## Sands\n\nいくつか例があったが自分の環境で動いたのは最後のだけだった\n\n[AutoHotkeyでSandS - Qiita](https://qiita.com/azuwai2/items/e65af02c061ce80ccf91)\n[US配列で悠々自適AutoHotkeyScripts](https://blog.phoshigaki.net/2018/10/usautohotkeyscripts.html)\n\n[AutoHotKey で SandS - by edvakf in hatena](https://edvakf.hatenadiary.org/entry/20101027/1288168554)\n\n````ahk\n*Space::\n  SendInput {RShift Down}\n  If SandS_SpaceDown = 1\n  {\n    Return\n  }\n  SandS_SpaceDown := 1\n  SandS_SpaceDownTime := A_TickCount ; milliseconds after computer is booted http://www.autohotkey.com/docs/Variables.htm\n  SandS_AnyKeyPressed := 0\n  ; watch for the next single key, http://www.autohotkey.com/docs/commands/Input.htm\n  Input, SandS_AnyKey, L1 V,{LControl}{RControl}{LAlt}{RAlt}{LShift}{RShift}{LWin}{RWin}{AppsKey}{F1}{F2}{F3}{F4}{F5}{F6}{F7}{F8}{F9}{F10}{F11}{F12}{Left}{Right}{Up}{Down}{Home}{End}{PgUp}{PgDn}{Del}{Ins}{BS}{Capslock}{Numlock}{PrintScreen}{Pause}\n  SandS_AnyKeyPressed := 1\nReturn\n\n*Space Up::\n  SendInput {RShift Up}\n  SandS_SpaceDown := 0\n  If SandS_AnyKeyPressed = 0\n  {\n    If A_TickCount - SandS_SpaceDownTime \u003c 200\n    {\n      SendInput {Space}\n    }\n    ; Send EndKey of the \"Input\" command above\n    ; You must use Send here since SendInput is ignored by \"Input\"\n    Send {RShift}\n  }\nReturn\n````\n\n↑こちらのスクリプトも、Alt+Spaceが効かなくなる問題があったため、記事で紹介されていた \u003chttp://lukewarm.s101.xrea.com/up/\u003e の 089 を使用した。\n\n## Altキーを英数/かなに変更\n\n\u003chttps://github.com/karakaram/alt-ime-ahk\u003e\n\nalt-ime-ahkをクリックするとAHKが起動する。\n常駐したければスタートアップに登録する。\n\n## CtrlとCapsLockをいれかえる\n\n### Caps Lockがなくなってもいいなら\n\n[【Windows10】Caps LockをCtrlに変更 - Qiita](https://qiita.com/peachft/items/1ed0a843817b9caa6aff)\n\n`HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Keyboard Layout`\n\n新規ファイルでバイナリ値を作成、`Scancode Map`と名前をつけて保存。\n\n````txt\n00,00,00,00,00,00,00,00,02,00,00,00,1d,00,3a,00,00,00,00,00\n````\n\nregファイルでワンクリックでやるなら\ncaps2ctrl.reg\n\n````reg\nWindows Registry Editor Version 5.00\n\n[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Keyboard Layout]\n\"Scancode Map\"=hex:00,00,00,00,00,00,00,00,02,00,00,00,1d,00,3a,00,00,00,00,00\n````\n\n### 入れ替えるなら\n\n公式に用意されたコマンドを使う\n\n\u003chttps://docs.microsoft.com/en-us/sysinternals/downloads/ctrl2cap\u003e\n\nregファイルでやる場合\ncaps2ctrl_swap.reg\n\n````reg\nWindows Registry Editor Version 5.00\n\n[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Keyboard Layout]\n\"Scancode Map\"=hex:00,00,00,00,00,00,00,00,03,00,00,00,1d,00,3a,00,3a,00,1d,00,00,00,00,00\n````\n\n## CapsLockModifier\n\n[US配列で悠々自適AutoHotkeyScripts](https://blog.phoshigaki.net/2018/10/usautohotkeyscripts.html)\n\n````ahk\n#InstallKeybdHook\n;CapsLockの押し下げを検知\n\\*CapsLock::\n\tSuspend, Permit\n\tisCapsDown := true\n\tKeyWait CapsLock\n\tisCapsDown := false\nReturn\n\n#If isCapsDown == true\t\t;以下のスクリプトはCapsLock押し下げ時のみ\ne::Suspend, Off ;Enable hotkeys\nd::Suspend, On ;Disable hotkeys\n\nc::sc03A ;CapsLock\n\nq::ExitApp\nz::+^#b\n\n;方向キー\ni::Up\nj::Left\nk::Down\nl::Right\n\n;ファンクションキー\nt::F1\ng::F2\nb::F3\ny::F4\nh::F5\nn::F6\t\t\t\t\t\t\t\t\t\nm::F7\nsc033::F8\t\t;カンマ(,)\n.::F9\n/::F10\n\n;削除系\nu::BackSpace\no::Delete\np::Esc\n\n;default\n; | t | y | u | i | o | p |\n;  | g | h | j | k | l |\n;   | b | n | m | , | . | / |\n\n;CapsLock down\n; | F1| F4| BS| ^ |Del|Esc|\n;  | F2| F5| \u003c | v | \u003e |\n;   | F3| F6| F7| F8| F9|F10|\n#If\t\t;以下のスクリプトは文脈に依存しない\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","AutoHotKey","Keyboard"]},"/note/Windows%E3%81%AE%E3%82%AB%E3%83%BC%E3%82%BD%E3%83%AB%E6%93%8D%E4%BD%9C%E3%82%92emacs%E3%83%A9%E3%82%A4%E3%82%AF%E3%81%AB%E3%81%99%E3%82%8B":{"title":"Windowsのカーソル操作をemacsライクにする","content":"\n[WindowsでUS配列をAutoHotKeyで快適にするキーカスタマイズ](note/WindowsでUS配列をAutoHotKeyで快適にするキーカスタマイズ.md) と同様の方法で設定\n\n[Windows 10でも「Emacs風キーバインド」を使おう【AutoHotKey】 | LFI](https://linuxfan.info/windows-emacs-keybindings)\n\n\u003chttps://github.com/lintaro-jp/gtk-emacs-theme-like.ahk\u003e\nこちらのスクリプトを使うと、カーソル移動のみをemacs風にしてくれる\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","AutoHotKey"]},"/note/Windows%E3%81%AEfont%E5%A4%89%E6%9B%B4":{"title":"Windowsのfont変更","content":"\n`Meiryo UIも大っきらい!!` を使用する\n\n## リポジトリ\n\n\u003chttps://github.com/Tatsu-syo/noMeiryoUI\u003e\n\n## インストール\n\n\u003chttp://tatsu.life.coocan.jp/MySoft/WinCust/index.html\u003e\n\nzipを解答して noMeiryoUI.exe を実行\n→ フォントを設定\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows"]},"/note/Windows%E3%81%AEfont%E8%BF%BD%E5%8A%A0":{"title":"Windowsのfont追加","content":"\n[Windowsのgit設定](note/Windowsのgit設定.md) でScoop for jpを設定する\n\n````sh\nscoop install main/sudo\nsudo scoop install cica -g\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows"]},"/note/Windows%E3%81%AEgit%E8%A8%AD%E5%AE%9A":{"title":"Windowsのgit設定","content":"\n\n````sh\n# ファイルの大文字・小文字を区別して認識する\n$ git config --global core.ignorecase false\n# 日本語のファイル名が文字化けしないでちゃんと表示される\n$ git config --global core.quotepath false\n# 改行コードが混在している場合は変換しない\n$ git config --global core.safecrlf true\n# 改行コードが混在している場合は変換しない\n$ git config --global core.autocrlf false\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","git"]},"/note/Windows%E3%81%AEvim%E8%A8%AD%E5%AE%9A":{"title":"Windowsのvim設定","content":"\n## Scoop for jpからインストールする\n\n\u003chttps://github.com/dooteeen/scoop-for-jp\u003e\n\n````sh\n$ scoop bucket add jp https://github.com/dooteeen/scoop-for-jp\nChecking repo... ok\nThe jp bucket was added successfully.\n$ scoop install vim-kaoriya\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","vim"]},"/note/Windows-%E3%83%87%E3%83%A5%E3%82%A2%E3%83%AB%E3%83%96%E3%83%BC%E3%83%88%E3%81%97%E3%81%A6%E3%81%84%E3%82%8Bubuntu%E3%82%92%E5%89%8A%E9%99%A4":{"title":"Windows デュアルブートしているubuntuを削除","content":"\n[LinuxとWindowsのデュアルブートをやめた](note/LinuxとWindowsのデュアルブートをやめた.md)\n\n````sh\nC:\\\u003ebcdedit /enum firmware\n\nファームウェアのブート マネージャー\n--------------------------------\nidentifier              {fwbootmgr}\ndisplayorder            {1b24c802-09c6-11e6-9bf5-806e6f6e6963}\n                        {bootmgr}\n                        {7760eed9-aced-11eb-9c79-806e6f6e6963}\ntimeout                 2\n\nWindows ブート マネージャー\n--------------------------------\nidentifier              {bootmgr}\ndevice                  partition=\\Device\\HarddiskVolume1\npath                    \\EFI\\Microsoft\\Boot\\bootmgfw.efi\ndescription             Windows Boot Manager\nlocale                  ja-JP\ninherit                 {globalsettings}\ndefault                 {current}\nresumeobject            {7089dc6c-401f-11e9-994c-cb5d728b39c4}\ndisplayorder            {current}\ntoolsdisplayorder       {memdiag}\ntimeout                 30\n\nファームウェア アプリケーション (101fffff\n--------------------------------\nidentifier              {1b24c802-09c6-11e6-9bf5-806e6f6e6963}\ndevice                  partition=\\Device\\HarddiskVolume1\npath                    \\EFI\\ubuntu\\shimx64.efi\ndescription             ubuntu\n\nファームウェア アプリケーション (101fffff\n--------------------------------\nidentifier              {7760eed9-aced-11eb-9c79-806e6f6e6963}\ndevice                  partition=\\Device\\HarddiskVolume1\npath                    \\EFI\\Ubuntu\\grubx64.efi\ndescription             ubuntu\n````\n\n削除\n\n````\nC:\\\u003ebcdedit /delete {7760eed9-aced-11eb-9c79-806e6f6e6963}\nこの操作を正しく終了しました。\n\nC:\\\u003ebcdedit /enum firmware\n\nファームウェアのブート マネージャー\n--------------------------------\nidentifier              {fwbootmgr}\ndisplayorder            {1b24c802-09c6-11e6-9bf5-806e6f6e6963}\n                        {bootmgr}\ntimeout                 2\n\nWindows ブート マネージャー\n--------------------------------\nidentifier              {bootmgr}\ndevice                  partition=\\Device\\HarddiskVolume1\npath                    \\EFI\\Microsoft\\Boot\\bootmgfw.efi\ndescription             Windows Boot Manager\nlocale                  ja-JP\ninherit                 {globalsettings}\ndefault                 {current}\nresumeobject            {7089dc6c-401f-11e9-994c-cb5d728b39c4}\ndisplayorder            {current}\ntoolsdisplayorder       {memdiag}\ntimeout                 30\n\nファームウェア アプリケーション (101fffff\n--------------------------------\nidentifier              {1b24c802-09c6-11e6-9bf5-806e6f6e6963}\ndevice                  partition=\\Device\\HarddiskVolume1\npath                    \\EFI\\ubuntu\\shimx64.efi\ndescription             ubuntu\n\nC:\\\u003ebcdedit /delete {1b24c802-09c6-11e6-9bf5-806e6f6e6963}\nこの操作を正しく終了しました。\n\nC:\\\u003ebcdedit /enum firmware\n\nファームウェアのブート マネージャー\n--------------------------------\nidentifier              {fwbootmgr}\ndisplayorder            {bootmgr}\ntimeout                 2\n\nWindows ブート マネージャー\n--------------------------------\nidentifier              {bootmgr}\ndevice                  partition=\\Device\\HarddiskVolume1\npath                    \\EFI\\Microsoft\\Boot\\bootmgfw.efi\ndescription             Windows Boot Manager\nlocale                  ja-JP\ninherit                 {globalsettings}\ndefault                 {current}\nresumeobject            {7089dc6c-401f-11e9-994c-cb5d728b39c4}\ndisplayorder            {current}\ntoolsdisplayorder       {memdiag}\ntimeout                 30\n\n````\n\n````sh\nC:\\\u003ediskpart\n\nMicrosoft DiskPart バージョン 10.0.17763.1\n\nCopyright (C) Microsoft Corporation.\nコンピューター: DESKTOP-3HKIQ1T\n\nDISKPART\u003e list disk\n\n  ディスク      状態           サイズ   空き   ダイナ GPT\n  ###                                          ミック\n  ------------  -------------  -------  -------  ---  ---\n  ディスク 0    オンライン           119 GB      0 B        *\n  ディスク 1    オンライン           465 GB  1024 KB        *\n\nDISKPART\u003e sel disk 0\n\nディスク 0 が選択されました。\n\nDISKPART\u003e list vol\n\n  Volume ###  Ltr Label        Fs    Type        Size     Status     Info\n  ----------  --- -----------  ----  ----------  -------  ---------  --------\n  Volume 0     E                       DVD-ROM         0 B  メディアなし\n  Volume 1     C   Windows      NTFS   Partition    118 GB  正常         ブート\n  Volume 2         SYSTEM       FAT32  Partition    100 MB  正常         システム\n  Volume 3     D                NTFS   Partition    215 GB  正常\n\nDISKPART\u003e sel vol\n\nボリュームが選択されていません。\n\nDISKPART\u003e sel vol 2\n\nボリューム 2 が選択されました。\n\nDISKPART\u003e assign letter=Z\n\nDiskPart はドライブ文字またはマウント ポイントを正常に割り当てました。\n\nDISKPART\u003e exit\n\nDiskPart を終了しています...\n````\n\n````\nC:\\\u003ecd /d Z:\\\n\nZ:\\\u003edir\n ドライブ Z のボリューム ラベルは SYSTEM です\n ボリューム シリアル番号は 7221-A80F です\n\n Z:\\ のディレクトリ\n\n2017/04/08  23:28    \u003cDIR\u003e          EFI\n               0 個のファイル                   0 バイト\n               1 個のディレクトリ      68,054,016 バイトの空き領域\n\nZ:\\\u003ecd EFI\n\nZ:\\EFI\u003edir\n ドライブ Z のボリューム ラベルは SYSTEM です\n ボリューム シリアル番号は 7221-A80F です\n\n Z:\\EFI のディレクトリ\n\n2015/11/24  15:41    \u003cDIR\u003e          .\n2015/11/24  15:41    \u003cDIR\u003e          ..\n2015/11/24  15:41    \u003cDIR\u003e          Microsoft\n2021/05/04  23:45    \u003cDIR\u003e          Boot\n2021/05/04  23:45    \u003cDIR\u003e          ubuntu\n               0 個のファイル                   0 バイト\n               5 個のディレクトリ      68,054,016 バイトの空き領域\n\nZ:\\EFI\u003ermdir /s ubuntu\nubuntu、よろしいですか (Y/N)? y\n\nZ:\\EFI\u003edir\n ドライブ Z のボリューム ラベルは SYSTEM です\n ボリューム シリアル番号は 7221-A80F です\n\n Z:\\EFI のディレクトリ\n\n2015/11/24  15:41    \u003cDIR\u003e          .\n2015/11/24  15:41    \u003cDIR\u003e          ..\n2015/11/24  15:41    \u003cDIR\u003e          Microsoft\n2021/05/04  23:45    \u003cDIR\u003e          Boot\n               0 個のファイル                   0 バイト\n               4 個のディレクトリ      71,808,000 バイトの空き領域\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Linux","Windows"]},"/note/Windows10%E3%81%A8Ubuntu16.04%E3%81%AE%E3%83%87%E3%83%A5%E3%82%A2%E3%83%AB%E3%83%96%E3%83%BC%E3%83%88%E8%A7%A3%E9%99%A4":{"title":"Windows10とUbuntu16.04のデュアルブート解除","content":"\n[デュアルブートから Ubuntu を削除する方法 | Windows10 と Ubuntu のデュアルブートからUbuntu を削除し UEFI ブートを修正する方法](https://bi.biopapyrus.jp/os/win/dualboot-fix-bootmenu.html)\nを大いに参考にした。\n\n## 確認\n\nWindowsの「システム情報」でBIOSモードがUEFIであることを確認する。\nレガシーBIOSの場合は手順が異なる。\n\nデュアルブート時の起動順は、BIOS -\u003e Grub -\u003e Ubuntu or Windowsを選択だった\n\n## bcdeditコマンドでエントリ確認\u0026削除\n\n[bcdeditとは](note/bcdeditとは.md)\n\nコマンドプロンプトを管理者権限で実行\n\n````\n$ bcdedit /enum firmware\n$ bcdedit /delete {id}\n````\n\n## パーティションの操作\n\n````sh\n$ diskpart\n$ list disk \nUEFIのあるディスクを選択する(disk0)\n$ sel disk 0\n$ list vol\nLABEL:SYSTEM、Fs:FAT32のvolumeを選択\n$ sel vol 2\nUEFI システムパーテイションを編集できるようにドライブレターを割り当ててマウントする\n````\n\n## EFIからubuntuディレクトリを削除\n\n````sh\n$ cd /d Z:\\\n$ dir\n$ rmdir /s ubuntu\n````\n\n再起動するとGrubが起動せず、Windowsのみブートした\n\n## パーティションの削除、再割り当て\n\nUbuntuに割り当てていたパーティションを削除する\n\nHDDのメイン領域に割り当てていた250GBとスワップ領域4GBを削除\n\nパーティション上で右クリック→ボリュームの削除で削除できる\n\n削除できたら、Windowsのパーティションでボリュームの拡張をクリック\n\n## 高速スタートアップをもとに戻す\n\nデュアルブートのため無効化していた項目。\nもし無効になったままだったら、電源の管理から有効にする\n\n## もし先にパーティションを削除してしまったら\n\n[デュアルブートした環境で先にUbuntuのパーティションを削除してしまったときの話 | (妄想)天使るしふぇちゃんの日記](https://ameblo.jp/lucifep2525/entry-12413328349.html)\n\nUbuntuを削除するときは先にブート構成データ(BCD)を変更して Ubuntuのブートエントリを削除してからパーティションを削除する。\n先にUbuntuのパーティションを削除してしまうと、最悪windowsが起動しなくなり、頑張って修復作業を行う必要が出てくるらしい。\n\n## 参考\n\n* [Windows 10でUbuntu GRUBブートローダーの削除方法 UEFI／レガシーBIOS | 俺の開発研究所](https://itlogs.net/ubuntu-grub-delete-uefi-bios/)\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["Windows","Ubuntu"]},"/note/XDG_BASE_DIRECTORY%E3%81%A7%E3%83%9B%E3%83%BC%E3%83%A0%E3%83%87%E3%82%A3%E3%83%AC%E3%82%AF%E3%83%88%E3%83%AA%E3%82%92%E6%95%B4%E7%90%86%E3%81%99%E3%82%8B":{"title":"XDG_BASE_DIRECTORYでホームディレクトリを整理する","content":"\n参考\n[ホームディレクトリのドットファイルを整理する。](https://chiyosuke.blogspot.com/2019/04/blog-post_27.html)\n\n## XDG_CONFIG_HOMEとは\n\nhttps://wiki.archlinux.org/title/XDG_Base_Directory に則って、 `~/.config` に設定ファイルを置くとHOMEフォルダがごちゃごちゃしなくていいようなのでやってみる。\n\nhttps://www.freedesktop.org/wiki/Specifications/ によると、 'XDG'は Cross-Desktop Group のことらしい\n\n## zshの設定ファイルを~/.configにする\n\n環境変数 `$ZDOTDIR` が設定されていると、そのディレクトリ以下の設定ファイルを見るようになる。\nzshはデフォルトで `~/.zshenv` を見るので、ここに書いても良いのだが、 `~/.zshenv` と `~/.config/zsh/.zshenv` が存在することになりちょっと気持ち悪い。\nここではシステムの `/etc/zshenv` に書くことにした。\n\n`sudo vim /etc/zshenv`\n\n````shell\nexport ZDOTDIR=$HOME/.config/zsh\n````\n\nこれで `~/.config/zsh/.zshenv(, .zshrcなど)` が読み込まれるようになる。\n\n## 環境変数を設定\n\n````shell:~/.zsh/.zshenv\nexport XDG_CONFIG_HOME=~/.config\nexport XDG_CACHE_HOME=~/.cache\nexport XDG_DATA_HOME=~/.local/share\nexport XDG_STATE_HOME=~/.local/state\n````\n\n## [Vim](note/Vim.md)\n\n[Neovim](note/Neovim.md) を使っている。もともと `$XDG_CONFIG_HOME/nvim/init.vim` を見るようになっていて、特別な設定はいらないのだが、vimの設定と統一しておきたかったので以下のようにした。\nvimはほぼ起動しないので、init.vimに書いてしまっても良かったのだがなんとなくこうしている。\n\n````vim:~/.config/nvim/init.vim\nset runtimepath+=$XDG_CONFIG_HOME/nvim,$XDG_CONFIG_HOME/nvim/after\nset packpath+=$XDG_CONFIG_HOME/nvim\nsource $XDG_CONFIG_HOME/nvim/vimrc\n````\n\n````vim:~/.config/nvim/vimrc\nlet $VIM_CACHE = expand('$XDG_CACHE_HOME/vim')\nlet $VIM_HOME = expand('$XDG_CONFIG_HOME/nvim')\n\n\" ディレクトリが無かったら作る\nif !isdirectory(expand($VIM_CACHE))\n  call mkdir(expand($VIM_CACHE), 'p')\nendif\n\n\" backup, undo\nset backup\nset backupdir=$VIM_CACHE/backup\nif !isdirectory(expand('$VIM_CACHE/backup'))\n  call mkdir(expand('$VIM_CACHE/backup'), 'p')\nendif\nset noswapfile\nset undodir=$VIM_CACHE/undo\nset undofile\nif !isdirectory(expand('$VIM_CACHE/undo'))\n  call mkdir(expand('$VIM_CACHE/undo'), 'p')\nendif\n\n\" viminfoファイルを~/.cacheに作る\nset viminfo+=n$VIM_CACHE/viminfo\n\n\" sessionファイルを~/.cacheに作る\nlet g:session_path = expand('$VIM_CACHE/sessions')\nif !isdirectory(g:session_path)\n    call mkdir(g:session_path, \"p\")\nendif\n\n\" ... その他設定\n\n````\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["shell","zsh"]},"/note/XML%E3%82%92%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%83%A9%E3%82%A4%E3%83%B3%E3%81%A7%E6%93%8D%E4%BD%9C%E3%81%99%E3%82%8B":{"title":"XMLをコマンドラインで操作する","content":"\n[xmlstarlet](http://xmlstar.sourceforge.net/docs.php) を使ってコマンドライン上で [XPath](note/XPath.md) を使ったselectやupdateが可能になる\n\n## インストール\n\nMacの場合 [Homebrew](note/Homebrew.md) で\n\n````shell\nbrew install xmlstarlet\n````\n\n## 使い方\n\n以下のようなxmlを考える\n\n````xml\n\u003ccontracts\u003e\n    \u003cclients\u003e\n        \u003cclient ref=\"123\"\u003e\n            \u003cname\u003eNicol\u003c/name\u003e\n        \u003c/client\u003e\n        \u003cclient ref=\"8234\"\u003e\n            \u003cname\u003eBasil\u003c/name\u003e\n        \u003c/client\u003e\n    \u003c/clients\u003e\n    \u003centries\u003e\n        \u003centry ref=\"63352\"\u003e\n            \u003cregCode\u003eBCG\u003c/regCode\u003e\n        \u003c/entry\u003e\n        \u003centry ref=\"3242\"\u003e\n            \u003cregCode\u003eTYD\u003c/regCode\u003e\n        \u003c/entry\u003e\n    \u003c/entries\u003e\n\u003c/contracts\u003e  \n````\n\n### 参照\n\n````shell\n$ xmlstarlet sel -t -c '//client[@ref=\"123\"]' -t -c '/contracts/entries/entry' temp.xml\n\u003cclient ref=\"123\"\u003e\n            \u003cname\u003eNicol\u003c/name\u003e\n        \u003c/client\u003e\u003centry ref=\"63352\"\u003e\n            \u003cregCode\u003eBCG\u003c/regCode\u003e\n        \u003c/entry\u003e\u003centry ref=\"3242\"\u003e\n            \u003cregCode\u003eTYD\u003c/regCode\u003e\n        \u003c/entry\u003e\n````\n\n### 更新\n\n#### 値の更新\n\n`inplace` でファイルを書き換える\n\n````shell\n$ xmlstarlet ed --inplace -u '/contracts/clients/client[@ref=\"123\"]/name' -v Jack temp.xml\n````\n\n結果\n\n````xml:temp.xml\n\u003ccontracts\u003e\n  \u003cclients\u003e\n    \u003cclient ref=\"123\"\u003e\n      \u003cname\u003eJack\u003c/name\u003e\n    \u003c/client\u003e\n    \u003cclient ref=\"8234\"\u003e\n      \u003cname\u003eBasil\u003c/name\u003e\n    \u003c/client\u003e\n  \u003c/clients\u003e\n  \u003centries\u003e\n    \u003centry ref=\"63352\"\u003e\n      \u003cregCode\u003eBCG\u003c/regCode\u003e\n    \u003c/entry\u003e\n    \u003centry ref=\"3242\"\u003e\n      \u003cregCode\u003eTYD\u003c/regCode\u003e\n    \u003c/entry\u003e\n  \u003c/entries\u003e\n\u003c/contracts\u003e\n````\n\n#### attributeの更新\n\n````shell\n$ xmlstarlet ed -u '//entry[@ref=\"3242\"]/@ref' -v 99 temp.xml\n\u003c?xml version=\"1.0\"?\u003e\n\u003ccontracts\u003e\n  \u003cclients\u003e\n    \u003cclient ref=\"123\"\u003e\n      \u003cname\u003eJack\u003c/name\u003e\n    \u003c/client\u003e\n    \u003cclient ref=\"8234\"\u003e\n      \u003cname\u003eBasil\u003c/name\u003e\n    \u003c/client\u003e\n  \u003c/clients\u003e\n  \u003centries\u003e\n    \u003centry ref=\"63352\"\u003e\n      \u003cregCode\u003eBCG\u003c/regCode\u003e\n    \u003c/entry\u003e\n    \u003centry ref=\"99\"\u003e\n      \u003cregCode\u003eTYD\u003c/regCode\u003e\n    \u003c/entry\u003e\n  \u003c/entries\u003e\n\u003c/contracts\u003e\n````\n\n### 削除\n\n````shell\n$ xmlstarlet ed -d '//entry[@ref=\"3242\"]' temp.xml\n\u003c?xml version=\"1.0\"?\u003e\n\u003ccontracts\u003e\n  \u003cclients\u003e\n    \u003cclient ref=\"123\"\u003e\n      \u003cname\u003eJack\u003c/name\u003e\n    \u003c/client\u003e\n    \u003cclient ref=\"8234\"\u003e\n      \u003cname\u003eBasil\u003c/name\u003e\n    \u003c/client\u003e\n  \u003c/clients\u003e\n  \u003centries\u003e\n    \u003centry ref=\"63352\"\u003e\n      \u003cregCode\u003eBCG\u003c/regCode\u003e\n    \u003c/entry\u003e\n  \u003c/entries\u003e\n\u003c/contracts\u003e\n````\n\n* [Edit xml file using shell script / command](https://superuser.com/questions/916665/edit-xml-file-using-shell-script-command)\n* [how to update the xml file using xmlstarlet](https://stackoverflow.com/questions/29265833/how-to-update-the-xml-file-using-xmlstarlet)\n* [How to search for a XML node and add or delete it using xmlstarlet](https://stackoverflow.com/questions/50597814/how-to-search-for-a-xml-node-and-add-or-delete-it-using-xmlstarlet)\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["shell","xml"]},"/note/XPath":{"title":"XPath","content":"\nXMLドキュメント内の特定の要素や属性にアクセスするためのパスを表す言語。\nXPathは、XMLドキュメントのツリー構造を使用して、XML要素と属性を識別するための簡潔で柔軟な方法を提供する。\n\nXPathの文法には、次のような構成要素が含まれる。\n\n* ノードテスト: ノードタイプに基づいてドキュメントツリー内のノードを選択するための式\n* 軸: 現在のノードに相対的なノードを選択するための指示子\n* 述語: ノード集合の一部を選択するための条件式\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["xml"]},"/note/YAML":{"title":"YAML","content":"\n\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["2023/05/04","yaml"]},"/note/Zettelkasten%E3%81%A8%E3%81%AF":{"title":"Zettelkastenとは","content":"\n\u003chttps://jmatsuzaki.com/archives/26856\u003e\n\n \u003e \n \u003e Zettelkastenの特徴を簡単に解説すると以下のような特徴をもったシステムといえます。\n \u003e \n \u003e * カードにはユニークなIDが付与され、IDを使って他のノートから一意に参照できる\n \u003e * ノートを分類・構造化することではなく、IDを使ったカード間のリンクによって知識のウェブを作る\n \u003e * 既存の分野で追加の調査を行った場合はいつでも追加のカードによって追記できる（追記もIDによって判別）\n \u003e * 1枚のカードには1つの概念・アイデアだけが含まれるようにする\n \u003e * 将来いつ読み返しても理解できるようにノートを書く\n \u003e \n \u003e このようなシステムによって、**ただ忘れないようにメモしておくだけのノートとしてではなく、考えるためのノート、第二の脳としてのノートを構築**するようになります。記憶のサポートとしてだけでなく、新しいアイデアの発想や新しい洞察をもたらしてくれるためのノートです。\n\nノートを丁寧に分類する必要なく、リンクをつなげていく考え方\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["obsidian"]},"/note/Zsh%E3%81%AE%E3%82%AD%E3%83%BC%E3%83%90%E3%82%A4%E3%83%B3%E3%83%89":{"title":"Zshのキーバインド","content":"\n\u003chttps://dev.classmethod.jp/articles/keybind-ctrl-a-z/\u003e\n\n`bindkey` で一覧がみれる\n","lastmodified":"2023-07-29T08:18:43.043498345Z","tags":["zsh"]},"/note/adb%E3%81%A7Android%E3%81%AE%E9%9D%99%E6%AD%A2%E7%94%BB%E5%8B%95%E7%94%BB%E3%82%92%E5%8F%96%E3%82%8B%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89":{"title":"adbでAndroidの静止画・動画を取るコマンド","content":"\n\u003chttps://littlewing.hatenablog.com/entry/2016/12/20/133901\u003e\n\u003chttps://qiita.com/AAkira/items/c8537c24d9c13bd39ae1\u003e\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Android","shell"]},"/note/adb%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%A7Android%E3%81%AE%E9%8C%B2%E7%94%BB%E3%81%A8PC%E3%81%B8%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC":{"title":"adbコマンドでAndroidの録画とPCへのコピー","content":"\n\n````shell\n#!/bin/sh\n\nDATE=`date '+%y%m%d%H%M%S'`\nFILE_NAME=record-${DATE}\nYOUR_PATH=~/Desktop\n\nadb shell screenrecord /sdcard/${FILE_NAME}.mp4 \u0026\npid=`ps x | grep -v grep | grep \"adb shell screenrecord\" | awk '{ print $1 }'`\n\nif [ -z \"$pid\" ]; then\n  printf \"Not running a screenrecord.\"\n  exit 1\nfi\n\nprintf \"Recording, finish? [y]\"\nwhile read isFinished; do\n  case \"$isFinished\" in\n    \"y\" | \"Y\") break ;;\n    *) printf \"Incorrect value.\" ;;\n  esac\ndone\n\nkill -9 $pid # Finished the process of adb screenrecord\nwhile :\ndo\n  alive=`adb shell ps | grep screenrecord | grep -v grep | awk '{ print $9 }'`\n  if [ -z \"$alive\" ]; then\n      break\n  fi\ndone\n\nprintf \"Finished the recording process : $pid\\nSending to $YOUR_PATH...\\n\"\nadb pull /sdcard/${FILE_NAME}.mp4 $YOUR_PATH\nadb shell rm /sdcard/${FILE_NAME}.mp4\n\necho \"Converts to GIF? [y]\"\nread convertGif\ncase $convertGif in\n    \"y\" | \"Y\") ffmpeg -i ${YOUR_PATH}/${FILE_NAME}.mp4 -vf scale=240:-1 -an -r 15 -pix_fmt rgb24 -f gif ${YOUR_PATH}/${FILE_NAME}.gif ;; # creating gif\n    *) ;;\nesac\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Android"]},"/note/adb%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%83%A6%E3%83%BC%E3%83%86%E3%82%A3%E3%83%AA%E3%83%86%E3%82%A3%E9%9B%86":{"title":"adbコマンドユーティリティ集","content":"\n\n````shell\n# キャプチャを撮ってPCにコピーし、サイズを変更\nadb_screencap() {\n  local DATE_TIME=$(date +\"%Y%m%d-%H%M%S\")\n  local FILE_NAME=${DATE_TIME}.png\n\n  local DEST_DIR=${1:-~/Desktop}\n  local SIZE=${2:-300x}\n\n  adb shell screencap -p /sdcard/$FILE_NAME\n  adb_pull_file $file_name $dest_dir\n\n  mogrify -resize $SIZE -unsharp 2x1.4+0.5+0 -quality 100 -verbose $DEST_DIR/$FILE_NAME\n}\n\n# PCにファイルをコピーして元ファイルは削除\nadb_pull_file() {\n  file_name=$1\n  directory=$2\n  if [[ -z $file_name -o -z $directory ]]; then\n    echo 'no file'\n    return 1\n  fi\n\n  adb pull /sdcard/$file_name $directory/$file_name\n  adb shell rm /sdcard/$file_name\n}\n\n# adbとはちょっと異なるが、mp4をgifに変換する\nmp4_to_gif() {\n  local FILE_NAME=$1\n  local DEST_FILE_NAME=$(echo $FILE_NAME | tr -d '.mp4')\n  ffmpeg -i $FILE_NAME -an -r 15 -pix_fmt rgb24 -s 540x960 -f gif $DEST_FILE_NAME\n}\n\n# https://github.com/fish-shell/fish-shell/issues/2036\nadb_screenrecord() {\n  local DATE_TIME=$(date +\"%Y-%m-%dT%H-%M-%S\")\n  local FILE_NAME=$DATE_TIME.mp4\n  local DEST_DIR=${1:-~/Desktop}\n\n  trap \"echo 'pull to $DEST_DIR/$FILE_NAME'; adb pull /sdcard/$FILE_NAME $DEST_DIR/$FILE_NAME; adb shell rm /sdcard/$FILE_NAME\" SIGINT\n\n  echo \"録画を開始しました。録画を終了する場合は、 Ctrl+C を押下してください\"\n  adb shell screenrecord /sdcard/$FILE_NAME --size 540x960\n}\n````\n\n[adbコマンドユーティリティ集](note/adbコマンドユーティリティ集.md)\n[adbでAndroidの静止画・動画を取るコマンド](note/adbでAndroidの静止画・動画を取るコマンド.md)\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/alpine%E3%81%A7Android%E3%82%A2%E3%83%97%E3%83%AA%E3%82%92%E3%83%93%E3%83%AB%E3%83%89%E3%81%99%E3%82%8B%E3%82%A4%E3%83%A1%E3%83%BC%E3%82%B8%E3%82%92%E4%BD%9C%E6%88%90":{"title":"alpineでAndroidアプリをビルドするイメージを作成","content":"\n\\#Docker\n\n## やったこと\n\n以下を参考にDockerfileを作成\n\n[Androidのビルド用Dockerイメージダイエット計画 - dely tech blog](https://tech.dely.jp/entry/2020/12/07/170000)\n[Androidアプリのビルド環境Dockerイメージ制作 - Qiita](https://qiita.com/kaihei777/items/1a94a8a329c8fb67d421)\n[DockerでAndroidアプリのビルド環境を作る - Qiita](https://qiita.com/kichinaga/items/66872432747e76d72af7)\n\n* Android SDKをインストールしたコンテナを公開してしまうとライセンス違反になるので公開はしない\n* ベースイメージはalpineをつかいサイズを小さくする\n\n### glibcをインストール\n\n[sgerrand/alpine-pkg-glibc: A glibc compatibility layer package for Alpine Linux](https://github.com/sgerrand/alpine-pkg-glibc)\n\n````shell\nwget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub\nwget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.35-r0/glibc-2.35-r0.apk\napk add glibc-2.35-r0.apk\n````\n\nlocaleの指定が必要ならglibc-i18nを入れる\n\n````shell\nwget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.35-r0/glibc-bin-2.35-r0.apk\nwget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.35-r0/glibc-i18n-2.35-r0.apk\napk add glibc-bin-2.35-r0.apk glibc-i18n-2.35-r0.apk\n/usr/glibc-compat/bin/localedef -i en_US -f UTF-8 en_US.UTF-8\n````\n\nDockerfileは、alpineにglibcをインストールしたイメージ https://hub.docker.com/r/frolvlad/alpine-glibc/ を参考にする\n\n[docker-alpine-glibc/Dockerfile at master · Docker-Hub-frolvlad/docker-alpine-glibc](https://github.com/Docker-Hub-frolvlad/docker-alpine-glibc/blob/master/Dockerfile)\n\n````Dockerfile\nENV LANG=C.UTF-8\n\n# install alpine-pkg-glibc apk and set C.UTF-8 locale as default\nRUN BASE_URL=\"https://github.com/sgerrand/alpine-pkg-glibc/releases/download\" \u0026\u0026 \\\n    VERSION=\"2.35-r0\" \u0026\u0026 \\\n    BASE_FILE=\"glibc-$VERSION.apk\" \u0026\u0026 BIN_FILE=\"glibc-bin-$VERSION.apk\" \u0026\u0026 I18N_FILE=\"glibc-i18n-$VERSION.apk\" \u0026\u0026 \\\n    wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub \u0026\u0026 \\\n    wget \"$BASE_URL/$VERSION/$BASE_FILE\" \u0026\u0026 wget \"$BASE_URL/$VERSION/$BIN_FILE\" \u0026\u0026 wget \"$BASE_URL/$VERSION/$I18N_FILE\" \u0026\u0026 \\\n    apk add --no-cache \"$BASE_FILE\" \"$BIN_FILE\" \"$I18N_FILE\" \u0026\u0026 \\\n    rm \"/etc/apk/keys/sgerrand.rsa.pub\" \u0026\u0026 \\\n    /usr/glibc-compat/bin/localedef --force --inputfile POSIX --charmap UTF-8 \"$LANG\" || true \u0026\u0026 \\\n    echo \"export LANG=$LANG\" \u003e /etc/profile.d/locale.sh \u0026\u0026 \\\n    apk del glibc-i18n \u0026\u0026 \\\n    rm \"/root/.wget-hsts\" \u0026\u0026 \\\n    apk del .build-dependencies \u0026\u0026 \\\n    rm \"$BASE_FILE\" \"$BIN_FILE\" \"$I18N_FILE\"\n````\n\n2.35でバグがあり、/lib64にglibcではなくmuslのまま配置されるので2.34に下げた\n[2.35-r0: glibc compatibility regression due to removal of /lib64 · Issue #181 · sgerrand/alpine-pkg-glibc · GitHub](https://github.com/sgerrand/alpine-pkg-glibc/issues/181)\n\n## 完成系\n\n````Dockerfile\nFROM alpine:3.16\n\nARG ANDROID_SDK_TOOLS=\"8512546\"\n\nENV LANG=C.UTF-8\nENV ANDROID_SDK_ROOT=/opt/android-sdk\nENV JAVA_HOME=/usr/local/java-8\nENV PATH=$PATH:${ANDROID_SDK_ROOT}/cmdline-tools/bin:${JAVA_HOME}/bin\n\n# 参考 https://github.com/Docker-Hub-frolvlad/docker-alpine-glibc\nRUN BASE_URL=\"https://github.com/sgerrand/alpine-pkg-glibc/releases/download\" \u0026\u0026 \\\n    VERSION=\"2.34-r0\" \u0026\u0026 \\\n    BASE_FILE=\"glibc-$VERSION.apk\" \u0026\u0026 BIN_FILE=\"glibc-bin-$VERSION.apk\" \u0026\u0026 I18N_FILE=\"glibc-i18n-$VERSION.apk\" \u0026\u0026 \\\n    wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub \u0026\u0026 \\\n    wget \"$BASE_URL/$VERSION/$BASE_FILE\" \"$BASE_URL/$VERSION/$BIN_FILE\" \"$BASE_URL/$VERSION/$I18N_FILE\" \u0026\u0026 \\\n    apk add --no-cache \"$BASE_FILE\" \"$BIN_FILE\" \"$I18N_FILE\" \u0026\u0026 \\\n    rm \"/etc/apk/keys/sgerrand.rsa.pub\" \u0026\u0026 \\\n    /usr/glibc-compat/bin/localedef --force --inputfile POSIX --charmap UTF-8 \"$LANG\" || true \u0026\u0026 \\\n    echo \"export LANG=$LANG\" \u003e /etc/profile.d/locale.sh \u0026\u0026 \\\n    apk del glibc-i18n \u0026\u0026 \\\n    rm \"$BASE_FILE\" \"$BIN_FILE\" \"$I18N_FILE\"\n\n# Java(Amazon Corretto 17)\nRUN mkdir -p $JAVA_HOME \u0026\u0026 cd $JAVA_HOME \u0026\u0026 \\\n    wget https://corretto.aws/downloads/latest/amazon-corretto-17-x64-alpine-jdk.tar.gz \u0026\u0026 \\\n    tar -xzf amazon-corretto-17-x64-alpine-jdk.tar.gz --strip-components 1 \u0026\u0026 \\\n    rm amazon-corretto-17-x64-alpine-jdk.tar.gz\n\n# Android SDK\nENV ANDROID_API_LEVELS=android-29,android-30\nENV ANDROID_BUILD_TOOLS_VERSIONS=29.0.3,30.0.1\nRUN FILE=commandlinetools-linux-${ANDROID_SDK_TOOLS}_latest.zip \u0026\u0026 \\\n    mkdir -p ${ANDROID_SDK_ROOT} \u0026\u0026 cd ${ANDROID_SDK_ROOT} \u0026\u0026 \\\n    wget https://dl.google.com/android/repository/${FILE} \u0026\u0026 \\\n    unzip ${FILE} \u0026\u0026 rm ${FILE} \u0026\u0026 \\\n    yes | sdkmanager --licenses \u003e /dev/null \u0026\u0026 \\\n    yes | sdkmanager $(echo ${ANDROID_BUILD_TOOLS_VERSIONS} | sed 's/,/\\n/g' | sed -E 's/(.+)/build-tools;\\1/g' | tr '\\n' ' ') \"platform-tools\" $(echo ${ANDROID_API_LEVELS} | sed 's/,/\\n/g' | sed -E 's/(.+)/platforms;\\1/g' | tr '\\n' ' ')\n    \nRUN mkdir /workspace\nWORKDIR /workspace\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Docker"]},"/note/apigw_lambda%E7%9F%A5%E8%A6%8B":{"title":"apigw_lambda知見","content":"\n* lambda\n  * endpointをpathごとに作る\n    * main関数のみエンドポイントごとに準備\n    * handler関数は共通\n    * handlerの中でpathごとに振り分け\n  * endpointは一つのlambda\n    * 中でGinなどを使ってrouting\n    * Ginを使わなくても単にrequest.pathで分岐処理書けばいいだけ？便利な機能が使える利点があるかもしれない\n    * Ginを使わないのであれば、mainが一個になるか複数になるかの違いだけになる\n    * endpoint一個だと、同時実行数の制限が懸念\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["AWS","Lambda"]},"/note/aws-cli%E3%81%A7IAM%E6%83%85%E5%A0%B1%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B":{"title":"aws cliでIAM情報を取得する","content":"\n\\#AWS\n\n[【AWS CLI】IAM関連の情報取得編 - サーバーワークスエンジニアブログ](https://blog.serverworks.co.jp/aws-cli-iam)\n\n````shell\nfunction describe_role() {\n  local role=$1\n\n  echo \"---- Role[$role] ----\"\n\n  if ! aws iam get-role --role-name ${role} \u003e/dev/null; then\n    error \"IAM Roleが存在しません: ${role}\"\n    exit 1\n  fi\n\n  # インラインポリシー以外\n  policies=$(aws iam list-attached-role-policies --role-name $role --query \"AttachedPolicies[].[PolicyArn]\" --output text)\n  echo \"[$role] Policies:\"\n  echo \"$policies\"\n  for policy in $policies; do\n    echo \"[$role] PolicyName: $policy\"\n    policy_version=$(aws iam get-policy --policy-arn $policy --query \"Policy.DefaultVersionId\" --output text)\n    aws iam get-policy-version --policy-arn $policy --version-id $policy_version --query \"PolicyVersion.Document.Statement\"\n  done\n\n  # インラインポリシー\n  inline_policies=$(aws iam list-role-policies --role-name $role --query \"PolicyNames\" --output text)\n  echo \"[$role] InlinePolicies:\"\n  echo \"$inline_policies\"\n  for policy in $inline_policies; do\n    echo \"[$role] InlinePolicyName: $policy\"\n    aws iam get-role-policy --role-name $role --policy-name $policy --query \"PolicyDocument\"\n  done\n}\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["AWS"]},"/note/aws-cli-filter%E3%81%A8query%E3%81%AE%E3%83%A1%E3%83%A2":{"title":"aws cli filterとqueryのメモ","content":"\n## autoscaling describe-auto-scaling-groups\n\nhttps://docs.aws.amazon.com/ja_jp/autoscaling/ec2/userguide/ec2-auto-scaling-tagging.html#use-tag-filters-aws-cli\nhttps://docs.aws.amazon.com/cli/latest/reference/autoscaling/describe-auto-scaling-groups.html\n\nこちらのような形式でfilterできる。\nワイルドカードが使えないので注意(1敗)\n\n````\n--filters Name=tag:`environment`,Values=`production`\n````\n\n````shell\n# ワイルドカード指定は効果がない\naws autoscaling describe-auto-scaling-groups --filters 'Name=tag:Name,Values=`*myvalue*`'\n\n# filtersとqueryの組み合わせはできる\naws autoscaling describe-auto-scaling-groups --filters \"Name=tag:Group,Values=`${Group}`\" \\\n  --query \"AutoScalingGroups[? (Tags[? (Key=='Name' \u0026\u0026 contains(Value, 'myvalue') \u0026\u0026 \\\n        !(starts_with(Value, 'foo') \u0026\u0026 starts_with(Value, 'bar')) \\\n        ) ] ) ] \\\n      .{ AutoScalingGroupName: AutoScalingGroupName,MaxSize: MaxSize, MinSize: MinSize, DesiredCapacity: DesiredCapacity}\"\n\n\n# この書き方は正しく無いみたいで、containsで書いているのに完全一致しか検索できなかった\naws autoscaling describe-auto-scaling-groups --query 'AutoScalingGroups[?contains(Tags[?Key==`Name`].Value, `myvalue`)]' \n````\n\nqueryだけでも絞り込みできるが、filtersと組み合わせた場合に比べて時間がかかっていた。\n内部的には、queryはすべて取得してから絞り込み、filterは前処理で絞り込むんでいるのかな？\n\n## queryについて\n\nJMESPathの記法で絞り込んだりフィールドの抽出を行う。\n\n* [JMESPath — JMESPath](https://jmespath.org)\n\n* [JMESPath Examples — JMESPath](https://jmespath.org/examples.html)\n\n* [AWS CLIのクエリの使い方 - karakaram-blog](https://www.karakaram.com/aws-cli-query-usage/)\n\n* [amazon web services - AWS-CLI: Ways to list down autoscalinggroups - Stack Overflow](https://stackoverflow.com/questions/43213828/aws-cli-ways-to-list-down-autoscalinggroups/43213944)\n\n* [amazon cloudformation - JMESPath JSON filter with multiple matches - Stack Overflow](https://stackoverflow.com/questions/37945318/jmespath-json-filter-with-multiple-matches)\n\n* [JmesPath find where not exists - Stack Overflow](https://stackoverflow.com/questions/42396971/jmespath-find-where-not-exists)\n\n* [I want to filter instances by matching a substring of a tag value · Issue #2206 · aws/aws-cli · GitHub](https://github.com/aws/aws-cli/issues/2206)\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["AWS","CLI"]},"/note/aws-sdk-go-v2%E3%82%92%E4%BD%BF%E3%81%86":{"title":"aws-sdk-go-v2を使う","content":"\n[AWS](note/AWS.md) を [Go](note/Go.md) で操作するライブラリ\n\naws-sdk-go-v2が2021-01-19にリリースされた。\n[AWS SDK for Go のバージョン 2 が一般公開されました](https://aws.amazon.com/jp/about-aws/whats-new/2021/01/aws-sdk-for-go-version-2-now-generally-available/)\n\n\u003chttps://aws.amazon.com/jp/sdk-for-go/\u003e\n\n \u003e \n \u003e AWS SDK for Go を使用すると、AWS の使用を迅速に開始できます。この SDK を使用して、Amazon S3、Amazon DynamoDB、Amazon SQS などの AWS の各種サービスと Go アプリケーションを簡単に統合できます。\n\n* モジュール化により使用するサービスごとにgo getでインストールして不要なサービスは除外できる\n* CPU およびメモリの使用率における顕著な改善\n* APIが簡潔になった\n* エラーハンドリングが強化された\n* pagination, waitが改善された\n* middlewareを使ってリクエスト時のカスタマイズが可能になった\n\n## インストール\n\n\u003chttps://github.com/aws/aws-sdk-go-v2\u003e\n\n````shell\n$ go get github.com/aws/aws-sdk-go-v2/aws\n$ go get github.com/aws/aws-sdk-go-v2/config\n\n# 使うサービスのみインストールする\n$ go get github.com/aws/aws-sdk-go-v2/service/s3\n````\n\n## リファレンス\n\n\u003chttps://pkg.go.dev/github.com/aws/aws-sdk-go-v2\u003e\n\n## 使い方\n\n````go\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3\"\n\t\"golang.org/x/xerrors\"\n)\n\nfunc RetrieveFile(ctx context.Context) ([]byte, error) {\n\tcfg, err := config.LoadDefaultConfig(context.TODO())\n\tif err != nil {\n\t\treturn nil, xerrors.Errorf(\": %w\", err)\n\t}\n\n\tclient = s3.NewFromConfig(cfg)\n\n\tinput := \u0026s3.GetObjectInput{\n\t\tBucket: aws.String(\"sample-bucket\"),\n\t\tKey:    aws.String(\"path/to/myfile\"),\n\t}\n\n\toutput, err := client.GetObject(ctx, input)\n\tif err != nil {\n\t\treturn nil, xerrors.Errorf(\": %w\", err)\n\t}\n\n\tdefer output.Body.Close()\n\tb, err := ioutil.ReadAll(output.Body)\n\tif err != nil {\n\t\treturn nil, xerrors.Errorf(\": %w\", err)\n\t}\n\n\tfmt.Printf(\"body: %s\\n\", string(b))\n\n\treturn b, nil\n}\n````\n\n## ユニットテスト\n\n\u003chttps://aws.github.io/aws-sdk-go-v2/docs/unit-testing/\u003e\n\nv1には `xxxiface` パッケージ([例: sqsiface](https://docs.aws.amazon.com/sdk-for-go/api/service/sqs/sqsiface/))があり、インターフェースが定義されていたがv2ではなくなっているので自分でinterfac\\[\\[\\]\\]eを定義してmockする。\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Go","AWS"]},"/note/aws-sdk-go-v2-%E3%81%A7%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%8F%E3%83%B3%E3%83%89%E3%83%AA%E3%83%B3%E3%82%B0":{"title":"aws-sdk-go-v2 でのエラーハンドリング","content":"\n\\#Go #AWS\n\n* aws-sdk-go-v2 でのエラーハンドリング\n  * \u003chttps://aws.github.io/aws-sdk-go-v2/docs/migrating/#errors-types\u003e\n  * v1ではawserrパッケージがあったが、v2では `github.com/aws/aws-sdk-go-v2/service/\u003cservice\u003e/types` に該当のエラーの型があるのでcastする\n\n````go\n// V2\n\nimport \"context\"\nimport \"github.com/aws/aws-sdk-go-v2/service/s3\"\nimport \"github.com/aws/aws-sdk-go-v2/service/s3/types\"\nimport \"github.com/aws/smithy-go\"\n\n// ...\n\nclient := s3.NewFromConfig(cfg)\n\noutput, err := s3.GetObject(context.TODO(), \u0026s3.GetObjectInput{\n\t// input parameters\n})\nif err != nil {\n\tvar nsk *types.NoSuchKey\n\tif errors.As(err, \u0026nsk) {\n\t\t// handle NoSuchKey error\n\t\treturn\n\t}\n\tvar apiErr smithy.APIError\n\tif errors.As(err, \u0026apiErr) {\n\t\tcode := apiErr.ErrorCode()\n\t\tmessage := apiErr.ErrorMessage()\n\t\t// handle error code\n\t\treturn\n\t}\n\t// handle error\n\treturn\n}\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Go","AWS"]},"/note/aws-sdk-go-v2-Athena%E3%81%AB%E3%82%AF%E3%82%A8%E3%83%AA%E3%82%92%E6%8A%95%E3%81%92%E3%81%A6%E7%B5%90%E6%9E%9C%E3%82%92%E3%83%9A%E3%83%BC%E3%82%B8%E3%83%B3%E3%82%B0%E3%81%A7%E5%8F%97%E3%81%91%E5%8F%96%E3%82%8B":{"title":"aws-sdk-go-v2 Athenaにクエリを投げて結果をページングで受け取る","content":"\n\n````go\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/service/athena\"\n\t\"github.com/aws/aws-sdk-go-v2/service/athena/types\"\n)\n\ntype awsClient struct {\n\tathenaClient *athena.Client\n}\n\nfunc NewAwsClient(ctx context.Context) (*awsClient, error) {\n\tcfg, err := config.LoadDefaultConfig(ctx, config.WithRegion(\"ap-northeast-1\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tathenaClient := athena.NewFromConfig(cfg)\n\treturn \u0026awsClient{\n\t\tathenaClient: athenaClient,\n\t}, nil\n}\n\ntype rowData map[string]string\n\nfunc (ac *awsClient) Query(ctx context.Context, query string, outputLocation string) ([]rowData, error) {\n\tinput := \u0026athena.StartQueryExecutionInput{\n\t\tQueryString: aws.String(query),\n\t\tResultConfiguration: \u0026types.ResultConfiguration{\n\t\t\tOutputLocation: aws.String(outputLocation),\n\t\t},\n\t}\n\n\toutput, err := ac.athenaClient.StartQueryExecution(ctx, input)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tqueryExecutionId := *output.QueryExecutionId\n\n\terr = ac.waitForQueryToComplete(ctx, queryExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trowData, err := ac.processResultRows(ctx, queryExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn rowData, nil\n}\nfunc (ac *awsClient) waitForQueryToComplete(ctx context.Context, queryExecutionId string) error {\n\tinput := \u0026athena.GetQueryExecutionInput{\n\t\tQueryExecutionId: aws.String(queryExecutionId),\n\t}\n\n\trunCount := 0\n\tmaxRunCount := 10\n\tsleepSec := 10\n\tfor runCount \u003c maxRunCount {\n\t\toutput, err := ac.athenaClient.GetQueryExecution(ctx, input)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tswitch output.QueryExecution.Status.State {\n\t\tcase types.QueryExecutionStateSucceeded:\n\t\t\treturn nil\n\t\tcase types.QueryExecutionStateFailed:\n\t\t\treturn fmt.Errorf(\"athena query failed to run with error message: %s\", *output.QueryExecution.Status.StateChangeReason)\n\t\tcase types.QueryExecutionStateCancelled:\n\t\t\treturn fmt.Errorf(\"athena query was cancelled\")\n\t\tdefault:\n\t\t\ttime.Sleep(time.Duration(sleepSec) * time.Second)\n\t\t\trunCount++\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"athena query was timeout\")\n}\n\nfunc (ac *awsClient) processResultRows(ctx context.Context, queryExecutionId string) ([]rowData, error) {\n\tinput := \u0026athena.GetQueryResultsInput{\n\t\tQueryExecutionId: aws.String(queryExecutionId),\n\t}\n\n\trds := make([]rowData, 0)\n\trns := make([]string, 0)\n\n\tpaginator := athena.NewGetQueryResultsPaginator(ac.athenaClient, input)\n\tfirst := true\n\tfor paginator.HasMorePages() {\n\t\toutput, err := paginator.NextPage(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif first {\n\t\t\tfor _, meta := range output.ResultSet.ResultSetMetadata.ColumnInfo {\n\t\t\t\trns = append(rns, *meta.Name)\n\t\t\t}\n\t\t}\n\n\t\tfor _, v := range output.ResultSet.Rows {\n\t\t\tif first {\n\t\t\t\t// Ignore first row of first run. It's header row\n\t\t\t\tfirst = false\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\trd := rowData{}\n\t\t\tfor i, d := range v.Data {\n\t\t\t\trd[rns[i]] = *d.VarCharValue\n\t\t\t}\n\t\t\trds = append(rds, rd)\n\t\t}\n\t}\n\n\treturn rds, nil\n}\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/04/19","AWS"]},"/note/bcdedit%E3%81%A8%E3%81%AF":{"title":"bcdeditとは","content":"\n[BCDEdit のコマンド ライン オプション | Microsoft Docs](https://docs.microsoft.com/ja-jp/windows-hardware/manufacture/desktop/bcdedit-command-line-options)\n\n \u003e \n \u003e BCDEdit は、ブート構成データ (BCD) を管理するためのコマンド ライン ツールです。\n \u003e BCD ファイルは、ブート アプリケーションやブート アプリケーションの設定を記述するために使用されるストアを提供します。\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Windows"]},"/note/build.gradle.kts%E3%81%A7fatJar%E3%82%92%E4%BD%9C%E3%82%8B":{"title":"build.gradle.ktsでfatJarを作る","content":"\nhttps://stackoverflow.com/questions/41794914/how-to-create-the-fat-jar-with-gradle-kotlin-script\n\n````kts\nval projectName = \"my-projet\"\n\napplication {\n    // mainを設定(コンパイル後Ktがつくことに注意)\n    mainClass.set(\"com.MainKt\")\n}\n\n// `fatJar` の名前でタスクを定義する\ntask(\"fatJar\", Jar::class) {\n    archiveBaseName.set(projectName)\n    manifest {\n        attributes[\"Main-Class\"] = mainClass\n    }\n    duplicatesStrategy = DuplicatesStrategy.EXCLUDE\n\n    from(\n        // classpathからjarファイルを取得して、zipに加える\n        configurations.runtimeClasspath.get().map {\n            if (it.isDirectory) it else zipTree(it)\n        }\n    )\n    exclude(\"META-INF/*.RSA\", \"META-INF/*.SF\", \"META-INF/*.DSA\")\n\n}\n\n````\n\ngradle installDist したときのディレクトリ名と実行ファイル名の設定\n\n````shell\nmy-project$ ./gradlew installDist\n\n# すると以下のツリーができる\n# my-project/build/install/my-project/lib\n# my-project/build/install/my-project/lib/...\n# my-project/build/install/my-project/bin\n# my-project/build/install/my-project/bin/my-project (executable)\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/buildgradle%E3%81%AEjacoco%E3%81%A7coverage%E3%82%92%E6%A8%99%E6%BA%96%E5%87%BA%E5%8A%9B":{"title":"buildgradleのjacocoでcoverageを標準出力","content":"\n# jacoco_coverageを標準出力\n\n````kotlin\ntasks.withType\u003cJacocoReport\u003e {\n    dependsOn(tasks.test)\n\n    reports {\n        xml.isEnabled = true\n        html.isEnabled = true\n    }\n\n    doLast {\n        val report = File(\"${jacoco.reportsDir}/test/jacocoTestReport.xml\")\n        printCoverage(report)\n    }\n}\n\n/**\n * JaCoCo のテストレポート(xml)をparseしてカバレッジを標準出力する\n */\nfun printCoverage(xml: File) {\n    if (!xml.exists()) return\n\n    val documentBuilder = javax.xml.parsers.DocumentBuilderFactory.newInstance()\n        .apply {\n            // DTDが見つからないエラーが出るため抑制\n            isValidating = false\n            isNamespaceAware = true\n            setFeature(\"http://xml.org/sax/features/namespaces\", false)\n            setFeature(\"http://xml.org/sax/features/validation\", false)\n            setFeature(\"http://apache.org/xml/features/nonvalidating/load-dtd-grammar\", false)\n            setFeature(\"http://apache.org/xml/features/nonvalidating/load-external-dtd\", false)\n        }\n        .newDocumentBuilder()\n    val document = documentBuilder.parse(xml)\n\n    val xPath = javax.xml.xpath.XPathFactory.newInstance().newXPath()\n\n    val counters =\n        xPath.evaluate(\"/report/counter\", document, javax.xml.xpath.XPathConstants.NODESET) as org.w3c.dom.NodeList\n\n    val metrics = mutableMapOf\u003cString, Double\u003e()\n    for (i in 0 until counters.length) {\n        val counter = counters.item(i)\n        val typeName = counter.attributes.getNamedItem(\"type\").nodeValue\n        val missed = counter.attributes.getNamedItem(\"missed\").nodeValue.toDouble()\n        val covered = counter.attributes.getNamedItem(\"covered\").nodeValue.toDouble()\n        val coverage = ((covered / (covered + missed)) * 10000).roundToInt().toDouble() / 100.toDouble()\n\n        metrics[typeName] = coverage\n    }\n\n    logger.quiet(\"----- Code Coverage ----------\")\n    metrics.entries.forEach { entry -\u003e\n        val key = entry.key\n        val value = entry.value\n        logger.quiet(String.format(\" - %-12s: %6.2f%%\", key, value))\n    }\n    logger.quiet(\"------------------------------\")\n}\n````\n\n````sh\n$ ./gradlew jacocoTestReport\n\n\u003e Task :jacocoTestReport\n----- Code Coverage ----------\n - INSTRUCTION :  99.99%\n - BRANCH      :  99.99%\n - LINE        :  99.99%\n - COMPLEXITY  :  99.99%\n - METHOD      :  99.99%\n - CLASS       :  99.99%\n------------------------------\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["unittest","gradle"]},"/note/c++%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89":{"title":"c++環境構築","content":"\n# c++環境構築\n\n## gccインストール\n\n\u003chttps://qiita.com/EngTks/items/ffa2a7b4d264e7a052c6\u003e\n\n### 初期状態\n\n````shell\ng++ --version\n````\n\nClangがデフォルトで入っている\ngccにのみ、stdc++.hというC++の標準ライブラリの集合体が入っているので有利\n\n### install\n\n````shell\nbrew install gcc\n````\n\n### pathの設定\n\n````shell\n$ cd /usr/local/bin\n$ ls -al | grep g++\n$ ln -s g++-10 g++\n$ g++ --version\ng++ (Homebrew GCC 10.2.0_3) 10.2.0\nCopyright (C) 2020 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n````\n\n### stdc++.hを使えるようにする\n\n````shell\n$ cp /usr/local/Cellar/gcc/10.2.0_3/include/c++/10.2.0/x86_64-apple-darwin20/bits/stdc++.h /usr/local/Cellar/gcc/10.2.0_3/include/c++/10.2.0/bits/\n````\n\n### エラー\n\n````shell\n$ gcc hello.cpp\nclang: error: invalid version number in '-mmacosx-version-min=11.1'\n````\n\n\u003chttps://stackoverflow.com/questions/63972113/big-sur-clang-invalid-version-error-due-to-macosx-deployment-target\u003e\n\nBig Surにアップデートした影響っぽい\n\n````shell\nsudo xcode-select --switch /Library/Developer/CommandLineTools\n````\n\n## vim + LSP\n\n\u003chttps://endaaman.me/tips/nvim-coc-ccls\u003e\n\n### LSP\n\nclangd, cquery, ccls が有名らしい\nclangdは重いらしい\ncqueryは開発がストップしている\ncclsを入れる\n\n[ccls](https://github.com/MaskRay/ccls/wiki)\n\n````shell\nbrew install ccls\n````\n\n### cclsの設定\n\ncclsのLSPサーバーに対して、シンボルの定義やその定義されたファイルパスなどを教える必要がある。 `compile_commands.json` を使う。\n\u003chttps://github.com/rizsotto/Bear\u003e で簡単に生成できる\n\n````shell\nbrew install bear\n````\n\n=\u003e Makefile作ってないから？使い方がよくわからなかった\n\n#### shell script wrapper\n\n\u003chttps://github.com/MaskRay/ccls/wiki/Build#macos\u003e\n\n````shell\n$ touch /usr/local/bin/ccls\n$ chmod +x /usr/local/bin/ccls\n$ vim /usr/local/bin/ccls\n````\n\n````shell\n#!/bin/sh\nexec /usr/local/Cellar/ccls/0.20201219/bin/ccls -init='{\"clang\":{\"extraArgs\":[\"-isystem\", \"/usr/local/Cellar/gcc/10.2.0_3/include/c++/10.2.0\"]}}' \"$@\"\n````\n\n### vim-lsp\n\n\u003chttps://github.com/prabirshrestha/vim-lsp/wiki/Servers-ccls\u003e\n\n````shell\nif executable('ccls')\n   au User lsp_setup call lsp#register_server({\n      \\ 'name': 'ccls',\n      \\ 'cmd': {server_info-\u003e['ccls']},\n      \\ 'root_uri': {server_info-\u003elsp#utils#path_to_uri(lsp#utils#find_nearest_parent_file_directory(lsp#utils#get_buffer_path(), 'compile_commands.json'))},\n      \\ 'initialization_options': {},\n      \\ 'whitelist': ['c', 'cpp', 'objc', 'objcpp', 'cc'],\n      \\ })\nendif\n````\n\n### quickrun\n\n\u003chttps://kenbannikki.com/notes/quickrun-for-cpp/\u003e\n\n````shell\nlet g:quickrun_config.cpp = {\n    \\ 'command': 'g++',\n    \\ 'input': 'input',  \" inputというファイルを標準入力として与える\n    \\ 'runner': 'system'  \" 非同期実行を行わない\n    \\ }\n````\n\nこの状態で:QuickRunか\u003cleader\u003e+ rすればソースファイルがコンパイルされ、inputというファイルを標準入力として与えられた状態でプログラムが実行されます。\n\nコマンドを打ち込む場合は、:QuickRun -input inputまたは:QuickRun \\\u003cinputとすれば同じことができます。\n\nまた、:QuickRun -input =5または:QuickRun \\\u003c=5で数値や文字列を直接渡すことができます。\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["競プロ","c++"]},"/note/cargo":{"title":"cargo","content":"\n\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Rust"]},"/note/chrome%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E9%81%B8%E6%8A%9E%E3%83%80%E3%82%A4%E3%82%A2%E3%83%AD%E3%82%B0%E3%81%A7%E9%9A%A0%E3%81%97%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E8%A1%A8%E7%A4%BA":{"title":"chromeのファイル選択ダイアログで隠しファイルを表示","content":"\nhttps://apple.stackexchange.com/questions/186376/hotkey-to-show-hidden-files-and-folders-in-file-open-dialog/186388\n\n`cmd + shift + .` でトグルできる\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/chrome-%E3%82%A2%E3%83%89%E3%83%AC%E3%82%B9%E3%83%90%E3%83%BC%E3%81%8B%E3%82%89%E3%83%95%E3%82%A9%E3%83%BC%E3%82%AB%E3%82%B9%E3%82%92%E5%A4%96%E3%81%99":{"title":"chrome アドレスバーからフォーカスを外す","content":"\n\u003chttps://github.com/philc/vimium/issues/840#issuecomment-17948885\u003e\n\nGoogle ChromeのSearch Engineで空のJavaScriptを実行するキーワードを設定しておく\n\n* Google Chromeの設定ページ→`Manage Search Engine`（`chrome://settings/searchEngines`）へ行く\n* `Other Search Engine`から`Add`で新規作成、任意のタイトルとショートカットとなるキーワード（`unfocus`の頭文字でここでは`u`）とURLの代わりの`javascript::`を入力・保存\n\nこれでアドレスバーにフォーカスが当たっている状態で`u`→`Enter`を押下すると`javascript::`というスクリプトが実行される\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/clasp":{"title":"clasp","content":"\nhttps://github.com/google/clasp\n\nGoogleが提供する [GAS](note/GAS.md) をローカルで開発するためのコマンドラインツール。\n\nclaspを使用することで、Google Apps Scriptをローカル環境で開発し、バージョン管理システム（Gitなど）を使用してコードを管理することができる。また、コマンドラインからGoogle Apps Scriptを操作することもできる。\n\n[TypeScript](note/TypeScript.md) で書くこともできて、ローカルで補完を効かせながら開発できるので効率がよく保守性も高い。\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/05/04","GAS"]},"/note/css-%E5%90%B9%E3%81%8D%E5%87%BA%E3%81%97%E3%82%92%E3%81%A4%E3%81%8F%E3%82%8B":{"title":"css 吹き出しをつくる","content":"\n# CSSで吹き出しを作る\n\n\u003chttps://lpeg.info/html/css_bubble.html\u003e\n\nVueコンポーネント+TailwindCSSでの書き方\n\nしたむきの枠線つき吹き出し\n\n````vue\n\u003ctemplate\u003e\n  \u003cdiv\n    class=\"speech-balloon relative inline-block rounded-3xl border border-gray-2 py-xxs px-m bg-white text-black text-center text-base\"\n    @click=\"$emit('click')\"\n  \u003e\n    {{ text }}\n  \u003c/div\u003e\n\u003c/template\u003e\n\n\u003cscript lang=\"ts\"\u003e\nimport { Vue, Component, Prop } from 'vue-property-decorator'\n\n/**\n * 吹き出し\n */\n@Component\nexport default class SpeechBalloon extends Vue {\n  @Prop({ required: true, type: String })\n  readonly text!: string\n}\n\u003c/script\u003e\n\n\u003cstyle scoped\u003e\n.speech-balloon:before {\n  @apply absolute;\n  @apply z-20;\n\n  content: '';\n  top: 100%;\n  left: 50%;\n  margin-left: calc(0px - theme('spacing.s'));\n  border: theme('spacing.s') solid transparent;\n  border-top: theme('spacing.s') solid theme('colors.white');\n}\n\n/* 下に載せる三角アイコン */\n.speech-balloon:after {\n  @apply absolute;\n  @apply z-10;\n\n  content: '';\n  top: 100%;\n  left: 50%;\n  margin-left: calc(0px - theme('spacing.s') - 2px);\n  border: calc(theme('spacing.s') + 2px) solid transparent;\n  border-top: calc(theme('spacing.s') + 1px) solid theme('colors.gray.2');\n}\n\u003c/style\u003e\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["css"]},"/note/date%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%A7unixtimestamp%E3%82%92%E5%A4%89%E6%8F%9B":{"title":"dateコマンドでunixtimestampを変換","content":"\n\\#shell\n\n## タイムスタンプから変換\n\n````shell\n$ date --iso-8601=\"seconds\" -d @1632689459\n2021-09-27T05:50:59+09:00\n````\n\n## タイムスタンプに変換\n\n````shell\n$ date +%s --date=\"2021-09-27T05:50:59+09:00\"\n1632689459\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["shell"]},"/note/dnsmasq%E3%82%92%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E5%86%85%E3%81%AB%E7%AB%8B%E3%81%A6%E3%81%A6DNS%E5%95%8F%E3%81%84%E5%90%88%E3%82%8F%E3%81%9B%E3%82%92%E3%82%AD%E3%83%A3%E3%83%83%E3%82%B7%E3%83%A5%E3%81%99%E3%82%8B":{"title":"dnsmasqをコンテナ内に立ててDNS問い合わせをキャッシュする","content":"\n[dnsmasq](https://wiki.archlinux.jp/index.php/Dnsmasq) は小規模なネットワーク向けのDNS、DHCPサーバー。\nDNSのキャッシュくらい、デフォルトであるものだと思っていたけどLinuxはそうではないようなので、こういうソフトウェアを入れてキャッシュさせる\n\nyum でインストールして、設定ファイルを書き換える\n\ndnsmasqをインストールすると、 `/etc/dnsmasq.conf` という設定ファイルが生成されるので、コメントアウトを外す\nとりあえず以下を設定する\n\n````\ndomain-needed #ドメインの無いホスト名のみ問い合わせの場合、上位DNSサーバに転送しない\nbogus-priv #プライベートIPアドレスの逆引きを上位DNSサーバに転送しない\nresolv-file #上位DNSサーバの設定\n````\n\n````Dockerfile\nFROM amazonlinux:2\n\nRUN yum install -y dnsmasq systemd\n\nRUN echo 'nameserver 8.8.8.8' \u003e /etc/dnsmasq_resolv.conf \\\n  \u0026\u0026 sed -i -e 's/#domain-needed/domain-needed/' -e 's/#bogus-priv/bogus-priv/' -e 's@#resolv-file=@resolv-file=/etc/dnsmasq_resolv.conf@' /etc/dnsmasq.conf \\\n  \u0026\u0026 systemctl enable dnsmasq\n\nENTRYPOINT [\"/sbin/init\"]\n````\n\n実行時は `--privileged` と、 `--dns=127.0.0.1` で `/etc/resolv.conf` に `nameserver 127.0.0.1` が書かれるようにする\n\n````shell\n$ docker build -t dnsmasq-test .\n$ docker run --privileged -it --dns=127.0.0.1 --name=dnsmasq dnsmasq-test\n````\n\n````shell\n# digをインストール\n$ yum install -y bind-utils\n$ dig https://httpbin.org\n\n; \u003c\u003c\u003e\u003e DiG 9.11.4-P2-RedHat-9.11.4-26.P2.amzn2.5.2 \u003c\u003c\u003e\u003e https://httpbin.org\n;; global options: +cmd\n;; Got answer:\n;; -\u003e\u003eHEADER\u003c\u003c- opcode: QUERY, status: NXDOMAIN, id: 59931\n;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 512\n;; QUESTION SECTION:\n;https://httpbin.org.           IN      A\n\n;; AUTHORITY SECTION:\norg.                    1800    IN      SOA     a0.org.afilias-nst.info. hostmaster.donuts.email. 1670768991 7200 900 1209600 3600\n\n;; Query time: 18 msec\n;; SERVER: 127.0.0.1#53(127.0.0.1)\n;; WHEN: Sun Dec 11 14:39:32 UTC 2022\n;; MSG SIZE  rcvd: 130\n\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Docker","Network"]},"/note/etcd":{"title":"etcd","content":"\n{{\u003c card-link \"https://etcd.io\" \u003e}}\n\n分散型のキーバリューストア\nGo言語製\n複数台で実行してクラスターを構築することで負荷分散を行う\n\n[etcdctl](note/etcdctl.md) で操作できる。\n\n## etcdのバックアップを取る\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/07/19"]},"/note/etcdctl":{"title":"etcdctl","content":"\n[etcd](note/etcd.md)のクライアント\n\netcdをインストールすると使えるようになるが、クライアントだけほしい場合もある。\n[Go](note/Go.md)なので `go install github.com/etcd-io/etcd/etcdctl@latest` で入るかと思ったがこれではエラーになってしまったので、一旦git cloneしてから入れた。\n\n````shell\ngit clone https://github.com/etcd-io/etcd.git\ncd etcd/etcdctl\ngo install\n\netcdctl version\n````\n\n````shell\netcdctl --endpoints= version\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/07/19"]},"/note/fish%E3%81%A8fzf%E3%82%92%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B%E3%82%8B":{"title":"fishとfzfを組み合わせる","content":"\n\u003chttps://github.com/jethrokuan/fzf\u003e を使っていた\n\n## 問題\n\nファイル名、ディレクトリ名にスペースが含まれていると、tab補完したときに正しく展開されない\n\n## 解決策\n\n\u003chttps://github.com/PatrickF1/fzf.fish\u003e を使うようにした\n\n標準の `CTRL-T` を使うだけでもいい気がする\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["fish","shell"]},"/note/fish%E3%81%AEhistory%E3%82%92zsh%E3%81%AB%E5%A4%89%E6%8F%9B":{"title":"fishのhistoryをzshに変換","content":"\n\\#fish #zsh\n\n\u003chttps://github.com/jverhoelen/fish-history-to-zsh\u003e\n\n````sh\ngit clone git@github.com:jverhoelen/fish-history-to-zsh.git\ncd fish-history-to-zsh\nnode index.js\n````\n\n## fishのhistoryファイル\n\n~/.local/share/fish/fish_history\nyamlで保存されているので、yamlをロードして変換している\n\nparseエラーが発生したので、fish_historyファイルから該当の行を消した。\n数が少なかったのでこれで問題なかった\n\n## zshのhistoryファイル\n\n~/.zsh_history\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["fish","zsh"]},"/note/fish%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3":{"title":"fishプラグイン","content":"\n# fish\n\nfish\n\n* fisher でプラグイン管理\n* fzf 用の設定\n\nrafaelrinaldi/pure\njethrokuan/z\n0rax/fish-bd\noh-my-fish/theme-bobthefish\njethrokuan/fzf\ndecors/fish-ghq\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["fish","terminal"]},"/note/font-%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E7%94%A8%E3%83%95%E3%82%A9%E3%83%B3%E3%83%88%E3%81%AB%E3%81%93%E3%81%A0%E3%82%8F%E3%82%8B":{"title":"font プログラミング用フォントにこだわる","content":"\n## 絶対条件\n\n* monospace\n* 0とO、1とlとIなどが見分けやすい\n* マルチバイト文字がくずれない\n\n## おすすめフォント\n\n* Cica\n* HackGen\n\n## 各ソフトに設定する\n\n### Chrome\n\n一括で設定する方法もあるが、サイトによっては見づらかったり、Web開発者だとフォントが変わってしまうのは嬉しくないので、おすすめはStylebotでサイトごとに設定\n\nbitbucket\n\n````css\nbody * {\n    font-family: Cica;\n}\n\n/* ページ全体ではなくコード部分だけに適用したい場合\n.code-diff {\n    font-family: Cica;\n    font-size: 14px;\n}\n.bitkit-diff-wrapper-diff .inline-content-wrapper {\n    font-family: Cica;\n    font-size: 14px;\n}\n*/\n````\n\n### Intellij IDEA\n\n### Visual Studio Code\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["font"]},"/note/font-Web%E3%83%95%E3%82%A9%E3%83%B3%E3%83%88%E3%82%92%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B":{"title":"font Webフォントを利用する","content":"\n\u003chttps://lpeg.info/webworks/google_fonts.html\u003e\n\n## フォントを利用する\n\n[Noto Sans JP](note/Noto%20Sans%20JP.md) を使いたい。\n\nNoto Sans系の違いは\n\n* [【WEBフォント】Noto Sans系日本語フォントは結局どれを使えばいいのか検証してみる | oku-log](https://oku-log.com/blog/noto-sans/)\n* [とりあえずNoto Sans。は、やめませんか？という話｜トモノ｜Web Designer｜note](https://note.com/minamotono/n/n765d41581136)\n\nfonts.google.comでfontを選択\n\n\u003chttps://fonts.google.com/specimen/Noto+Sans+JP\u003e\n\n使用する太さの `Select this style` をクリック\n\n`Use on the web` で使いかたを選択して、コピー\n\n````html\n\u003clink rel=\"preconnect\" href=\"https://fonts.gstatic.com\"\u003e  \n\u003clink href=\"https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@100\u0026display=swap\" rel=\"stylesheet\"\u003e\n````\n\nフォントを指定\n\n````css\nfont-family: 'Noto Sans JP', sans-serif;\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["font"]},"/note/fzf":{"title":"fzf","content":"\n[fzf](https://github.com/junegunn/fzf) は、コマンドラインでインクリメンタルにあいまい検索ができるツール。\n標準出力をパイプで渡してフィルタリングしたり、カレントディレクトリ配下のファイルを再帰的に表示したりといったことができる。\n\n[Homebrew](note/Homebrew.md) やgitでインストールできる。\n\n````shell\ngit clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf\n~/.fzf/install\n````\n\ninstallすると `~/.fzf.zsh` ができるので、shellの起動時に読み込む。\n\n````shell\n[ -f ~/.fzf.zsh ] \u0026\u0026 source ~/.fzf.zsh\nexport FZF_DEFAULT_COMMAND='fd --type file --hidden --follow --exclude .git'\nexport FZF_CTRL_T_COMMAND='fd --type file --hidden --follow --exclude .git'\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/05/06","CLI","terminal"]},"/note/fzf.vim%E3%81%AE%E4%BD%BF%E3%81%84%E6%96%B9":{"title":"fzf.vimの使い方","content":"\n## fzf\n\nhttps://github.com/jethrokuan/fzf#usage\n\n* `FZF_DEFAULT_COMMAND` でfzf実行時に使用するコマンドを指定\n* ripgrep が高速なのでこんな風にするといい `FZF_DEFAULT_COMMAND=rg --hidden -g \"!.git/*\" -l \"\"`\n* `FZF_CTRL_T_COMMAND='rg --files --hidden --follow --glob \"!.git/*\"'` で、`ctrl-t` を押すとfzfが実行される\n* `FZF_CTRL_T_OPTS='--preview \"bat --color=always --style=header,grid --line-range :100 {}\"'` プレビューオプション\n\n## fzf.vim\n\n* Rgの結果をquickfixに送る\n  * https://github.com/junegunn/fzf.vim/issues/586\n  * `shift` や `alt-a` `alt-d` で全選択・解除してEnter\n  * QuickFix の操作は `:cp` や `:cn`、ウィンドウを開くのは `:cwindow` `:cclose`\n* Filesの結果は `shift` でしか選択できない\n\n````\n[[plugins]]\nrepo = 'junegunn/fzf.vim'\ndepends = ['fzf']\non_cmd = [\n  'Files',\n  'GFiles',\n  'GFiles?',\n  'Tags',\n  'Commands',\n  'Rg',\n  'History',\n  'Buffers',\n]\nhook_add = '''\n    command! -bang -nargs=* Rg\n        \\ call fzf#vim#grep(\n        \\   'rg --column --line-number --hidden --no-heading --color=always --smart-case -g \"!.git/*\" -- '.shellescape(\u003cq-args\u003e), 1,\n        \\   fzf#vim#with_preview(), \u003cbang\u003e0)\n\n    fun! FzfOmniFiles()\n        let is_git = system('git status')\n        if v:shell_error\n            :Files\n        else\n            :GFiles\n        endif\n    endfun\n\n    nnoremap \u003cC-j\u003e\u003cC-j\u003e :Commands\u003cCR\u003e\n    nnoremap \u003cC-j\u003e\u003cC-h\u003e :History\u003cCR\u003e\n    nnoremap \u003cC-j\u003e\u003cC-p\u003e :call FzfOmniFiles()\u003cCR\u003e\n    nnoremap \u003cC-j\u003e\u003cC-g\u003e :Rg\u003cSpace\u003e\n    nnoremap \u003cC-j\u003e\u003cC-b\u003e :Buffers\u003cCR\u003e\n    nnoremap \u003cC-j\u003e. :\u003cC-u\u003eFiles ~/.dotfiles\u003cCR\u003e\n'''\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["vim","shell"]},"/note/git%E3%82%B3%E3%83%9F%E3%83%83%E3%83%88%E3%81%ABissue%E7%95%AA%E5%8F%B7%E3%82%92%E3%81%84%E3%82%8C%E3%82%8B":{"title":"gitコミットにissue番号をいれる","content":"\n\\#git\n\n`.git/hooks/prepare-commit-msg`\n\n````shell\n#!/bin/bash -u\n\n# https://qiita.com/koara-local/items/eae7942131e53cb8031a\n\ncurrent_branch=$(git branch | grep \"^\\*\")\n\nif [[ ! \"$current_branch\" =~ .*/[A-Z]+-[0-9]+.* ]]; then\n    exit 0\nfi\n\n# e.g. feature/AAA-123-xxx-hogehoge -\u003e AAA-123\nissue_id=$(echo \"$current_branch\" | sed -E 's/^.*\\/([A-Z]+-[0-9]+).*$/\\1/')\n\n# Insert Issue ID at the beginning of the commit message if it doesn't exist\nif [[ ! $(head -n 1 $1 | grep \"$issue_id\") ]]; then\n  sed -i -e '1 s@\\(.*\\)@'\"${issue_id}\"' \\1@' $1\nfi\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["git"]},"/note/git%E3%83%AA%E3%83%9D%E3%82%B8%E3%83%88%E3%83%AA%E3%81%AE%E8%BB%BD%E9%87%8F%E5%8C%96%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AB%E3%82%84%E3%81%A3%E3%81%9F%E3%81%93%E3%81%A8":{"title":"gitリポジトリの軽量化のためにやったこと","content":"\n\\#git\n\nリポジトリの軽量化をしたい。\n今あるファイルを消すだけではリポジトリサイズは減らない。\n自由にしていいリポジトリであれば、gitの履歴を改変する、LFS化するなどする。\n\n## git-lfs をインストールする\n\n1. [https://git-lfs.github.com/](https://git-lfs.github.com/ \"https://git-lfs.github.com/\")\n   1. macの場合\n\n````shell\n$ brew install git-lfs\n$ git lfs install \n$ git lfs version \ngit-lfs/2.12.1 (GitHub; darwin amd64; go 1.15.3)\n````\n\n## リポジトリ軽量化\n\n過去コミットに残っている巨大ファイルを削除して軽量化する。\ngit filter-branch を使う方法は、履歴が多いとかなり遅いため実用的じゃなかった。\n\n[BFG](https://rtyley.github.io/bfg-repo-cleaner/)を使うことにした。\n\n* 大きいファイルを削除することができる (\u003chttps://support.atlassian.com/bitbucket-cloud/docs/maintain-a-git-repository/\u003e)\n* HEADに存在するファイルは消されないらしいので安心して実行する (\u003chttps://rtyley.github.io/bfg-repo-cleaner/#protected-commits:~:text=Your%20current%20files%20are%20sacred\u003e)\n\n1. \u003chttps://repo1.maven.org/maven2/com/madgag/bfg/1.14.0/bfg-1.14.0.jar\u003e からjar実行ファイルをダウンロードする\n1. bareリポジトリをクローン\n\n````shell\n$ git clone --mirror git://example.com/some-big-repo.git\n````\n\n3. BFGで巨大ファイルを削除\n\n````shell\n$ java -jar bfg.jar --strip-blobs-bigger-than 100M some-big-repo.git\n````\n\n4. BFGでコミットはきれいになった状態だがまだ実体は残っているので、きれいにする\n\n````shell\n$ cd some-big-repo.git\n$ git reflog expire --expire=now --all \u0026\u0026 git gc --prune=now --aggressive\n````\n\n5. 事前にバックアップをとってからpushする(`--mirror` でcloneしているため、リモートのリポジトリのすべてのrefsがアップデートされるためバックアップ推奨)\n\n````shell\n$ git push\n````\n\n## LFSの設定\n\n[git lfs migrate で Git-LFS 移行したときのメモ](https://nanmo.hateblo.jp/entry/2019/08/31/120008)\n\nBFGでもLFSに変換できるようだ (\u003chttps://support.atlassian.com/bitbucket-cloud/docs/use-bfg-to-migrate-a-repo-to-git-lfs/\u003e)\n今はBFGよりgit-lfs-migrateを使ったほうがいいようなのでそうする\n\n````shell\n# lfs化するファイルを事前調査\n$ git lfs migrate info --everything\nmigrate: Sorting commits: ..., done.\nmigrate: Examining commits: 100% (4422/4422), done.\n*.png \t1.4 GB\t5711/5711 files(s)\t100%\n*.jpg \t672 MB\t4431/4431 files(s)\t100%\n\n# lfs化\n$ git lfs migrate import --include=\"*.png,*.jpg\" --everything\n\n# 現時点でのサイズ\n$ du -sh ./*\n4.0K\t./config\n4.0K\t./HEAD\n 24K\t./hooks\n4.0K\t./info\n1.8G\t./lfs\n2.0G\t./objects\n4.0K\t./packed-refs\n204K\t./refs\n\n# gc\n$ git reflog expire --expire=now --all \u0026\u0026 git gc --prune=now --aggressive\n$ du -sh ./*\n4.0K\t./config\n4.0K\t./HEAD\n 24K\t./hooks\n4.0K\t./info\n1.8G\t./lfs\n162M\t./objects\n4.0K\t./packed-refs\n  0B\t./refs\n\n# =\u003e lfsができてobjectsのサイズが減っている\n````\n\n## 作業全体\n\n````shell\n# bareでリポジトリをクローン\n$ git clone --mirror git@github.com/bigrepo.git\n\n# 10MB以上のコミットを削除\n$ java -jar bfg-1.13.0.jar --strip-blobs-bigger-than 10M bigrepo.git/\n\nUsing repo : bigrepo.git\n\nScanning packfile for large blobs: 51747\nScanning packfile for large blobs completed in 469 ms.\n....\n\n\n# 実体を削除\n$ cd bigrepo.git\n$ git reflog expire --expire=now --all \u0026\u0026 git gc --prune=now --aggressive\n\n# lfs化するファイルを事前調査\n$ git lfs migrate info --everything\nmigrate: Sorting commits: ..., done.\nmigrate: Examining commits: 100% (4422/4422), done.\n*.png \t1.4 GB\t5711/5711 files(s)\t100%\n*.jpg \t672 MB\t4431/4431 files(s)\t100%\n\n# lfs化\n$ git lfs migrate import --include=\"*.png,*.jpg\" --everything\n\n# 現時点でのサイズ\n$ du -sh ./*\n4.0K\t./config\n4.0K\t./HEAD\n 24K\t./hooks\n4.0K\t./info\n1.8G\t./lfs\n2.0G\t./objects\n4.0K\t./packed-refs\n204K\t./refs\n\n# gc\n$ git reflog expire --expire=now --all \u0026\u0026 git gc --prune=now --aggressive\n$ du -sh ./*\n4.0K\t./config\n4.0K\t./HEAD\n 24K\t./hooks\n4.0K\t./info\n1.8G\t./lfs\n162M\t./objects\n4.0K\t./packed-refs\n  0B\t./refs\n\n# =\u003e lfsができてobjectsのサイズが減っている\n\n$ git push\n\n\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["git"]},"/note/git%E5%85%A8%E5%B1%A5%E6%AD%B4%E3%81%8B%E3%82%89grep%E3%81%99%E3%82%8B":{"title":"git全履歴からgrepする","content":"\n\\#git\n\n\u003chttps://suzuken.hatenablog.jp/entry/2018/12/05/155040\u003e\n\n## ファイルの中身を検索\n\n`git grep`\n\n過去のcommitにあったすべてのコードから正規表現で検索する\n\n````shell\n$ git grep '\u003cregexp\u003e' $(git rev-list --all)\n````\n\npathを指定する場合は以下\n\n````shell\n$ git grep '\u003cregexp\u003e'  $(git rev-list --all -- path/to/dir) -- path/to/dir\n````\n\n* `-w`: wordマッチ\n* `-v`: 一致しない\n* `-I`: binaryを無視\n\n## 変更内容を検索\n\nコミットの内容をキーワード検索できる\n\n### コミットメッセージとコミットの内容の両方を検索\n\n````shell\n$ git log -S '\u003cword\u003e'\n````\n\n`-S` オプションで文字列をルックアップできる。 `-G` だと正規表現がつかえる。\n\n### コミットメッセージのみ検索\n\n````shell\n$ git log --grep=\"\u003cword\u003e\"\n````\n\n* `-p | --patch`: 差分内容も見れる\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["git"]},"/note/git-shallow-clone%E3%81%A8sparse-checkout%E3%82%92%E6%B4%BB%E7%94%A8":{"title":"git shallow cloneとsparse checkoutを活用","content":"\n\\#git\n\n## Shallow clone\n\n`depth` を指定すると、その数のコミットログだけを取得するので、コミット数の多いリポジトリでデータ量を削減できる。\n\n````shell\n$ git clone --depth=1 git@github.com:git/git.git\n\n# -b \u003cbranch\u003e でブランチ指定\n$ git clone --depth=1 -b main git@github.com:git/git.git\n````\n\ngit log で過去のログを見ることはできない。CIなどでビルドするときによく使われる\n\n## Sparse checkout\n\n[git-sparse-checkout](note/git-sparse-checkout.md)\n\nリポジトリの中で必要なファイルだけを展開することで、ディスク使用量を削減できる。\n\nshallow cloneと組み合わせて、`depth=1` で取得したあとファイルの展開をしない\n\n````shell\n# clone後ファイルを展開しない\n$ git clone --depth=1 --no-checkout git@github.com:git/git.git\n\n$ cd git\n$ mkdir .git/info\n\n# checkoutするpath一覧を設定\n$ echo \"Documentation\" \u003e .git/info/sparse-checkout\n# sparse checkoutを行うよう設定\n$ git config core.sparsecheckout true\n# checkoutする\n$ git checkout -f master\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["git"]},"/note/git-sparse-checkout":{"title":"git-sparse-checkout","content":"\n\\#git\n\n\u003chttps://git-scm.com/docs/git-sparse-checkout\u003e\n\nリポジトリから一部だけを取得する設定\n必要なのが巨大なリポジトリのうちの1ファイルだけの場合などに、\n全体をcheckoutすると容量を食うので、ファイルやディレクトリを指定してcheckoutすることができる\n\n## sparse checkout を利用してみる\n\n1. まずは空っぽのローカルリポジトリを作成\n\n````shell\ngit init .\n````\n\n2. ローカルリポジトリ内で以下のコマンドを実行。 gitconfigファイルに `sparsecheckout=true` の1行が追加されます。\n\n````shell\ngit config core.sparsecheckout true\n````\n\n3. .git/info以下にsparse-checkoutという名前のファイルを作成。\n\n````shell\nmkdir .git/info\nvi .git/info/sparse-checkout\n````\n\n4. 必要なファイルやディレクトリを記述していきます。 記述方法は.gitignoreと同じで、ファイル名やディレクトリ名の先頭に「!」を付けると除外指定もできます。\n\n````gitignore\nhoge.txt\n/fuga\n!/fuga/piyO\n````\n\n5. リモートリポジトリを指定します。\n\n````shell\ngit remote add origin XXXX\n````\n\n6. 最後にpull\n\n````shell\ngit pull origin master\n````\n\n## 一部だけを除外したい\n\n一度全体をcheckout対象に含めてから、除外したいものだけを `!` で指定するという方法\n\n\u003chttps://git-scm.com/docs/git-sparse-checkout#_full_pattern_set\u003e\n\nネストすることも可能\n\n````gitignore\n/*\n!unwanted\nunwanted/**/wanted\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["git"]},"/note/go%E3%81%A7DB%E3%81%AB%E7%B5%A1%E3%82%80%E3%83%86%E3%82%B9%E3%83%88%E3%82%92%E3%81%97%E3%81%9F%E3%81%84":{"title":"goでDBに絡むテストをしたい","content":"\n\\#Go\n\n[GolangでDBアクセスがあるユニットテストのやり方を考える - Qiita](https://qiita.com/seya/items/582c2bdcca4ad50b03b7)\n\n* SQLが実行される箇所をmockする(実際にDBに接続してSQLの結果を得る必要がない場合)\n  \n  * sqlmock を使う\n* 実際のDBとテストデータを用意してSQLも実際に実行する\n\n* テスト用DBの用意\n  \n  * \u003chttps://github.com/DATA-DOG/go-txdb\u003e でテストケースごとに独立したトランザクション内でテストデータを用意・Rollbackを行う\n    * \u003chttps://zenn.dev/rinchsan/articles/83cf6f3b5d70c4d9b5d4\u003e\n    * mysql だとnested transactionが使えないからコミットしている場合、Savepointにかえるとかしないと、rollbackできなさそう…？\n    * 毎回deleteする、でもよくない？\n  * \u003chttps://github.com/go-testfixtures/testfixtures\u003e でfixtureを用意する\n  * \u003chttps://github.com/testcontainers/testcontainers-go\u003e や \u003chttps://github.com/ory/dockertest\u003e を利用する\n    * \u003chttps://qiita.com/yasuflatland-lf/items/4f18b55c2a6492d0c462\u003e\n    * Makefileでdocker-compose up してもいいけど、テストコードで書いておくとSkipも可\n* CIではスキップしたい\n\n````go\nfunc skipCI(t *testing.T) {\n  if os.Getenv(\"CI\") != \"\" {\n    t.Skip(\"Skipping testing in CI environment\")\n  }\n}\n\nfunc TestNewFeature(t *testing.T) {\n  skipCI(t)\n}\n````\n\nあるいはshortではスキップにする `go test -short`\n\n````go\nif testing.Short() {\n  t.Skip(\"skipping testing in short mode\")\n}\n````\n\n### dockertestとfixtureを使ったテスト\n\ndockertest を使ってコンテナを起動し、testfixtures でテストデータを流し込む\n\n````go\npackage db_test\n\nimport (\n\t\"database/sql\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/go-testfixtures/testfixtures/v3\"\n\t\"github.com/ory/dockertest/v3\"\n)\n\nvar (\n\tpool     *dockertest.Pool\n\tresource *dockertest.Resource\n\tdb       *sql.DB\n\tfixtures *testfixtures.Loader\n)\n\nfunc prepareTestDatabase() error {\n\tvar err error\n\n\tpool, err = dockertest.NewPool(\"\")\n\t// コンテナの起動に時間がかかるため\n\tpool.MaxWait = 2 * time.Minute\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tbasepath, _ := os.Getwd()\n\n\tuser := \"user\"\n\t// DB名に test が入っていないと、fixtureのload時にエラーになる (https://github.com/go-testfixtures/testfixtures#security-check)\n\tdbName := \"test_db\"\n\n\t// Dockerコンテナ起動時の細かいオプションを指定する\n\trunOptions := \u0026dockertest.RunOptions{\n\t\tRepository: \"mysql\",\n\t\tTag:        \"5.7\",\n\t\tEnv: []string{\n\t\t\tfmt.Sprintf(\"MYSQL_DATABASE=%s\", dbName),\n\t\t\tfmt.Sprintf(\"MYSQL_USER=%s\", user),\n\t\t\tfmt.Sprintf(\"MYSQL_PASSWORD=%s\", user),\n\t\t\t\"MYSQL_ROOT_PASSWORD=secret\",\n\t\t\t\"TZ=Asia/Tokyo\",\n\t\t},\n\t\tMounts: []string{\n\t\t\tbasepath + \"/etc/01_create_table.sql:/docker-entrypoint-initdb.d/01_create_table.sql\",\n\t\t},\n\t\tCmd: []string{\n\t\t\t\"mysqld\",\n\t\t\t\"--character-set-server=utf8\",\n\t\t\t\"--collation-server=utf8_unicode_ci\",\n\t\t},\n\t}\n\n\t// imageをpullして起動する\n\tresource, err = pool.RunWithOptions(runOptions)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// コンテナが起動されたことを確認するためのコマンドを定義\n\tif err := pool.Retry(func() error {\n\t\ttime.Sleep(10 * time.Second)\n\t\terr := connectDb(resource.GetPort(\"3306/tcp\"))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn db.Ping()\n\t}); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc connectDb(port string) error {\n\tdsn := fmt.Sprintf(\"%s:%s@tcp(localhost:%s)/%s?parseTime=true\u0026loc=Asia%%2FTokyo\",\n\t\tuser,\n\t\tuser,\n\t\tport,\n\t\tdbName,\n\t)\n\tvar err error\n\tdb, err = sql.Open(\"mysql\", dsn)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc prepareFixture() error {\n\tvar err error\n\t// fixtureを設定\n\tfixtures, err = testfixtures.New(\n\t\ttestfixtures.Database(db),\n\t\ttestfixtures.Dialect(\"mysql\"),\n\t\ttestfixtures.Directory(\"testdata/fixtures\"), // The directory containing the YAML files\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\nfunc loadFixture() {\n\tif err := fixtures.Load(); err != nil {\n\t\tlog.Fatalf(\"Could not load fixture: %v\", err)\n\t}\n}\n\nfunc clearDb() {\n\tvar err error\n\tif _, err = db.Exec(\"DELETE FROM myroad_t\"); err != nil {\n\t\tlog.Fatalf(\"Could not delete: %v\", err)\n\t}\n\tif _, err = db.Exec(\"DELETE FROM notification_info_t\"); err != nil {\n\t\tlog.Fatalf(\"Could not delete: %v\", err)\n\t}\n\tif _, err = db.Exec(\"DELETE FROM routine_push_time_t\"); err != nil {\n\t\tlog.Fatalf(\"Could not delete: %v\", err)\n\t}\n\tif _, err = db.Exec(\"DELETE FROM send_close_road_regulation_t\"); err != nil {\n\t\tlog.Fatalf(\"Could not delete: %v\", err)\n\t}\n\tif _, err = db.Exec(\"DELETE FROM token_endpoint_arn_t\"); err != nil {\n\t\tlog.Fatalf(\"Could not delete: %v\", err)\n\t}\n}\n\n// テスト時に共通で実行する処理で、DBの用意などを行う\nfunc TestMain(m *testing.M) {\n\tif _, ci := os.LookupEnv(\"SHORT_TEST\"); ci {\n\t\tfmt.Printf(\"short modeのためテストをskipします\")\n\t\treturn\n\t}\n\n\t// テストデータ準備 start\n\tvar err error\n\terr = prepareTestDatabase()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\terr = prepareFixture()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tclearDb()\n\t// テストデータ準備 end\n\n\tcode := m.Run()\n\n\t// You can't defer this because os.Exit doesn't care for defer\n\tif err := pool.Purge(resource); err != nil {\n\t\tlog.Fatalf(\"Could not purge resource: %s\", err)\n\t}\n\n\tos.Exit(code)\n\n}\n\nfunc TestFindUser(t *testing.T) {\n\tgormDb, err := gorm.Open(mysql.New(mysql.Config{\n\t\tConn: db,\n\t}))\n\tif err != nil {\n\t\tt.Fatalf(\"error gorm.Open: %v\", err)\n\t}\n\tgormDb.Logger = gormDb.Logger.LogMode(logger.Info)\n\n\ttype fields struct {\n\t\tnowFactory repository.NowFactory\n\t}\n\ttype args struct {\n\t\tuserIds []string\n\t}\n\n\ttests := []struct {\n\t\tname    string\n\t\tfields  fields\n\t\targs    args\n\t\twant    []mydata\n\t\twantErr bool\n\t}{\n        // テストケース\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tloadFixture()\n\n\t\t\tc := \u0026Client{\n\t\t\t\tdb:         gormDb,\n\t\t\t\tnowFactory: tt.fields.nowFactory,\n\t\t\t}\n\t\t\tgot, err := c.FindUser(tt.args.userIds)\n\n\t\t\tif tt.wantErr {\n\t\t\t\tassert.Error(t, err)\n\t\t\t} else {\n\t\t\t\tassert.NoError(t, err)\n\t\t\t}\n\t\t\tassert.ElementsMatch(t, tt.want, got)\n\n\t\t})\n\t}\n}\n````\n\nfixtures には `テーブル名.yaml` の規則でファイルを置く\n\n`testdata/fixtures/user_t.yaml`\n\n````yaml\n- user_id: \"AAAAAAAxxxx\"\n  name: \"foo\"\n  created_at: 1596715200\n- user_id: \"AAAAAAAyyyy\"\n  name: \"bar\"\n  created_at: 1596815200\n````\n\n## docker-compose.ymlを使ってテストしたい\n\ntestcontainersではdocker-compose.ymlを使ってcomposeを実行できる\n\n````yml:docker-compose.yml\nversion: '3.8'\n\nservices:\n  db:\n    image: mysql:5.7\n    platform: linux/x86_64\n    environment:\n      MYSQL_DATABASE: test_db\n      MYSQL_USER: user\n      MYSQL_PASSWORD: user\n      MYSQL_ROOT_PASSWORD: root\n      TZ: \"Asia/Tokyo\"\n    command: mysqld --character-set-server=utf8 --collation-server=utf8_unicode_ci --default-authentication-plugin=mysql_native_password\n    volumes:\n      - ./sql:/docker-entrypoint-initdb.d\n    ports:\n      - \"3306:3306\"\n````\n\n````go\nimport (\n\t\"database/sql\"\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/docker/go-connections/nat\"\n\t\"github.com/go-testfixtures/testfixtures/v3\"\n\t\"github.com/testcontainers/testcontainers-go\"\n\t\"github.com/testcontainers/testcontainers-go/wait\"\n)\n\nvar (\n\tcompose  *testcontainers.LocalDockerCompose\n\tdb       *sql.DB\n\tfixtures *testfixtures.Loader\n)\n\nfunc prepareContainer(t *testing.T) error {\n\tpwd, _ := os.Getwd()\n\tcomposeFilePaths := []string{pwd + \"/etc/db/docker-compose.yml\"}\n\tidentifier := \"mydb\"\n\n\tcompose = testcontainers.NewLocalDockerCompose(composeFilePaths, identifier)\n\n\tuser := \"user\"\n\t// DB名に test が入っていないと、fixtureのload時にエラーになる (https://github.com/go-testfixtures/testfixtures#security-check)\n\tdbName := \"test_db\"\n\tport := \"3306\"\n\tdsn := fmt.Sprintf(\"%s:%s@tcp(localhost:%s)/%s?charset=utf8\u0026parseTime=true\u0026loc=Asia%%2FTokyo\",\n\t\tuser,\n\t\tuser,\n\t\tport,\n\t\tdbName,\n\t)\n\tdbURL := func(port nat.Port) string {\n\t\treturn dsn\n\t}\n\texecError := compose.\n\t\tWaitForService(\"db\", wait.ForSQL(nat.Port(port), \"mysql\", dbURL)).\n\t\tWithCommand([]string{\"up\", \"-d\"}).\n\t\tInvoke()\n\terr := execError.Error\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Could not run compose file: %v - %v\", composeFilePaths, err)\n\t}\n\n\tdb, err = sql.Open(\"mysql\", dsn)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn db.Ping()\n}\n\nfunc TestSample(t *testing.T) {\n\t// テストデータ準備 start\n\tif testing.Short() {\n\t\tt.Skip(\"skip integration test\")\n\t}\n\tvar err error\n\terr = prepareContainer(t)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer func() {\n\t\tif err := compose.Down().Error; err != nil {\n\t\t\tt.Fatalf(\"Could not purge resource: %v\", err)\n\t\t}\n\t}()\n\t// テストデータ準備 end\n\n\t// ... test\n}\n\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Go"]},"/note/go%E3%81%A7singleton":{"title":"goでsingleton","content":"\n\\#Go\n\n[How singleton pattern works with Golang | by Jefferson Otoni Lima | Golang Issue | Medium](https://medium.com/golang-issue/how-singleton-pattern-works-with-golang-2fdd61cd5a7f)\n[Go 言語における Singleton Pattern | text.Baldanders.info](https://text.baldanders.info/golang/singleton-pattern/)\n\n## よくやるやつ\n\nなにも考えずにつくるとこうなる\n\n````go\nvar instance *Config\n\nfunc GetInstance() *Config {\n    if instance == nil {\n        instance = \u0026Config{}\n    }\n    return instance\n}\n````\n\nこれはスレッドセーフではないので、instanceの生成処理に時間がかかる場合にgoroutineなどで同時にアクセスすると、\n複数回生成実行される\n\n=\u003e Singletonでない\n\n## 解決策\n\n`sync.Once` か `sync.Mutex` を使うといい\n\n````go\nvar instance *Config\nvar once sync.Once\n\nfunc GetInstance() *Config {\n\tonce.Do(func() {\n\t\tinstance = NewConfig()\n\t})\n\treturn instance\n}\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Go"]},"/note/go%E3%81%AElint%E3%81%ABstaticcheck%E3%82%92%E4%BD%BF%E3%81%86":{"title":"goのlintにstaticcheckを使う","content":"\n\u003chttps://blog.cybozu.io/entry/2021/02/26/081013\u003e\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/go%E8%A4%87%E6%95%B0%E3%83%90%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%99%E3%82%8B":{"title":"go複数バージョンをインストールする","content":"\n\u003chttps://kazuhira-r.hatenablog.com/entry/2021/02/23/200101\u003e\n\n\u003chttps://golang.org/doc/manage-install\u003e\n\n## インストール\n\n````shell\n$ go get golang.org/dl/go1.10.7\n$ go1.10.7 download\n````\n\n## アンインストール\n\n````shell\n$ rm $HOME/go/bin/go1.10.7\n$ rm -rf $HOME/sdk/go1.10.7\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/go-%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%A0%E3%82%A8%E3%83%A9%E3%83%BC":{"title":"go カスタムエラー","content":"\n[Go](note/Go.md) でカスタムエラーを作る\n\n[aws-sdk-go-v2 でのエラーハンドリング](note/aws-sdk-go-v2%20でのエラーハンドリング.md)\nhttps://github.com/aws/aws-sdk-go-v2/issues/1110\n\n````go\nif err != nil {\n    var myerr *MyError\n    if errors.As(err, \u0026myerr) {\n        return nil, ErrHoge\n    }\n    return nil, err\n}\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Go"]},"/note/go-%E3%83%A2%E3%82%B8%E3%83%A5%E3%83%BC%E3%83%AB%E3%81%AE%E3%82%BF%E3%82%B0%E3%82%92%E5%88%A5%E3%81%AE%E3%82%B3%E3%83%9F%E3%83%83%E3%83%88%E3%83%8F%E3%83%83%E3%82%B7%E3%83%A5%E3%81%AB%E3%81%A4%E3%81%91%E7%9B%B4%E3%81%97%E3%81%9F%E3%82%89cache%E3%81%8C%E6%AE%8B%E3%81%A3%E3%81%A6%E3%81%84%E3%81%A6%E3%83%91%E3%83%83%E3%82%B1%E3%83%BC%E3%82%B8%E3%81%86%E3%81%BE%E3%81%8F%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%82%81%E3%81%AA%E3%81%8B%E3%81%A3%E3%81%9F":{"title":"go モジュールのタグを別のコミットハッシュにつけ直したらcacheが残っていてパッケージうまく読み込めなかった","content":"\nそもそもそんなことしないほうがいいというのは承知で、開発中のパッケージなどでタグをうちまちがえたので修正したところ新しいコミットがダウンロードされなかった。\n\n## 手順\n\n* モジュールAのコミットAにtag v1.0.0をつけてpush\n* モジュールAを使っているリポジトリで `go get ~~~@v1.0.0`\n* モジュールAでファイル追加してコミットする(コミットB)\n* v1.0.0を消してコミットBにv1.0.0をつけなおしてpush\n* 再度 `go get ~~~@v1.0.0` したが変更がないためダウンロードしてくれなかった\n\n## 解消方法\n\n* `go clean -modcache` でクリアして、go.sumに書いてあるハッシュも消してから go get\n* `~/go/pkg/mod` にファイルがダウンロードされて、先程追加したファイルも存在することを確認\n\nしかしこれだけでは足りなかった。\ngo buildしたところ、モジュールの修正が反映されていなくて、たとえば追加したstructを使っている箇所でビルドエラーとなる。\nまだキャッシュが残っているみたい。\n\n`go clean -modcache` で `~/go/pkg/mod` が消えたのでいいと思ったが、\n`go clean -cache` で `go env GOCACHE` にあるビルドキャッシュなども消さないといけなかった\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/05/18","Go"]},"/note/go-1.19%E3%82%A2%E3%83%83%E3%83%97%E3%83%87%E3%83%BC%E3%83%88%E5%86%85%E5%AE%B9":{"title":"go 1.19アップデート内容","content":"\n[Go Memory Modelを読む【入門編】 - Google スライド](https://docs.google.com/presentation/d/1jJvL__7VYHs4Qv-mGsuAThXpWiSpek27wXln9K2PVJU)\n[What is Soft Memory Limit? - Speaker Deck](https://speakerdeck.com/yagipy/what-is-soft-memory-limit)\n[\\[shared\\] 20220815 What's new in Go 1.19? - Google スライド](https://docs.google.com/presentation/d/1FkXdI9oR8mUCzh-woca7O3K_T5iZCirp7QcoJY3d4Wk)\n[Go1.19で採用された Pattern-defeating Quicksort の紹介 - Speaker Deck](https://speakerdeck.com/po3rin/go1-dot-19decai-yong-sareta-pattern-defeating-quicksort-falseshao-jie)\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Go"]},"/note/go-install%E3%81%A7tools.go%E3%82%92%E6%8E%92%E9%99%A4":{"title":"go-installでtools.goを排除","content":"\n\\#Go\n\n\u003chttps://zenn.dev/tarotaro0/articles/1d5bf3e32d5ef2\u003e\n\n[note/Go](Go.md) ではnpmのdevdependenciesの仕組みがないため、通常だとgo.modから消えてしまう\n\nそこで、これらのツールをmoduleによって管理するために、`tools.go`を用いる方法が[公式のgo wikiでも紹介されている](https://github.com/golang/go/wiki/Modules#how-can-i-track-tool-dependencies-for-a-module)。\n\n````go\n// +build tools\n\npackage tools\n\nimport (\n\t// Tools we use during development.\n\t_ \"golang.org/x/lint/golint\"\n\t_ \"honnef.co/go/tools/cmd/staticcheck\"\n)\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/go-jira%E3%82%92%E3%81%A4%E3%81%8B%E3%81%A3%E3%81%9Fjira%E3%81%AE%E6%93%8D%E4%BD%9C":{"title":"go-jiraをつかったjiraの操作","content":"\n\\#jira\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/go-task%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6GoEcho%E3%81%AE%E7%92%B0%E5%A2%83%E3%81%A7%E3%83%9B%E3%83%83%E3%83%88%E3%83%AA%E3%83%AD%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B":{"title":"go-taskを使ってGo,Echoの環境でホットリロードする","content":"\n\\#Go\n\nGoのホットリロードはRealizeやAirを使っていたが、[go-task](https://github.com/go-task/task) がいい感じにMakefileを置き換えてくれてホットリロードも実現できるので使ってみた。\n\n[go-taskでサーバーのライブリロードを実現する - Qiita](https://qiita.com/croquette0212/items/dab91c1075c1f3ac7b8d)\n\nwatch機能があり、 `sources` で指定したファイルに変更があった場合にリロードしてくれる。\n\n````shell\ntask -w \u003cTASK\u003e\n````\n\nこれだけだと、起動済みサーバーを終了してから再起動とはならないので、PIDを保存しておいてSIGTERMでkillする\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Go"]},"/note/go_context%E3%81%AE%E3%82%BF%E3%82%A4%E3%83%A0%E3%82%A2%E3%82%A6%E3%83%88%E3%81%A8%E3%82%AD%E3%83%A3%E3%83%B3%E3%82%BB%E3%83%AB":{"title":"go_contextのタイムアウトとキャンセル","content":"\n\\#Go \n\n[Goのcontextによるキャンセルやタイムアウト - oinume journal](https://journal.lampetty.net/entry/cancel-and-timeout-with-context-in-go)\n[context.WithCancel, WithTimeout で知っておいた方が良いこと - Carpe Diem](https://christina04.hatenablog.com/entry/tips-for-context-with-cancel_1)\n\n````go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tif err := printHello(ctx); err != nil {\n\t\t\tfmt.Printf(\"cannot print greeting: %v\\n\", err)\n\t\t\treturn\n\t\t}\n\t}()\n\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tif err := printGoodbye(ctx); err != nil {\n\t\t\tfmt.Printf(\"cannot print goodbye: %v\\n\", err)\n\t\t\treturn\n\t\t}\n\t}()\n\n\twg.Wait()\n}\n\nfunc printHello(ctx context.Context) error {\n\tctx, cancel := context.WithTimeout(ctx, 4*time.Second)\n\tdefer cancel()\n\n\tswitch _, err := communicate(ctx); {\n\tcase err != nil:\n\t\treturn err\n\t}\n\tfmt.Printf(\"%s world!\\n\", \"hello\")\n\treturn nil\n}\n\nfunc printGoodbye(ctx context.Context) error {\n\tctx, cancel := context.WithTimeout(ctx, 2*time.Second)\n\tdefer cancel()\n\n\tswitch _, err := communicate(ctx); {\n\tcase err != nil:\n\t\treturn err\n\t}\n\tfmt.Printf(\"%s world!\\n\", \"goodbye\")\n\treturn nil\n}\n\nfunc communicate(ctx context.Context) (string, error) {\n    // n秒後に処理を継続\n\tselect {\n\tcase \u003c-ctx.Done():\n\t\treturn \"\", ctx.Err()\n\tcase \u003c-time.After(5 * time.Second):\n\t\t//fmt.Printf(\"1 second elapsed\\n\")\n\t}\n\treturn \"handshake\", nil\n}\n````\n\n* `communicate` を5秒(タイムアウト値より長い)にする → タイムアウトして `cannot print greeting: deadline exceeded`\n* `communicate` を3秒(helloのタイムアウト値より短い、goodbyeのタイムアウト値より長い)にする → helloは完了するがgoodbyeはタイムアウトする\n* `communicate` を1秒(タイムアウト値より短い)にする → 両方完了する\n\n## 親のcontextをキャンセルすると、子のcontextもキャンセルされる\n\n````go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tif err := printHello(ctx); err != nil {\n\t\t\tfmt.Printf(\"cannot print greeting: %v\\n\", err)\n            cancel()\n\t\t\treturn\n\t\t}\n\t}()\n\n\twg.Add(1)\n\tgo func() {\n\t\tdefer wg.Done()\n\t\tif err := printGoodbye(ctx); err != nil {\n\t\t\tfmt.Printf(\"cannot print goodbye: %v\\n\", err)\n\t\t\treturn\n\t\t}\n\t}()\n\n\twg.Wait()\n}\n\nfunc printHello(ctx context.Context) error {\n\tctx, cancel := context.WithTimeout(ctx, 2*time.Second)\n\tdefer cancel()\n\n\tswitch _, err := communicate(ctx); {\n\tcase err != nil:\n\t\treturn err\n\t}\n\tfmt.Printf(\"%s world!\\n\", \"hello\")\n\treturn nil\n}\n\nfunc printGoodbye(ctx context.Context) error {\n\tctx, cancel := context.WithTimeout(ctx, 4*time.Second)\n\tdefer cancel()\n\n\tswitch _, err := communicate(ctx); {\n\tcase err != nil:\n\t\treturn err\n\t}\n\tfmt.Printf(\"%s world!\\n\", \"goodbye\")\n\treturn nil\n}\n\nfunc communicate(ctx context.Context) (string, error) {\n    // n秒後に処理を継続\n\tselect {\n\tcase \u003c-ctx.Done():\n\t\treturn \"\", ctx.Err()\n\tcase \u003c-time.After(5 * time.Second):\n\t\t//fmt.Printf(\"1 second elapsed\\n\")\n\t}\n\treturn \"handshake\", nil\n}\n````\n\n=\u003e printHelloがタイムアウト → 親の `cancel()` を実行 → 子の `ctx.Done()` が実行されてprintGoodbyeも終了する\n\n````\ncannot print greeting: context deadline exceeded\ncannot print goodbye: context canceled\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/go_httpClient%E3%82%92%E3%83%86%E3%82%B9%E3%83%88%E3%81%99%E3%82%8B":{"title":"go_httpClientをテストする","content":"\n\\#Go\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/go_install":{"title":"go_install","content":"\n\\#Go \n\n# go install\n\ngo 1.16から、グローバルにインストールする機能が追加された\n\nいままでgo.modのないディレクトリに移動して\n\n````shell\nGOMODULE111=off go get github.com/xxx\n````\n\nとかやってたのを、\n\n````shell\ngo install github.com/xxx@latest\n````\n\nで$GOPATH/binにインストールされるようになった\n\n## go clean\n\n`-i` で go install で作られたものを削除する\n\n### 削除前にコマンドを確認する\n\n````bash\ngo clean -i -n github.com/sample_user/sample\n````\n\n### 削除する\n\n````bash\ngo clean -i github.com/sample_user/sample\n````\n\nsrc配下に残っているものは消えないので、手動で対象ディレクトリをまるごと削除する\n\n````bash\nrm -rf $GOPATH/src/github.com/sample_user/sample\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/go_json%E3%81%ABmap%E3%82%92marshal%E3%81%99%E3%82%8B":{"title":"go_jsonにmapをmarshalする","content":"\n\\#Go\n\n`map[string]interface{}` をmarshal,unmarshalできる\n\n````go\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n)\n\ntype required struct {\n\tName string\n\tAge  int\n}\ntype param struct {\n\trequired\n\tOption map[string]interface{}\n}\n\nfunc main() {\n\tjs := `{\n\t\t\t\"name\": \"John\",\n\t\t\t\"age\": 25,\n\t\t\t\"option\": {\n\t\t\t\t\"address\": {\n\t\t\t\t\t\"postal\": 1555555,\n\t\t\t\t\t\"name\": \"X-X-X\"\n\t\t\t\t},\n\t\t\t\t\"height\": 172\n\t\t\t}\n\t\t}`\n\n\tvar param param\n\terr := json.Unmarshal(js, \u0026param)\n\tif err != nil {\n\t\tfmt.Printf(\"%v\", err)\n\t\treturn\n\t}\n}\n````\n\n必須パラメータを埋め込みにしてみた\n\n## オプションのキーをフラットにしたい\n\n上の例では、 `option`のキーにオプションのパラメータを詰めたことで `option: map[string]interface{}` にmarshalできた。\n以下のようなJSONはmarshalできるか？\n\n````json\n{\n  \"name\": \"John\",\n  \"age\": 25,\n  \"address\": {\n    \"postal\": 1555555,\n    \"name\": \"X-X-X\"\n  },\n  \"height\": 172\n}\n````\n\n[dictionary - How to embed a map into a struct so that it has a flat json representation - Stack Overflow](https://stackoverflow.com/questions/31036343/how-to-embed-a-map-into-a-struct-so-that-it-has-a-flat-json-representation)\n\n \u003e \n \u003e The short answer is no. The language does not allow you to embed either type (slice or map) in a struct.  \n \u003e Just use a `map[string]interface{}`. Deal with the fact that the values for \"key1\" and \"key2\" are strings and everything else is a float somewhere else. That's really the only way you're getting that output. You can make the problem as complicated as you'd like beyond this (like transform into a type more like yours or something) but if you're averse to implementing `MarshalJSON` the only model which will produce the results you want is `map[string]interface{}`\n\nその場合は単に `map[string]interface{}` にするくらい\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Go"]},"/note/go_mockery":{"title":"go_mockery","content":"\n[go_testifyを使う](note/go_testifyを使う.md) でtestify/mockを使ったが、\nmockを手で作成するのは骨が折れる\n\nそこでtestifyのmock生成には [mockery](https://github.com/vektra/mockery) を使うと便利\n\n## インストール\n\ndockerやbrewでもインストールできる。`go install` で入れる場合は以下\n\n````shell\ngo install github.com/vektra/mockery/v2@latest\n````\n\n## gomockとの比較\n\nmockライブラリといえば [gomock](https://github.com/golang/mock) も有名\n\ntestifyを使わない場合はこちらでもいいと思う\n\n## 余談\n\n一時期メンテナンスされていなかったが、引き継いだメンテナがいて開発再開された。\n\nhttps://github.com/vektra/mockery/issues/237#issuecomment-622492842\n\n今はv2だが、[v3対応中](https://github.com/vektra/mockery#v3)らしい\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Go","unittest"]},"/note/go_testify%E3%82%92%E4%BD%BF%E3%81%86":{"title":"go_testifyを使う","content":"\n\\#Go\n\n## testify\n\n\u003chttps://github.com/stretchr/testify\u003e\n\nassert, mock, suiteなど、テストに便利な機能を提供するライブラリ\n\nGoには標準で `testing` ライブラリが備わっていて、標準で十分な場面もあるが、\nある程度大きなプロジェクトになってくるとやはり物足りなくなってくる\n\n## assert\n\nライブラリをimportする\n\n````go\nimport (\n    \"testing\"\n    \"github.com/stretchr/testify/assert\"\n)\n````\n\n`assert.\u003cアサーション関数\u003e(testing.T, 期待値, 実際の値)`\n\n````go\nfunc TestSomething(t *testing.T) {\n  assert.Equal(t, 123, 123, \"等しい\")\n  assert.NotEqual(t, 123, 456, \"等しくない\")\n  var obj *object = nil\n  assert.Nil(t, obj)\n  \n  obj = \u0026object{\n    Value: \"Something\",\n  }\n  if assert.NotNil(t, obj) {\n    assert.Equal(t, \"Something\", obj.Value)\n  }\n  \n  actualObj, err := SomeFunction()\n  // errors.Is を使った比較\n  assert.ErrorIs(t, expectedError, err)\n\n}\n````\n\n## mock\n\n通信やDBをmockする機能が用意されている。\n\n### テスト対象\n\n例として以下のインターフェースをmockする\n\n````go\ntype ItemRepository interface {\n    Get(id int) (string, error)\n}\n````\n\n````go\ntype Item struct {\n    repo ItemRepository\n}\n\nfunc (i *Item) Name(id int) (string, error) {\n    name, err := i.repo.Get(id)\n    if name == nil || err != nil {\n        return \"\", err\n    }\n    return name, nil\n}\n````\n\n### モック作成\n\n* メソッド内でCalledメソッドを実行し、retを取得\n* ret.Get(戻り値のindex)をメソッドの戻り値とする\n  * 戻り値がエラーの場合はret.Error(戻り値のindex)\n\n````go\nimport mock \"github.com/stretchr/testify/mock\"\n\n// mock.Mockを埋め込む\ntype MockItemRepository struct {\n    mock.Mock\n}\n\n// インターフェースを実装\nfunc (_m *MockUserInterface) Get(id int) (string, error) {\n    ret := _m.Called(id)\n    return ret.Get(0).(string), ret.Error(1)\n}\n\n````\n\nmockを毎回手で書くのは大変なので、mockeryを使うと便利 [go_mockery](note/go_mockery.md)\n\n### テスト実行\n\n1. モックの期待引数、戻り値を設定\n1. テスト対象にモックを注入\n1. テスト実行(内部でモック実行)\n1. mockの実行回数をassert\n\n````go\nfunc TestItem(t *testing.T) {\n    expected := \"みかん\"\n\n    // モック\n    mockRepo := new(MockItemRepository)\n    // モックの戻り値を設定\n    mockRepo.\n        On(\"Get\", 1).\n        Return(expected, nil)\n\n    // テスト対象(モックを注入)\n    i := \u0026Item{\n        repo: mockRepo,\n    }\n    // テスト実行(内部でモック実行されて記録される)\n    got, err := i.Name(1)\n    assert.Error(t, err)\n    \n    // 少なくとも一回呼び出されたことを確認する\n    mockRepo.AssertExpectations(suite.T())\n    // 回数をassertしたい場合\n    mockRepo.AssertNumberOfCalls(suite.T(), \"Get\", 1)\n    // 一回も呼び出されていないことを確認する場合\n    // mockRepo.AssertNotCalled(suite.T(), \"Get\", 1)\n}\n````\n\n## suite\n\n各test前後に\n\n````go\npackage main\n\nimport (\n    \"os\"\n    \"testing\"\n    \n    \"github.com/stretchr/testify/assert\"\n    \"github.com/stretchr/testify/suite\"\n)\n\ntype MyTestSuiteStruct struct {\n    suite.Suite\n}\n\n// 各testの前に実行される\nfunc (suite *MyTestSuiteStruct) SetupTest() {\n    os.Setenv(\"HELLO\", \"WORLD\")\n}\n\n// 各testの後に実行される\nfunc (suite *MyTestSuiteStruct) TearDownTest() {\n\tos.Clearenv()\n}\n\n// 各テストは \"Test\" で始まる必要がある\nfunc (suite *MyTestSuiteStruct) TestHello() {\n    // *testing.T の代わりに suite.T() を使う\n    assert.Equal(suite.T(), 1, 1)\n    assert.Equal(suite.T(), \"WORLD\", os.Getenv(\"HELLO\"))\n}\n\n// 'go test' でsuiteを実行するために、*testing.Tを引数にもつ通常のテストを作って\n// suite.Runを実行する\nfunc TestMyTestSuite(t *testing.T) {\n    suite.Run(t, new(MyTestSuiteStruct))\n}\n````\n\n各テスト前後にそれぞれ、 `SetupTest()` と `TearDownTest()` が実行される。\n下記のインターフェースをそれぞれ実装することで実行される仕組みとなっている。\n\n````go\ntype SetupTestSuite interface {\n    SetupTest()\n}\n\ntype TearDownTestSuite interface {\n    TearDownTest()\n}\n````\n\n他にもテスト全体の前後に一回実行される処理も定義することができる。\n[こちらを参照](https://pkg.go.dev/github.com/stretchr/testify/suite)\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/gomplate":{"title":"gomplate","content":"\n\\#Go\n\nhttps://docs.gomplate.ca/installing/\n\ngoのテンプレートエンジン\n\n使い方\n\n````shell\n$ echo 'My voice is my {{.Env.THING}}. {{(datasource \"vault\").value}}' \\\n  | docker run -i -e THING=passport -v /home/me/.vault-token:/root/.vault-token hairyhenderson/gomplate -d vault=vault:///secret/sneakers -f -\nMy voice is my passport. Verify me.\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Go"]},"/note/hubs_cloud":{"title":"hubs_cloud","content":"\n# hubs_cloud\n\nVR空間をデプロイできる\n\n## リンク\n\n* [公式](https://hubs.mozilla.com/cloud)\n* [AWS Marketplace](https://aws.amazon.com/marketplace/pp/B084WNGRRP)\n* [日本語で試した人](https://mitomemel.hatenablog.com/entry/2020/05/09/120007)\n\n## ユーザー制限\n\n* \u003chttps://hubs.mozilla.com/docs/hubs-faq.html#can-i-prevent-unregistered-attendees-from-attending-my-event\u003e\n  * 招待URLからのアクセスのみに絞ることは hubs.mozilla.com でもできる\n  * 承認済みユーザーのみに絞るにはHubs Cloud\n* \u003chttps://hubs.mozilla.com/docs/hubs-cloud-limiting-user-access.html\u003e\n  * you can create accounts for a list of emails or disable existing accounts\n  * Discord Bot OAuth もあるらしい\n\n## 構成\n\n\u003chttps://hubs.mozilla.com/docs/hubs-cloud-aws-architecture.html\u003e\n\n* EC2\n\n## コスト\n\n* \u003chttps://hubs.mozilla.com/docs/hubs-cloud-aws-estimated-cost-charts.html\u003e\n  * ccu(concurrent users)に応じてインスタンスタイプの目安決まる\n* \u003chttps://hubs.mozilla.com/docs/hubs-cloud-aws-costs.html\u003e\n  * Personal vs Enterprise\n    * サーバーが1台のみか、1台or複数台数が選べるかの違い\n    * multi serversの場合は2 app x 2 streamの4台が推奨\n* \u003chttps://hubs.mozilla.com/docs/hubs-cloud-aws-costs.html#minimize-your-costs---a-user-story\u003e\n  * 普段はオフラインにする\n  * database pausingをONにする\n  * CDNにCloudflare workerをつかう\n  * イベント開始1.5H前にオンラインにする(起動に10分くらいかかる)、インスタンスタイプを上げる\n* \u003chttps://hubs.mozilla.com/docs/hubs-cloud-aws-costs.html#factors-creating-aws-cost-estimates\u003e\n  * AWS Server Type on AWS EC2 instances\n  * Number of servers\n  * Database usage (Aurora serverless)\n  * Storage for 3D assets for scenes and avatars (EFS)\n  * Data transfer costs (Cloudfront)\n  * Domain costs ($ 1 per domain/mo.) +  $0.40/mo for the database secrets\n* \u003chttps://hubs.mozilla.com/docs/hubs-cloud-aws-costs.html#offline-mode---manual\u003e\n  * offlineモード\n  * EC2とDBのコストはゼロになる\n  * backupとdataを保管するためのStorage料金のみ\n* \u003chttps://hubs.mozilla.com/docs/hubs-cloud-aws-estimated-ccu-limits.html\u003e\n  * 接続可能数\n\n## カスタマイズ\n\n* \u003chttps://hubs.mozilla.com/docs/hubs-cloud-customizing-look-and-feel.html\u003e\n  * 企業ロゴ、テーマなどを設定できる\n\n## セットアップ\n\n\u003chttps://hubs.mozilla.com/docs/hubs-cloud-getting-started.html\u003e\n\u003chttps://hubs.mozilla.com/docs/hubs-cloud-aws-quick-start.html\u003e\n\n### ドメイン\n\n\u003chttps://hubs.mozilla.com/docs/hubs-cloud-aws-domain-recipes.html\u003e\n\n \u003e \n \u003e To make HC set up easier, we recommend setting up your domain's nameservers to point to AWS Route 53 as the hosting/DNS provider (AWS Route 53 Hosted Zones)\n\n* Route53でドメインを2個買うのが一番手っ取り早いっぽい？\n  \n  * \n     \u003e \n     \u003e we recommend setting up your domain's nameservers to point to AWS Route 53 as the hosting/DNS provider\n  \n  * nameserverをRoute53に設定すればよさそう\n* USING the domains already? Already hosting something and can't change nameservers? Then use Recipe 3 for deployment\n  \n  * Route53以外でも一応できる\n  * OR you have a SECOND LEVEL domain that is \".co.uk\" or \".com.fr\", there's a known bug that you need to follow the Recipe 3 for these domains.\n  * セカンドレベルドメインで使いたければ専用の手順へ\n* Recipe 1: Route53でルートドメインを持っている場合\n  \n  * `myhub.com` または `hubs.myhub.com` をHubsに使える\n  * CFnがroot domain (myhub.com) の操作をする\n  * `myhub.com` がほかの用途に使われていない\n  * `anothersubdomain.myhub.com` が任意の用途に使える\n* Recipe 2: Route53にルートドメインがすでにあって、サブドメイン使う場合\n  \n  * セカンドレベルドメイン(.co.jp)の場合はバグがあって使えないのでRecipe 3 へ\n  * mysite.com - Houses subdomain as Hub site domain name + the other sites or purposes at the root\n  * myhub.link - Short link domain name\n  * mysite-internal.com - Internal server domain. This can be any name you want, and will not be seen by users.\n* Recipe 3: Route53にドメインを作れない場合\n  \n  * mysite.com CAN NOT be set up on Route 53\n  * mysite.com connects to your hub OR hub.mysite.com connects to your hub\n  * myhub.link - Short link domain name\n  * mysite-internal.com - Internal server domain + email domain. This can be any name you want, and will not be seen by users.\n  * (optional) mysite-mail.com - Email domain, if using mysite-internal.com for emails is not what you want.\n\n## セットアップ後\n\n\u003chttps://hubs.mozilla.com/docs/hubs-cloud-aws-updating-the-stack.html\u003e\n\n* CloudFormationからstackをアップデート\n* オフラインにしたりDBのauto-posingを切り替えたり\n\n## 日本語化\n\n\u003chttps://mitomemel.hatenablog.com/entry/2020/05/09/120007\u003e\n\u003chttps://hubs.mozilla.com/docs/hubs-cloud-custom-clients.html\u003e\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/img%E3%82%BF%E3%82%B0%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%8C404%E3%81%AE%E3%81%A8%E3%81%8D%E3%81%AB%E4%BB%A3%E6%9B%BF%E7%94%BB%E5%83%8F%E3%82%92%E8%A1%A8%E7%A4%BA%E3%81%99%E3%82%8B":{"title":"imgタグで画像が404のときに代替画像を表示する","content":"\n[HTML img タグで画像が 404 エラーのときに代替画像を表示する方法 - to-me-mo-rrow - 未来の自分に残すメモ -](https://r17n.page/2019/11/23/html-alt-image-when-404-error-on-img-tag/)\n\n## TL;DR\n\n* `onerror=\"this.src = 'alt.png'; this.removeAttribute('onerror')\"` を指定\n  * エラー時には代替画像を読み込んで、`onerror` 属性自身も削除\n* `onload=\"this.removeAttribute('onerror'); this.removeAttribute('onload');` も一緒に指定\n  * エラー無し時に `onerror`, `onload` 属性を消せる\n* 上記をまとめると以下\n\n````html\n\u003cimg src=\"404.png\"  \n onerror=\"this.src='alt.png'; this.removeAttribute('onerror'); this.removeAttribute('onload');\"  \n onload=\"this.removeAttribute('onerror'); this.removeAttribute('onload');\"  \n\u003e\n````\n\nhttps://developer.mozilla.org/ja/docs/Web/HTML/Element/img#browser_compatibility\nonerrorは非推奨なことに留意する\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["frontend"]},"/note/jenkins":{"title":"Jenkins","content":"\nJava製のCI/CDツール\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/04/30","Jenkins"]},"/note/jenkins%E3%81%AE%E8%A6%8B%E3%81%9F%E7%9B%AE%E3%82%92%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%9E%E3%82%A4%E3%82%BA":{"title":"jenkinsの見た目をカスタマイズ","content":"\n[note/Jenkins](Jenkins.md) のデフォルトの見た目は古臭いので、好きなテーマに変更する。\nまた、環境ごとの違いをひと目でわかりやすくすることで事故を防ぐ。\n\n## jenkins-material-theme をダウンロード\n\n\u003chttp://afonsof.com/jenkins-material-theme/\u003e\nから色とロゴを指定してテーマをダウンロードする。\n\n## プラグインを設定\n\n\\[Jenkinsの管理\\] -\u003e \\[プラグインの管理\\] -\u003e \\[利用可能\\] -\u003e [Simple Theme Plugin](https://plugins.jenkins.io/simple-theme-plugin/) をインストール\n\nダウンロードしたスタイルシートのファイル（jenkins-material-theme.css）を Jenkins フォルダの userContent フォルダへ配置する\n\n* Jenkinsを置いてあるサーバにSSHログイン\n* /ドキュメントルート/userContent/jenkins-material-theme.css\n\nJenkinsの管理のシステムの設定でダウンロードしたテーマを指定する。\n\nURL of theme CSS: `/userContent/jenkins-material-theme.css`\n\n## material-theme を適用したときに、pipelineエディタでカーソル位置と実際に編集される位置がずれる\n\n`:not(div.ace_editor)` に `font-family: Roboto, sans-serif!important` が設定されているため等幅フォントになっていない。\n\n[Main Script -- Replay -- the cursor in the editor is out of phase · Issue #184 · afonsof/jenkins-material-theme](https://github.com/afonsof/jenkins-material-theme/issues/184)\n\n等幅フォントを設定してあげればよい。\n自分でカスタマイズできるのが利点\n\n````css:jenkins-material-theme.css\n#main-panel\u003epre *,\n.ace_editor .ace_scroller .ace_content * {\n  font-family: Roboto Mono, monospace !important;\n}\n\ndiv.ace_editor.ace-tomorrow,\ndiv.ace_editor.ace-tomorrow * {\n  font: 12px/normal Roboto Mono, monospace !important;\n}\n````\n\n## 参考\n\n[Jenkinsのテーマ(UI)を変えてみた | レコチョクのエンジニアブログ](https://techblog.recochoku.jp/2021)\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Jenkins"]},"/note/jenkins%E3%81%AEEC2Slave%E3%81%AE%E5%88%9D%E6%9C%9F%E5%8C%96":{"title":"jenkinsのEC2Slaveの初期化","content":"\nJenkins EC2 は init scriptの他にUser dataでも初期化処理をかける\n\nこうかくと、yum updateされる\n\n````txt\n#cloud-config\ntimezone: \"Asia/Tokyo\"\nrepo_update: true\nrepo_upgrade: all\n````\n\nこれはそもそもAmazon EC2の機能でcloud initによる初期処理を行っている\n\n\u003chttps://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/user-data.html\u003e\n\u003chttps://aws.amazon.com/jp/premiumsupport/knowledge-center/execute-user-data-ec2/\u003e\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Jenkins"]},"/note/jenkins%E3%81%AEslave%E3%81%8B%E3%82%89ssh%E5%85%AC%E9%96%8B%E9%8D%B5%E8%AA%8D%E8%A8%BC%E3%81%8C%E3%81%86%E3%81%BE%E3%81%8F%E8%A1%8C%E3%81%8B%E3%81%AA%E3%81%8B%E3%81%A3%E3%81%9F":{"title":"jenkinsのslaveからssh公開鍵認証がうまく行かなかった","content":"\n# jenkins ssh\n\n考えてみたら当たり前って感じだけど、Slaveに鍵を置いていない場合、slaveからsshすることができない\n\n## 解決方法\n\n* 認証情報にJenkinsのssh鍵を設定\n\n* ビルドの設定で、 `秘密テキストや秘密ファイルを使用する` にチェックして設定\n  \n  ````\n  SSH User Private Key\n                \n  Key File Variable: SSH_KEY\n  認証情報: 上記で設定した認証情報を選択\n  ````\n\n* シェル実行時に鍵ファイルを指定\n  \n  ````\n  ssh -i ${SSH_KEY} -o StrictHostKeyChecking=no \u003cuser\u003e@\u003chost\u003e \u003csome command\u003e\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Jenkins"]},"/note/jenkins%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC%E3%81%ABbrew%E3%82%92%E5%85%A5%E3%82%8C%E3%81%9F%E3%81%8Cpath%E3%81%8C%E8%AA%8D%E8%AD%98%E3%81%95%E3%82%8C%E3%81%AA%E3%81%84":{"title":"jenkinsサーバーにbrewを入れたがpathが認識されない","content":"\n## トラブルシュート\n\n### PATHが認識されない\n\nJenkinsの管理 -\u003e システムの設定 -\u003e グローバルプロパティにPATHを設定してもうまく設定されない\n\n````\nキー: PATH\n値: /usr/local/bin:$PATH\n````\n\nではなく\n\n````\nキー: PATH+EXTRA\n値: /usr/local/bin\n````\n\nとする。EXTRAの部分はなんでもいいみたい\n\n\u003chttps://ikesyo.hatenablog.com/entry/2018/03/27/191317\u003e\n\u003chttps://issues.jenkins.io/browse/JENKINS-41339\u003e\n\n### linuxbrewで入れたコマンドが実行できない\n\n下記の通り入れたがpathが通っていない\n\n````\nキー: PATH+EXTRA\n値: /home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin\n````\n\njenkinsジョブで実行\n\n````bash\necho $PATH\n# =\u003e `/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin:/sbin:/bin:/usr/sbin:/usr/bin`\n````\n\n````bash\nls -al /home\ntotal 0\ndrwxr-xr-x  3 root     root      22 Dec 16  2019 .\ndr-xr-xr-x 18 root     root     257 Dec 16  2019 ..\ndrwx------  5 ec2-user ec2-user 196 Dec  9 13:12 ec2-user\n````\n\nssh でjenkinsユーザーでログインすると見えるがジョブからは見えない\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Jenkins"]},"/note/jenkins-JobDSL%E3%81%A7closure%E5%86%85%E3%81%8B%E3%82%89function%E3%82%92%E5%91%BC%E3%81%B6":{"title":"jenkins JobDSLでclosure内からfunctionを呼ぶ","content":"\n[Jenkins Job DSL Plugin](note/Jenkins%20Job%20DSL%20Plugin.md) でいい感じに書くためのテクニック\n\n素直に書いた場合は以下のようにそれぞれにジョブの定義を書くことになるが、共通化したい部分が出てくることがある。\n\n````groovy\nCREDENTIAL_ID = 'secret_key'\nREPO_URL = 'https://example.com/repo.git'\n\npipelineJob(\"build-A\") {\n  parameters {\n    choiceParam(\"STAGE\", [\"stage1\", \"stage2\"], \"\")\n  }\n\n  description('ビルドします')\n  logRotator {\n    numToKeep(5)\n  }\n  definition {\n    cpsScm {\n      scm {\n        git {\n          remote {\n            url(REPO_URL)\n            credentials(CREDENTIAL_ID)\n          }\n        }\n      }\n      lightweight(true)\n      scriptPath(jenkinsfilePath)\n    }\n  }\n}\n\npipelineJob(\"build-B\") {\n  parameters {\n    choiceParam(\"ENV\", [\"dev1\", \"dev2\"], \"\")\n  }\n\n  // ↓ここから同じ記述なので共通化したい\n  description('ビルドします')\n  logRotator {\n    numToKeep(5)\n  }\n  definition {\n    cpsScm {\n      scm {\n        git {\n          remote {\n            url(REPO_URL)\n            credentials(CREDENTIAL_ID)\n          }\n        }\n      }\n      lightweight(true)\n      scriptPath(jenkinsfilePath)\n    }\n  }\n}\n\n````\n\n### 最初にやったこと\n\n単純にメソッドに抜き出した\n\n````groovy\nCREDENTIAL_ID = 'secret_key'\nREPO_URL = 'https://example.com/repo.git'\n\ndef pipelineTemplate(def context, String jenkinsfilePath) {\n  description('ビルドします')\n  logRotator {\n    numToKeep(5)\n  }\n  definition {\n    cpsScm {\n      scm {\n        git {\n          remote {\n            url(REPO_URL)\n            credentials(CREDENTIAL_ID)\n          }\n        }\n      }\n      lightweight(true)\n      scriptPath(jenkinsfilePath)\n    }\n  }\n}\n\npipelineJob(\"build-A\") {\n  parameters {\n    choiceParam(\"STAGE\", [\"stage1\", \"stage2\"], \"\")\n  }\n\n  pipelineTemplate('A/Jenkinsfile')\n}\n\npipelineJob(\"build-B\") {\n  parameters {\n    choiceParam(\"ENV\", [\"dev1\", \"dev2\"], \"\")\n  }\n  pipelineTemplate(delegate, 'B/Jenkinsfile')\n}\n\n\n````\n\nこれで実行すると、以下のエラーが出てジョブが作られない\n\n`ERROR: (script, line 8) No signature of method: script.description() is applicable for argument types: (java.lang.String) values: [ビルドします]`\n\ndescriptionやlogRotatorなどはpipelineJobの中でしか使えないmethodなので、pipelineJobのオブジェクトを渡す必要があった。\n\nhttps://stackoverflow.com/questions/27931795/how-to-refactor-common-jenkins-jobdsl-code\nhttps://stackoverflow.com/questions/6305910/how-do-i-create-and-access-the-global-variables-in-groovy\n\n### 動くようにしたもの\n\n````groovy\nCREDENTIAL_ID = 'secret_key'\nREPO_URL = 'https://example.com/repo.git'\n\ndef pipelineTemplate(def context, String jenkinsfilePath) {\n  // context.method の形式で呼ぶ\n  context.description('ビルドします')\n  context.logRotator {\n    numToKeep(5)\n  }\n  context.definition {\n    cpsScm {\n      scm {\n        git {\n          remote {\n            url(REPO_URL)\n            credentials(CREDENTIAL_ID)\n          }\n        }\n      }\n      lightweight(true)\n      scriptPath(jenkinsfilePath)\n    }\n  }\n}\n\npipelineJob(\"build-A\") {\n  parameters {\n    choiceParam(\"STAGE\", [\"stage1\", \"stage2\"], \"\")\n  }\n\n  pipelineTemplate(delegate, 'A/Jenkinsfile')\n}\n\npipelineJob(\"build-B\") {\n  parameters {\n    choiceParam(\"ENV\", [\"dev1\", \"dev2\"], \"\")\n  }\n  pipelineTemplate(delegate, 'B/Jenkinsfile')\n}\n````\n\nmethodの引数にcontext(名前は何でもいい)を追加して、呼び出し元でclosureのdelegateプロパティを渡すことでclosure内のメソッドにアクセスできるようにした。\ndelegateはGroovyのclosureの中で使えるプロパティでthisのようなもの\nhttp://docs.groovy-lang.org/latest/html/gapi/groovy/lang/Closure.html#getDelegate()\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Groovy","Jenkins"]},"/note/jq":{"title":"jq","content":"\n## vimでjqコマンドを使いやすくする\n\n````vimscript\n\" jq command\ncommand! -nargs=? Jq call s:Jq(\u003cf-args\u003e)\nfunction! s:Jq(...)\n    if 0 == a:0\n        let l:arg = \".\"\n    else\n        let l:arg = a:1\n    endif\n    execute \"%! jq \" . l:arg\nendfunction\n````\n\n## 配列の長さを調べる\n\n````shell\njq '.array[] | length'\n````\n\n## 配列に特定のキーを含まないものを検索する\n\n\u003chttps://stackoverflow.com/questions/70369094/jq-output-is-empty-when-tag-name-does-not-exist\u003e\n\n次のようなAWS CLIの出力について考える\n\n````json\n{\n  \"Reservations\": [\n    {\n      \"Instances\": [\n        {\n          \"PrivateIpAddress\": \"10.0.0.1\",\n          \"Tags\": [\n            {\n              \"Key\": \"Name\",\n              \"Value\": \"Balance-OTA-SS_a\"\n            },\n            {\n              \"Key\": \"Environment\",\n              \"Value\": \"alpha\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"Instances\": [\n        {\n          \"PrivateIpAddress\": \"10.0.0.2\",\n          \"Tags\": [\n            {\n              \"Key\": \"Name\",\n              \"Value\": \"Balance-OTA-SS_a\"\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}\n````\n\n````shell\njq '.Reservations[].Instances[] | ({IP: .PrivateIpAddress, Ambiente: (.Tags[]|select(.Key==\"Environment\")|.Value)})'\n````\n\nとすると、TagsにEnvironmentを含むもののみ出力される。\nこれを、Environmentを含まないものはnullとして出力したいときは以下のようにする\n\n````shell\njq '.Reservations[].Instances[] | { IP: .PrivateIpAddress, Ambiente: (.Tags|from_entries.Environment) }'\n\n# または\njq '.Reservations[].Instances[] | { IP: .PrivateIpAddress, Ambiente: ((.Tags[] | select(.Key == \"Environment\") | .Value) // null) }'\n````\n\n`//` についてはこちらに書いてある\n\u003chttps://stedolan.github.io/jq/manual/#ConditionalsandComparisons\u003e\n\n## エスケープ処理済みのJSON文字列を作成する\n\n[jqを利用してエスケープ処理済みのJSON文字列を作成する方法 | DevelopersIO](https://dev.classmethod.jp/articles/how-to-create-an-escaped-json-string-using-jq/)\n\n`jq '@json'`\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["jq","shell","json"]},"/note/jq%E3%81%AE%E3%82%AF%E3%82%A8%E3%83%AA%E5%86%85%E3%81%A7shell%E5%A4%89%E6%95%B0%E3%82%92%E4%BD%BF%E3%81%86":{"title":"jqのクエリ内でshell変数を使う","content":"\n文字列結合で変数を埋め込む方法がまっさきに思いつく\n\n````shell\n$ name=\"bob\"\n$ cat sample.json | jq '.content | select( .name == '$name' )'\n````\n\nよりスマートなやり方がjqのオプションである\n\n## `--arg` を使用する\n\n[jq Manual (development version)](https://stedolan.github.io/jq/manual/#Invokingjq)\n\n````shell\n$ name_var=\"bob\"\n$ cat sample.json | jq --arg name $name_var '.content | select( .body == $name )'\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/01/04","jq","shell"]},"/note/jq%E3%81%AE%E9%85%8D%E5%88%97%E3%81%A7%E3%83%AB%E3%83%BC%E3%83%97%E5%87%A6%E7%90%86%E3%82%92%E3%81%99%E3%82%8B":{"title":"jqの配列でループ処理をする","content":"\n\n````json\n[\n  {\n    \"name\": \"John\",\n    \"age\": 20\n  },\n  {\n    \"name\": \"Alice\",\n    \"age\": 25\n  },\n  {\n    \"name\": \"Bob\",\n    \"age\": 14\n  }\n]\n````\n\n## `length` を使ってインデックスでアクセスする\n\n````bash\njson=$(cat list.json)\nlen=$(echo $json | jq length)\nfor i in $( seq 0 $(($len - 1)) ); do\n  row=$(echo $json | jq .[$i])\ndone\n\n````\n\nよく、in の次にjqコマンドを書く例を見かけるが、これは良くない\n\n````shell\nfor item in $(jq -c '.[]' list.json); do\n  name=$(echo \"$item\" | jq -r '.name')\n  age=$(echo \"$item\" | jq -r '.age')\n  echo \"name: $name, age: $age\"\ndone\n````\n\n何度もjqを呼び出すのでパフォーマンスが良くない\n\n## `while read -r` を使う\n\n[詳細解説 jqコマンドとシェルスクリプトの正しい使い方と考え方 〜 データの流れを制するUNIX哲学流シェルプログラミング - Qiita](https://qiita.com/ko1nksm/items/55a86f95fdf790f863cc)\n\n````shell\nTAB=$(printf '\\t')\njq -r '.[] | [.name, .age, .count] | @tsv' list.json | {\n  while IFS=\"$TAB\" read -r name age; do\n    printf \"name: %-10s age: %2d\\n\" \"$name\" \"$age\"\n  done\n}\n````\n\n### while文の中で変数を更新したい場合\n\nパイプで渡すと変数が更新されないので注意\n\\[\\[shellでwhile readの中で変数を変更しても反映されない\\]\n\n````shell\n$ TAB=$(printf '\\t')\n$ children=0\n$ while IFS=\"$TAB\" read -r name age; do\n  printf \"name: %-10s age: %2d\\n\" \"$name\" \"$age\"\n  if [[ $age -lt 18 ]]; then\n    children=$((children+1))\n  fi\ndone \u003c \u003c(jq -r '.[] | [.name, .age] | @tsv' list.json)\n$ echo $children\n1\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/01/04","jq","shell"]},"/note/kibana-%E6%95%B0%E5%80%A4%E3%81%A7%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%83%BC%E3%81%99%E3%82%8B":{"title":"kibana 数値でフィルターする","content":"\nhttps://stackoverflow.com/questions/40241904/kibana-filter-on-count-greater-than-or-equal-to-x\n\nX AxisのJSON inputに `{\"min_doc_count\": 1000}` を指定する\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["監視"]},"/note/kibana-%E6%AD%A3%E8%A6%8F%E8%A1%A8%E7%8F%BE%E3%81%A7%E3%82%AF%E3%82%A8%E3%83%AA%E3%82%92%E6%9B%B8%E3%81%8F":{"title":"kibana 正規表現でクエリを書く","content":"\nKibanaはElasticsearchの記法でクエリを書くので、こちらのドキュメントを参照する\n\n[Regexp query | Elasticsearch Guide \\[8.4\\] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-regexp-query.html)\n\n````json\n{\n  \"query\": {\n    \"regexp\": {\n      \"user.id\": {\n        \"value\": \"k.*y\",\n        \"flags\": \"ALL\",\n        \"case_insensitive\": true,\n        \"max_determinized_states\": 10000,\n        \"rewrite\": \"constant_score\"\n      }\n    }\n  }\n}\n````\n\n正規表現で使えるsyntaxについてはこちら\n\n[Regular expression syntax | Elasticsearch Guide \\[8.4\\] | Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/current/regexp-syntax.html)\n\n### 否定先読み(negative lookahead)\n\n「~を含まない」で検索したいとき役に立つ\n\n`flags` を `COMPLEMENT` か `ALL` にすると有効になる\n\n* `a~bc` =\u003e a(b以外)c にマッチする (abcにはマッチしない、aacやa1cにはマッチする)\n* `~(.*(foo|bar).*)` =\u003e foo,barを含まない文字列にマッチする\n\nhttps://stackoverflow.com/questions/38645755/negative-lookahead-regex-on-elasticsearch\n\n### 積集合(INTERSECTION)\n\n`\u0026` が AND operator として使える\n\n* `aaa.+\u0026.+bbb` =\u003e 'aaabbb' にマッチする\n* `.*night.*\u0026~(.*-(fox|wolf).*)` =\u003e (night を含む) かつ (-fox または -wolf を含まない)\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/ktlint":{"title":"ktlint","content":"\n# ktlint\n\n[Kotlin](note/Kotlin.md) でlintを設定する\n\n\u003chttps://github.com/pinterest/ktlint\u003e\n\n.editorconfig を置くとそちらの設定が優先される\n\nデフォルト設定に従うことにした\n\n## Gradle(kts)\n\n[プラグインなしで設定する場合](https://github.com/pinterest/ktlint#without-a-plugin)\n\n面倒だったのでプラグインを使った\n\n\u003chttps://github.com/jlleitschuh/ktlint-gradle\u003e\n\nbuild.gradle.kts\n\n````kts\nplugins {\n  id \"org.jlleitschuh.gradle.ktlint\" version \"\u003ccurrent_version\u003e\"\n}\n````\n\n````sh\n$ ./gradlew ktlintCheck\n=\u003e linterを実行\n\n$ ./gradlew ktlintFormat\n=\u003e フォーマットをかけて保存\n````\n\n### Intellij IDEAの場合\n\nIDEAにKotlinのcode style等を設定するタスクを追加してくれる。素敵\n\n````kts\nplugins {\n  id(\"org.jlleitschuh.gradle.ktlint-idea\") version \"\u003ccurrent_version\u003e\"\n}\n````\n\n````sh\n./gradlew ktlintApplyToIdea\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Kotlin","linter"]},"/note/kube-prometheus-stack-%E3%81%AECRD%E3%81%8CToo-long%E3%81%A7%E4%BD%9C%E3%82%89%E3%82%8C%E3%81%AA%E3%81%84":{"title":"kube-prometheus-stack のCRDがToo longで作られない","content":"\nArgo CD v2.5からは、server side applyを有効にすると `Too long: must have at most 262144 bytes` が解消される。将来的にデフォルトがserver side applyになるということらしい\nkube-prometheus-stackにはこちらつけておくといい\n[https://www.arthurkoziel.com/fixing-argocd-crd-too-long-error/](https://www.arthurkoziel.com/fixing-argocd-crd-too-long-error/)\n\nhttps://github.com/prometheus-community/helm-charts/issues/579\n\nしかしServerSideApply=trueにしてsyncしたところエラーがでた(server side applyは関係ないような気がする、たまたまタイミングでは)\n`Prometheus.monitoring.coreos.com \"monitoring-prometheus\" is invalid: spec.shards: Invalid value: \"null\": spec.shards in body must be of type integer: \"null\"`\n\nhttps://github.com/prometheus-community/helm-charts/issues/579 でnullを指定するといいっていうのが反映されていた。\nデフォルト値の `shards: 1` でもnullのときと変わらないようなので、null指定を消した\nhttps://github.com/prometheus-community/prometheus-operator/blob/f20fd9c4e6912ab63497648032ca2aa6684923a2/pkg/prometheus/statefulset.go#L82\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/03/09","Kubernetes","Prometheus"]},"/note/kubectl":{"title":"kubectl","content":"\n[Kubernetes](note/Kubernetes.md) 向けのコマンドラインツール\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/05/04","Kubernetes"]},"/note/kubernetes%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E5%86%85%E3%81%AB%E3%83%97%E3%83%A9%E3%82%A4%E3%83%99%E3%83%BC%E3%83%88docker%E3%83%AC%E3%82%B8%E3%82%B9%E3%83%88%E3%83%AA%E3%82%92%E4%BD%9C%E3%82%8B":{"title":"kubernetesクラスタ内にプライベートdockerレジストリを作る","content":"\nサンプルだとよくECRやGCRにコンテナイメージをアップロードするように言われるが、とりあえずローカルで確認したいときに、Kubernetesクラスタ内にdockerレジストリを作る方法について調べた。\n\n## registryを作成\n\n[Using a Local Registry with Minikube](https://gist.github.com/trisberg/37c97b6cc53def9a3e38be6143786589)\n\nhttps://hub.docker.com/\\_/registry を使う\n\ndocker-registry.yaml\n\n````yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: docker-registry\n  labels:\n    app: docker-registry\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: docker-registry\n  template:\n    metadata:\n      labels:\n        app: docker-registry\n    spec:\n      containers:\n      - name: docker-registry\n        image: registry:2.8\n        ports:\n        - containerPort: 5000\n        volumeMounts:\n        - name: registry\n          mountPath: /var/lib/registry\n      volumes:\n      - name: registry\n        hostPath:\n          type: Directory\n          path: /tmp/.registry/storage\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: docker-registry\nspec:\n  ports:\n  - name: \"http-port\"\n    protocol: TCP\n    port: 5000\n    targetPort: 5000\n  selector:\n    app: docker-registry\n````\n\n````shell\n$ kubectl apply -f docker-registry.yaml\n````\n\n### 確認\n\n適当なpodを作って、疎通確認\n\npod-nginx.yaml\n\n````yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n````\n\n````shell\n$ kubectl apply -f pod-nginx.yaml\n$ kubectl exec nginx -it -- bash\nroot@nginx:/# curl docker-registry:5000/v2/_catalog\n{\"repositories\":[\"v2/my_app\"]}\n````\n\n## kanikoのイメージアップロード先を指定\n\nhttps://github.com/GoogleContainerTools/kaniko\n\n````yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: kaniko\nspec:\n  containers:\n    - name: kaniko\n      image: gcr.io/kaniko-project/executor:latest\n      args:\n        - \"--insecure\"\n        - \"--dockerfile=\u003cpath to Dockerfile within the build context\u003e\"\n        - \"--context=\u003cpath to Dockerfile context dir\u003e\"\n        - \"--destination=docker-registry:5000/myapp:version\"\n````\n\n````shell\n$ kubectl apply -f kaniko.yaml\n````\n\n### `http: server gave HTTP response to HTTPS client` エラーが出た\n\nhttps://github.com/GoogleContainerTools/kaniko#flag---insecure\n\nkaniko 実行時に `--insecure` オプションをつける\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/01/04","Docker","Kubernetes"]},"/note/kubernetes%E5%91%A8%E8%BE%BA%E3%81%AE%E4%BE%BF%E5%88%A9%E3%83%84%E3%83%BC%E3%83%AB":{"title":"kubernetes周辺の便利ツール","content":"\n[ワイがお世話になっているKubernetes関連のツール達 - 守りたい、この睡眠時間](https://tomioka-shogorila.hatenablog.com/entry/2020/03/10/230206)\n[Kubernetesを使う上で知っておきたいツールやプラグイン](https://zenn.dev/tmrekk/articles/580f2e2bb39d5f)o\n[kubectlのプラグイン機構とおすすめプラグインのご紹介 〜 Kubernetes制御用コマンド \\#k8sjp - Yahoo! JAPAN Tech Blog](https://techblog.yahoo.co.jp/entry/2020081830014718/)\n\n## [Krew](note/Kubernetes%20Krew.md)\n\nhttps://github.com/kubernetes-sigs/krew/\n\nkubectl用のプラグイン管理\n\nインストールはこちら\nhttps://krew.sigs.k8s.io/docs/user-guide/setup/install/\nアップデートは自身\n\n````shell\nkubectl krew update\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Kubernetes"]},"/note/kubernetes-EBS%E3%82%92%E3%82%A2%E3%82%BF%E3%83%83%E3%83%81%E3%81%99%E3%82%8B":{"title":"kubernetes EBSをアタッチする","content":"\nCSI driverをインストールする\n\nCSI ... Common Storage Interface\nk8sが外部のストレージを使うときの規格\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Kubernetes"]},"/note/kubernetes-external-secrets":{"title":"kubernetes external secrets","content":"\n\\#Kubernetes\n\n[AWS Secrets Managerを使用したKubernetes Secret管理 | BTC Cloud](https://cloud.bigtreetc.com/column/eks-secrets/)\n\n[External Secretsを試してみる - TECHSTEP](https://techstep.hatenablog.com/entry/2020/12/19/002142)\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Kubernetes"]},"/note/kubernetes-resources%E3%81%AE%E8%A8%AD%E5%AE%9A%E5%80%A4%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6-Kubernetes":{"title":"kubernetes resourcesの設定値について Kubernetes","content":"\n\u003chttps://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\u003e\n[Kubernetes のリソース制限とその挙動確認 - YasuBlog](https://dunkshoot.hatenablog.com/entry/kubernetes_manage_resource)\n\n* requestsに `memory: 256MiB` を設定すると256MiB以上空きがあるNodeにスケジュールされて、256MiB以上使用する可能性がある\n* limitsに `memory: 4GiB` を設定すると、4GiB以上のメモリを利用しようとするとOOM KillerによりPodが落とされる\n* resourcesのrequestsに指定されたmemory,cpuの値を元にスケジュール先のNodeを選択する\n\n## limits\n\nlimitsの値を超えた場合の挙動について\n\n* memoryを超えた場合: OOM KillerによりPodが強制終了\n* cpuを超えた場合: 強制終了はしないがCPU速度が遅くなる\n\nlimits はNodeのallocatableなリソース量を超えて指定することができる。\n\n## オーバーコミット\n\nオーバーコミットは、コンテナの limits の合計を Node の割当可能リソース量より大きくすること\n例えばメモリ2GBのNodeには、requests 0.5GB, limits 1GB の Pod を4個起動できる。limits の合計は 4GB となりオーバーコミットの状態だが、Pod が常に最大値使うわけではない場合には許容できる。\n負荷が高まって全Podがlimitsぎりぎりまでリソースを使うようになると、Nodeの割当可能リソースを超過してしまう。\nこうなると、Eviction Managerによりもっともrequestsを超過してリソースを使用しているPodがEvictされる。\n\nオーバーコミットさせるとPodの集約率は上がるがPodの稼働率は下がる可能性がある。\n逆にrequestsとlimitsを近づけすぎると、Podの集約率は下がってリソース効率は悪くなるが稼働は安定する。\n\n## CPU\n\n2 vCPUのEC2インスタンスのCPUをフルで使いたい場合は `cpu: 2` と記載する。\n1 vCPU分のリソースの場合は `cpu: 1` または `cpu: 1000m` と書く。\n(1 CPU = 1000m)\n\n## メモリ\n\nバイト単位で書く(1024000, 1Gi、256Mなど)\n\n## PrometheusでPodのCPU、メモリ使用率を確認する\n\nkubectl topコマンドでもできるがPrometheusの場合\n\n[K8s Monitor Pod CPU and memory usage with Prometheus | by Kim Wuestkamp | ITNEXT](https://itnext.io/k8s-monitor-pod-cpu-and-memory-usage-with-prometheus-28eec6d84729)\n\n### CPU\n\n````\n# container usage\nrate(container_cpu_usage_seconds_total{pod=~\"compute-.*\", image!=\"\", container_name!=\"POD\"}[5m])\n\n# container requests\navg(kube_pod_container_resource_requests_cpu_cores{pod=~\"compute-.*\"})\n\n# container limits\navg(kube_pod_container_resource_limits_cpu_cores{pod=~\"compute-.*\"})\n\n# throttling\nrate(container_cpu_cfs_throttled_seconds_total{pod=~\"compute-.*\", container_name!=\"POD\", image!=\"\"}[5m])\n````\n\n### Memory\n\n````\n# container usage\ncontainer_memory_working_set_bytes{pod_name=~\"compute-.*\", image!=\"\", container_name!=\"POD\"}\n\n# container requests\navg(kube_pod_container_resource_requests_memory_bytes{pod=~\"compute-.*\"})\n\n# container limits\navg(kube_pod_container_resource_limits_memory_bytes{pod=~\"compute-.*\"})\n````\n\n[How to display Kubernetes request and limit in Grafana / Prometheus properly](https://gist.github.com/max-rocket-internet/6a05ee757b6587668a1de8a5c177728b)\n\n````\nsum(rate(container_cpu_usage_seconds_total{pod=~\"jenkins-agent-.*\", image!=\"\", container!=\"POD\"}[5m])) by (pod, container, namespace) / sum(kube_pod_container_resource_requests{resource=\"cpu\", unit=\"core\", pod=~\"jenkins-agent-.*\", container!=\"POD\"}) by (pod, container, namespace)\nsum(rate(container_cpu_usage_seconds_total{pod=~\"jenkins-agent-.*\", image!=\"\", container!=\"POD\"}[5m])) by (pod, container) / sum(container_spec_cpu_quota{pod=~\"jenkins-agent-.*\", image!=\"\", container!=\"POD\"}/container_spec_cpu_period{pod=~\"jenkins-agent-.*\", image!=\"\", container!=\"POD\"}) by (pod, container)\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/01/23","Kubernetes"]},"/note/kustomize-build%E3%81%99%E3%82%8B%E3%81%A8%E3%81%8D%E4%B8%80%E9%83%A8%E3%81%AEoverlays%E3%81%AE%E3%81%A8%E3%81%8D%E3%81%A0%E3%81%91base%E3%81%AE%E3%83%AA%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%92%E5%89%8A%E9%99%A4%E3%81%97%E3%81%9F%E3%81%84":{"title":"kustomize buildするとき、一部のoverlaysのときだけbaseのリソースを削除したい","content":"\n[【kustomize】特定の環境だけbaseのリソースを削除する | amateur engineer's blog](https://amateur-engineer-blog.com/remove-resouce-kustomize-base/)\n\nbaseのapiVersionと一部環境だけ異なるという場合に必要となる\n\nbase/hpa.yaml\n\n````yaml\napiVersion: autoscaling/v1\nkind: HorizontalPodAutoscaler\n````\n\noverlays/stg/hpa.yaml\n\n````yaml\napiVersion: autoscaling/v2beta1\nkind: HorizontalPodAutoscaler\n````\n\nこれでkustomize build すると、v1とv2beta1両方が作られてしまう。\n\n````yaml\n---\napiVersion: autoscaling/v1\nkind: HorizontalPodAutoscaler\n---\napiVersion: autoscaling/v2beta1\nkind: HorizontalPodAutoscaler\n````\n\nこれを回避するため、 `patch: $delete` でファイルを削除する\n\n`delete-hpa-v1.yaml`\n\n````yaml\n$patch: delete \napiVersion: autoscaling/v1\nkind: HorizontalPodAutoscaler\n````\n\n`base/kustomization.yaml`\n\n````yaml\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nresources:\n- deployment.yaml\n- hpa.yaml\n````\n\n`overlays/stg/kustomization.yaml`\n\n````yaml\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nnamespace: app-stg\n\nresources:\n- ./../../base\n\npatchesStrategicMerge:\n  - delete-hpa-v1.yaml\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/02/27","Kubernetes"]},"/note/localstack":{"title":"localstack","content":"\nhttps://github.com/localstack/localstack\nhttps://localstack.cloud/\n\n[localstack](note/localstack.md) は、クラウドアプリケーションを開発するためのmockを提供するツール。\nローカルにAWSと同様の機能とAPIを提供する環境を構築する。\n最初の開発元はAtlassian\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["AWS"]},"/note/localstack%E3%81%A7S3%E3%82%92mock%E3%81%99%E3%82%8B":{"title":"localstackでS3をmockする","content":"\n[localstack](note/localstack.md) を使って [S3](note/S3.md) をモックできる\n\n## 構築\n\n````yml:docker-compose.yml\nversion: \"3.8\"\n\nservices:\n  localstack:\n    container_name: \"${LOCALSTACK_DOCKER_NAME-localstack_main}\"\n    image: localstack/localstack\n    network_mode: bridge\n    ports:\n      - \"127.0.0.1:53:53\"\n      - \"127.0.0.1:53:53/udp\"\n      - \"127.0.0.1:443:443\"\n      - \"127.0.0.1:4566:4566\"\n      - \"127.0.0.1:4571:4571\"\n    environment:\n      - SERVICES=s3\n      - DEBUG=${DEBUG- }\n      - DATA_DIR=/tmp/localstack/data\n      - DOCKER_HOST=unix:///var/run/docker.sock\n      - DEFAULT_REGION=ap-northeast-1\n    volumes:\n      - \"./work:/tmp/localstack\"\n      - \"/var/run/docker.sock:/var/run/docker.sock\"\n````\n\n````shell\ndocker-compose up -d\n````\n\n## localstack用のプロファイルを作成する\n\n````shell\n$ aws configure --profile localstack-push\nAWS Access Key ID [****************ummy]: dummy\nAWS Secret Access Key [****************ummy]: dummy\nDefault region name [ap-northeast-1]: ap-northeast-1\nDefault output format [json]: json\n````\n\n## localstackのS3にバケットを作成する\n\n````shell\n$ aws --profile localstack-push --endpoint-url=http://localhost:4566 s3 mb s3://sample-bucket\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["AWS","unittest"]},"/note/localstack%E3%81%A8sam%E3%82%92%E9%80%A3%E6%90%BA":{"title":"localstackとsamを連携","content":"\n\\#AWS #sam\n\n## 事象\n\n[SAM](note/SAM.md) コマンドで実行したLambdaから、 [localstack](note/localstack.md) で立てたS3にアクセスできない\n\n## TL;DR\n\nmacの場合、Lambdaから接続するhostを `localstack` ではなく `host.docker.internal` にする\n\n\u003chttps://github.com/localstack/localstack/issues/878\u003e\n\n## 実装\n\n````yml:docker-compose.yml\nversion: \"3.8\"\n\nservices:\n  localstack:\n    container_name: \"${LOCALSTACK_DOCKER_NAME-localstack_main}\"\n    image: localstack/localstack\n    network_mode: bridge\n    ports:\n      - \"127.0.0.1:53:53\"\n      - \"127.0.0.1:53:53/udp\"\n      - \"127.0.0.1:443:443\"\n      - \"127.0.0.1:4566:4566\"\n      - \"127.0.0.1:4571:4571\"\n    environment:\n      - SERVICES=s3\n      - DEBUG=${DEBUG- }\n      - DATA_DIR=/tmp/localstack/data\n      - DOCKER_HOST=unix:///var/run/docker.sock\n      - DEFAULT_REGION=ap-northeast-1\n    volumes:\n      - \"./work:/tmp/localstack\"\n      - \"/var/run/docker.sock:/var/run/docker.sock\"\n````\n\n````go:main.go\npackage main\n\nimport (\n\t\"context\"\n\t\"io/ioutil\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/config\"\n\t\"github.com/aws/aws-sdk-go-v2/credentials\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3\"\n)\n\nfunc handler(event events.CloudWatchEvent) (string, error) {\n\tcfg, _ := config.LoadDefaultConfig(context.TODO(),\n\t\tconfig.WithCredentialsProvider(credentials.NewStaticCredentialsProvider(\"dummy\", \"dummy\", \"dummy\")),\n\t)\n\n    // localstack S3のURL\n    er := awsS3.EndpointResolverFromURL(\"http://host.docker.internal:4566\")\n\tclient := s3.NewFromConfig(cfg,\n\t\ts3.WithEndpointResolver(er),\n        // localstack S3の場合、virtual hostでのアクセスができないためpath styleを使う\n\t\tfunc(o *s3.Options) {\n\t\t\to.UsePathStyle = true\n\t\t},\n\t)\n\n\tinput := \u0026s3.GetObjectInput{\n\t\tBucket: aws.String(\"sample-bucket\"),\n\t\tKey:    aws.String(\"path/to/file\"),\n\t}\n\n\toutput, err := client.GetObject(context.TODO(), input)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tdefer output.Body.Close()\n\tb, err := ioutil.ReadAll(output.Body)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn string(b), nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n````\n\n## 参考\n\n[AWS SAM CLI と localstack を利用して Lambda をローカル実行してみよう](https://bsblog.casareal.co.jp/archives/5571)\n[AWS SAM Local と LocalStack を使って ローカルでAWS Lambdaのコードを動かす | DevelopersIO](https://dev.classmethod.jp/articles/sam-local-with-localstack/)\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["AWS","sam"]},"/note/lodash%E3%82%92%E4%BD%BF%E3%81%84%E3%81%9F%E3%81%8F%E3%81%AA%E3%81%84%E3%81%A7%E3%81%94%E3%81%96%E3%82%8B":{"title":"lodashを使いたくないでござる","content":"\n\\#JavaScript\n\n[lodash やめ方 - Qiita](https://qiita.com/mizchi/items/af17f45d5653b76f6751)\n\nだいたいはES6標準の書き方で書けるようになっているが、どうしてもlodashの関数を使いたいときがある。\nそんなときは https://github.com/angus-c/just/ を使ってみてもいいかもしれない。\n\n[lodashの代わりにjustを使う](https://zenn.dev/terrierscript/articles/2020-11-26-lodash-just)\n\n* パッケージは`just-***`という名前で単関数が独立している。必要なものだけ使える\n* zero-dependencyな作り。\n* 比較的簡素に作られているので自前実装に参考にしやすい\n\nあるいは、lodash自身が個別にモジュール化してくれているのでそれをインストールしてもいいかも\n\n例: https://www.npmjs.com/package/lodash.debounce\n\n````shell\nnpm i \n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["JavaScript"]},"/note/lombok%E4%BD%BF%E7%94%A8%E6%99%82%E3%81%ABmaven-compile%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%AB%E3%81%AA%E3%82%8B":{"title":"lombok使用時にmaven compileエラーになる","content":"\nlombok使用時にmaven compileエラーになる\n\n````sh\n$ mvn compile\n\n...\n\nCaused by: java.lang.ClassNotFoundException: com.sun.tools.javac.code.TypeTags\n    at java.lang.ClassLoader.findClass (ClassLoader.java:719)\n    at java.lang.ClassLoader.loadClass (ClassLoader.java:589)\n    at lombok.launch.ShadowClassLoader.loadClass (ShadowClassLoader.java:422)\n    at java.lang.ClassLoader.loadClass (ClassLoader.java:522)\n    at java.lang.Class.forName0 (Native Method)\n    at java.lang.Class.forName (Class.java:377)\n    at lombok.javac.JavacTreeMaker$SchroedingerType.getFieldCached (JavacTreeMaker.java:156)\n    at lombok.javac.JavacTreeMaker$TypeTag.typeTag (JavacTreeMaker.java:245)\n    at lombok.javac.Javac.\u003cclinit\u003e (Javac.java:155)\n\n````\n\n* lombok: 1.16.20\n* jdk: 1.8\n\nbrewでopenjdkがインストールされていてバージョンが変わっていた\nなにかに依存して入っていた模様\n\n````\n$ mvn --version\nApache Maven 3.8.1 (05c21c65bdfed0f71a2f2ada8b84da59348c4c5d)\nMaven home: /usr/local/Cellar/maven/3.8.1/libexec\nJava version: 15.0.2, vendor: N/A, runtime: /usr/local/Cellar/openjdk/15.0.2/libexec/openjdk.jdk/Contents/Home\n````\n\n[java.lang.ClassNotFoundException: com.sun.tools.javac.code.TypeTags · Issue #1651 · projectlombok/lombok](https://github.com/projectlombok/lombok/issues/1651)\n\nlombok 1.16.22 で解消している模様\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/mac%E3%81%A7at%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%82%92%E4%BD%BF%E3%81%86":{"title":"macでatコマンドを使う","content":"\n\\#shell\n\n[Macでatコマンドが実行できないときの対処法 - Qiita](https://qiita.com/shge/items/6c43947a77abd9d2d1b2)\n\n````shell\nsudo launchctl load -w /System/Library/LaunchDaemons/com.apple.atrun.plist\n````\n\n`/usr/libexec/atrun` にフルディスクアクセスをつける\n\n## コマンドの使い方\n\n[atコマンドについて詳しくまとめました 【Linuxコマンド集】](https://eng-entrance.com/linux-command-at)\n\n````shell\n$ at 11:00\n\u003e echo \"hello from at\" \u003e ~/work/at.log\n[Ctrl+D]\n````\n\n* `-t [YYYY]MMDDHHmm[.SS]`: 時刻指定の書式を西暦4桁、月2桁、日2桁、時2桁、分2桁の書式で入力できる\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["shell"]},"/note/maven%E3%81%A7spring%E3%81%AE%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89%E6%99%82%E3%81%AB%E3%82%A8%E3%83%A9%E3%83%BC":{"title":"mavenでspringのライブラリダウンロード時にエラー","content":"\nspring-libs-release からダウンロードしようとするも、エラーになる\nhttps://repo.spring.io/libs-release からダウンロードしなきゃならないところ、\nhttp://repo.springsource.org/libs-release/\nから取得しようとしてタイムアウトエラーになっている\n524 Origin timeout\n\nやったこと\n~/.m2/repository/org/springframework を削除したところ mvn package がすぐ終わった\n最初、1ライブラリだけを消したがそれだと意味ない\n\nrepositories に\n\n````\n                \u003crepository\u003e\n                        \u003cid\u003espring\u003c/id\u003e\n                        \u003cname\u003espring\u003c/name\u003e\n                        \u003curl\u003ehttps://repo.spring.io/libs-release/\u003c/url\u003e\n                \u003c/repository\u003e\n````\n\nを書いてみたりしたが、最初のmetadataのダウンロードがうまくいくがその後失敗するので意味なかった\n一度消して再ダウンロードしたときにはcentralからダウンロードされるようになった\n\nhttpsでアクセスさせたいのにそれを設定する方法がないみたい\n\n原因\nmvn が spring-libs-release というidのrepositoryからダウンロードしようとする。\nこれがどこで設定されているかわからない、設定したものではないのでおそらくspringからダウンロードしたライブラリのpomにかかれている。\n古いライブラリに書かれているんじゃないか。確かめる前に削除してしまったのでわからないが\n\nsettings.xmlにtimeoutを書いておくのもありだと思う\nいくら調べても困っている人がいなくて逆に困った。こんなのメジャーな問題っぽいけどな\n\nこういうのも見つけた。repoのURLが一部使えなくなるよ これに引っかかったのでは\nhttps://spring.io/blog/2020/10/29/notice-of-permissions-changes-to-repo-spring-io-fall-and-winter-2020\n\n結論\n一度 ~/.m2/repostitory を消すのが最強\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["spring","Java"]},"/note/maven%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%81%8C%E7%AA%81%E7%84%B6%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%8F%E3%81%AA%E3%81%A3%E3%81%9F":{"title":"mavenライブラリが突然ダウンロードできなくなった","content":"\ninhouse repositoryに登録したものがダウンロードできなくなった\n\n## やったこと\n\n### キャッシュクリア\n\n````shell\nrm -rf ~/.m2/repository/path/to/library\n````\n\n=\u003e 再ダウンロードは動くがされない\n\n### 直接s3からダウンロード\n\ninhouse repoがs3にあるため、s3コマンドでダウンロードする\n\n````shell\naws s3 cp s3://inhouse-repo/path/to/library/library.jar\n````\n\n=\u003e 403エラーで取得できず。他のライブラリはこのコマンドでダウンロードできたので、アップロード時に権限設定をミスったか？\n\n## 解決\n\nここまで調べたところで、時間がたったあとに再度ビルドしたらなぜか解決した…\nなにか裏でやってくれてるのかな\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/mvnd%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6maven%E3%83%93%E3%83%AB%E3%83%89%E3%82%92%E9%AB%98%E9%80%9F%E5%8C%96":{"title":"mvndを使ってmavenビルドを高速化","content":"\n\\#Java \n\nhttps://github.com/apache/maven-mvnd\n\n \u003e \n \u003e This project aims at providing faster Maven builds using techniques known from Gradle and Takari\n\nGradleのようにdeamonを立てることでビルドを高速化するプロジェクト。\n\n### Java 8 では動かない\n\nhttps://github.com/apache/maven-mvnd/issues/547\n\njdk \u003e= 11 である必要がある。\n\n### M1 Macでは動かない\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/neovim0.5.0%E3%81%AB%E3%81%97%E3%81%9F%E3%82%89undo%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%81%8C%E5%A3%8A%E3%82%8C%E3%81%9F":{"title":"neovim0.5.0にしたらundoファイルが壊れた","content":"\nbrewでインストールされるNeovimのバージョンが0.5.0になった。\n\nファイルを開くと、 `E824: Incompatible undo file: /path/to/undo` というメッセージが出るようになって、過去にさかのぼってのundoができなくなった\n\n## 対応\n\nhttps://www.reddit.com/r/neovim/comments/lxu7p3/error_incompatible_undo_file_whenever_i_open_a/\n\n[Vim](note/Vim.md) や0.5.0より前の[Neovim](note/Neovim.md) との互換性がなくなったため、諦めるしか無い\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["vim"]},"/note/nvim-treesitter":{"title":"nvim-treesitter","content":"\n[nvim-treesitter/nvim-treesitter: Nvim Treesitter configurations and abstraction layer](https://github.com/nvim-treesitter/nvim-treesitter)\n\n[Neovim](note/Neovim.md) でtree-sitterを使ってテキストの構文解析やハイライトなどの機能を実現するプラグイン\n\n[tree-sitterについて](https://tree-sitter.github.io/tree-sitter/)\n\n \u003e \n \u003e Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source file and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:\n \u003e \n \u003e General enough to parse any programming language\n \u003e Fast enough to parse on every keystroke in a text editor\n \u003e Robust enough to provide useful results even in the presence of syntax errors\n \u003e Dependency-free so that the runtime library (which is written in pure C) can be embedded in any application\n\nさまざまなプログラミング言語やファイル形式の構文解析をサポートしていて、独自に追加することもできます。\n\n* ソースコードやテキストファイルを構文解析し、抽象構文木（AST）を生成します。これにより、コードの構造や意味を理解し、他の機能を実現する基盤となります。\n* 構文解析の結果を使用して、シンタックスハイライトを行います\n* [パーサーを追加することが可能です](https://github.com/nvim-treesitter/nvim-treesitter#adding-parsers)\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Neovim"]},"/note/powerline":{"title":"powerline","content":"\n# powerline\n\n* powerlineをインストール\n  \n  * pipでインストールする\n  * \u003chttps://powerline.readthedocs.io/en/master/installation.html#pip-installation\u003e\n* font\n  \n  * powerline対応のフォントでないとうまく表示されない\n  * Nerd fonts, Cicaなど\n* tmux\n  \n  * 次のようにする\n  \u003c!----\u003e\n  \n````\n  run-shell \"powerline-daemon -q\"\n  source-file \"path/to/powerline/bindings/tmux/powerline.conf\"\n  ````\n\n## problem\n\n### tmux + fishで現在のパスをpaneに表示できない\n\n[fishプラグイン](note/fishプラグイン.md)\n\n* tmux実行時のpathが表示されてしまう\n* \u003chttps://github.com/tmux/tmux/issues/1889\u003e\n  * 解決してない\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["terminal"]},"/note/pver_with_cobra":{"title":"pver_with_cobra","content":"\n# pver_with_cobra\n\n* cobra init\n* cobra add\n* new関数でコマンドを初期化\n  * DIのためと思ってそうしたけど、後でroot.go内で初期化するようにしたので必要なかった\n  * rootコマンドはテストしづらくなるが、rootには機能もたせないのがよさそう\n* testを追加\n  * `cmd.SetOut` でbufferに出力させる\n* cmdパッケージは入出力、serviceパッケージはビジネスロジック、infraパッケージはAPI,DBみたいにわけた\n  * テストは書きやすくなった気がする\n* ダックタイピングがちょっとわかった\n  * service層にはinterfaceをもたせてinfra層で実装することで依存関係逆転させた\n* デバッグ目的以外でcmd層以外では出力しない\n* \n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Go"]},"/note/python%E3%83%97%E3%83%AD%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E3%81%AE%E5%A7%8B%E3%82%81%E6%96%B9":{"title":"pythonプロジェクトの始め方","content":"\n[Python](note/Python.md)\n\n[Python オレオレ、コレだけはやっておけ 2021 - Qiita](https://qiita.com/shoot16625/items/9eefc6e81b3cf209729b)\n\n## dataclass\n\n[Python3.7からは「Data Classes」がクラス定義のスタンダードになるかもしれない - Qiita](https://qiita.com/tag1216/items/13b032348c893667862a)\n\n## 日付計算\n\n* [\\[Python3\\] struct_timeからdatetimeに変換する方法（タイムゾーン付き） - Qiita](https://qiita.com/non_cal/items/9fcb5f6b4eabed4d6026)\n* [日付フォーマット(datetime⇔文字列） | Python Snippets](https://python.civic-apps.com/date-format/)\\_\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/05/04","Python"]},"/note/ripgrep%E3%81%A7%E8%A4%87%E6%95%B0%E8%A1%8C%E3%81%AB%E3%81%BE%E3%81%9F%E3%81%8C%E3%82%8B%E6%A4%9C%E7%B4%A2":{"title":"ripgrepで複数行にまたがる検索","content":"\n\\#shell \n\nhttps://til.hashrocket.com/posts/9zneks2cbv-multiline-matches-with-ripgrep-rg\n\n````shell\n$ echo 'apple\\norange\\nbanana\\nkiwi' | rg 'orange.*kiwi'\n````\n\n=\u003e マッチしない\n\n````shell\n$ echo 'apple\\norange\\nbanana\\nkiwi' | rg --multiline 'orange.*kiwi'\n````\n\n=\u003e マッチしない\n`.` が `\\n` にマッチしないため。\n\n`dot all` modifier = `(?s)` をつかう\n\n````shell\n$ echo 'apple\\norange\\nbanana\\nkiwi' | rg --multiline '(?s)orange.*kiwi'\norange\nbanana\nkiwi\n````\n\n=\u003e マッチする\n\n`--multiline-dotall` でもよい\n\n````shell\n$ echo 'apple\\norange\\nbanana\\nkiwi' | rg --multiline --multiline-dotall 'orange.*kiwi'\norange\nbanana\nkiwi\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/sam-deploy%E3%81%A7cloudformation%E3%81%AEstack%E3%81%8CROLLBACK_COMPLETE%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%A6%E5%86%8D%E3%83%87%E3%83%97%E3%83%AD%E3%82%A4%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%8F%E3%81%AA%E3%81%A3%E3%81%9F%E3%81%A8%E3%81%8D":{"title":"sam deployでcloudformationのstackがROLLBACK_COMPLETEになって再デプロイできなくなったとき","content":"\n\\#sam #AWS \n\nsam deploy(cloudformation deploy)に失敗したときに、以下のようなメッセージがでて再実行してもエラーになる\n\n````\nError: Failed to create/update the stack: \u003cstack_name\u003e, Waiter StackCreateComplete failed: Waiter encountered a terminal failure state: For expression \"Stacks[].StackStatus\" we matched expected path: \"ROLLBACK_COMPLETE\" at least once\n````\n\nこの場合はstackを削除する\n\n````shell\naws cloudformation delete-stack --stack-name \u003cstack_name\u003e\n````\n\n## 2回目以降の実行で、UPDATE_ROLLBACK_FAILED状態のままになっている場合\n\n[UPDATE_ROLLBACK_FAILED 状態のままになっている CloudFormation スタックを更新する](https://aws.amazon.com/jp/premiumsupport/knowledge-center/cloudformation-update-rollback-failed/)\n\nrollbackを続行する\n\n````shell\naws cloudformation continue-update-rollback --stack-name \u003cstack_name\u003e\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":[]},"/note/shell%E3%81%A7while-read%E3%81%AE%E4%B8%AD%E3%81%A7%E5%A4%89%E6%95%B0%E3%82%92%E5%A4%89%E6%9B%B4%E3%81%97%E3%81%A6%E3%82%82%E5%8F%8D%E6%98%A0%E3%81%95%E3%82%8C%E3%81%AA%E3%81%84":{"title":"shellでwhile readの中で変数を変更しても反映されない","content":"\n`while read` でループ実行したいときに、パイプで値を渡すことができる。\nこのときに、while文の中で変数をアップデートしても、変更が反映されない\n\n````shell\n$ sum=0\n$ echo -e \"1\\n2\\n3\" | while read -r num; do echo \"number: $num\"; sum=$((sum+num)); done \u003c \u003c(echo -e \"1\\n2\\n3\")\nnumber: 1\nnumber: 2\nnumber: 3\n$ echo $sum\n0\n````\n\nこれは、パイプはサブプロセスで実行されるため親プロセスの変数に影響を与えられないため。\nhttps://unix.stackexchange.com/questions/143958/in-bash-read-after-a-pipe-is-not-setting-values\n\n````bash\ncmd1 | cmd2\n````\n\n \u003e \n \u003e `bash` run `cmd2` in a subshell, so changing variable won't be visible to parent shell.\n\nなのでpipeではなく `\u003c` で値を渡す\n[shellのプロセス置換Process Substitution](note/shellのプロセス置換Process%20Substitution.md)\n\n````\nwhile read line; do\ndone \u003c \u003c(echo -e \"foo\\nbar\\nbaz\")\n````\n\nこれを使うと次のように書いて反映されるようにできる\n\n````shell\n$ sum=0\n$ while read -r num; do echo \"number: $num\"; sum=$((sum+num)); done \u003c \u003c(echo -e \"1\\n2\\n3\")\nnumber: 1\nnumber: 2\nnumber: 3\n$ echo $sum\n6\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/01/04","shell"]},"/note/shell%E3%81%AE%E3%83%97%E3%83%AD%E3%82%BB%E3%82%B9%E7%BD%AE%E6%8F%9BProcess-Substitution":{"title":"shellのプロセス置換Process Substitution","content":"\n[プロセス置換 (Process Substitution)について - 一から勉強させてください](https://dangerous-animal141.hatenablog.com/entry/2020/06/06/175650)\n[zsh: 14 Expansion](https://zsh.sourceforge.io/Doc/Release/Expansion.html#Process-Substitution)\n\ndiffとかで見るこの書き方\n\n````shell\n$ diff \u003c(ls one.txt) \u003c(ls two.txt)\n````\n\nコマンドの結果をinputとして渡しているように見える。\nリダイレクトに見えるが矢印の方向が逆\n\n* `\u003c(list)`\n  * リストの結果を入力ファイルに置き換える\n* `\u003e(list)`\n  * リストの結果を出力ファイルに置き換える\n\n[shellのリダイレクト](note/shellのリダイレクト.md)\n\n## 応用例\n\n[標準出力と標準エラー出力にリダイレクトしながら出力をターミナルに表示 (bash, tee, process substitution) - いろいろ備忘録日記](https://devlights.hatenablog.com/entry/2022/02/04/073000)\n\n````shell\n$ ./script.sh 1\u003e \u003e(tee -a stdout.log) 2\u003e \u003e(tee -a stderr.log \u003e\u00262)\n````\n\nこのようにすると、 `./script.sh` の出力をteeコマンドのプロセスにリダイレクトすることで、標準出力しつつファイルに書くことができる\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/01/04","shell","zsh"]},"/note/shell%E3%81%AE%E3%83%AA%E3%83%80%E3%82%A4%E3%83%AC%E3%82%AF%E3%83%88":{"title":"shellのリダイレクト","content":"\n[シェルのリダイレクトとパイプまとめ \\[Linux\\] │ Web備忘録](https://webbibouroku.com/Blog/Article/redirect-pipe)\n\n## リダイレクト\n\n入出力の向き先を変更する\n\n### `\u003e`\n\n`n\u003e\u0026m` とすると、ファイルディスクリプタnをmにリダイレクトする\n`2\u003e\u00261` とすると標準エラー(FD2)の出力先が標準出力(FD1)にマージされる\n\n`\u003e\u003e` とすると、ファイルを追記モードで開いてリダイレクトする\n\n### `\u003c`\n\n標準入力にリダイレクト\n\n````shell\ncat - \u003chello.txt\n````\n\nでファイル内容を標準入力にリダイレクトしている\n\n### `\u003c(cmd)` コマンドの実行結果を標準入力にリダイレクト\n\n[shellのプロセス置換Process Substitution](note/shellのプロセス置換Process%20Substitution.md)\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/01/04","shell"]},"/note/shell%E3%81%AE%E6%A4%9C%E7%B4%A2%E3%81%97%E3%81%AB%E3%81%8F%E3%81%84%E6%A9%9F%E8%83%BD":{"title":"shellの検索しにくい機能","content":"\nbashやzshでリダイレクトの機能など検索がしにくいので、ここにメモっていく\n\n[shellのプロセス置換Process Substitution](note/shellのプロセス置換Process%20Substitution.md)\n[shellのリダイレクト](note/shellのリダイレクト.md)\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["2023/01/04"]},"/note/shell-%E3%83%A9%E3%83%B3%E3%83%80%E3%83%A0%E6%96%87%E5%AD%97%E5%88%97%E3%82%92%E7%94%9F%E6%88%90%E3%81%99%E3%82%8B%E3%83%AF%E3%83%B3%E3%83%A9%E3%82%A4%E3%83%8A%E3%83%BC":{"title":"shell ランダム文字列を生成するワンライナー","content":"\n固定文字列を付与したい場合はawkなどでつければよい\n\n````shell\n$ cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 10 | awk '{ print \"prefix:\" $1 }'\n\nprefix:0dCIkKBOq8bcM4yCP0Su5AE0yb6OUBtJ\nprefix:ferc9H8Qx0QvaK3klwAiMGejgWVDycL0\nprefix:pYJGcHzrxYtlT8p4dw8JT567XmeljRRq\nprefix:dJ1g2vryv1U2EmE0fW4bOT8DlW2plXQx\nprefix:W952QQrK0XFG1hyUzh4vy1D6vWAU2Xt9\nprefix:IEXRe5sAhmnYenIhMse2C63qYZSpmlTY\nprefix:IaMWJGHRqhQXj8RhqsOJtT8OAYAoPvPY\nprefix:h89cSAk63KSTCa3J880qYmjpoRFHi3DJ\nprefix:MUEAglVmFbIwCdRzBllDcPIQzIjN0ivu\nprefix:7sNNrE29j5QaHk1h3zuAaeqSXftzWcn3\n````\n\n## 仕組み\n\n* `/dev/urandom` でランダム文字列を生成\n* `tr -dc 'a-zA-Z0-9'`: 英数字以外を削除\n  * `-d`: \\\u003c文字セット\u003eに含まれる文字があったら削除する\n  * `-c`: \\\u003c文字セット\u003eに含まれない文字全て（の補集合）を対象とする\n* `fold`: テキストを指定した幅で改行する\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["shell"]},"/note/shell-script-%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%84JSON%E3%81%A7for-loop%E3%81%99%E3%82%8B%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3":{"title":"shell script テキストファイルやJSONでfor loopするパターン","content":"\n## ファイルを読み込んで一行ずつ処理する\n\nname_list.txt\n\n````txt\nJohn\nBob\nAlice\n````\n\n````bash\nwhile read -r line || [ -n \"$line\" ]\ndo\n  echo \"name: ${line}\"\ndone \u003c name_list.txt ```\n\n## JSONの配列を一つずつ処理する\n\n[jqの配列でループ処理をする](note/jqの配列でループ処理をする.md)\n````\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["shell"]},"/note/spotless%E3%81%A7%E3%82%B3%E3%83%BC%E3%83%89%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%83%E3%83%88%E3%81%99%E3%82%8B":{"title":"spotlessでコードフォーマットする","content":"\n\u003chttps://github.com/diffplug/spotless/tree/main/plugin-maven\u003e\n\nJava,Kotlinのプロジェクトにフォーマッタとしてspotlessを導入する\n\n## Java\n\nlink: [JavaのFormatter](note/JavaのFormatter.md)\n\n以下のフォーマッタが利用可能\n\n\u003chttps://github.com/google/google-java-format\u003e\n\u003chttps://github.com/jhipster/prettier-java\u003e\n\u003chttps://github.com/diffplug/spotless/blob/main/ECLIPSE_SCREENSHOTS.md\u003e\n\n[JavaユーザならCode FormatterにはSpotlessがオススメ - 京都行きたい](https://progret.hatenadiary.com/entry/2019/12/09/165048)\n\n\u003chttps://github.com/diffplug/spotless/tree/main/plugin-maven#java\u003e\n\n````xml\n            \u003cplugin\u003e\n                \u003cgroupId\u003ecom.diffplug.spotless\u003c/groupId\u003e\n                \u003cartifactId\u003espotless-maven-plugin\u003c/artifactId\u003e\n                \u003cversion\u003e2.9.0\u003c/version\u003e\n                \u003cconfiguration\u003e\n                    \u003cformats\u003e\n                        \u003c!-- you can define as many formats as you want, each is independent --\u003e\n                        \u003cformat\u003e\n                            \u003c!-- define the files to apply to --\u003e\n                            \u003cincludes\u003e\n                                \u003cinclude\u003e*.md\u003c/include\u003e\n                                \u003cinclude\u003e.gitignore\u003c/include\u003e\n                            \u003c/includes\u003e\n                            \u003c!-- define the steps to apply to those files --\u003e\n                            \u003ctrimTrailingWhitespace/\u003e\n                            \u003cendWithNewline/\u003e\n                            \u003cindent\u003e\n                                \u003ctabs\u003etrue\u003c/tabs\u003e\n                                \u003cspacesPerTab\u003e4\u003c/spacesPerTab\u003e\n                            \u003c/indent\u003e\n                        \u003c/format\u003e\n                    \u003c/formats\u003e\n                    \u003c!-- define a language-specific format --\u003e\n                    \u003cjava\u003e\n                        \u003cincludes\u003e\n                            \u003cinclude\u003esrc/main/java/**/*.java\u003c/include\u003e\n                        \u003c/includes\u003e\n                        \u003cimportOrder /\u003e \u003c!-- standard import order --\u003e\n                        \u003c!-- no need to specify files, inferred automatically, but you can if you want --\u003e\n                        \u003cremoveUnusedImports /\u003e\n                        \u003c!-- apply a specific flavor of google-java-format --\u003e\n                        \u003cgoogleJavaFormat\u003e\n                            \u003cversion\u003e1.7\u003c/version\u003e\n                            \u003cstyle\u003eAOSP\u003c/style\u003e\n                        \u003c/googleJavaFormat\u003e\n                    \u003c/java\u003e\n                \u003c/configuration\u003e\n            \u003c/plugin\u003e\n        \u003c/plugins\u003e\n````\n\n### Google Java Formatのインデントサイズ変更\n\nGoogle Java Formatはインデントサイズが2\nすっきりして見た目はいいんだけど、既存への影響が大きい\n\n\u003chttps://github.com/diffplug/spotless/issues/420\u003e\nAOSPスタイルだとインデントサイズは4\n\neclipse を使うことで、フォーマットが柔軟に変更できる\n\n## Kotlin\n\n\u003chttps://github.com/pinterest/ktlint\u003e\n\u003chttps://github.com/Angry-Potato/prettier-plugin-kotlin\u003e\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["Java","Kotlin"]},"/note/spring-boot-configuration":{"title":"spring-boot-configuration","content":"\n# spring-boot-configuration\n\nSpring Boot で application.yml を Kotlin でバインディングできるようにしたい\n\n## 環境\n\n* Spring Boot 2.4.0\n* Kotlin 1.4.10\n\n## きっかけ\n\nSpring Bootでは環境別に設定を切り替える仕組みとしてapplication.propertiesやapplication.ymlファイルを使えます。\napplication.ymlにカスタムプロパティを書きたい。\n\n読み込む方法は主に2つ\n\n* `@Value`\n* `@ConfigurationProperties`\n\n### `@Value` の場合\n\nApiConfiguration.kt\n\n````\n@Configuration\nclass ApiConfiguration(\n    @Value(\"\\${api.url}\") url: String,\n){\n\n    @Bean\n    fun apiClient(): RestOperations = RestTemplateBuilder()\n            .rootUri(url)\n            .build()\n\n}\n````\n\napplication.yml\n\n````\napi:\n    url: \"http://api.example.com\"\n````\n\nこれで設定できるが、application.ymlで以下の警告がでる。\n\n`Cannot resolve configuration property 'api.url'`\n\nそれに、propertyがどこで使われているかや、型や説明がコードで明確になっていたほうが嬉しい\nおすすめなのは以下\n\n### `@ConfigurationProperties` の場合\n\n\u003chttps://spring.pleiades.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-external-config-constructor-binding\u003e\n\u003chttps://spring.pleiades.io/guides/tutorials/spring-boot-kotlin/\u003e\n\nApiConfiguration.kt\n\n````kotlin\n@ConstructorBinding\n@ConfigurationProperties(\"api\")\ndata class ApiConfiguration(\n    val url: String,\n    val connection: Connection,\n) {\n\n    // ネストした情報はdata class内にさらにdata classを書く\n    // api.connection.timeout となる\n    data class Connection(\n        val timeout: Int,\n    )\n}\n````\n\nこれだけだとバインドされないので、機能を有効化する必要がある\n\n````kotlin\n@SpringBootApplication\n@ConfigurationPropertiesScan\nclass MyApplication\n\nfun main(args: Array\u003cString\u003e) {\n    runApplication\u003cMyApplication\u003e(*args)\n}\n````\n\nもしくは `@Configuration` クラスに個別に指定する\n\n````kotlin\n@Configuration\n@EnableConfigurationProperties(ApiConfiguration::class)\nclass MyConfiguration {\n}\n````\n\n### 補完が効くようにする\n\nカスタムプロパティをIDEに認識させるためには、 `META-INF/spring-configuration-metadata.json` が存在する必要がある。\n\n\u003chttps://spring.pleiades.io/spring-boot/docs/current/reference/html/appendix-configuration-metadata.html#configuration-metadata-annotation-processor\u003e\n\nbuild.gradle.kts\n\n````\ndependencies {\n    annotationProcessor(\"org.springframework.boot:spring-boot-configuration-processor\")\n}\n````\n\nIntellijでは、 `Preferences | Build, Execution, Deployment | Compiler | Annotation Processors` で `Enable annotation processing` を有効にするとビルド時に生成されるようになるとあるが、自分の環境では生成されなかった。\n\nドキュメントをよく見たら、Kotlinの場合 `kapt` が必要とのこと\n\u003chttps://spring.pleiades.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-kotlin-configuration-properties\u003e\n\nbuild.gradle.kts\n\n````\nplugins {\n  ...\n  kotlin(\"kapt\") version \"1.4.10\"\n}\n\ndependencies {\n  ...\n  kapt(\"org.springframework.boot:spring-boot-configuration-processor\")\n}\n````\n\nkaptタスクを実行\n\n````sh\n./gradlew kaptKotlin\n````\n\n自分の環境では `build/tmp/kapt3/classes/main/META-INF/spring-configuration-metadata.json` に作成された\n","lastmodified":"2023-07-29T08:18:43.047498643Z","tags":["spring"]},"/note/spring-mock-rest-server":{"title":"spring-mock-rest-server","content":"\n# spring mock rest server\n\n[SpringFramework](note/SpringFramework.md) のユニットテストでHTTPサーバーをmockする\n\nRestTemplateをmockするか、RestTemplateの通信先をmockするか\ngoのhttptest.Serverみたいな\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["spring"]},"/note/spring-validation":{"title":"spring-validation","content":"\n# spring validation\n\n[SpringFramework](note/SpringFramework.md) REST APIでパラメータをバリデーションしたい\n\n@Validated, @Validをつけてもvalidationされなかった\n\n2.3からvalidationライブラリが含まれなくなった\n\u003chttps://github.com/spring-projects/spring-boot/wiki/Spring-Boot-2.3-Release-Notes#validation-starter-no-longer-included-in-web-starters\u003e\n\n### 対応\n\n自分で入れる\n\n### 結果\n\nvalidationが効くようになった\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["spring"]},"/note/springdoc":{"title":"springdoc","content":"\n# springdoc\n\n[SpringFramework](note/SpringFramework.md) でOpenAPI仕様書を作成するライブラリ\n\nspringfoxをやめた\nOAS3にイマイチたいおうしてない\n\noneOfが使えなかった\n\u003chttps://swagger.io/docs/specification/data-models/inheritance-and-polymorphism/\u003e\n\nやったこと\n\nライブラリ入れた\nOpenAPI()に変更した\nannotationをv3に変更した\n\n\u003chttps://www.b1a9idps.com/posts/springdoc-openapi-1\u003e\n\u003chttps://qiita.com/yukithm/items/fafc54bc331696b0c333\u003e\n\u003chttps://springdoc.org/#migrating-from-springfox\u003e\n\u003chttps://github.com/springdoc/springdoc-openapi\u003e\n\n### oneOfで警告がでる\n\n\u003chttps://github.com/OpenAPITools/openapi-generator/blob/master/modules/openapi-generator/src/main/java/org/openapitools/codegen/DefaultCodegen.java#L2319\u003e\n\nbefore\n\n````\n@Schema(\n    description = \"1区間情報\",\n    oneOf = [Section.SectionPoint::class, Section.SectionMove::class],\n    discriminatorProperty = \"sectionType\",\n)\nsealed class Section(val sectionType: string) {\n    data class SectionPoint(val name: String): Section(\"point\"){}\n    data class SectionMove(val move: String): Section(\"move\"){}\n}\n````\n\nafter\n\n````\n@Schema(\n    description = \"1区間情報\",\n    oneOf = [Section.SectionPoint::class, Section.SectionMove::class],\n    discriminatorProperty = \"sectionType\",\n    discriminatorMapping = [\n        DiscriminatorMapping(value = \"point\", schema = Section.SectionPoint::class),\n        DiscriminatorMapping(value = \"move\", schema = Section.SectionMove::class),\n    ],\n)\nsealed class Section() {\n    data class SectionPoint(val sectionType: string, val name: String): Section(){}\n    data class SectionMove(val sectionType: string, val move: String): Section(){}\n}\n````\n\n### Jacksonでdeserializeするための設定\n\nJsonTypeInfo, JsonSubTypesのアノテーションを追加した\n\n````\n@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = \"type\")\n@JsonSubTypes(\n    value = [\n        JsonSubTypes.Type(value = SectionRecord.Point::class, name = \"point\"),\n        JsonSubTypes.Type(value = SectionRecord.Move::class, name = \"move\"),\n    ]\n)\n````\n\n## openapi-generatorでStackOverflowErrorとなる\n\n上記のJsonTypeInfoを入れたら、swagger.yamlからコード生成するときに無限ループとなった\n\n````\n[main] INFO  o.o.codegen.DefaultGenerator - Generator 'typescript-axios' is considered stable.\nException in thread \"main\" java.lang.StackOverflowError\n\tat java.util.regex.Pattern.error(Pattern.java:1969)\n\tat java.util.regex.Pattern.\u003cinit\u003e(Pattern.java:1354)\n\tat java.util.regex.Pattern.compile(Pattern.java:1054)\n\tat java.lang.String.replace(String.java:2239)\n\tat org.openapitools.codegen.utils.ModelUtils.getSimpleRef(ModelUtils.java:405)\n\tat org.openapitools.codegen.utils.ModelUtils.getReferencedSchema(ModelUtils.java:832)\n\tat org.openapitools.codegen.DefaultCodegen.addProperties(DefaultCodegen.java:3024)\n\tat org.openapitools.codegen.DefaultCodegen.addProperties(DefaultCodegen.java:3000)\n\tat org.openapitools.codegen.DefaultCodegen.addProperties(DefaultCodegen.java:3025)\n\tat org.openapitools.codegen.DefaultCodegen.addProperties(DefaultCodegen.java:3010)\n\tat org.openapitools.codegen.DefaultCodegen.addProperties(DefaultCodegen.java:3025)\n````\n\nswagger.yaml\n\n````yaml\n    SectionRecord:\n      required:\n      - type\n      type: object\n      properties:\n        type:\n          type: string\n      description: ルート詳細の1区間情報\n      discriminator:\n        propertyName: type\n        mapping:\n          point: '#/components/schemas/Point'\n          move: '#/components/schemas/Move'\n      oneOf:\n      - $ref: '#/components/schemas/Point'\n      - $ref: '#/components/schemas/Move'\n    Move:\n      required:\n      - distanceMetre\n      - move\n      - transitFare\n      - transitMinutes\n      type: object\n      allOf:\n      - $ref: '#/components/schemas/SectionRecord'\n      - type: object\n        properties:\n          move:\n            type: string\n            enum:\n            - TRAIN\n            - EXPRESS_TRAIN\n            - BULLET_TRAIN\n            - LOCAL_BUS\n            - HIGHWAY_BUS\n            - FERRY\n            - AIRPLANE\n            - CYCLE_SHARING\n            - CYCLE\n            - TAXI\n            - CAR\n            - CAR_SHARING\n            - RENTAL_CAR\n            - WALK\n          distanceMetre:\n            type: integer\n            format: int32\n          transitMinutes:\n            type: integer\n            format: int32\n          transitFare:\n            type: integer\n            format: int32\n          transport:\n            $ref: '#/components/schemas/TransportRecord'\n    Point:\n      required:\n      - coord\n      - isFirstSpot\n      - isLastSpot\n      - name\n      type: object\n      allOf:\n      - $ref: '#/components/schemas/SectionRecord'\n      - type: object\n        properties:\n          name:\n            type: string\n          coord:\n            $ref: '#/components/schemas/CoordinateRecord'\n          departureTime:\n            type: string\n            format: date-time\n          arrivalTime:\n            type: string\n            format: date-time\n          isFirstSpot:\n            type: boolean\n          isLastSpot:\n            type: boolean\n\n````\n\n親のoneOfと子のallOfで循環参照しているのが原因ぽい\nためしに子のallOfを消したら通った。\n\n### やったこと\n\nSchemaのoneOfの定義を削除した\n\n````\n@Schema(description = \"ルート詳細の1区間情報\")\n@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = \"type\")\n@JsonSubTypes(\n    value = [\n        JsonSubTypes.Type(value = SectionRecord.Point::class, name = \"point\"),\n        JsonSubTypes.Type(value = SectionRecord.Move::class, name = \"move\"),\n    ]\n)\nsealed class SectionRecord() {\n    data class Point(\n\n````\n\nswagger.yaml\n\n````yaml\n    SectionRecord:\n      required:\n      - type\n      type: object\n      properties:\n        type:\n          type: string\n      description: ルート詳細の1区間情報\n      discriminator:\n        propertyName: type\n    Move:\n      required:\n      - distanceMetre\n      - move\n      - transitFare\n      - transitMinutes\n      type: object\n      allOf:\n      - $ref: '#/components/schemas/SectionRecord'\n      - type: object\n        properties:\n          move:\n            type: string\n            enum:\n            - TRAIN\n            - EXPRESS_TRAIN\n            - BULLET_TRAIN\n            - LOCAL_BUS\n            - HIGHWAY_BUS\n            - FERRY\n            - AIRPLANE\n            - CYCLE_SHARING\n            - CYCLE\n            - TAXI\n            - CAR\n            - CAR_SHARING\n            - RENTAL_CAR\n            - WALK\n          distanceMetre:\n            type: integer\n            format: int32\n          transitMinutes:\n            type: integer\n            format: int32\n          transitFare:\n            type: integer\n            format: int32\n          transport:\n            $ref: '#/components/schemas/TransportRecord'\n    Point:\n      required:\n      - coord\n      - isFirstSpot\n      - isLastSpot\n      - name\n      type: object\n      allOf:\n      - $ref: '#/components/schemas/SectionRecord'\n      - type: object\n        properties:\n          name:\n            type: string\n          coord:\n            $ref: '#/components/schemas/CoordinateRecord'\n          departureTime:\n            type: string\n            format: date-time\n          arrivalTime:\n            type: string\n            format: date-time\n          isFirstSpot:\n            type: boolean\n          isLastSpot:\n            type: boolean\n\n````\n\n````diff\n\u003c         mapping:\n\u003c           point: '#/components/schemas/Point'\n\u003c           move: '#/components/schemas/Move'\n\u003c       oneOf:\n\u003c       - $ref: '#/components/schemas/Point'\n\u003c       - $ref: '#/components/schemas/Move'\n````\n\noneOfの定義が消えた\n\n生成されたコードも問題なし\n\n````\nexport interface SectionRecord {\n  /**\n   *\n   * @type {string}\n   * @memberof SectionRecord\n   */\n  type: string\n}\nexport interface Move extends SectionRecord {\n\t// ....\n}\nexport interface Point extends SectionRecord {\n\t// ....\n}\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["spring"]},"/note/springdoc%E3%81%A7polymorphism%E3%82%92%E8%A1%A8%E7%8F%BE%E3%81%99%E3%82%8B%E3%81%AE%E3%81%8C%E9%9B%A3%E3%81%97%E3%81%8B%E3%81%A3%E3%81%9F":{"title":"springdocでpolymorphismを表現するのが難しかった","content":"\n# springdoc-bug\n\nnestしたpolymorphismがうまく反映されなかった\n\n````kotlin\n@Schema(description = \"ルート詳細の1区間情報\")\n@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = \"type\")\n@JsonSubTypes(\n    value = [\n        JsonSubTypes.Type(value = SectionRecord.Point::class, name = \"point\"),\n        JsonSubTypes.Type(value = SectionRecord.Move::class, name = \"move\"),\n    ]\n)\nsealed class SectionRecord() {\n    data class Point(\n        val name: String,\n        val coord: CoordinateRecord,\n        @JsonFormat(pattern = \"yyyy-MM-dd'T'HH:mm:ss\")\n        val departureTime: LocalDateTime? = null,\n        @JsonFormat(pattern = \"yyyy-MM-dd'T'HH:mm:ss\")\n        val arrivalTime: LocalDateTime? = null,\n        val isFirstSpot: Boolean = false,\n        val isLastSpot: Boolean = false,\n    ) : SectionRecord()\n\n    data class Move(\n        val move: MoveTypeRecord,\n        val distanceMeter: Int,\n        val transitMinutes: Int,\n        val transitFare: Int,\n        @Schema(description = \"駅等の入口名称等\", example = \"A3口\")\n        val entranceGateway: String? = null,\n        @Schema(description = \"駅等の出口名称\", example = \"6番口(赤レンガ倉庫口)\")\n        val exitGateway: String? = null,\n        val transport: TransportRecord?,\n        val directOperations: List\u003cDirectOperationRecord\u003e = listOf(),\n    ) : SectionRecord()\n}\n\n@Schema(description = \"直通区間の情報\")\n@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = \"type\")\n@JsonSubTypes(\n    value = [\n        JsonSubTypes.Type(value = DirectOperationRecord.Point::class, name = \"point\"),\n        JsonSubTypes.Type(value = DirectOperationRecord.Move::class, name = \"move\"),\n    ]\n)\nsealed class DirectOperationRecord() {\n    data class Point(\n        val name: String,\n        val coord: CoordinateRecord,\n        @JsonFormat(pattern = \"yyyy-MM-dd'T'HH:mm:ss\")\n        val departureTime: LocalDateTime? = null,\n        @JsonFormat(pattern = \"yyyy-MM-dd'T'HH:mm:ss\")\n        val arrivalTime: LocalDateTime? = null,\n    ) : DirectOperationRecord()\n\n    data class Move(\n        val move: MoveTypeRecord,\n        val distanceMeter: Int,\n        val transitMinutes: Int,\n        val transitFare: Int,\n        val transport: TransportRecord?,\n    ) : DirectOperationRecord()\n}\n\n````\n\nやっぱり書き方が正しくないっぽい…\n\n````kotlin\n@Schema(\n    description = \"ルート詳細の1区間情報\",\n    oneOf = [SectionRecord.SectionPoint::class, SectionRecord.SectionMove::class],\n    discriminatorProperty = \"type\",\n    discriminatorMapping = [\n        DiscriminatorMapping(value = \"point\", schema = SectionRecord.SectionPoint::class),\n        DiscriminatorMapping(value = \"move\", schema = SectionRecord.SectionMove::class),\n    ],\n)\nsealed class SectionRecord(val type: String) {\n    data class SectionPoint(\n        val name: String,\n        val coord: CoordinateRecord,\n        @JsonFormat(pattern = \"yyyy-MM-dd'T'HH:mm:ss\")\n        val departureTime: LocalDateTime? = null,\n        @JsonFormat(pattern = \"yyyy-MM-dd'T'HH:mm:ss\")\n        val arrivalTime: LocalDateTime? = null,\n        val isFirstSpot: Boolean = false,\n        val isLastSpot: Boolean = false,\n    ) : SectionRecord(\"point\")\n\n    data class SectionMove(\n        val move: MoveTypeRecord,\n        val distanceMeter: Int,\n        val transitMinutes: Int,\n        val transitFare: Int,\n        @Schema(description = \"駅等の入口名称等\", example = \"A3口\")\n        val entranceGateway: String? = null,\n        @Schema(description = \"駅等の出口名称\", example = \"6番口(赤レンガ倉庫口)\")\n        val exitGateway: String? = null,\n        val transport: TransportRecord?,\n        val directOperations: List\u003cDirectOperationRecord\u003e = listOf(),\n    ) : SectionRecord(\"move\")\n}\n\n@Schema(\n    description = \"ルート詳細の1区間情報\",\n    oneOf = [DirectOperationRecord.DirectOperationPoint::class, DirectOperationRecord.DirectOperationMove::class],\n    discriminatorProperty = \"type\",\n    discriminatorMapping = [\n        DiscriminatorMapping(value = \"point\", schema = DirectOperationRecord.DirectOperationPoint::class),\n        DiscriminatorMapping(value = \"move\", schema = DirectOperationRecord.DirectOperationMove::class),\n    ],\n)\nsealed class DirectOperationRecord(val type: String) {\n    data class DirectOperationPoint(\n        val name: String,\n        val coord: CoordinateRecord,\n        @JsonFormat(pattern = \"yyyy-MM-dd'T'HH:mm:ss\")\n        val departureTime: LocalDateTime? = null,\n        @JsonFormat(pattern = \"yyyy-MM-dd'T'HH:mm:ss\")\n        val arrivalTime: LocalDateTime? = null,\n    ) : DirectOperationRecord(\"point\")\n\n    data class DirectOperationMove(\n        val move: MoveTypeRecord,\n        val distanceMeter: Int,\n        val transitMinutes: Int,\n        val transitFare: Int,\n        val transport: TransportRecord?,\n    ) : DirectOperationRecord(\"move\")\n}\n````\n\nこれだとうまくいったので、JsonSubTypesで反映させるのは正しいやり方ではなかったみたい\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["spring"]},"/note/sql%E3%81%A7sum_case_when%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E5%A0%B4%E5%90%88%E5%88%86%E3%81%91%E9%9B%86%E8%A8%88":{"title":"sqlでsum_case_whenを使って場合分け集計","content":"\n\\#sql\n\n````sql\nSELECT SUM(CASE WHEN flag = 1 THEN 1 ELSE 0 END) FROM table\n````\n\n### 件数を集計したい場合\n\n````sql\nSELECT api_path\n    ,sum(case when status_code = 200 then 1 else 0 end) as success\n    ,sum(case when status_code = 500 then 1 else 0 end) as error\nFROM access_log\nGROUP BY api_path\nORDER BY api_path\n````\n\n### 条件に応じてカラムを集計したい場合\n\n````sql\nCREATE TABLE `売上` (\n  `id`             int           NOT NULL AUTO_INCREMENT,\n  `プロジェクトID` varchar(3)    NOT NULL,\n  `計上年月日`     date          NOT NULL,\n  `金額`           decimal(11,2) NOT NULL,\n  PRIMARY KEY(`id`)\n);\n````\n\n````sql\nSELECT\n  `プロジェクトID`,\n  SUM(`金額`) AS `売上額`,\n  SUM(CASE WHEN `計上年月日` \u003e '2020-07-20' THEN `金額` ELSE 0 END) AS `売上残`\nFROM `売上予定`\nGROUP BY `プロジェクトID`;\n````\n\n結果\n\n````tsv\nプロジェクトID    売上額       売上残\n001             600000.00   200000.00\n002             100000.00   0.00\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":[]},"/note/ssh":{"title":"ssh","content":"\n\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["terminal"]},"/note/ssh%E3%81%A7%E6%8E%A5%E7%B6%9A%E5%BE%8C%E3%81%AB%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%82%92%E5%AE%9F%E8%A1%8C%E3%81%99%E3%82%8B":{"title":"sshで接続後にコマンドを実行する","content":"\n踏み台サーバーにログインしたあと、毎回専用ユーザーになるのが面倒だったので調べた\n\n### ログイン後別のユーザーになりたい\n\n````.ssh/config\nHost bastion_aws\n  HostName x.x.x.x\n  RemoteCommand su - user2\n  RequestTTY force\n````\n\n### ログイン後所定のディレクトリに移動したい\n\n````.ssh/config\nHost bastion\n  HostName x.x.x.x\n  RemoteCommand cd temp; bash\n  RequestTTY force\n````\n\n末尾のbashがないと、コマンド実行後すぐに切断される\n\n### sshコマンドオプションでも可能\n\n````bash\nssh -t user1@remote.host \"sudo su - user2\" \n````\n\n`-t` でtty割り当て\n\n## 解説\n\n\u003chttps://man7.org/linux/man-pages/man5/ssh_config.5.html\u003e\n\n* RemoteCommand サーバに接続後、リモートホストで実行されるコマンド。\n* RequestTTY 接続先のサーバでシェルを起動するかを指定する。\n\n### RequestTTY\n\nRequestTTYは4つの値のうちの1つを持つことができます\n\n* `no` - SSHは端末の出力を要求しません。\n* `yes` - SSHは、その入力元が端末でもある場合に端末出力を要求します。\n* `force` - SSHは、入力ソースの種類にかかわらず、常に端末の出力を要求します。\n* `auto` -SSHは、ログインセッションを開くときに端末の出力を要求します。\n\nRequestTTYにforceかyesをつけないと、接続後にttyが割り当てられない\n\n### RemoteCommand\n\n接続後にリモートで実行されるコマンド\nこのコマンドを実行すると切断される\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["shell","terminal"]},"/note/ssh%E3%81%A7-tt%E3%81%8C%E5%BF%85%E8%A6%81%E3%81%AA%E5%A0%B4%E5%90%88":{"title":"sshで-ttが必要な場合","content":"\n[ssh](note/ssh.md) でコマンドが実行できないときがあり調べた\n\n[sshを使ってリモートマシンでコマンドを叩く際の注意点 - 覚書](https://satoru-takeuchi.hatenablog.com/entry/2017/04/11/223932)\n\nman(1) [ssh](http://d.hatena.ne.jp/keyword/ssh)より抜粋:\n\n \u003e \n \u003e -t Force pseudo-terminal allocation. This can be used to execute arbitrary screen-based programs on a remote machine, which can be very useful, e.g. when implementing menu services.\n\nまずはインターネット上からcrontabに書いたコマンドを実行すると、正しく[IPアドレス](http://d.hatena.ne.jp/keyword/IP%A5%A2%A5%C9%A5%EC%A5%B9)が得られました。これで解決したと思ってcrontab上の[ssh](http://d.hatena.ne.jp/keyword/ssh)に-tオプションを付与したものの、またしても[IPアドレス](http://d.hatena.ne.jp/keyword/IP%A5%A2%A5%C9%A5%EC%A5%B9)を書き込んでいるはずのファイルは空でした。\n\nman(1) [ssh](http://d.hatena.ne.jp/keyword/ssh)を再度読んでみると、さきほど抜粋した-tオプションの説明には続きがありました。\n\n \u003e \n \u003e -t Force pseudo-terminal allocation. This can be used to execute arbitrary screen-based programs on a remote machine, which can be very useful, e.g. when implementing menu services. Multiple -t options force tty allocation, even if [ssh](http://d.hatena.ne.jp/keyword/ssh) has no local tty.\n\ncronなどのttyを持たないプロセス([daemon](http://d.hatena.ne.jp/keyword/daemon))から[ssh](http://d.hatena.ne.jp/keyword/ssh)を実行する場合は、-tオプションだけでは不十分で、-ttオプションが必要と書いてあります。crontab上の[ssh](http://d.hatena.ne.jp/keyword/ssh)に-ttオプションを付与したところ、無事問題は解決できました。最初からmanをちゃんと読んでおけばもう少し解決が楽でした。反省。\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["ssh","terminal"]},"/note/ssh-%E8%B8%8F%E3%81%BF%E5%8F%B0%E3%81%A7-su-user-%E3%81%97%E3%81%A6%E3%81%8B%E3%82%89%E6%8E%A5%E7%B6%9A%E3%81%99%E3%82%8Bssh%E5%85%88%E3%82%92sshconfig%E3%81%A7%E8%A8%AD%E5%AE%9A%E3%81%99%E3%82%8B":{"title":"ssh 踏み台で su user してから接続するssh先をsshconfigで設定する","content":"\nローカル -\u003e 踏み台 -\u003e 許可されたユーザーにsuする -\u003e ターゲットにssh というケース\n\n## functionを作る\n\n````shell\nfunction ssh_via_bastion() {\n    ssh -t bastion_host \"su - superuser -c 'ssh $1'\"\n}\nssh_via_bastion \u003ctarget_host\u003e\n````\n\nこれでもいいが、sshコマンドじゃないしできれば `.ssh/config` で一括管理したい\n\n## .ssh/configに設定する\n\n踏み台経由で真っ先に思い浮かぶのは `ProxyCommand` を使ったやり方\n\n````ssh-config\nHost host-you-want-to-access\n  ProxyCommand ssh -W %h:%p \u003cbastion_host\u003e\n  HostName \u003ctarget_host\u003e\n````\n\nこれは踏み台にsshするときのユーザーと、踏み台からtarget_hostにsshするときのユーザーが同じなら問題ない。\n今回は踏み台で別のユーザーになる必要がある。\n\n`RemoteCommand` で、sshした先でコマンドを実行することができる\n\n````ssh-config\nHost host-you-want-to-access\n  # これ！\n  RemoteCommand sudo su - root -c 'ssh \u003ctarget_host\u003e'\n  # tty割当しないと対話できない\n  RequestTTY force\n  HostName \u003cbastion_host\u003e\n````\n\n````shell\n$ ssh host-you-want-to-access\n=\u003e 踏み台経由でアクセスできる\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["2023/01/24","shell"]},"/note/ssh-host-key-verification%E3%81%AB%E5%A4%B1%E6%95%97%E3%81%99%E3%82%8B":{"title":"ssh host key verificationに失敗する","content":"\n[エンジニアなら知らないとヤバいSSHの基礎 - もちゅろぐ](https://blog.mothule.com/tools/ssh/tools-ssh-basic#known_hosts%E3%81%A8%E3%81%AF)\n`~/.ssh/known_hosts` には接続経験のあるホストの公開鍵を保存してある\nこのファイルに書いてある公開鍵に紐づく秘密鍵があるか検証することで、万が一サーバ側の公開鍵が変更されていても気付ける仕組みとなってます。\n\n`ssh-keygen -R $host` でknown_hostsを削除できる\n\n### ssh-keyscan\n\n[ssh-keyscan(1) - OpenBSD manual pages](https://man.openbsd.org/ssh-keyscan.1)\nhostの公開鍵を収集する\n\n````shell\n$ ssh-keyscan github.com\n# github.com:22 SSH-2.0-babeld-fc31accb\n# github.com:22 SSH-2.0-babeld-fc31accb\n# github.com:22 SSH-2.0-babeld-fc31accb\ngithub.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ==\n# github.com:22 SSH-2.0-babeld-fc31accb\ngithub.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=\n# github.com:22 SSH-2.0-babeld-fc31accb\ngithub.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["shell"]},"/note/starship":{"title":"starship","content":"\nhttps://starship.rs\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["2023/01/13","shell"]},"/note/svelte_typescript_svelte-material-ui":{"title":"svelte_typescript_svelte-material-ui","content":"\n[Svelte](note/Svelte.md) \n\n# svelte_typescript_svelte-material-ui\n\n## svelte-material-ui を導入する\n\n参考\n\u003chttps://github.com/hperrin/svelte-material-ui\u003e\n\u003chttps://github.com/hperrin/smui-example-rollup/\u003e\n\n### インストール\n\n````sh\nyarn add -D svelte-material-ui\n````\n\nrollupでPostCSSを使うためのプラグインを導入\n\nPostCSS 8 を使用するよう警告が出たため別でインストール\n\u003chttps://github.com/postcss/postcss/wiki/PostCSS-8-for-end-users\u003e\n\n````sh\nyarn add -D rollup-plugin-postcss\nyarn add -D postcss\n````\n\nsassをインストール\n\n````sh\nyarn add -D node-sass sass\n````\n\n### rollup.config\n\nrollup.config.js\n\n````\nimport postcss from 'rollup-plugin-postcss'\n\nexport default {\n\n  plugins: [\n    postcss({\n      extract: true,\n      minimize: true,\n      use: [\n        [\n          'sass',\n          {\n            includePaths: ['./theme', './node_modules'],\n          },\n        ],\n      ],\n    }),\n  ]\n\n}\n````\n\n### themeファイルを作成\n\n空ファイルでOK\n\n````sh\ntouch theme/_smui-theme.scss\n````\n\n### フォント、アイコンを使用できるようにする\n\npublic/index.html\n\n````\n\u003chead\u003e\n \n   \u003clink rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\" /\u003e\n   \u003clink rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css?family=Roboto:300,400,500,600,700\" /\u003e\n   \u003clink rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css?family=Roboto+Mono\" /\u003e\n\u003c/head\u003e\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["TypeScript","Svelte"]},"/note/terminal%E3%81%8B%E3%82%89%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%92%E8%B5%B7%E5%8B%95%E7%B5%82%E4%BA%86%E3%81%99%E3%82%8B":{"title":"terminalからアプリケーションを起動・終了する","content":"\n\\#shell #Mac\n\n### 起動\n\n````shell\nosascript -e \"quit app '\u003cアプリケーション名\u003e'\"\n````\n\n### 終了\n\n````shell\nopen -a \"\u003cアプリケーション名\u003e\"\n````\n\n[ネットワークに応じて処理を振り分けるスクリプト](blog/ネットワークに応じて処理を振り分けるスクリプト.md) と組み合わせれば、自宅では起動したいが会社ではオフにしたいアプリケーション(VPNなど)を自動オンオフできる\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["shell","Mac"]},"/note/tig":{"title":"tig","content":"\nTUIのGitクライアントツール\n\n設定ファイル\n\n* ~/.tigrc\n* $XDG_CONFIG_HOME/tig/config\n\n## TIPS\n\n### blameの操作\n\n* blame viewを開く `b`\n* 親のコミットに遡る 該当行で `,`\n* 親のコミットからもとのコミットに戻る `\u003c`\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["2023/02/03","git","terminal"]},"/note/tmux":{"title":"tmux","content":"\n\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["tmux","terminal"]},"/note/tmux%E3%81%A7brew-shellenv%E3%81%8C%E3%81%AA%E3%81%AB%E3%82%82%E8%A1%A8%E7%A4%BA%E3%81%95%E3%82%8C%E3%81%AA%E3%81%84":{"title":"tmuxでbrew shellenvがなにも表示されない","content":"\n## 事象\n\nzshでターミナルを開く\n→ tmuxコマンドでtmuxを開く\n→ brewでインストールしたコマンドがPATHに入っていない\n\nzshenvで `eval $(brew shellenv)` でPATHを設定しているのだが、\n`brew shellenv` コマンドを実行してもなにも表示されないのが原因のようだった\n\n### ソースを見る\n\n\u003chttps://github.com/Homebrew/brew/blob/master/Library/Homebrew/cmd/shellenv.sh\u003e\n\n`HOMEBREW_SHELLENV_PREFIX` と `HOMEBREW_PREFIX` が同じ場合は何もしないとなっている\n\n````shell\n$ echo $HOMEBREW_SHELLENV_PREFIX\n/opt/homebrew\n\n$ echo $HOMEBREW_PREFIX\n/opt/homebrew\n````\n\n### ワークアラウンド\n\n正しいかは怪しいが、環境変数を一旦クリアすることで再セットされる\n\n\u003chttps://github.com/Homebrew/brew/issues/11851\u003e\n\n````shell\nunset HOMEBREW_SHELLENV_PREFIX\neval $(/opt/homebrew/bin/brew shellenv)\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["tmux","shell"]},"/note/tmux%E3%81%A7ssh%E6%99%82%E3%81%AB%E8%89%B2%E3%82%92%E5%A4%89%E3%81%88%E3%82%8B":{"title":"tmuxでssh時に色を変える","content":"\nhttps://bacchi.me/linux/change-terminal-bgcolor/\n\n````bash\nfunction ssh() {\n  # tmux起動時\n  if [[ -n $(printenv TMUX) ]] ; then\n      # 現在のペインIDを記録\n      local pane_id=$(tmux display -p '#{pane_id}')\n      # 接続先ホスト名に応じて背景色を切り替え\n      if [[ `echo $1 | grep 'prd'` ]] ; then\n          tmux select-pane -P 'bg=colour52,fg=white'\n      elif [[ `echo $1 | grep 'stg'` ]] ; then\n          tmux select-pane -P 'bg=colour25,fg=white'\n      fi\n\n      # 通常通りssh続行\n      command ssh $@\n\n      # デフォルトの背景色に戻す\n      tmux select-pane -t $pane_id -P 'default'\n  else\n      command ssh $@\n  fi\n}\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["tmux","shell"]},"/note/tmux%E3%81%AEwindow%E3%82%92fzf%E3%81%A7%E7%A7%BB%E5%8B%95%E3%81%99%E3%82%8B":{"title":"tmuxのwindowをfzfで移動する","content":"\nhttps://github.com/sainnhe/tmux-fzf\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["tmux"]},"/note/ts-jest-vue":{"title":"ts-jest-vue","content":"\n# ts-jest vue\n\n## 問題\n\nLogo.spec.js -\u003e Logo.spec.ts にリネームしてyarn testしたらエラー\n\ntest/Logo.spec.ts\n\n````\nimport { mount } from '@vue/test-utils'\nimport Logo from '@/components/Logo.vue'\n\ndescribe('Logo', () =\u003e {\n  test('is a Vue instance', () =\u003e {\n    const wrapper = mount(Logo)\n    expect(wrapper.vm).toBeTruthy()\n  })\n})\n````\n\n````\n    test/Logo.spec.ts:2:20 - error TS2307: Cannot find module '@/components/Logo.vue' or its corresponding type declarations.\n\n    2 import Search from '@/pages/search.vue'\n                         ~~~~~~~~~~~~~~~~~~~~\n````\n\n## 対応\n\ntsconfig.json\n\n````\n{\n  \"compilerOptions\": {\n    \"types\": [\n      \"@types/node\",\n      \"@nuxt/types\",\n      \"@types/jest\"\n    ]\n  }\n}\n````\n\n~/@types/vue-shim.d.ts を作成\nファイル名は何でもよさげ\n\n````typescript\ndeclare module '*.vue' {\n  import Vue from 'vue'\n  export default Vue\n}\n````\n\n=\u003e `yarn test` が通るようになった\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["Vuejs"]},"/note/ts-nuxt-storybook%E3%81%AE%E6%A7%8B%E7%AF%89":{"title":"ts-nuxt-storybookの構築","content":"\n# ts nuxt storybookの構築\n\n* Nuxt.js 2.14.6\n* TypeScript 4.0.5\n* Storybook 6.1.10\n* @nuxtjs/tailwindcss: 3.1.0\n\n## TypeScriptで書かれたVueコンポーネントを使う\n\n````diff\nmodule.exports = {\n  webpackFinal: async (config) =\u003e {\n\n+    config.module.rules.push({\n+      test: /\\.ts$/,\n+      exclude: /node_modules/,\n+      use: [\n+        {\n+          loader: 'ts-loader',\n+          options: {\n+            appendTsSuffixTo: [/\\.vue$/],\n+            transpileOnly: true,\n+          },\n+        },\n+      ],\n+    })\n\n    return config\n  },\n}\n````\n\n## TailwindCSSを使う\n\n.storybook/main.js\n\n````diff\nmodule.exports = {\n  webpackFinal: async (config) =\u003e {\n\n+    config.module.rules.push({\n+      test: /\\.css$/,\n+      exclude: /node_modules/,\n+      use: [\n+        {\n+          loader: 'postcss-loader',\n+          options: {\n+            ident: 'postcss',\n+            plugins: [require('tailwindcss')('./tailwind.config.js')],\n+          },\n+        },\n+      ],\n+    })\n+\n+    config.module.rules.push({\n+      test: /\\.scss$/,\n+      exclude: /node_modules/,\n+      use: [\n+        {\n+          loader: 'postcss-loader',\n+          options: {\n+            ident: 'postcss',\n+            plugins: [require('tailwindcss')('./tailwind.config.js')],\n+          },\n+        },\n+        {\n+          loader: 'sass-loader',\n+        },\n+      ],\n+    })\n\n    return config\n  },\n}\n````\n\n.storybook/preview.js\n\n````diff\n+ import './tailwind.css'\n````\n\n.storybook/tailwind.css\n\n````diff\n+ @import 'tailwindcss/base';\n+ @import 'tailwindcss/components';\n+ @import 'tailwindcss/utilities';\n````\n\n## 共通のCSSを読み込む\n\n.storybook/preview.js\n\n````\n+ import '~/assets/style/common.css'\n````\n\n## Link\n\n[TypeScript](note/TypeScript.md) [Nuxt.js](note/Nuxt.js.md) [Vue.js](note/Vue.js.md)\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["TypeScript","Vuejs"]},"/note/typescript-TypeGuard":{"title":"typescript-TypeGuard","content":"\n[TypeScript](note/TypeScript.md)\n\n# typescript TypeGuard\n\n````\nclass Animal {\n}\n\nclass Duck extends Animal {\n}\n\nclass Tiger extends Animal {\n}\n\nconst isDuck = (animal: Animal): animal is Duck =\u003e \n        animal.type === 'duck' \u0026\u0026 animal.call !== undefined\n\nconst animal = someFunc()\nif (isDuck(animal)) {\n    animal.call()\n}\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["TypeScript"]},"/note/typescript-openapi":{"title":"typescript-openapi","content":"\n# typescript openapi\n\n\u003chttps://github.com/OpenAPITools/openapi-generator/blob/master/docs/generators/typescript-axios.md\u003e\n\npackage.json\n\n````json\n{\n    \"scripts\": {\n        \"openapi-generate\": \"rm -f api_client/*.ts \u0026\u0026 TS_POST_PROCESS_FILE='yarn prettier --write' openapi-generator-cli generate -i http://localhost:8080/api/v3/api-docs -g typescript-axios -o api_client --additional-properties=disallowAdditionalPropertiesIfNotPresent=false,modelPropertyNaming=camelCase,supportsES6=true,useSingleRequestParameter=true --enable-post-process-file\"\n    }\n}\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["TypeScript","OpenAPI"]},"/note/unicode%E3%81%A8emoji%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6":{"title":"unicodeとemojiについて","content":"\n## バージョン\n\n* emoji 11.0 からは Unicode のバージョンと揃っている\n\n* 最新はemoji 14.0\n\n* emoji 1.0 で初めて整理された\n  \n  * \u003chttps://emojipedia.org/emoji-1.0/\u003e\n  * Unicode 6.1 までの絵文字 + すこし\n  \u003c!----\u003e\n  \n````\n  The first release of emoji documentation from Unicode, which includes all emojis approved between 2010—2015. \n  \n  Published in August 2015, this primarily includes emojis from Unicode 6.0, Unicode 6.1, and clarified which of the new pictographic characters from Unicode 7.0 and Unicode 8.0 would be recommended for emoji presentation.\n  \n  Until this release, no major vendors supported emojis from Unicode 7.0 or above.\n  ````\n\n* AndroidのバージョンとUnicode\n  \n  * \u003chttps://developer.android.com/guide/topics/resources/internationalization\u003e\n  * Unicode 6.1 までだったらだいたい使える…？\n\n## 合成絵文字\n\n## スキントーン\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["文字コード"]},"/note/unison":{"title":"unison","content":"\n# unison\n\nファイルの双方向同期がしたかった\nGoogleDriveへのバックアップのため\nrsync + lsyncd が見つかった\nリアルタイム性は重視してない\n\nunisonコマンド\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":[]},"/note/vim%E3%81%A7%E3%83%9E%E3%83%BC%E3%82%AB%E3%83%BC%E6%96%87%E5%AD%97%E5%88%97%E3%82%92%E5%9F%8B%E3%82%81%E8%BE%BC%E3%82%93%E3%81%A7%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E6%8A%98%E3%82%8A%E3%81%9F%E3%81%9F%E3%82%80":{"title":"vimでマーカー文字列を埋め込んでファイルを折りたたむ","content":"\n[Vim](note/Vim.md) の折りたたみ機能を使って、markerを埋め込み大きなファイルを移動しやすくすることができます。\n\n[マーカー文字列を埋め込んで、ソースコードを折り畳み表示する — 名無しのvim使い](https://nanasi.jp/articles/howto/fold/fold-marker.html)\n[.vimrc整理術 - Qiita](https://qiita.com/naoty_k/items/674787bc2d9885f81a0b)\n\n## markerで囲む\n\nvimには、コードの中にある目印となるマーカー （デフォルトでは「{{{」と「}}}」） を書いておくことで、そのマーカーに囲まれた範囲を折り畳む機能があります。\nさらに数字をつけることで階層を設定することもできる。\n\n````vim\n\" 基本設定 {{{1\n\nset nocompatible\nset number\n\n\" マッピング {{{1\n\nnnoremap H b\nnnoremap J }\nnnoremap K {\nnnoremap L w\n\n\" カラースキーム {{{1\n\nsyntax on\ncolorscheme hybrid\n\n\" プラグイン {{{1\n\n\" neobundle {{{2\n\n...\n\n\" unite.vim {{{2\n\n...\n\n\" neocomplcache {{{2\n\n...\n\n````\n\n## modelineを有効にする\n\n[モードラインを使って、ファイルごとにvimエディタのオプションを指定する。 — 名無しのvim使い](http://nanasi.jp/articles/howto/file/modeline.html)\n\n````vim\n\" モードラインを有効にする\nset modeline\n\n\" 3行目までをモードラインとして検索する\nset modelines=3\n````\n\n## modelineで折りたたみの設定をする\n\nファイルの最初か最後に以下を追加する。\n\n````vim\n\" vim: foldmethod=marker\n\" vim: foldcolumn=3\n````\n\n## folding系のコマンド\n\n[vimで折畳み(folding)まとめ - Qiita](https://qiita.com/ysuzuki19/items/23a998d3636684ec1ca1)\n\n詳しくは `help fold`\n\n````\nコマンド\t動作\nzf\t折畳作成\nzd\t折畳削除\nzD\t折畳を全て削除\nzE\tページ全体の折畳みを全て削除\nvisual + zf\t選択範囲を折畳\n2 + zF\t2行折畳\n2,5 fo\t2行から5行を折畳\nzo\t折畳を削除せず開く\nzO\t折畳みを全て削除せず開く\nzc\t開いている折畳を閉じる\nzC\t開いている折畳を全て閉じる\nza\t折畳の状態を切り替える\nzA\t全ての折畳の状態を切り替える\nzv\tカーソル行を表示\nzx\t折畳のUndo\nzX\t折畳のRedo\nzm\tページ内の折畳を一段階閉じる\nzM\tページ内の折畳を全段階閉じる\nzr\tページ内の折畳を一段階開く\nzR\tページ内の折畳を全段階開く\n2,5 foldo\t2行から5行の折畳を開く\n2,5 foldc\t2行から5行の折畳を閉じる\nzn\tファイル全体の折畳を開く\nzN\tファイル全体の折畳を閉じる\nzi\tファイル全体の折畳の状態を反転\nzj\t上の折畳に移動\nzk\t下の折畳に移動\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["vim"]},"/note/vim%E3%81%A7buffer%E5%90%8C%E5%A3%AB%E3%81%AEdiff%E3%82%92%E5%8F%96%E3%82%8B":{"title":"vimでbuffer同士のdiffを取る","content":"\n1. vimを開く\n1. テキストを貼り付ける\n1. `:vnew` でウィンドウを開く\n1. 比較したいテキストを開いたウィンドウに貼り付け\n1. `:windo diffthis`\n1. `:diffoff` で終了\n\n[ファイル同士の比較をvimdiffで取る](note/ファイル同士の比較をvimdiffで取る.md)\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["vim"]},"/note/vim%E3%83%86%E3%82%AF%E3%83%8B%E3%83%83%E3%82%AF":{"title":"vimテクニック","content":"\n## 現在のファイル内をgrepする\n\nQuickFixにわたすといい感じ\n\n`:grep /pattern/ % | cw`\n\n## vimgrepをripgrepで行う\n\n.vimrcに以下を書く\n\n````vim\n\" Use extend grep\nif executable('rg')\n    let \u0026grepprg = 'rg --vimgrep --no-hidden'\n    set grepformat=%f:%l:%c:%m\nendif\n````\n\n## `\u003cC-r\u003e` を使う\n\nコマンドモードで `\u003cC-r\u003e` のあとに続けて入力することで、いろいろなペーストができる\n\n````\n:help \u003cC-r\u003e\n\nCTRL-R {register}\t\t\t\t\t*c_CTRL-R* *c_\u003cC-R\u003e*\n\t\t\t'\"'\tthe unnamed register, containing the text of\n\t\t\t\tthe last delete or yank\n\t\t\t'%'\tthe current file name\n\t\t\t'#'\tthe alternate file name\n\t\t\t'*'\tthe clipboard contents (X11: primary selection)\n\t\t\t'+'\tthe clipboard contents\n\t\t\t'/'\tthe last search pattern\n\t\t\t':'\tthe last command-line\n\t\t\t'-'\tthe last small (less than a line) delete\n\t\t\t'.'\tthe last inserted text\n\n\nCTRL-R CTRL-F\t\t\t\t*c_CTRL-R_CTRL-F* *c_\u003cC-R\u003e_\u003cC-F\u003e*\nCTRL-R CTRL-P\t\t\t\t*c_CTRL-R_CTRL-P* *c_\u003cC-R\u003e_\u003cC-P\u003e*\nCTRL-R CTRL-W\t\t\t\t*c_CTRL-R_CTRL-W* *c_\u003cC-R\u003e_\u003cC-W\u003e*\nCTRL-R CTRL-A\t\t\t\t*c_CTRL-R_CTRL-A* *c_\u003cC-R\u003e_\u003cC-A\u003e*\nCTRL-R CTRL-L\t\t\t\t*c_CTRL-R_CTRL-L* *c_\u003cC-R\u003e_\u003cC-L\u003e*\n\t\tInsert the object under the cursor:\n\t\t\tCTRL-F\tthe Filename under the cursor\n\t\t\tCTRL-P\tthe Filename under the cursor, expanded with\n\t\t\t\t'path' as in |gf|\n\t\t\tCTRL-W\tthe Word under the cursor\n\t\t\tCTRL-A\tthe WORD under the cursor; see |WORD|\n\t\t\tCTRL-L\tthe line under the cursor\n\n````\n\n[愛用しているvimプラグイン](blog/愛用しているvimプラグイン.md)\n[vim 使っているplugin](note/vim%20使っているplugin.md)\n[ファイル同士の比較をvimdiffで取る](note/ファイル同士の比較をvimdiffで取る.md)\n[Vimでバッファ同士の差分をとる](note/Vimでバッファ同士の差分をとる.md)\n[vimでbuffer同士のdiffを取る](note/vimでbuffer同士のdiffを取る.md)\n[Vimでアルファベットを連番で入力する](note/Vimでアルファベットを連番で入力する.md)\n[fzf.vimの使い方](note/fzf.vimの使い方.md)\n[vimでマーカー文字列を埋め込んでファイルを折りたたむ](note/vimでマーカー文字列を埋め込んでファイルを折りたたむ.md)\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["vim"]},"/note/vim-%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%84%E3%82%8Bplugin":{"title":"vim 使っているplugin","content":"\n2020年版 [vim](Vim.md) プラグイン\n\n\u003chttps://engineering.mercari.com/blog/entry/mercari_codecast_1/\u003e\nこれをみて真面目に [vim](Vim.md) で書こうと思った\n小さいやつなら十分\n\n## vim-gitgutter\n\n変更行にマーク表示\n\n## fugitive\n\nGit操作\n\n### 注意\n\n* `Gstatus` を実行するとshellを起動するっぽいので、zshなどでpluginもりもりだったりすると遅くて使い物にならない\n* `set shell=bash\\ -l` としておくと解消される\n\n## defx\n\nファイラー\nデフォルトのキーマッピングがないので自分で設定する\n`ryanoasis/vim-devicons`, `kristijanhusak/defx-icons` を入れるとアイコンが表示される\n\n## machakann/vim-sandwich\n\n囲める\n\n* `sa` で追加、`sr` で置き換え、`sb` で削除\n* `saiwt` でtagを追加\n* `sritt` でtagを変更\n  * emmet ライクに、`div.main` などとすると `\u003cdiv class=\"main\"\u003e\u003c/div\u003e` に展開される\n\n## junegunn/vim-easy-align\n\nalignment\n\n* `gaip*|` テーブルを整形\n* `gaip\u003cRight\u003e*,` カンマ区切り\n\n## terryma/vim-multiple-cursors\n\nvscode や Sublime Text の複数選択ができる \u003cc-n\u003e\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["vim"]},"/note/vim-conceal":{"title":"vim-conceal","content":"\n# vim conceal\n\n## きっかけ\n\nvimでmarkdownを編集中、\\_斜体_や**太字**を表すためのアンダースコアやアスタリスクが表示されなくなってしまった。\nカーソル位置と編集してる位置がずれてしまったり、どこに隠れているのかがわかりにくくて記号じゃなくて文字のほうを消してしまったりと不便だったので、見えるようにしたい。\n\n* 個人の感覚によると思うが、私はテキスト編集中はあるがままに表示してほしい\n* colorschemeでわかりやすく表示されるので、隠す必要がない\n\n## 調査\n\n.vimrcやpluginをON/OFFしながら確認した結果、 [Yggdroot/indentLine](https://github.com/Yggdroot/indentLine) を有効にしていると発生することがわかった。\nREADMEでこちらの記載を見つけた。\n\n \u003e \n \u003e Change Conceal Behaviour\n \u003e \n \u003e This plugin enables the Vim conceal feature which automatically hides stretches of text based on syntax highlighting. This setting will apply to all syntax items.\n \u003e \n \u003e For example, users utilizing the built in json.vim syntax file will no longer see quotation marks in their JSON files.\n\nどうやらconcealという設定で、例えばJSONのquotationを非表示にするといったことができるらしい。\n\nconcealについての設定のデフォルト値が以下のようになっている。\n\n````\nlet g:indentLine_concealcursor = 'inc'\nlet g:indentLine_conceallevel = 2\n````\n\n## 対応方法\n\ndein.nvimを使用しているので、以下のように設定した\n\n````\n[[plugins]]\nrepo = 'Yggdroot/indentLine'\nhook_add = '''\n    let g:indentLine_conceallevel = 0\n'''\n````\n\n## 結果\n\nアンダースコアやアスタリスクが表示されるようになった\n\n## conceal とは\n\n\u003chttps://vim-jp.org/vimdoc-ja/syntax.html#conceal\u003e\n\n### conceallevel\n\n \u003e \n \u003e ````\n \u003e 0               テキストは通常通り表示される\n \u003e 1               各ブロックの Conceal されたテキストは一つの文字に置換\n \u003e                 される。構文アイテムに代理文字 (:syn-cchar 参照) が\n \u003e                 指定されていないときは 'listchars' の設定が使われる\n \u003e                  (初期設定はスペース)。\n \u003e                 文字は \"Conceal\" 強調グループを使って強調表示される。\n \u003e 2               Conceal されたテキストは構文アイテムに指定された代理文\n \u003e                 字 (:syn-cchar) として表示される。それが指定されて\n \u003e                 いないときは完全に非表示になる。\n \u003e 3               Conceal されたテキストは完全に非表示になる。\n \u003e ````\n\n### concealcursor\n\n \u003e \n \u003e ````\n \u003e    カーソル行のテキストを Conceal 表示するモードを設定する。現在のモード\n \u003e    がこのオプション値に含まれているなら他の行と同様に Conceal 表示され\n \u003e    る。\n \u003e      n             ノーマルモード\n \u003e      v             ビジュアルモード\n \u003e      i             挿入モード\n \u003e      c             コマンドライン編集 ('incsearch' 用)\n \u003e ````\n\n\u003chttps://mfumi.hatenadiary.org/entry/20140328/1395946070\u003e\n\u003chttps://qiita.com/xeno14/items/8d1c8f38595337bab7c8\u003e\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["vim"]},"/note/vim-lsp":{"title":"vim-lsp","content":"\n# vim-lsp\n\n* ale.vim\n  * lintエンジン\n  * lspクライアント\n* prabirshrestha/vim-lsp\n  * lspクライアント\n* mattn/vim-lsp-settings\n  * vim-lspの設定をかんたんにする\n  * language serverのインストールを `:LspInstallServer` `:LspUninstallServer` で行う\n  * \n    ````\n      hook_add = '''\n      let g:lsp_settings = {}\n      let g:lsp_settings_filetype_go = ['gopls', 'golangci-lint-langserver']\n      let g:lsp_settings['gopls'] = {\n          \\  'workspace_config': {\n          \\    'usePlaceholders': v:true,\n          \\  },\n          \\  'initialization_options': {\n          \\    'usePlaceholders': v:true,\n          \\  },\n          \\}\n      '''\n    ````\n  \n  ````\n  ````\n\n* prabirshrestha/asyncomplete.vim\n  * 補完プラグイン\n* prabirshrestha/asyncomplete-lsp.vim\n  * lsp用の補完\n  * \n    ````\n      [[plugins]]\n      repo = 'prabirshrestha/asyncomplete.vim'\n      \n      [[plugins]]\n      repo = 'prabirshrestha/asyncomplete-lsp.vim'\n      on_ft = ['python', 'go']\n      depends = ['asyncomplete.vim', 'vim-lsp']\n    ````\n  \n  ````\n  ````\n\n* スニペット補完\n  * prabirshrestha/asyncomplete-ultisnips.vim\n  * SirVer/ultisnips\n  * hona/vim-snippets\n\n## LSP Language Server Protocol\n\n* IDEみたいな機能を提供するサーバー\n\n## Link\n\n* [fzf.vimの使い方](note/fzf.vimの使い方.md)\n* [vim 使っているplugin](note/vim%20使っているplugin.md)\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["vim","lsp"]},"/note/vscode%E6%8B%A1%E5%BC%B5":{"title":"vscode拡張","content":"\n[VisualStudio Code](note/VisualStudio%20Code.md) の拡張機能\n\n## Settings Sync\n\n\u003chttps://code.visualstudio.com/docs/editor/settings-sync\u003e\n\n公式の設定同期機能が[ver1.48](https://code.visualstudio.com/updates/v1_48#_settings-sync) でリリースされた\n\n## [Project Manager](https://marketplace.visualstudio.com/items?itemName=alefragnani.project-manager)\n\nプロジェクト一覧にアクセスしやすくなる\n標準でもOpenやOpen Recentなどからフォルダを開けるが、これを使うとよく使うプロジェクトや、git管理のディレクトリをすぐ開くことができる\n\n* `Project Manager: Save Project` 現在のwindowをprojectに保存する\n* `Project Manager: Edit Project` プロジェクト一覧を手で編集する(`projects.json`)\n  * `\"projectManager.projectsLocation\": \"~/vscode/\"` setting.jsonで場所を変更することもできる\n* `Project Manager: List Projects to Open` プロジェクト一覧を表示して開く\n  * 入力で絞り込むことができるので、開くときはこちらが便利\n* `Project Manager: List Projects to Open in New Window` プロジェクト一覧を表示して新しいウィンドウで開く\n* `Project Manager: Refresh Projects` Refresh the cached projects\n\n### Git管理のディレクトリ一覧を表示\n\nsettings.jsonに、gitリポジトリ一覧のあるルートディレクトリを指定する\n`\"projectManager.git.baseFolders\": \"~/repos\"`\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["vscode"]},"/note/vue-awesome-swiper%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%82%AB%E3%83%AB%E3%83%BC%E3%82%BB%E3%83%AB%E9%A2%A8UI%E3%82%92%E4%BD%9C%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F":{"title":"vue-awesome-swiperを使ってカルーセル風UIを作ってみた","content":"\n# vue-awesome-swiperを使ってカルーセル風UIを作ってみた\n\n\u003chttps://github.surmon.me/vue-awesome-swiper/\u003e\n\u003chttps://swiperjs.com/swiper-api\u003e\n\n\u003chttps://www.kabanoki.net/4783/\u003e\n\u003chttps://mykii.blog/nuxt-vue-awesome-swiper/\u003e\n\u003chttps://webrandum.net/js-library-swiper/\u003e\n\n````sh\nyarn add swiper vue-awesome-swiper\n````\n\n### globalに定義する\n\n````\nimport Vue from 'vue'\nimport VueAwesomeSwiper from 'vue-awesome-swiper'\n\n// import style (\u003e= Swiper 6.x)\nimport 'swiper/swiper-bundle.css'\n\n// import style (\u003c= Swiper 5.x)\nimport 'swiper/css/swiper.css'\n\nVue.use(VueAwesomeSwiper, /* { default options with global component } */)\n````\n\n### Vueコンポーネントに定義する\n\nslide.js\n\n````js\nimport { Swiper, SwiperSlide, directive } from 'vue-awesome-swiper'\n\n// import style (\u003e= Swiper 6.x)\nimport 'swiper/swiper-bundle.css'\n\n// import style (\u003c= Swiper 5.x)\nimport 'swiper/css/swiper.css'\n\nexport default {\n  components: {\n    Swiper,\n    SwiperSlide\n  },\n  directives: {\n    swiper: directive\n  }\n}\n````\n\n### 実践例\n\nTypeScript で vue-property-decorator を使ってコンポーネントを作成\n\n````ts\n\u003ctemplate\u003e\n  \u003cswiper\n    ref=\"swiperSection\"\n    :options=\"swiperOption\"\n    @slide-change=\"onSlideChange\"\n  \u003e\n    \u003cswiper-slide v-for=\"item in items\" :key=\"item.id\"\u003e\n      \u003cdiv\u003e\n        {{ item.name }}\n      \u003c/div\u003e\n    \u003c/swiper-slide\u003e\n  \u003c/swiper\u003e\n\u003c/template\u003e\n\n\u003cscript lang=\"ts\"\u003e\nimport { Vue, Component, Prop } from 'vue-property-decorator'\nimport type { SwiperOptions } from 'swiper'\nimport SwiperClass from 'swiper'\nimport { Swiper, SwiperSlide } from 'vue-awesome-swiper'\nimport 'swiper/swiper-bundle.css'\n\n@Component({\n  components: {\n    Swiper,\n    SwiperSlide,\n  },\n})\nexport default class Slide extends Vue {\n  items = [\n    { id: 'cat', name: 'tama' },\n    { id: 'dog', name: 'pochi' },\n  ]\n\n\n  $refs!: {\n    swiperSection: InstanceType\u003ctypeof Swiper\u003e\n  }\n\n  // Swiperの設定\n  get swiperOption(): SwiperOptions {\n    return {\n      slidesPerView: 'auto',\n      centeredSlides: true,\n      initialSlide: 1,\n      spaceBetween: 5,\n    }\n  }\n\n  get swiper(): SwiperClass | null {\n    return this.$refs.swiperSection.$swiper\n  }\n\n  /**\n   * スライド変更イベントリスナー\n   */\n  onSlideChange() {\n    if (!this.sectionSlider) {\n      return\n    }\n\n    this.$emit('updateSlide', this.sectionSlider.activeIndex)\n  }\n}\n\u003c/script\u003e\n\n\u003cstyle scoped\u003e\n/* ライブラリで指定されているclassを上書き */\n.swiper-slide:nth-child(odd) {\n  background-color: #aebeff;\n}\n\u003c/style\u003e\n````\n\n### Swiper6.x系を入れると、NavigationとPaginationが機能しない\n\n\u003chttps://github.com/surmon-china/vue-awesome-swiper/issues/680\u003e\n\n````\nimport Vue from 'vue'\nimport { Swiper as SwiperClass, Pagination, Navigation } from 'swiper/swiper.esm'\nimport getAwesomeSwiper from 'vue-awesome-swiper/dist/exporter'\n\n// import style\nimport 'swiper/swiper-bundle.min.css'\n\nSwiperClass.use([Pagination, Navigation])\nVue.use(getAwesomeSwiper(SwiperClass))\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["Vuejs","TypeScript"]},"/note/vue-property-decorator%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9FTypeScript%E3%81%AAVue%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92CompositionAPI%E3%81%AB%E7%A7%BB%E8%A1%8C%E3%81%99%E3%82%8B":{"title":"vue-property-decoratorを使ったTypeScriptなVueファイルをCompositionAPIに移行する","content":"\nclass componentは非推奨になったわけではなくて今後も使えるそうですが、\nTypeScriptで書く場合にVolarの恩恵を最大限受けるために、Composition APIのスタイルに書き換えました。\nついでにscript setupにもしています。\n\n## Composition APIへの書き換え\n\n参考: [From vue-class-component to Composition API | by Giacomo Voß | Level Up Coding](https://levelup.gitconnected.com/from-vue-class-component-to-composition-api-ef3c3dd5fdda)\n\n### 概観\n\nvue-class-component(vue-property-decorator) で書かれたVueコンポーネントをscript setupに書き換えると以下のようになります。\n\n````vue\n\u003ctemplate\u003e\n  \u003cbutton type=\"button\" @click=\"handleClick\"\u003e\n    {{ text }}\n    \u003cIconButton /\u003e\n  \u003c/button\u003e\n\u003c/template\u003e\n\n\u003cscript lang=\"ts\"\u003e\nimport { Component, Vue, Prop, Emit } from 'vue-property-decorator'\nimport IconButton from '@/components/atoms/IconButton.vue'\n\n@Component({\n  components: {\n    IconButton,\n  },\n})\nexport default class ButtonPrimary extends Vue {\n  @Prop({ type: String, required: true })\n  private readonly text!: string\n\n  @Emit('clickButton')\n  handleClick() {}\n}\n\u003c/script\u003e\n````\n\n````vue\n\u003ctemplate\u003e\n  \u003cbutton type=\"button\" @click=\"handleClick\"\u003e\n    {{ text }}\n    \u003cIconButton /\u003e\n  \u003c/button\u003e\n\u003c/template\u003e\n\n\u003cscript lang=\"ts\" setup\u003e\nimport IconButton from '@/components/atoms/IconButton.vue'\n\ninterface Props {\n  text: string\n}\ndefineProps\u003cProps\u003e()\n\ndefineEmits\u003c{\n  (e: 'clickButton'): void\n}\u003e()\n\u003c/script\u003e\n````\n\n以下個別に見ていきます。\n\n### @Component\n\nclass component\n\n````vue\n\u003ctemplate\u003e\n  \u003cdiv\u003e\n    \u003cChildComponent1 /\u003e\n    \u003cChildComponent2 /\u003e\n  \u003c/div\u003e\n\u003c/template\u003e\n\n\u003cscript lang=\"ts\"\u003e\nimport ChildComponent1 from './ChildComponent1.vue'\nimport ChildComponent2 from './ChildComponent2.vue'\n\n@Component({\n  components: {\n    ChildComponent1,\n    ChildComponent2,\n  },\n})\nexport default class MyComponent extends Vue {\n\n}\n\u003c/script\u003e\n````\n\nscript setup\n\n````vue\n\u003ctemplate\u003e\n  \u003cdiv\u003e\n    \u003cChildComponent1 /\u003e\n    \u003cChildComponent2 /\u003e\n  \u003c/div\u003e\n\u003c/template\u003e\n\n\u003cscript setup lang=\"ts\"\u003e\nimport ChildComponent1 from './ChildComponent1.vue'\nimport ChildComponent2 from './ChildComponent2.vue'\n\u003c/script\u003e\n````\n\nimport文を書くだけでコンポーネントを使用できるようになりました。\n\n## Data\n\nclass component\n\n````vue\n\u003cscript lang=\"ts\"\u003e\n@Component\nexport default class MyComponent extends Vue {\n  message = 'Hello'\n\n  onInput(value: string) {\n    this.message = value\n  }\n}\n\u003c/script\u003e\n````\n\nscript setup\n\n````vue\n\u003cscript setup lang=\"ts\"\u003e\nconst message = ref('Hello')\n\nconst onInput = (value: string) =\u003e {\n  message.value = value\n}\n\u003c/script\u003e\n````\n\n`ref` で宣言することでreactiveな値として使用できるようになります。\n値にアクセスするには `.value` をつける必要があります。\n\n### @Prop\n\nclass component\n\n````vue\n\u003cscript lang=\"ts\"\u003e\n@Component\nexport default class MyComponent extends Vue {\n  @Prop({ type: String, required: true })\n  private readonly text!: string\n\n  // default値\n  @Prop({ type: Number, default: 2 })\n  private readonly num!: number\n\n  // Object\n  @Prop({ type: Object, required: true })\n  private readonly myObj!: MyObj\n\n}\n\u003c/script\u003e\n````\n\nscript setup\n\n````vue\n\u003cscript setup lang=\"ts\"\u003e\ninterface Props {\n  text: string\n  num?: number\n  myObj: MyObj\n}\nconst props = withDefaults(defineProps\u003cProps\u003e(), {\n  num: 2,\n})\n\n\u003c/script\u003e\n````\n\n独自型もきちんと型を付けられるようになり、コンポーネントを利用する側でも補完が効くようになります。\n\n### @Emit\n\nclass component\n\n````vue\n\u003cscript lang=\"ts\"\u003e\n@Component\nexport default class MyComponent extends Vue {\n  @Emit('clickButton')\n  handleClick(num: number) {\n    return num\n  }\n\n}\n\u003c/script\u003e\n````\n\nscript setup\n\n````vue\n\u003cscript setup lang=\"ts\"\u003e\nconst emits = defineEmits\u003c{\n  (e:'click-button', num: number): void\n}\u003e()\n\nconst handleClick = (num: number) =\u003e {\n  emits('click-button', num)\n}\n\u003c/script\u003e\n````\n\n### @Watch\n\nclass component\n\n````vue\n\u003cscript lang=\"ts\"\u003e\n@Component\nexport default class MyComponent extends Vue {\n  checkBox: boolean = false\n\n  @Watch('checkBox')\n  watchValue(value: boolean) {\n    if (value) {\n        alert('checked!!')\n    }\n  }\n}\n\u003c/script\u003e\n````\n\nscript setup\n\n````vue\n\u003cscript setup lang=\"ts\"\u003e\nconst checkBox = ref(false)\n\nwatch(\n  checkBox,\n  (value: boolean) =\u003e {\n    if (value) {\n        alert('checked!!')\n    }\n  }\n)\n\u003c/script\u003e\n````\n\n### @Ref\n\nclass component\n\n````vue\n\u003ctemplate\u003e\n  \u003cChildComponent ref=\"childComponent\" /\u003e\n  \u003cbutton ref=\"submitButton\"\u003eSubmit\u003c/button\u003e\n\u003c/template\u003e\n\n\u003cscript lang=\"ts\"\u003e\nimport ChildComponent from './ChildComponent.vue'\n\n@Component\nexport default class MyComponent extends Vue {\n  @Ref() readonly childComponent!: ChildComponent\n  @Ref('submitButton') readonly button!: HTMLButtonElement\n}\n\u003c/script\u003e\n````\n\nscript setup\n\n````vue\n\u003ctemplate\u003e\n  \u003cChildComponent ref=\"childComponent\" /\u003e\n  \u003cbutton ref=\"submitButton\"\u003eSubmit\u003c/button\u003e\n\u003c/template\u003e\n\n\u003cscript setup lang=\"ts\"\u003e\nconst childComponent = ref\u003cChildComponent\u003e()\nconst submitButton = ref\u003cHTMLButtonElement\u003e()\n\u003c/script\u003e\n````\n\n同じ変数名のrefで宣言するだけで参照できるようになりました\n\n### Computed\n\nclass component\n\n````vue\n\u003cscript lang=\"ts\"\u003e\n@Component\nexport default class MyComponent extends Vue {\n  firstName = 'John'\n  lastName = 'Doe'\n\n  get name() {\n    return this.firstName + ' ' + this.lastName\n  }\n\n  set name(value) {\n    const splitted = value.split(' ')\n    this.firstName = splitted[0]\n    this.lastName = splitted[1] || ''\n  }\n}\n\u003c/script\u003e\n````\n\nscript setup\n\n````vue\n\u003cscript setup lang=\"ts\"\u003e\nconst firstName = ref('John')\nconst lastName = ref('Doe')\n\nconst name = computed({\n  get: () =\u003e  firstName + ' ' + lastName,\n  set: (value) =\u003e {\n    const splitted = value.split(' ')\n    firstName.value = splitted[0]\n    lastName.value = splitted[1] || ''\n  }\n})\n\n\u003c/script\u003e\n````\n\n### Hooks\n\nclass component\n\n````vue\n\u003cscript lang=\"ts\"\u003e\n@Component\nexport default class MyComponent extends Vue {\n  mounted() {\n    console.log('mounted')\n  }\n}\n\u003c/script\u003e\n````\n\nscript setup\n\n````vue\n\u003cscript setup lang=\"ts\"\u003e\nonMounted(() =\u003e {\n  console.log('mounted')\n})\n\u003c/script\u003e\n````\n\nライフサイクルフックの変更はこちらを参照\n[ライフサイクルフック | Vue.js](https://v3.ja.vuejs.org/guide/composition-api-lifecycle-hooks.html)\n\n* setup は beforeCreate と created のライフサイクルで実行されるため、これらのフック内で実行していたコードはsetup内に直接書く\n* mounted -\u003e onMounted のように、onXXXXXという名前に変わった\n\n## モジュールやライブラリの移行\n\n* vuex -\u003e pinia\n  * \u003chttps://github.com/Seb-L/pinia-plugin-persist\u003e\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["Vuejs","TypeScript"]},"/note/vue-tsc":{"title":"vue-tsc","content":"\n[ViteでVue3のTypescript環境を構築する | miyauci.me](https://miyauchi.dev/ja/posts/vite-vue3-typescript/)\n\n[vue-tsc を使った TypeScript Strict Mode の漸進的導入 - VisasQ Dev Blog](https://tech.visasq.com/introduce-vue-tsc/)\n\n[volar/packages/vue-tsc at master · johnsoncodehk/volar · GitHub](https://github.com/johnsoncodehk/volar/tree/master/packages/vue-tsc)\n\neslintだけではTypeScriptで書かれたvue3のtemplateの中をチェックできないので、vue-tcsでコンパイルして静的にチェックする。\nvolarと同じらしいのでvscode上の指摘はこっちでチェックできる\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["TypeScript","Vuejs"]},"/note/wezterm":{"title":"wezterm","content":"\n## tab title, pane titleにcurrent pathを設定する\n\n### OSC\n\n\u003chttps://wezfurlong.org/wezterm/shell-integration.html\u003e のページに `OSC 133` という単語が出てくる。\n\nエスケープシーケンスで意味のあるマークを挿入して、コマンドの出力を一まとまりに扱うための仕様らしい。\n[ZshでOSC 133に対応する](https://zenn.dev/ymotongpoo/articles/20220802-osc-133-zsh)\n\u003chttps://gitlab.freedesktop.org/Per_Bothner/specifications/blob/master/proposals/semantic-prompts.md\u003e\n\n[ANSI escape sequences](https://en.wikipedia.org/wiki/ANSI_escape_code#Escape_sequences)  にはいくつかカテゴリが存在するらしい\nよく色つけに使われる `\\033[XXXm` というのもこれ\n\n````shell\n$ echo -en \"\\e[41mColor\\e[mWhite\"\n````\n\n`\\033`, `\\x1b`, `\\e` などはどれもESCを表す\nこの `\\e[` を CSI (Control Sequence Introducer) といい、 `\\e]` は OSC (Operating System Command) という\n\nこれを踏まえて、 [wezterm](note/wezterm.md) で変数を扱えるようにしたりタイトルを設定したりする\n\n### 変数を設定する\n\n\u003chttps://wezfurlong.org/wezterm/config/lua/pane/get_user_vars.html\u003e\n\n````shell\nprintf \"\\033]1337;SetUserVar=%s=%s\\007\" foo `echo -n bar | base64`\n````\n\nとすると、以下のようにして取得できる\n\n````lua\nwezterm.log_info('foo var is ' .. pane:get_user_vars().foo)\n````\n\nつまり OSC 1337 + `SetUserVar=key=value` + `\\007` とすると `get_user_vars` で取得できる。\n\nechoで書くとこうなる\n\n````shell\necho \"\\x1b]1337;SetUserVar=key=$(echo -n value | base64)\\x07\"\n````\n\n### 現在いるディレクトリのgitリポジトリ名をtabのtitleに設定する\n\n\u003chttps://wezfurlong.org/wezterm/config/lua/window-events/format-tab-title.html\u003e で、変数 `panetitle` を取得して値があればそれをtabに設定する\n\n`~/.config/wezterm/wezterm.lua`\n\n````lua\nwezterm.on(\"format-tab-title\", function(tab, tabs, panes, config, hover, max_width)\n\tlocal title\n\tlocal user_title = tab.active_pane.user_vars.panetitle\n\tif user_title ~= nil and #user_title \u003e 0 then\n\t\ttitle = tab.tab_index + 1 .. \":\" .. user_title\n\telse\n\t\ttitle = tab.tab_index + 1 .. \":\" .. tab.active_pane.current_working_dir\n\tend\n\n\tlocal solid_left_arrow = utf8.char(0x2590)\n\tlocal solid_right_arrow = utf8.char(0x258c)\n\tlocal edge_background = \"#363636\"\n\tlocal background = scheme.ansi[1]\n\tlocal foreground = scheme.ansi[5]\n\n\tif tab.is_active then\n\t\tbackground = scheme.brights[1]\n\t\tforeground = scheme.brights[8]\n\telseif hover then\n\t\tbackground = scheme.cursor_bg\n\t\tforeground = scheme.cursor_fg\n\tend\n\tlocal edge_foreground = background\n\n\treturn {\n\t\t{ Attribute = { Intensity = \"Bold\" } },\n\t\t{ Background = { Color = edge_background } },\n\t\t{ Foreground = { Color = edge_foreground } },\n\t\t{ Text = solid_left_arrow },\n\t\t{ Background = { Color = background } },\n\t\t{ Foreground = { Color = foreground } },\n\t\t{ Text = title },\n\t\t{ Background = { Color = edge_background } },\n\t\t{ Foreground = { Color = edge_foreground } },\n\t\t{ Text = solid_right_arrow },\n\t\t{ Attribute = { Intensity = \"Normal\" } },\n\t}\nend)\n````\n\n* zshの `precmd` hookを登録して、コマンド実行のたびに `panetitle` を更新するようにする\n* `vsc_info` も使用してgitのディレクトリ内にいるときはリポジトリ名をセットする\n\n`~/.zshrc`\n\n````shell\nfunction rename_wezterm_title {\n  echo \"\\e]1337;SetUserVar=panetitle=$(echo -n $1 | base64)\\x07\"\n}\n\nautoload -Uz add-zsh-hook\nautoload -Uz vcs_info\nzstyle ':vcs_info:*' enable git\nzstyle ':vcs_info:*' formats '%r'\n_precmd_wezterm () {\n  if [[ $TERM_PROGRAM = WezTerm ]]; then\n    vcs_info\n    if [[ -n ${vcs_info_msg_0_} ]]; then\n      rename_wezterm_title ${vcs_info_msg_0_}\n    else\n      rename_wezterm_title $(basename $(pwd))\n    fi\n  fi\n}\n\nadd-zsh-hook precmd _precmd_wezterm\n````\n\n### pane titleを設定する\n\n上記でtabのタイトルがセットできたが、tab一覧を表示したときにはpane titleが表示される。\npane titleはデフォルトでprocess名が入るので、どのtabなのかわかりにくい。\n\n\u003chttps://wezfurlong.org/wezterm/config/lua/pane/get_title.html\u003e\n\nOSC 1 でセットすることができるので、先程同様 `precmd` でセットする\n\n````shell\necho \"\\x1b]1;$(pwd)\"\n````\n\n## 前回開いていたtabを復元する\n\n[tmux-resurrect](https://github.com/tmux-plugins/tmux-resurrect), [tmux-continuum](https://github.com/tmux-plugins/tmux-continuum) のように、前回開いていたタブの一覧を復元したい。\n`20220807-113146-c2fee766` 時点では、weztermにそのような機能はないため自分で保存、復元を行うようにする。\n\n### 現在のタブ一覧を保存する\n\n\u003chttps://wezfurlong.org/wezterm/cli/cli/list.html\u003e\n`wezterm cli list` で開いているtabの一覧を出力できる。\n`--format=json` をつけるとJSONにできる。\n\nこの出力結果をどこかに保存する処理を定期実行すればよさそう。\n今回はcronに設定することにした。\n\n`crontab -e`\n\n````shell\n*/5 * * * * zsh -c \"wezterm cli list --format=json \u003e ~/.cache/wezterm/tabs.json\"\n````\n\n### タブを復元する\n\nこちらのような関数を用意した。(require: jq)\n\n````shell\nfunction restore_wezterm_tabs() {\n  cat ~/.cache/wezterm/tabs.json | jq -r '.[] | .cwd' | sed \"s#file://$(hostname)##i\" | xargs -i wezterm cli spawn --cwd {}\n}\n````\n\n`wezterm cli spawn --cwd \u003cdirectory\u003e` でディレクトリを指定してtabを開くことができるので、JSONに保存した各tabの情報から `cwd` の項目を拾って引数にする\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["shell","terminal"]},"/note/windows%E3%82%BB%E3%83%83%E3%83%88%E3%82%A2%E3%83%83%E3%83%97":{"title":"windowsセットアップ","content":"\n久々にWindowsを起動してアップデートもろもろしたのでメモ\n\n## Windowsアップデート\n\n1909のままになっていた\n2021/05/11でサポート終了するので、最新の20H2にアップデートする\n[Windows 10 Home and Pro | Microsoft Docs](https://docs.microsoft.com/ja-jp/lifecycle/products/windows-10-home-and-pro)\n\n### 手動アップデート\n\nWindows Updateで更新のチェックをしても出てこなかったので、手動でアップデートする\n\n\u003chttps://www.microsoft.com/ja-jp/software-download/windows10\u003e から今すぐアップデートをクリックして更新アシスタントをダウンロード\n\n更新アシスタントを起動してアップデート\n\n## CapsLockをCtrlキーにする\n\n[CapsLockキーって使ってますか？あまり使わないならCtrlキーと交換、あるいはCtrlキーに変えてしまいましょう | IT業務で使えるプログラミングテクニック](https://kekaku.addisteria.com/wp/20180531022629)\n\n`caps2ctrl_swap.reg`\n\n````reg\nWindows Registry Editor Version 5.00\n\n[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Keyboard Layout]\n\"Scancode Map\"=hex:00,00,00,00,00,00,00,00,03,00,00,00,1d,00,3a,00,3a,00,1d,00,00,00,00,00\n````\n\n## ChocolateyではなくScoopをつかって環境構築\n\n[Scoop環境構築](note/Scoop環境構築.md)\n\n### Scoop以外でいれたもの\n\n* Visual Studio Code\n* Google Chrome\n\n## キーボード配列を変更\n\nUS配列に慣れてしまったので、日本語配列のキーボードを使用しているがレイアウトはUSとして使用する。\n設定 \u003e 時刻と言語 \u003e 言語 \u003e 日本語 \u003e オプション \u003e ハードウェアキーボードレイアウト \u003e レイアウトを変更する \u003e 英語キーボード(101/102キー)\n\n### 日本語キーボードでUS配列を設定しGoogle日本語入力を使用しているときに、Ctrl+Spaceで全角/半角を切り替える\n\n[Google入力を英語配列キーボードで使っている人向け日本語入力切り替えの変更方法｜システムエンジニアの技術LOG](https://ko-log.net/tech-log/archives/3826932.html)\n\n1. タスクバーの右下にあるIMEを右クリックしてプロパティを開く\n1. キー設定の選択 \u003e 編集\n1. 入力キーが `Hankaku/Zenkaku` の行を選択して、 `Hankaku/Zenkaku` をダブルクリックするとキー入力のダイアログが表示される\n1. Ctrl Space キーを押す\n1. これをHankaku/Zenkakuの全項目に繰り返す\n1. Ctrl+Spaceで切り替えられるようになる\n\n### 英語レイアウトで変換キーをIMEのON、無変換キーをIMEのOFFにする\n\nCtrl+Spaceキーはトグルなので、現在の状態を確認せねばならず煩わしい。\nMacのかな/英数キーのようなことをしたい。\n\n[WindowsでAX配列を使う - Qiita](https://qiita.com/Big/items/c97573965804fb21ff9e)\n\nWindowsの場合英語レイアウトにすると変換、無変換キーが認識されなくなる。\nAX配列にすると認識されるため実現できる。\n\nただしレジストリの変更を伴うため、自己責任となる。\n\n### Ctrl-n,Ctrl-pで変換候補を選択\n\n\\[備忘録的なblog: google日本語入力の候補移動キーの変更\\](\u003chttp://se-bikou.blogspot.com/2011/04/google.html]\u003e\n\nキー設定 \u003e 編集\n\n|モード|入力キー|コマンド|\n|---------|------------|------------|\n|変換前入力中|Ctrl n|予測変換|\n|変換中|Ctrl n|次候補を選択|\n|変換中|Ctrl p|前候補を選択|\n\n## WSL2\n\n\u003chttps://docs.microsoft.com/ja-jp/windows/wsl/install-win10#manual-installation-steps\u003e\n\n[WSL/WSL2 インストール (Windows 10でUbuntu) - PS Work](https://pswork.jp/wsl/windows-10-wsl-install/)\nStoreでインストールするより手動のほうが場所を決められるのでいいとかいてある\n自分もそう思うが、久しぶりに開くとわからなくなりそうなので一旦Storeからのままにしておく\n\n## Windows ターミナル\n\n\u003chttps://docs.microsoft.com/ja-jp/windows/terminal/get-started\u003e\n\nStoreからと書いてあるが、Scoopでインストールした\n\n## PATH修正\n\nもとのPATH\n\n````sh\nPS C:\\Users\\ikorihn\u003e $env:Path.Split(\";\")\nD:\\app\\oracleuser\\product\\12.1.0\\dbhome_1\\bin\nC:\\Program Files\\Java\\jdk1.8.0_73\\bin\nC:\\Program Files (x86)\\Intel\\iCLS Client\\\nC:\\Program Files\\Intel\\iCLS Client\\\nC:\\WINDOWS\\system32\nC:\\WINDOWS\nC:\\WINDOWS\\System32\\Wbem\nC:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\\nC:\\Program Files\\Intel\\Intel(R) Management Engine Components\\DAL\nC:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\DAL\nC:\\Program Files\\Intel\\Intel(R) Management Engine Components\\IPT\nC:\\Program Files (x86)\\Intel\\Intel(R) Management Engine Components\\IPT\nD:\\utils\\vim74-kaoriya-win64\\\nC:\\Python36\nC:\\ProgramData\\chocolatey\\bin\nC:\\Users\\ikorihn\\AppData\\Local\\atom\\bin\nC:\\Users\\ikorihn\\AppData\\Local\\atom\\app-1.9.9\\resources\\app\\apm\\bin\nC:\\WINDOWS\\system32\nC:\\WINDOWS\nC:\\WINDOWS\\System32\\Wbem\nC:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\\nD:\\utils\\Neovim\\bin\nC:\\WINDOWS\\System32\\OpenSSH\\\nC:\\Users\\ikorihn\\scoop\\shims\nC:\\Users\\ikorihn\\AppData\\Local\\atom\\bin\nC:\\Users\\ikorihn\\AppData\\Local\\Microsoft\\WindowsApps\nC:\\Python27\\Scripts\n\nC:\\Users\\ikorihn\\AppData\\Local\\Programs\\Microsoft VS Code\\bin\n````\n\n## 参考\n\n[Windows 10再インストールしたメモ - HackMD](https://hackmd.io/@Eai/Win10-reinstall)\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["Windows"]},"/note/xcode-select%E3%81%AE%E3%83%90%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%E3%81%8C%E5%8F%A4%E3%81%84%E3%81%A8%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E3%81%A7%E3%82%8B":{"title":"xcode-selectのバージョンが古いとエラーがでる","content":"\n\n````shell\n$ /usr/bin/git\n2022-09-14 19:57:46.548 xcodebuild[4220:18896] [MT] DVTPlugInLoading: Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin), error = Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n  Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n  Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n  Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n  Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}, dyldError = dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0000): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n  Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n  Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\n2022-09-14 19:57:46.570 xcodebuild[4220:18896] [MT] DVTAssertions: ASSERTION FAILURE in /System/Volumes/Data/SWE/Apps/DT/BuildRoots/BuildRoot2/ActiveBuildRoot/Library/Caches/com.apple.xbs/Sources/DVTFrameworks/DVTFrameworks-21303/DVTFoundation/PlugInArchitecture/DataModel/DVTPlugIn.m:374\nDetails:  Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin)\nPlease ensure Xcode packages are up-to-date — try running 'xcodebuild -runFirstLaunch'.\n\nNSBundle error: Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n  Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n  Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n  Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n  Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}\nObject:   \u003cDVTPlugIn: 0x60000126a3a0\u003e\nMethod:   -loadAssertingOnError:error:\nThread:   \u003c_NSMainThread: 0x60000363c2c0\u003e{number = 1, name = main}\nHints:\n\nBacktrace:\n  0  0x0000000105ef9410\n  1  0x0000000105ef8aec\n  2  0x0000000105ef8c6c\n  3  0x0000000105da72ac\n4  0x0000000105d6d118\n  5  0x0000000105d6b528\n  6  0x00000001af9541b4\n  7  0x00000001af963414\n  8  0x0000000105f3d58c\n  9  0x0000000105f194b0\n 10  0x0000000105d6b3c0\n 11  0x0000000105d6b5e0\n 12  0x0000000106e2f2ec\n 13  0x0000000106e2eae0\n 14  0x0000000106e2e1e8\n 15  0x00000001047cc324\n 16  0x0000000104375e0c\nsh: line 1:  4240 Abort trap: 6           /Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find git 2\u003e /dev/null\ngit: error: sh -c '/Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find git 2\u003e /dev/null' failed with exit code 34304: (null) (errno=Invalid argument)\nxcode-select: Failed to locate 'git', requesting installation of command line developer tools.\n````\n\nxcodeとCommandLineToolsをアップデートした。\n→ アップデートが成功しない…\n\nxcodeとCLTをアンインストールしてから再インストールすることに。\n\n以下を削除\n\n* /Applications/Xcode.app\n* /Library/Developer/CommandLineTools\n* ~/Library/Developer\n* ~/Library/Caches/com.apple.dt.Xcode\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["Mac"]},"/note/xlsx2csv":{"title":"xlsx2csv","content":"\n\u003chttps://github.com/dilshod/xlsx2csv\u003e\n\n````sh\n$ xlsx=新しいファイル.xlsx\n$ xlsx2csv -a -q all $xlsx ${xlsx/.xlsx/}\n-a: すべてのシートをcsvにする\n-q: カラムをダブルクウォートで囲む\n````\n\n-aをつけると、ディレクトリが作成されその中にシートごとにcsvが作られる\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["shell"]},"/note/yq":{"title":"yq","content":"\n\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["2023/05/04","shell","yaml","yq"]},"/note/yq-%E3%83%81%E3%83%BC%E3%83%88%E3%82%B7%E3%83%BC%E3%83%88":{"title":"yq チートシート","content":"\n[yq](note/yq.md) にはGo版とPython版があるので、注意する。Go版をここでは使う\n\nhttps://mikefarah.gitbook.io/yq/\nhttps://github.com/mikefarah/yq\n\n## \n\n## shellの変数を使う\n\nこのような書き方では変数が正しく利用されない\n\n````shell\nMY_NAME=Alice\nyq \".users.$MY_NAME\" group.yaml\n````\n\n`env` や `strenv` を使うことで環境変数が展開される\n\n````shell\nlts_version=$(curl -LSs https://updates.jenkins.io/stable/latestCore.txt)\necho \"${lts_version}\"\nval=\"${lts_version}\" ./yq e -i '.controller.tag=strenv(val)' $file\n````\n\n````shell\ninstalled_plugins=$(./yq '.controller.installPlugins' $file)\nfor p in $(echo $PLUGIN_NAME_VERSION); do\n  name=$(echo $p | cut -d':' -f1)\n  installed_plugins=$(echo \"$installed_plugins\" | sed -r \"s/$name:.*/$p/\")\ndone\nupdated_plugins=$(echo \"$installed_plugins\" | sed -e \"s/- /'/\" -e \"s/$/'/g\" | tr '\\n' \",\")\necho \"$updated_plugins\"\nval=\"[${updated_plugins}]\" ./yq e -P -i '.controller.installPlugins=env(val)' $file\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["2023/01/27","shell","yaml","yq"]},"/note/yum-%E3%83%91%E3%83%83%E3%82%B1%E3%83%BC%E3%82%B8%E3%83%90%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%E3%82%92%E6%8C%87%E5%AE%9A%E3%81%97%E3%81%A6%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%99%E3%82%8B":{"title":"yum パッケージバージョンを指定してインストールする","content":"\n\n````shell\n$ yum --showduplicates search java-17-\nLoaded plugins: ovl, priorities\n============================================================================== N/S matched: java-17- ===============================================================================\n1:java-17-amazon-corretto-17.0.1+12-2.amzn2.1.aarch64 : Amazon Corretto development environment\n1:java-17-amazon-corretto-17.0.1+12-3.amzn2.1.aarch64 : Amazon Corretto development environment\n1:java-17-amazon-corretto-17.0.2+8-1.amzn2.1.aarch64 : Amazon Corretto development environment\n1:java-17-amazon-corretto-17.0.3+6-1.amzn2.1.aarch64 : Amazon Corretto development environment\n1:java-17-amazon-corretto-17.0.4+8-1.amzn2.1.aarch64 : Amazon Corretto development environment\n1:java-17-amazon-corretto-17.0.4+9-1.amzn2.1.aarch64 : Amazon Corretto development environment\n1:java-17-amazon-corretto-17.0.5+8-1.amzn2.1.aarch64 : Amazon Corretto development environment\n1:java-17-amazon-corretto-17.0.6+10-1.amzn2.1.aarch64 : Amazon Corretto development environment\n1:java-17-amazon-corretto-devel-17.0.1+12-2.amzn2.1.aarch64 : Amazon Corretto 17 development tools\n1:java-17-amazon-corretto-devel-17.0.1+12-3.amzn2.1.aarch64 : Amazon Corretto 17 development tools\n1:java-17-amazon-corretto-devel-17.0.2+8-1.amzn2.1.aarch64 : Amazon Corretto 17 development tools\n1:java-17-amazon-corretto-devel-17.0.3+6-1.amzn2.1.aarch64 : Amazon Corretto 17 development tools\n1:java-17-amazon-corretto-devel-17.0.4+8-1.amzn2.1.aarch64 : Amazon Corretto 17 development tools\n1:java-17-amazon-corretto-devel-17.0.4+9-1.amzn2.1.aarch64 : Amazon Corretto 17 development tools\n1:java-17-amazon-corretto-devel-17.0.5+8-1.amzn2.1.aarch64 : Amazon Corretto 17 development tools\n1:java-17-amazon-corretto-devel-17.0.6+10-1.amzn2.1.aarch64 : Amazon Corretto 17 development tools\n1:java-17-amazon-corretto-headless-17.0.1+12-2.amzn2.1.aarch64 : Amazon Corretto headless development environment\n1:java-17-amazon-corretto-headless-17.0.1+12-3.amzn2.1.aarch64 : Amazon Corretto headless development environment\n1:java-17-amazon-corretto-headless-17.0.2+8-1.amzn2.1.aarch64 : Amazon Corretto headless development environment\n1:java-17-amazon-corretto-headless-17.0.3+6-1.amzn2.1.aarch64 : Amazon Corretto headless development environment\n1:java-17-amazon-corretto-headless-17.0.4+8-1.amzn2.1.aarch64 : Amazon Corretto headless development environment\n1:java-17-amazon-corretto-headless-17.0.4+9-1.amzn2.1.aarch64 : Amazon Corretto headless development environment\n1:java-17-amazon-corretto-headless-17.0.5+8-1.amzn2.1.aarch64 : Amazon Corretto headless development environment\n1:java-17-amazon-corretto-headless-17.0.6+10-1.amzn2.1.aarch64 : Amazon Corretto headless development environment\n1:java-17-amazon-corretto-javadoc-17.0.1+12-2.amzn2.1.aarch64 : Amazon Corretto 17 API documentation\n1:java-17-amazon-corretto-javadoc-17.0.1+12-3.amzn2.1.aarch64 : Amazon Corretto 17 API documentation\n1:java-17-amazon-corretto-javadoc-17.0.2+8-1.amzn2.1.aarch64 : Amazon Corretto 17 API documentation\n1:java-17-amazon-corretto-javadoc-17.0.3+6-1.amzn2.1.aarch64 : Amazon Corretto 17 API documentation\n1:java-17-amazon-corretto-javadoc-17.0.4+8-1.amzn2.1.aarch64 : Amazon Corretto 17 API documentation\n1:java-17-amazon-corretto-javadoc-17.0.4+9-1.amzn2.1.aarch64 : Amazon Corretto 17 API documentation\n1:java-17-amazon-corretto-javadoc-17.0.5+8-1.amzn2.1.aarch64 : Amazon Corretto 17 API documentation\n1:java-17-amazon-corretto-javadoc-17.0.6+10-1.amzn2.1.aarch64 : Amazon Corretto 17 API documentation\n1:java-17-amazon-corretto-jmods-17.0.1+12-2.amzn2.1.aarch64 : Amazon Corretto 17 jmods\n1:java-17-amazon-corretto-jmods-17.0.1+12-3.amzn2.1.aarch64 : Amazon Corretto 17 jmods\n1:java-17-amazon-corretto-jmods-17.0.2+8-1.amzn2.1.aarch64 : Amazon Corretto 17 jmods\n1:java-17-amazon-corretto-jmods-17.0.3+6-1.amzn2.1.aarch64 : Amazon Corretto 17 jmods\n1:java-17-amazon-corretto-jmods-17.0.4+8-1.amzn2.1.aarch64 : Amazon Corretto 17 jmods\n1:java-17-amazon-corretto-jmods-17.0.4+9-1.amzn2.1.aarch64 : Amazon Corretto 17 jmods\n1:java-17-amazon-corretto-jmods-17.0.5+8-1.amzn2.1.aarch64 : Amazon Corretto 17 jmods\n1:java-17-amazon-corretto-jmods-17.0.6+10-1.amzn2.1.aarch64 : Amazon Corretto 17 jmods\n````\n\n使いたいパッケージバージョンをフルで指定する\narchは書かなくてもいい\n\n````shell\n$ yum install java-17-amazon-corretto-17.0.6+10-1.amzn2.1\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["2023/04/04","Linux"]},"/note/yum-S3%E3%81%AB%E3%82%AB%E3%82%B9%E3%82%BF%E3%83%A0%E3%83%AA%E3%83%9D%E3%82%B8%E3%83%88%E3%83%AA%E3%82%92%E4%BD%9C%E6%88%90%E3%81%97%E3%81%A6%E3%81%9D%E3%81%93%E3%81%8B%E3%82%89%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%99%E3%82%8B":{"title":"yum S3にカスタムリポジトリを作成してそこからインストールする","content":"\n自前のyumリポジトリサーバを構築し、そのリポジトリからインストールできるようにする。\n\n## 参考\n\n[(CentOS7)プライベート環境に必要なパッケージのみ提供するyumリポジトリサーバを構築する - zaki work log](https://zaki-hmkc.hatenablog.com/entry/2020/03/08/222941)\n[S3にyumリポジトリを作成してプライベートサブネットから参照する | Awstut](https://awstut.com/2022/03/19/yum-repository-in-s3/)\n\n## 手順\n\n### ディレクトリを作成\n\nとりあえず `/tmp/repo` に作る\n\n````shell\nmkdir -p /tmp/repo/\n````\n\n### 配置したいrpmパッケージをダウンロード\n\ncurlやwgetでも良いが、今回は `yumdownloader` を使う。入っていなければ `yum install yum-utils`\nzstdのrpmを入れてみる\n\n````shell\n$ cd /tmp/repo\n$ yumdownloader zstd\n````\n\n### リポジトリ作成\n\ncreaterepoをインストールして使う\n\n````shell\n$ yum install createrepo\n\n$ createrepo -v /tmp/repo\nSpawning worker 0 with 1 pkgs\nSpawning worker 1 with 0 pkgs\nWorker 0: reading zstd-1.5.2-1.amzn2.x86_64.rpm\nWorkers Finished\nSaving Primary metadata\nSaving file lists metadata\nSaving other metadata\nGenerating sqlite DBs\nSqlite DBs complete\n````\n\n### S3へアップロード\n\n````shell\n$ aws s3 cp /tmp/repo s3://my-bucket/repos/ --recursive\n````\n\n## 利用側の手順\n\n### リポジトリを設定\n\n````shell\n$ vi /etc/yum.repos.d/myprivate.repo\n````\n\n````conf\n[myprivate]\nenabled=1\ngpgcheck=0\nname=my repo\nbaseurl=https://myrepository.example.com/repos\n````\n\n### 更新\n\n````shell\n$ yum makecache fast\n````\n\n### 確認\n\n````shell\n$ yum repolist all\n\nmyprivateが存在する\n````\n\n### インストール\n\n一時的に設定済みのrepoを無効化して、これだけが使われるようにしてみる\n\n````shell\n$ yum --disablerepo=* --enablerepo=myprivate install zstd\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["2023/04/05","Linux"]},"/note/zap.Logger%E3%81%A7%E3%83%AD%E3%82%B0%E5%87%BA%E5%8A%9B%E6%99%82%E3%81%ABSentry%E3%81%AB%E3%82%82%E5%87%BA%E5%8A%9B%E3%81%99%E3%82%8B":{"title":"zap.Loggerでログ出力時にSentryにも出力する","content":"\n\u003chttps://docs.sentry.io/platforms/go/\u003e\n\nzap初期化時に、Hookを登録することができる。\nzapcore.Entryを引数に取るので、そこからメッセージやログレベルを取得してやればよい\n\n````go\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/aws/aws-lambda-go/events\"\n\t\"github.com/getsentry/sentry-go\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n)\n\nfunc NewLogger(levelStr string) (*zap.Logger, error) {\n\tlevel := parseLogLevel(levelStr)\n\tconfig := zap.Config{\n\t\tLevel: zap.NewAtomicLevelAt(level),\n\t}\n\n\t// 環境変数SENTRY_DSNを設定するか、ClientOptionsに設定する\n\terr := sentry.Init(sentry.ClientOptions{})\n\tif err != nil {\n\t\tfmt.Printf(\"sentry.Init: %s\", err)\n\t}\n\n\treturn config.Build(zap.Hooks(func(entry zapcore.Entry) error {\n\t\tif entry.Level == zapcore.ErrorLevel {\n\t\t\tdefer sentry.Flush(2 * time.Second)\n\t\t\tev := sentry.NewEvent()\n\t\t\tev.Level = sentry.LevelError\n\t\t\tev.Message = entry.Message\n\t\t\tsentry.CaptureEvent(ev)\n\t\t}\n\t\treturn nil\n\t}))\n}\n\nfunc parseLogLevel(levelStr string) zapcore.Level {\n\tswitch strings.ToUpper(levelStr) {\n\tcase zapcore.DebugLevel.CapitalString():\n\t\treturn zapcore.DebugLevel\n\tcase zapcore.InfoLevel.CapitalString():\n\t\treturn zapcore.InfoLevel\n\tcase zapcore.WarnLevel.CapitalString():\n\t\treturn zapcore.WarnLevel\n\tcase zapcore.ErrorLevel.CapitalString():\n\t\treturn zapcore.ErrorLevel\n\tdefault:\n\t\treturn zapcore.InfoLevel\n\t}\n}\n\n````\n\n[logging - How to use Sentry with go.uber.org/zap/zapcore logger - Stack Overflow](https://stackoverflow.com/questions/64801270/how-to-use-sentry-with-go-uber-org-zap-zapcore-logger)\n[\\[Go\\]Sentryに対応したcustom errorの作り方](https://zenn.dev/tomtwinkle/articles/18447cca3232d07c9f12)\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["Go"]},"/note/zsh":{"title":"zsh","content":"\n\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["shell","terminal"]},"/note/zsh%E3%81%A7%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E8%A3%9C%E5%AE%8C%E3%82%92%E8%A8%AD%E5%AE%9A%E3%81%99%E3%82%8B":{"title":"zshでコマンド補完を設定する","content":"\n補完コマンドのあるディレクトリを `FPATH` に追加する\n\n`~/.zshenv`\n\n````shell\nFPATH=$(brew --prefix)/share/zsh/site-functions/:$FPATH\n````\n\n````shell\nfpath=($(brew --prefix)/share/zsh/site-functions/(N-/) $fpath)\n````\n\n## zinitの場合\n\n* `as'completion'` 補完modifier\n* `has'\u003ccommand\u003e'` コマンドが存在する場合\n\n````shell\n# https://github.com/BurntSushi/ripgrep\nzinit ice lucid as'completion' blockf has'rg'\nzinit snippet /opt/homebrew/share/zsh/site-functions/_rg\n\n# https://github.com/sharkdp/fd\nzinit ice lucid as'completion' blockf has'fd'\nzinit snippet /opt/homebrew/share/zsh/site-functions/_fd\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["zsh"]},"/note/zsh%E3%81%A7homebrew%E3%81%A7%E5%85%A5%E3%82%8C%E3%81%9Faws-cli-v2%E3%81%AE%E8%A3%9C%E5%AE%8C%E3%82%92%E5%8A%B9%E3%81%8B%E3%81%9B%E3%82%8B":{"title":"zshでhomebrewで入れたaws-cli-v2の補完を効かせる","content":"\n\u003chttps://docs.aws.amazon.com/ja_jp/cli/latest/userguide/cli-configure-completion.html\u003e\n\n````shell:~/.zshrc\n# AWS CLI v2\nautoload bashcompinit \u0026\u0026 bashcompinit\nautoload -Uz compinit \u0026\u0026 compinit\ncompinit\ncomplete -C aws_completer aws\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["zsh","aws"]},"/note/zsh%E3%81%A7path%E3%81%AE%E9%87%8D%E8%A4%87%E3%82%92%E9%99%A4%E5%A4%96%E3%81%99%E3%82%8B":{"title":"zshでpathの重複を除外する","content":"\n\u003chttps://tech.serhatteker.com/post/2019-12/remove-duplicates-in-path-zsh/\u003e\n\n````bash\ntypeset -U path\n````\n\nThat’s all.\n\nAs you can imagine `-U` stands for ‘unique’. From [doc](https://github.com/antonio/zsh-config/blob/master/help/typeset):\n\n````txt\n-U     For  arrays  (but not for associative arrays), keep only the\n       first occurrence of each duplicated value.  This may also be\n       set for colon-separated special parameters like PATH or FIG‐\n       NORE, etc.  This flag has a different meaning when used with\n````\n\nBtw. just care it is not `-u`. This flag just converts the content to uppercase.\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["zsh"]},"/note/zsh%E3%81%AE%E8%B5%B7%E5%8B%95%E3%81%8C%E9%81%85%E3%81%84%E3%81%AE%E3%82%92%E8%A7%A3%E6%B6%88%E3%81%97%E3%81%9F":{"title":"zshの起動が遅いのを解消した","content":"\n[zsh Zinitに変える](note/zsh%20Zinitに変える.md) をしたけど遅くなってきたので調査した\n\n## 調査方法\n\n[〇〇envのせいでzshの起動が遅いからチューニングした - Qiita](https://qiita.com/Suzuki09/items/6c27a8a875cf94d981a4)\n\n起動速度の計測\n\n````shell\ntime (zsh -i -c exit)\n````\n\n[zshとNeovimの簡単な起動速度の測定方法](https://zenn.dev/yutakatay/articles/zsh-neovim-speedcheck)\n\nzprofを使ってどの処理に時間かかっているかを測定\n\n````shell:.zshrc\nif [ \"$ZSHRC_PROFILE\" != \"\" ]; then\n  zmodload zsh/zprof \u0026\u0026 zprof \u003e /dev/null\nfi\n\nfunction zsh-profiler() {\n  ZSHRC_PROFILE=1 zsh -i -c zprof\n}\n````\n\n[zshの起動を高速化した - memo/note/blog](https://note.youyo.io/post/speed-up-zsh-startup/)\n\nコメントアウトしながらどれが遅いかを調査\n\n## やったこと\n\n### compinitを1回だけ実行するようにした\n\n複数回実行している箇所があったので直した\n\n### `brew --prefix` コマンドを1回だけ実行するようにした\n\nbrewで入れたコマンドにpathを通すために、毎回 `$(brew --prefix)` でbrewのディレクトリを取得していたが、これが結構時間がかかっていた。\n\n````shell\npath=(\n    $(brew --prefix)/opt/coreutils/libexec/gnubin(N-/) # coreutils\n    $(brew --prefix)/opt/ed/libexec/gnubin(N-/) # ed\n    $(brew --prefix)/opt/findutils/libexec/gnubin(N-/) # findutils\n    $(brew --prefix)/opt/gnu-sed/libexec/gnubin(N-/) # sed\n    $(brew --prefix)/opt/gnu-tar/libexec/gnubin(N-/) # tar\n    $(brew --prefix)/opt/grep/libexec/gnubin(N-/) # grep\n    ${path}\n)\nmanpath=(\n    $(brew --prefix)/opt/coreutils/libexec/gnuman(N-/) # coreutils\n    $(brew --prefix)/opt/ed/libexec/gnuman(N-/) # ed\n    $(brew --prefix)/opt/findutils/libexec/gnuman(N-/) # findutils\n    $(brew --prefix)/opt/gnu-sed/libexec/gnuman(N-/) # sed\n    $(brew --prefix)/opt/gnu-tar/libexec/gnuman(N-/) # tar\n    $(brew --prefix)/opt/grep/libexec/gnuman(N-/) # grep\n    ${manpath}\n)\n````\n\n↓\n\n````shell\nexport BREW_PREFIX=$(brew --prefix)\npath=(\n    $BREW_PREFIX/opt/coreutils/libexec/gnubin(N-/) # coreutils\n    $BREW_PREFIX/opt/ed/libexec/gnubin(N-/) # ed\n    $BREW_PREFIX/opt/findutils/libexec/gnubin(N-/) # findutils\n    $BREW_PREFIX/opt/gnu-sed/libexec/gnubin(N-/) # sed\n    $BREW_PREFIX/opt/gnu-tar/libexec/gnubin(N-/) # tar\n    $BREW_PREFIX/opt/grep/libexec/gnubin(N-/) # grep\n    $BREW_PREFIX/opt/mysql-client/bin(N-/) # mysql\n    ${path}\n)\nmanpath=(\n    $BREW_PREFIX/opt/coreutils/libexec/gnuman(N-/) # coreutils\n    $BREW_PREFIX/opt/ed/libexec/gnuman(N-/) # ed\n    $BREW_PREFIX/opt/findutils/libexec/gnuman(N-/) # findutils\n    $BREW_PREFIX/opt/gnu-sed/libexec/gnuman(N-/) # sed\n    $BREW_PREFIX/opt/gnu-tar/libexec/gnuman(N-/) # tar\n    $BREW_PREFIX/opt/grep/libexec/gnuman(N-/) # grep\n    ${manpath}\n)\n````\n\n### zinit -\u003e sheldon に移行した\n\nパッケージマネージャはもともと [zplug](https://github.com/zplug/zplug) を使っていて、1年くらい前に [zinit](https://github.com/zdharma-continuum/zinit) に移行したが、あるとき作者さんがリポジトリを削除して、現在あるのはfork版となっている。\nメンテナンスに不安を感じたのと、設定が難しいなと感じていたので [sheldon](https://github.com/rossmacarthur/sheldon) に移行した。\n\n`.zshrc`\n\n````shell\n# zshrcにはこれだけ\neval \"$(sheldon source)\"\n````\n\n`~/.config/sheldon/plugins.toml`\n\n````toml\nshell = \"zsh\"\n\n# zsh-deferを使って、デフォルトで遅延読み込みする\napply = [\"defer\"]\n[plugins.zsh-defer]\ngithub = \"romkatv/zsh-defer\"\napply = [\"source\"]\n[templates]\ndefer = { value = 'zsh-defer source \"{{ file }}\"', each = true }\n\n[plugins.compinit]\ninline = 'autoload -Uz compinit \u0026\u0026 compinit'\n\n[plugins.fast-syntax-highlighting]\ngithub = \"zdharma-continuum/fast-syntax-highlighting\"\n[plugins.zsh-completions]\ngithub = \"zsh-users/zsh-completions\"\n[plugins.zsh-autosuggestions]\ngithub = \"zsh-users/zsh-autosuggestions\"\n[plugins.zsh-history-substring-search]\ngithub = \"zsh-users/zsh-history-substring-search\"\n\n# remoteのshellを実行する\n[plugins.aws_zsh_completer]\nremote = \"https://raw.githubusercontent.com/aws/aws-cli/v2/bin/aws_zsh_completer.sh\"\n\n[plugins.dotfiles-defer]\nlocal = \"~/.config/zsh\"\nuse = [\"{functions}.zsh\"]\n\n# 同期的に読み込みたいものは source を指定する\n[plugins.dotfiles-sync]\nlocal = \"~/.config/zsh\"\nuse = [\"{options,plugins}.zsh\"]\napply = [\"source\"]\n````\n\nこれにより、ほとんどの設定やプラグインを非同期で読み込むようになり起動時には時間があまりかからなくなった。\n\n## 結果\n\n* もともと1.4sかかっていたのが、`brew --prefix` の改善で500msまで早くなった\n* zinit -\u003e sheldon移行で200msまで早くなった\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["zsh"]},"/note/zsh%E3%81%AEPATH%E3%81%A8path%E3%81%AE%E9%81%95%E3%81%84":{"title":"zshのPATHとpathの違い","content":"\n[zsh](note/zsh.md) で、PATHを追加するときに大文字のPATHと小文字のpathとで挙動が違った\n\n\u003chttps://unix.stackexchange.com/questions/532148/what-is-the-difference-between-path-and-path-lowercase-versus-uppercase-with\u003e\n\n`$PATH` はstringで、`$path` は `$PATH` に紐付けられた配列ということらしい\n\n````shell\n$ echo $PATH\n/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\n\n$ echo $path\n/opt/homebrew/bin /opt/homebrew/sbin /usr/local/bin /usr/bin /bin /usr/sbin /sbin\n\n$ typeset -p path\ntypeset -aT PATH path=( /opt/homebrew/bin /opt/homebrew/sbin /usr/local/bin /usr/bin /bin /usr/sbin /sbin)\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["zsh"]},"/note/zsh%E3%81%AEPATH%E8%BF%BD%E5%8A%A0%E3%81%AE%E3%81%A8%E3%81%8D%E3%81%AFN-%E3%82%92%E3%81%A4%E3%81%91%E3%82%8B":{"title":"zshのPATH追加のときはN-をつける","content":"\n[zsh で path にディレクトリを追加するときは (N-/) を付けよう - Qiita](https://qiita.com/mollifier/items/42ae46ff4140251290a7)\n\n````shell\n# 間違いではない\npath=($HOME/bin $path)\n# よりよい\npath=($HOME/bin(N-/) /usr/local/bin(N-/) $path)\n````\n\n## 解説\n\n`(N-/)` はファイル名修飾子\nファイル名に条件つけて絞り込みができるようになる。\n\n* `/`\n  * ディレクトリが存在するときだけ `()` の左側の値に展開される。\n  * ディレクトリが存在しない場合や、ファイル、シンボリックリンクの場合にエラー\n* `N`\n  * ディレクトリが存在しないときにエラーではなく空文字に展開される\n* `-`\n  * シンボリックリンクの実態を追いかける\n\n````shell\n$ ls -1 /\nApplications\nbin\ncores\ndev\netc -\u003e private/etc\nhome -\u003e /System/Volumes/Data/home\nLibrary\nopt\nprivate\nsbin\nSystem\ntmp -\u003e private/tmp\nUsers\nusr\nvar -\u003e private/var\nVolumes\n\n$ echo /tmp\n/tmp\n\n$ echo /tmp(/)\nzsh: no matches found: /tmp(/)\n\n$ echo /tmp(N/)\n\n$ echo /private/tmp(N/)\n/private/tmp\n\n$ echo /tmp(N-/)\n/tmp\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["zsh"]},"/note/zsh-%E3%83%9E%E3%83%AB%E3%83%81%E3%83%90%E3%82%A4%E3%83%88%E6%96%87%E5%AD%97%E3%82%92zsh_history%E3%81%AE%E5%BD%A2%E5%BC%8F%E3%81%AB%E5%A4%89%E6%8F%9B%E3%81%99%E3%82%8B":{"title":"zsh マルチバイト文字をzsh_historyの形式に変換する","content":"\n## マルチバイト文字をzsh_historyの形式に変換する\n\n[zsh 文字化けしたzsh_historyファイルを読めるようにする](note/zsh%20文字化けしたzsh_historyファイルを読めるようにする.md) と逆のことをすればいい\n\nつまり、`0x83-0xA2` のとき、直前に `0x83` を入れてから6bit目を反転させればいい\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["zsh"]},"/note/zsh-%E5%91%BC%E3%81%B3%E5%87%BA%E3%81%97%E5%85%83%E3%81%AEfunction%E5%90%8D%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B":{"title":"zsh 呼び出し元のfunction名を取得する","content":"\nhttps://stackoverflow.com/questions/31426565/get-name-of-calling-function-in-zsh\n\n````shell\nfunction a(){\n    c\n}\n\nfunction b(){\n    c\n}\n\nfunction c(){\n     #if a call me; then...\n     #if b call me; then...\n}\n````\n\nbash \n\n* `${FUNCNAME[1]}` is a (caller name)\n* `${FUNCNAME[0]}` is c (current name)\n\n[zsh](note/zsh.md)\n\n$funcstack\n\n* `${funcstack[2]}` is a (caller name)\n* `${funcstack[1]}` is c (current name)\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["zsh"]},"/note/zsh-%E6%96%87%E5%AD%97%E5%8C%96%E3%81%91%E3%81%97%E3%81%9Fzsh_history%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E8%AA%AD%E3%82%81%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%99%E3%82%8B":{"title":"zsh 文字化けしたzsh_historyファイルを読めるようにする","content":"\n[zsh](note/zsh.md) のhistoryファイルは特殊な処理が入っているので文字化けする\n[zsh historyにおける非ASCII文字の扱いについて](note/zsh%20historyにおける非ASCII文字の扱いについて.md)\n\n## 文字化けしたzsh_historyファイルを読めるようにする\n\n`ぁあぃいぅうぜそぞただちぢっつづ` という文字列を使って調べていく。\nこれらは頭2バイトが `e381`、末尾1バイトがそれぞれいかのようになる。\n\n* `ぁ`: `81`\n* `あ`: `82`\n* `ぃ`: `83`\n* `い`: `84`\n* `ぅ`: `85`\n* `う`: `86`\n* `ぜ`: `9c`\n* `そ`: `9d`\n* `ぞ`: `9e`\n* `た`: `9f`\n* `だ`: `a0`\n* `ち`: `a1`\n* `ぢ`: `a2`\n* `っ`: `a3`\n* `つ`: `a4`\n* `づ`: `a5`\n\nzsh_historyで見ると以下のようなバイト列になっている(わかりやすいよう適宜スペースを入れている)\n\n````txt\nE38181 E38182 E38183A3 E38183A4 E38183A5 E38183A6 E38183BC E38183BD E38183BE E38183BF E3818380 E3818381 E3818382 E381A3 E381A4 E381A5\n````\n\nzsh_historyの文字コードはlatin1なのでほぼUTF-8と同じ。\n文字コード表をもとに当てはまる文字に戻すと、 `0x83-0xA2` のとき、直前に `0x83` を入れてから6bit目を反転させていることがわかる。\n\n````txt\nE38181 E38182 E38183A3 E38183A4 E38183A5 E38183A6 E38183BC E38183BD E38183BE E38183BF E3818380 E3818381 E3818382 E381A3 E381A4 E381A5\n````\n\n`0x83` を消して、直後の6bit目を反転させると以下のようになる\n\n````txt\nE38181 E38182 E38183 E38184 E38185 E38186 E3819C E3819D E3819E E3819F E381A0 E381A1 E381A2 E381A3 E381A4 E381A5\n````\n\nこれがもとの文字列のバイト列に一致する。\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["zsh"]},"/note/zsh-Zinit%E3%81%AB%E5%A4%89%E3%81%88%E3%82%8B":{"title":"zsh Zinitに変える","content":"\n\u003chttps://tech.zeals.co.jp/entry/2019/09/18/110923kk\u003e\n\nzplug起動に時間がかかる\n\n## インストール\n\n\u003chttps://github.com/zdharma/zinit\u003e\n\n推奨の方法でインストールする\n\n````sh\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/zdharma/zinit/master/doc/install.sh)\"\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["zsh"]},"/note/zsh-fzf-tab%E3%82%92%E3%81%A4%E3%81%8B%E3%81%A3%E3%81%A6%E3%81%84%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%ABfzf%E3%81%A7double-star%E3%81%A7%E3%81%AE%E8%A3%9C%E5%AE%8C%E3%81%8C%E5%8A%B9%E3%81%8B%E3%81%AA%E3%81%84":{"title":"zsh fzf-tabをつかっているときにfzfでdouble starでの補完が効かない","content":"\n[fzf-tab](https://github.com/Aloxaf/fzf-tab) を入れていると、 [fzf](note/fzf.md) の `**\u003cTAB\u003e` によってディレクトリ配下のファイルを再帰的に表示するキーバインドが実行されなくてこまった。\n\n## 対応方法\n\nhttps://github.com/Aloxaf/fzf-tab/issues/65#issuecomment-1344970328\n\n````shell\n# fzf-tabを入れいているとFZF_COMPLETION_TRIGGERによるトリガーが効かなくなるため、ワークアラウンドとしてTAB2回で発動するようにする\nfzf-completion-notrigger() {\n    # disable trigger just this once\n    local FZF_COMPLETION_TRIGGER=\"\"\n    # if fzf-completion can't come up with something, call fzf-tab-complete\n    # instead of the default completion widget (expand-or-complete).\n    #\n    # FIXME: triggers an infinite recursion on an empty prompt\n    # _zsh_autosuggest_highlight_reset:3: maximum nested function level reached; increase FUNCNEST?\n    #\n    #local fzf_default_completion='fzf-tab-complete'\n    fzf-completion \"$@\"\n}\nzle -N fzf-completion-notrigger\n\n# Set an aggressive $KEYTIMEOUT to make usage of single \u003cTab\u003e less miserable\nKEYTIMEOUT=20\n# Bind double \u003cTab\u003e\nbindkey '\\t\\t' fzf-completion-notrigger\n````\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["2023/05/06","zsh","terminal"]},"/note/zsh-history%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E9%9D%9EASCII%E6%96%87%E5%AD%97%E3%81%AE%E6%89%B1%E3%81%84%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6":{"title":"zsh historyにおける非ASCII文字の扱いについて","content":"\n## [zsh](note/zsh.md) のヒストリファイルの仕様について\n\nzshのhistoryファイルを直接開くと、日本語が文字化けしているが、\nhistoryコマンドの結果は文字化けしていない。\n\n内部でなにか変換をかけているはずで、調べてみたところ、同じようなところで困っている人がいた。\n\nhttps://github.com/dvorka/hstr/pull/416\n[.zsh_historyにおける非ASCII文字の扱いについて - 生涯未熟](https://syossan.hateblo.jp/entry/2017/10/09/181928)\n\nどうやらmetafy/unmetafyという処理をしているらしく、\nメタなバイトがあったら `0x83` を挿入して、`0x20`とのxorを取り6bit目を反転させている。\n\nhttps://github.com/zsh-users/zsh/blob/master/Src/utils.c#L4921-L4933\n\n````c\nmod_export char *\nunmetafy(char *s, int *len)\n{\n    char *p, *t;\n\n    for (p = s; *p \u0026\u0026 *p != Meta; p++);\n    for (t = p; (*t = *p++);)\n\tif (*t++ == Meta \u0026\u0026 *p)\n\t    t[-1] = *p++ ^ 32;\n    if (len)\n\t*len = t - s;\n    return s;\n}\n````\n\n* [zsh 文字化けしたzsh_historyファイルを読めるようにする](note/zsh%20文字化けしたzsh_historyファイルを読めるようにする.md)\n* [zsh マルチバイト文字をzsh_historyの形式に変換する](note/zsh%20マルチバイト文字をzsh_historyの形式に変換する.md)\n* [Goでzsh_historyをパースするプログラムを書いてみる](note/Goでzsh_historyをパースするプログラムを書いてみる.md)\n* [fishのhistoryをzshに変換](note/fishのhistoryをzshに変換.md)\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":["zsh"]},"/posts/":{"title":"_index","content":"lists\n","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":[]},"/posts/2020":{"title":"2020","content":"","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":[]},"/posts/2021":{"title":"2021","content":"","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":[]},"/posts/2022":{"title":"2022","content":"","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":[]},"/posts/2023":{"title":"2023","content":"","lastmodified":"2023-07-29T08:18:43.05149894Z","tags":[]}}